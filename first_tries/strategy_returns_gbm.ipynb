{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe8ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get current working directory (where notebook is running)\n",
    "current_dir = os.getcwd()\n",
    "# Go up one level, then into utils\n",
    "utils_path = os.path.abspath(os.path.join(current_dir, '..', 'utils'))\n",
    "# Add to sys.path\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "from trend_regime_utils import load_trend_data, process_trend_data, create_advanced_feat, mayority_vote_cluster_smooth\n",
    "from bull_trend_regime_utils import load_bull_trend_data, create_advanced_bull_feat, merge_clean_final_clusters\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import joblib\n",
    "\n",
    "# For API Keys\n",
    "from dotenv import load_dotenv\n",
    "# Alpaca API keys\n",
    "API_KEY = None\n",
    "SECRET_KEY = None\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if API_KEY is None:\n",
    "    API_KEY = os.environ.get('ALP_API_KEY')\n",
    "\n",
    "if SECRET_KEY is None:\n",
    "    SECRET_KEY = os.environ.get('ALP_SEC_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6032b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n"
     ]
    }
   ],
   "source": [
    "EARLIEST_DATE = datetime(2016, 1, 16, tzinfo=ZoneInfo('America/New_York'))\n",
    "LAST_DATE = datetime(2025, 7, 20, tzinfo=ZoneInfo('America/New_York'))\n",
    "\n",
    "df_trend_raw = load_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE)\n",
    "\n",
    "df_trend_processed = process_trend_data(df_trend_raw)\n",
    "\n",
    "df_trend_feat = create_advanced_feat(df_trend_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7a72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the project root (one level up from current working directory)\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, 'models')\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "## If want to predict\n",
    "# Load models\n",
    "scaler = joblib.load(os.path.join(MODEL_DIR, \"trend_scaler.pkl\"))\n",
    "umap_model = joblib.load(os.path.join(MODEL_DIR, \"trend_umap_model.pkl\"))\n",
    "gmm_model = joblib.load(os.path.join(MODEL_DIR, \"trend_gmm_model.pkl\"))\n",
    "\n",
    "# scale data\n",
    "trend_scaled = scaler.transform(df_trend_feat)\n",
    "\n",
    "# Apply UMAP transformation\n",
    "trend_umap = umap_model.transform(trend_scaled)\n",
    "\n",
    "# Predict clusters\n",
    "trend_gmm_labels = gmm_model.predict(trend_umap)\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# print(silhouette_score(trend_umap, trend_gmm_labels))\n",
    "\n",
    "df_with_clusters = pd.DataFrame(trend_gmm_labels, columns=[\"cluster\"], index=df_trend_feat.index)\n",
    "\n",
    "df_cluster_smooth = mayority_vote_cluster_smooth(df_with_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5115ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bull_raw = load_bull_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE)\n",
    "\n",
    "bull_features_df = create_advanced_bull_feat(df_bull_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d6abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only bull days \n",
    "bull_days = df_cluster_smooth[df_cluster_smooth==1]\n",
    "\n",
    "# Keep only rows in bull_features_df where the index exists in bull_days\n",
    "only_bull_features_df = bull_features_df[bull_features_df.index.isin(bull_days.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e874c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\Documents\\TFG\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## If want to predict\n",
    "# Load models\n",
    "bull_scaler = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_scaler.pkl\"))\n",
    "bull_umap_model = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_umap_model.pkl\"))\n",
    "spectral_model = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_spectral_model.pkl\"))\n",
    "\n",
    "# scale data\n",
    "bull_trend_scaled = bull_scaler.transform(only_bull_features_df)\n",
    "\n",
    "# Apply UMAP transformation\n",
    "bull_trend_umap = bull_umap_model.transform(bull_trend_scaled)\n",
    "\n",
    "# Predict clusters, SpectralClustering doesnâ€™t have a .predict() method for unseen data.\n",
    "# Every time you call fit_predict(), it re-computes clusters from scratch, so for new data, you need to re-run it on all data (old + new)\n",
    "bull_trend_spectral_labels = spectral_model.fit_predict(bull_trend_umap)\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# print(silhouette_score(bull_trend_umap, bull_trend_spectral_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11edb463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_cluster\n",
       "1                0.251719\n",
       "0                0.240257\n",
       "2                0.187987\n",
       "3                0.175608\n",
       "4                0.144429\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute final clusters\n",
    "df_final_clusters = merge_clean_final_clusters(bull_trend_spectral_labels, only_bull_features_df, df_with_clusters)\n",
    "\n",
    "df_final_clusters.value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37298a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAs:  0\n"
     ]
    }
   ],
   "source": [
    "tickers_to_trade = [\n",
    "    \"SPY\",  # S&P 500 ETF\n",
    "    \"EFA\",  # MSCI EAFE (Developed Markets ex-US) ETF\n",
    "    \"EEM\",  # MSCI Emerging Markets ETF\n",
    "    \"TLT\",  # 20+ Year Treasury Bond ETF\n",
    "    \"GLD\",  # Gold ETF\n",
    "    \"USO\",  # Crude Oil ETF\n",
    "    \"QQQ\",  # Nasdaq 100 ETF\n",
    "    \"IWM\"   # Russell 2000 ETF\n",
    "]\n",
    "\n",
    "df_trade_raw = load_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE, all_tickers=tickers_to_trade)\n",
    "\n",
    "print(\"NAs: \", df_trade_raw.pivot(columns=\"symbol\").isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc6785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sma_crossover(df, short_window, long_window, signal_name):\n",
    "    \"\"\"Buy when short SMA crosses above long SMA, sell when crosses below.\"\"\"\n",
    "    \"\"\"Trend-following / Momentum\"\"\"\n",
    "    df = df.copy()\n",
    "    df['SMA_short'] = df['close'].rolling(short_window).mean()\n",
    "    df['SMA_long'] = df['close'].rolling(long_window).mean()\n",
    "    df[signal_name] = np.where(df['SMA_short'] > df['SMA_long'], 1, -1)\n",
    "    return df.drop(columns=['SMA_short', 'SMA_long'])\n",
    "\n",
    "def add_rsi(df, period, signal_name):\n",
    "    \"\"\"Buy when RSI < 30 (oversold), sell when RSI > 70 (overbought).\"\"\"\n",
    "    \"\"\"Mean reversion\"\"\"\n",
    "    df = df.copy()\n",
    "    delta = df['close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    df['RSI'] = rsi\n",
    "    df[signal_name] = np.where(df['RSI'] < 30, 1, np.where(df['RSI'] > 70, -1, 0)) # 65 35 for large periods maybe\n",
    "    return df.drop(columns=['RSI'])\n",
    "\n",
    "\n",
    "def add_bollinger_bands(df, window, num_std, signal_name):\n",
    "    \"\"\"Buy when price closes below lower band, sell when above upper band.\"\"\"\n",
    "    \"\"\"Volatility breakout & Reversion\"\"\"\n",
    "    df = df.copy()\n",
    "    sma = df['close'].rolling(window).mean()\n",
    "    rolling_std = df['close'].rolling(window).std()\n",
    "    upper_band = sma + num_std * rolling_std\n",
    "    lower_band = sma - num_std * rolling_std\n",
    "    df[signal_name] = np.where(df['close'] < lower_band, 1, np.where(df['close'] > upper_band, -1, 0))\n",
    "    return df\n",
    "\n",
    "# ---- Apply all strategies ----\n",
    "def add_all_strategies(df):\n",
    "    df = add_sma_crossover(df, short_window=5, long_window=10, signal_name=\"S1_1_signal\")\n",
    "    df = add_sma_crossover(df, short_window=10, long_window=20, signal_name=\"S1_2_signal\")\n",
    "    df = add_sma_crossover(df, short_window=14, long_window=28, signal_name=\"S1_3_signal\")\n",
    "    df = add_rsi(df, period=7, signal_name=\"S2_1_signal\")\n",
    "    df = add_rsi(df, period=14, signal_name=\"S2_2_signal\")\n",
    "    df = add_rsi(df, period=21, signal_name=\"S2_3_signal\")\n",
    "    df = add_bollinger_bands(df, window=10, num_std=1, signal_name=\"S3_1_signal\")\n",
    "    df = add_bollinger_bands(df, window=20, num_std=1, signal_name=\"S3_2_signal\")\n",
    "    df = add_bollinger_bands(df, window=40, num_std=1.5, signal_name=\"S3_3_signal\")\n",
    "    return df\n",
    "\n",
    "df_strats = add_all_strategies(df_trade_raw)\n",
    "\n",
    "# How This Works\n",
    "# Signals are numeric:\n",
    "# 1 = long bias,\n",
    "# -1 = short bias,\n",
    "# 0 = neutral (for RSI & Bollinger).\n",
    "\n",
    "# No lookahead bias in signal generation: All rolling and EMA operations use only past data.\n",
    "\n",
    "# Drop helper columns so only S1_signal to S6_signal remain, ready for ML feature building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eae2c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_signal_distribution(df, signal_cols, symbol_col='symbol'):\n",
    "    \"\"\"\n",
    "    Plots barplots showing distribution of signal values (1, 0, -1)\n",
    "    per ticker and per strategy in a 3x2 subplot layout.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(18, 10))\n",
    "    axes = axes.flatten()  # Flatten to easily iterate\n",
    "    \n",
    "    for i, strat in enumerate(signal_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Count frequency of each signal per ticker\n",
    "        counts = (\n",
    "            df.groupby(symbol_col)[strat]\n",
    "            .value_counts()\n",
    "            .unstack(fill_value=0)\n",
    "            .reset_index()\n",
    "            .melt(id_vars=symbol_col, var_name='Signal', value_name='Count')\n",
    "        )\n",
    "        \n",
    "        # Plot on the corresponding subplot\n",
    "        sns.barplot(data=counts, x=symbol_col, y='Count', hue='Signal', palette='coolwarm', ax=ax)\n",
    "        \n",
    "        ax.set_title(f\"Signal Distribution for {strat}\", fontsize=12)\n",
    "        ax.set_xlabel(\"Ticker\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.legend(title=\"Signal\")\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Hide any unused subplots if signal_cols < 6\n",
    "    for j in range(len(signal_cols), 12):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "strategies = [\"S1_1_signal\", \"S1_2_signal\", \"S1_3_signal\", \"S2_1_signal\", \"S2_2_signal\", \"S2_3_signal\", \"S3_1_signal\", \"S3_2_signal\", \"S3_3_signal\"]\n",
    "\n",
    "plot_signal_distribution(df_strats, strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df45b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 10\n",
    "\n",
    "def compute_forward_returns(df, horizon=HORIZON):\n",
    "    \"\"\"\n",
    "    For each symbol and timestamp, compute forward return over `horizon` days.\n",
    "    Forward return = (close at t+horizon / close at t) - 1\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['forward_return'] = df.groupby('symbol')['close'].shift(-horizon) / df['close'] - 1\n",
    "    return df\n",
    "\n",
    "def generate_strategy_returns(df, horizon=HORIZON):\n",
    "    \"\"\"\n",
    "    For each strategy S1..S6, compute forward return assuming you go LONG when signal=1,\n",
    "    SHORT when signal=-1, and 0 when neutral (signal=0).\n",
    "    \n",
    "    The strat_return per row per strategy is:\n",
    "      forward_return * signal at current time\n",
    "    \n",
    "    Returns a DataFrame in long format:\n",
    "      ['symbol', 'timestamp', 'strategy', 'signal', 'forward_return', 'strat_return']\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = compute_forward_returns(df, horizon=horizon)\n",
    "    \n",
    "    strategy_cols = [\"S1_1_signal\", \"S1_2_signal\", \"S1_3_signal\", \"S2_1_signal\", \"S2_2_signal\", \"S2_3_signal\", \"S3_1_signal\", \"S3_2_signal\", \"S3_3_signal\"]\n",
    "    records = []\n",
    "    \n",
    "    for strat in strategy_cols:\n",
    "        temp = df[['symbol', 'close', strat, 'forward_return']].copy()\n",
    "        temp = temp.rename(columns={strat: 'signal'})\n",
    "        temp['strategy'] = strat\n",
    "        \n",
    "        # strat_return is forward return weighted by position signal\n",
    "        # Long = profit if price rises, Short = profit if price falls\n",
    "        temp['strat_return'] = temp['forward_return'] * temp['signal']\n",
    "        \n",
    "        ###### Optionally remove neutral signals to reduce noise\n",
    "        # Neutral signals are safe to exclude if you want your model to focus on\n",
    "        #  performance conditional on entering a trade. Keep them if you want \n",
    "        # the model to learn when to trade vs when not to\n",
    "        temp = temp[temp['signal'] != 0]\n",
    "        \n",
    "        records.append(temp[['symbol', 'strategy', 'signal', 'forward_return', 'strat_return']])\n",
    "    \n",
    "    df_strat_returns = pd.concat(records).reset_index()\n",
    "    return df_strat_returns.set_index('timestamp')\n",
    "\n",
    "\n",
    "df_return_strats = generate_strategy_returns(df_strats, horizon=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "611837d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        ###### Optionally remove neutral signals to reduce noise\n",
    "        # Neutral signals are safe to exclude if you want your model to focus on\n",
    "        #  performance conditional on entering a trade. Keep them if you want \n",
    "        # the model to learn when to trade vs when not to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1790a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>strategy</th>\n",
       "      <th>signal</th>\n",
       "      <th>strat_return</th>\n",
       "      <th>prev_regime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.033131</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-15 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.015712</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-16 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-17 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010904</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-18 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.022591</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-13 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.088631</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-16 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.059295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.081531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.086058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-20 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.079885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91467 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          symbol     strategy  signal  strat_return  \\\n",
       "timestamp                                                             \n",
       "2016-11-14 05:00:00+00:00    EEM  S1_1_signal      -1     -0.033131   \n",
       "2016-11-15 05:00:00+00:00    EEM  S1_1_signal      -1     -0.015712   \n",
       "2016-11-16 05:00:00+00:00    EEM  S1_1_signal      -1     -0.013028   \n",
       "2016-11-17 05:00:00+00:00    EEM  S1_1_signal      -1     -0.010904   \n",
       "2016-11-18 05:00:00+00:00    EEM  S1_1_signal      -1     -0.022591   \n",
       "...                          ...          ...     ...           ...   \n",
       "2025-06-13 04:00:00+00:00    USO  S3_3_signal      -1      0.088631   \n",
       "2025-06-16 04:00:00+00:00    USO  S3_3_signal      -1      0.059295   \n",
       "2025-06-17 04:00:00+00:00    USO  S3_3_signal      -1      0.081531   \n",
       "2025-06-18 04:00:00+00:00    USO  S3_3_signal      -1      0.086058   \n",
       "2025-06-20 04:00:00+00:00    USO  S3_3_signal      -1      0.079885   \n",
       "\n",
       "                           prev_regime  \n",
       "timestamp                               \n",
       "2016-11-14 05:00:00+00:00            3  \n",
       "2016-11-15 05:00:00+00:00            3  \n",
       "2016-11-16 05:00:00+00:00            3  \n",
       "2016-11-17 05:00:00+00:00            3  \n",
       "2016-11-18 05:00:00+00:00            3  \n",
       "...                                ...  \n",
       "2025-06-13 04:00:00+00:00            1  \n",
       "2025-06-16 04:00:00+00:00            1  \n",
       "2025-06-17 04:00:00+00:00            1  \n",
       "2025-06-18 04:00:00+00:00            1  \n",
       "2025-06-20 04:00:00+00:00            1  \n",
       "\n",
       "[91467 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shift clusters since they are computed at the end of the day, so that info is not available, drop frist day since is nan\n",
    "shifted_regimes = df_final_clusters[[\"final_cluster\"]].shift(1).dropna().astype(int)\n",
    "\n",
    "# join with clusters (first months have no cluster so have to drop them)\n",
    "df_joined = df_return_strats.join(shifted_regimes, how='inner')\n",
    "df_joined.rename(columns={\"final_cluster\": \"prev_regime\"}, inplace=True)\n",
    "\n",
    "df_joined.drop(columns=\"forward_return\", inplace=True)\n",
    "# drop last days without available returns\n",
    "df_joined.dropna(subset=['strat_return'], inplace=True)\n",
    "\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c82fcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\AppData\\Local\\Temp\\ipykernel_8024\\3722318940.py:16: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_mean_return_per_strategy(df):\n",
    "    \"\"\"\n",
    "    Plot mean strat_return grouped only by strategy.\n",
    "    \"\"\"\n",
    "    # Compute mean strat_return per strategy\n",
    "    grouped = df.groupby('strategy')['strat_return'].mean().reset_index()\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    # Create barplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=grouped,\n",
    "        x='strategy',\n",
    "        y='strat_return',\n",
    "        palette='Set2'\n",
    "    )\n",
    "\n",
    "    plt.title('Mean Strategy Return')\n",
    "    plt.xlabel('Strategy')\n",
    "    plt.ylabel('Mean strat_return')\n",
    "\n",
    "    # Add value annotations on top of bars\n",
    "    for i, row in grouped.iterrows():\n",
    "        plt.text(i, row['strat_return'], f'{row[\"strat_return\"]:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_mean_return_per_strategy(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41af956d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ0AAAJICAYAAADLk5XhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Qd0FGUXBuCbRm+h9957RzrSRAWliIJ0RVAsKIgCgiAigqggKiKCoBSVJk30pym9d6QXkd57TUj+8971WyabTUg2m2R38z7n7Nlkd2Z2MrO7mblz7/38wsPDw4WIiIiIiIiIiMiN/N25MCIiIiIiIiIiImDQiYiIiIiIiIiI3I5BJyIiIiIiIiIicjsGnYiIiIiIiIiIyO0YdCIiIiIiIiIiIrdj0ImIiIiIiIiIiNyOQSciIiIiIiIiInI7Bp2IiIiIiIiIiMjtGHQiIiIinxEeHu6Ry/JUSeFvJCIiosTDoBMREZGP69ChgxQrVkzatGkT5TRvvfWWTtO3b1/xJJcvX5aPP/5YGjZsKKVLl5aqVatKp06dZMmSJRGmO3PmjHTr1k1OnjzpltedOXOmjBgxQjxtH1pvxYsXl4oVK0rLli1l3rx5sV7mli1bdJslpjlz5ujfcuLECbcv23F74VayZEmpVq2avPDCC7Jz506Jr32FGxEREYkEJvYKEBERUfzz9/eX7du3a3Ame/bsEZ67deuW/Pnnn+Jp7ty5I+3atZP79+9rcCRfvnxy/fp1+f333+W1116T/v37awAK1q5dKytWrHDba3/zzTca4PIkCJgMGjTI/ju2C/bn5MmT5Z133pEMGTJI3bp1YxVYO3z4sPiyZ555Rlq3bm3//d69e3Lw4EEZN26cdOnSRf744w/JkiWLW1/Tuo+IiIiSOgadiIiIkgAELA4dOqQn2Z07d47wHAJOKVOmlHTp0oknwboiKPK///1P8ufPb38cWU8ISI0ZM0bat28vAQEBkhSkSZNGypcvH+nxOnXqSPXq1TVrKDZBp6QAAVbHbYZgYp48eeSll16SxYsXa2DTnQoXLuzW5REREXkzltcRERElAalSpdKABAI5jhYtWiSPPfaYBAZGvBYVFhYm48ePl0aNGmlpG6aZMmVKhGmQbYNpmjZtKmXLltUTfJTxrV+/3j7Nl19+qcv466+/pFmzZvZlzZ07N9p1vnDhgn09HHXv3l169OihmSsItvTr108fb9Cggb1EsH79+jJs2DDNhsK6vffee/r4vn37NFPqkUcekVKlSknt2rVl6NChGsgy86FM79dff41Q+nXq1Cnp1auXBi3KlSuny92zZ0+E9Tp37pyWKmKaKlWqyPvvvy+jRo3SZQJK9rAuyNiyGjt2rFSqVElu374tsZU8eXJJliyZ+Pn5xXjfYRvh78Pfib8R23DDhg36M+6jKxdztl3NvOvWrdPSNWyfmjVrysiRI/U98jBbt26V5s2b67rivYT3pNGqVSunpaEIniJbyRUmwGrdZleuXNH9VaNGDSlTpow8++yz+vdY3bhxQ6dBkK9ChQq6r5Fphr89qu2F53766Sfd5tjHeG+Y9xveD3gfouQP2/Hu3bux+vwRERF5OgadiIiIkognnnjCXmJnPYleuXKlnug7Gjx4sGYTPfXUU1qO1KRJEw02fP311/ZpPv30Uw2YPPfcczJhwgT58MMP9eS9Z8+eEQIo58+flyFDhkjHjh31RDp37tzy7rvvRlvehWAQAmEIbnz11Ve67iEhIfocgh0vvviiZmjVq1dPXnnlFX0c0yEYZUybNk0DCFhHlFohKITMFqzb8OHD5bvvvpMnn3xST+Z//PFH+zJQcoUg3S+//CJZs2aVS5cuaeDj77//loEDB8pnn32mQQEsy/wNCIBhXRFAQekfelEhwPX999/b1wfrgMCCY/APPZmwf/D3RNf0OzQ01H7Dco4cOaIBt5s3b8rTTz8d432HbYS/D38n/kZsw9hw3K7G22+/rYEVvCbeU3hPoIzvYRDIefzxx3V5RYoU0WDO0qVL7dts27ZtcuzYMfv0p0+f1kAX+llFB/vIus2wnbB/PvjgA0mbNq0GKQHbEvtu2bJl+tp4DyBLqmvXrhECT9huKO98/fXXNZiI5eG98DAIviEwiOUiuIb3G+7xd+AzhCDVrFmzIgSVYvL5IyIi8njhRERE5NPat2+vt9u3b4eXL18+fNKkSfbn5syZE163bt3wsLCw8EcffTT83Xff1cePHDkSXqxYsfBvv/02wrJGjRoVXqZMmfBLly7p77169QqfPHlyhGn+97//hRctWjR827Zt+vuYMWP097Vr19qnOXnypD42ceLEaNcdy6pRo4ZOi1vZsmXDX3jhhfBFixZFmG727Nn6/PHjx+2P4e9p2LBhhOlWrVoV3q5du/Dr169HeLxp06a6XOu8ZlvA559/rn/3iRMn7I/dvXs3vEGDBuGvv/66/j5z5kxdh127dtmnwetUq1ZNl2c899xzug7Gli1bdL6tW7dGuR2w/8w2sN6wj5o1axb++++/26eN6b7D32ddr/Xr1+syce/42rhFt13NvHgNq/r164d37949yr/L7LcJEyZEeLx58+bhLVq00J+vXbum+/2LL76wP//NN9+EV6pUSd/TUXG2vXArXbp0eOfOncP37Nljn/aXX37R57Zv325/DJ8J7KeWLVvq73j/Yhq8J4379++HP/744/p4VNsLz7Vu3dr+e2hoqH4OsW1CQkIivAdfeeWVWO1DIiIiT8dMJyIioiQiRYoUWhplzbL57bffNMPEWmYEKI9DZg2mt2aK4HdkhWDkM0CWBzJEkAm0efNmmT17tsyfP9+e+WNl7a1jmpmjiXl0GjdurGV5yJhB2VahQoW0afibb74pb7zxhq5jdEqUKBHh91q1asnUqVO1JA09rpDZgqbhWH/H9bVCtguWlS1bNvu2QHN29FPC+phthl5BKIWy9mF69NFHIywL5WLYVmakPZS5FShQQMu1ooNSQGTD4IaMoKJFi2qvq9GjR2sWTGz3XVw4blfD8W/Afn7YPgZkeVmhbxdKF5FJhIwkvA/M+8psM8yD93R0UCKH7YVsK2ThoawOZX/IOLL+Ddi/yPrCNjbbC2WB2He7d++Wq1ev6nYNCgrSdTPwHnBc94dtF/QgCw4O1teylrSiEbwpu0yIfUhERJQQ2EiciIgoCUGACf2MUGKHwAtOthHAcYQSOUDpmTNnz57V+127dmmpEu5RGoYmyjlz5tTnHANC1tIxnKw7m8YZnOij1A4389roiYMG4whIOQZ1HHtZOZZbff7551oehmBIjhw5tFQP2yI62B4o70KgwBmU612+fFkyZcoU6TnHxxCkQJkUSupQIohyLYzO9zCpU6fWkjYDfZNQeoVgHHoyZcyY0b6uMdl3ceG4XQ3HIBD2c0z2cebMmSNtM8yH8k/83SixQ9AJwToEbf755x/th/QwKI002wz7GUFB9IHCex5lnibYim2GEtCo9i+ew/5FYMi8d63r+jAIPsZ0G5r1ie99SERElBAYdCIiIkpCkJmDk3hkO+GkF72VrJk5jo2Wf/jhB53eEQJLCAig5w0aJSNjqmDBgnpCvmLFCg0IxRV6KCEDCL2RrJBt9NFHH+nIY8hWii7o5AiBBjR+RqAM2TPIogFrXyJnMB0aQL/zzjtOn0e/HqwXgiGOLl68GOF3bE9kJiHYhGwlBL+s/ZhiCoEa9EJC/yxsD9NbKCb7zhkTgHFs3I5sI2fLcSdkElkDT2gij+BS+vTp9Xds+7x58+r7Fu8xvNecjeT3MGgA/vzzz2vQccaMGdqLzOxfZI2hv5Iz+Jxg/yLwhO1jDTw57l93cHUfEhEReRqW1xERESUhCI6gPAhBIQQ9osqkqFy5st7jJBuZIuaGMrQvvvhCMzHQxBr3aA6ODCdzIo7G5FGNOhcbuXLl0iDD8ePHIz139OhRvUfQBhyzT6KCsiSsK0rcTMAJWSMHDhyIsL6Oy0PQA6+JIJh1eyBbCeVbCJBgGox0t3fvXvt8GKFs1apVkdYDQS68JoIKGC0NAQ1XIHiFDLCFCxfKxo0bY7zvnP2NJhvH2mgewaDomr27CzLWDOwH7HdkcpnMKQTE0DQczcWXL18uLVq0cPm10CgcAS5kvJltgX2Hpt7IWrJuszVr1mhpp9m/KHHD6xvIxjINz90ppvuQiIjI0zHTiYiIKIlBeVf37t016DBgwACn0yB7CaVbGKkNvYeQDYWgC0bsQtYHskKQoYNABUbWQm8a3BDMQhAGrKPXuRocwAhlCNAgsIW+OFhnlPJhRDhkbeFmzQxZsmSJPobeT86gxAr9kJDxhEwZlMx9++232s/Jur5YHnoKIZCDeTp37qwBJtyjnA09eRYtWqTZMhg9DjBaG5b76quvavYRljFp0iTNhHHMTMEIbwhgYfnYpnGBkfKwr1ByiF5HMdl35m9ERhEy09DfCPOh3BCjo2G/ItCDbRPdiHrugr5U6KGE1//pp590fbHtrBB0+vLLL/VnVzLDDAQb8d567733NIAzaNAgXTZ6faH07uWXX9b1QK8ujG7Yvn17LfGsUqWK9oPCfNhu2Kd4r+/fvz9ST7S4iuk+JCIi8nQMOhERESUxyKxBwAEn1lEFZwBlbQg6/Pzzz5r9giwQBKzQDweZHzh5RwDnk08+0SALyoAQvMDJ+0svvaT9d9D42FU4uUYQBeuwYMECDQAgsyRfvnzaCwmBKHOyX61aNf27UGKGPlUI/jiDYBuyR3788UcNrmAbIIBhAizXrl3TbYPAEvou4XUQ/EDmCbYDlo+h7NHMGSf+KGszpXkIuk2cOFEfwzT4HYED9AEymVlW9erV08wVa2NqV6DUrEOHDhqIQ8AGQZKH7TtAoAUBJwTJ0JQdfaXGjBmjf3evXr00GwhN4pHR5mz93QnrO3z4cA0CInsN+xqZRVbIBitevLiul6uZYQYy3X755Re9ocQOy0XJHfbvyJEjtaE3Mu169+6t7wUDQR+sJ6ZD1lODBg2kbdu2MnfuXHG3mOxDIiIiT+eHIewSeyWIiIiIvN3Bgwc1QINeUdbMFwSlMIobRkwzcPiF0kaMpodMJXo4lEGifxcCY3EN1LkCGUfbt2/XQJO1YToCdigBRYCUiIiIImKmExEREZEboNwQGV9oVN2oUSMtF0MJ3u7du+Xtt9/WadB8HY3MUSKIQAUylCh66JG1bNkyLd1EdllcsufiAqWdffv21aATAonINkK/LjS0d2x2T0RERDbMdCIiIiJyEzTARokdmm/jEKtkyZLyyiuvaEYToCQLZXVolo1eUM2aNUvsVfZ4yC5CmSNK6tD8G6VwiWX9+vValolAGPYlylPRBwr9vIiIiCgyBp2IiIiIiIiIiMjtYja+MBERERERERERUSww6ERERERERERERG7HoBMREREREREREbkdR69LINu2bdOGokFBQYm9KkREREREREREMRISEiJ+fn5SoUIFiS0GnRIIAk7s2U5ERERERERE3iQusQwGnRKIyXAqU6ZMYq8KEREREREREVGM7Nq1S1zFnk5EREREREREROR2DDoREREREREREZHbMehERERERERERERux6ATERERERERERG5HYNORERERERERETkdhy9joiIiIiIiIjixf379yUkJCSxV4OiEBQUJAEBARJfGHQiIiIiIq+yZMkSGTNmjBw9elSyZs0qbdq0kW7dusV5ngMHDsiwYcNk27ZtkiJFCmnUqJH07dtX0qRJY59mz5498tlnn8nu3bslLCxMSpQoIT179pRKlSrZp7l06ZKMHTtW/vzzT7l48aLkzp1bWrVqJR07dozXA3siIk8SHh4uZ86ckStXriT2qtBDZMiQQbJnzy5+fn7ibn7heCdQvNu1a5felylTJrFXhYiIiMhrrVu3Trp06aInM2nTppXr16/r4717944y8BSTeRAoeuKJJ+Ty5cuSKlUquXfvnoSGhkqtWrVk4sSJOs3Zs2elWbNmcvXqVUmZMqU+dvv2bf157ty5kj9/fp2vZcuWcvDgQfH399eA1bVr13Ta1q1by9ChQxNkOxERJbbTp09rwAmBfnyvxkdAg+IG/xdv3bol586d08BTjhw53B7PYE8nIiIiIvIayCDCQTICO5s2bZIBAwbo4+PHj9eAj6vzTJ8+XQNORYoUkbVr18rs2bM1aLR69WrZuXOnToPMJQScSpUqJevXr5cNGzbozwg8rVy5UqdZvny5BpySJUsm8+bN09dDcAtmzZqlmU9EREmhpM4EnDJlyqTBeWSQ8pbCo27YL9g/2E/YX9hv7sagExERERF5hbt378qWLVv05xYtWuhVc5St4R7ZSyY45Mo8CC5BkyZN9CC8ePHiGlCyPmcNajlescdBOwQGBkqDBg2kadOmUrRoUX2sfv36eo/AF7KliIh8nenhhAwn8nxmP8VH7y0GnYiIiIjIK/z777/2q7DoPWEOlFESAP/884/L85j7bNmy2efNmTNnhOcQkMqYMaP8/fffUq1aNb3h56eeekqfg4YNG2pm1ccff2xfDrKdAP2ccuXK5fbtQkTkqVhS5x3icz8x6EREREREXsH0YgKUBTj+fOPGDZfnMfemV5N1GrMMlB98+umnOtIPSupwM8/fuXPH6Trv27dPG4/DY489JunTp3fpbyciIvJGDDoREREREcUAGqm++uqrmjH1xx9/yIoVK6R06dLa68ma2WQgC6pTp04alMqcObP069cvUdabiMjTdOjQQYoVKxbhhu/TevXqyQcffKD98zxp3VByXbFiRe0NiH598eHLL7/U1/I1gYm9AkREREREMYGR4Ky9mgyTcWR9PrbzpE6dWpuoWjOWzM8Y8Q6+/vprna9t27ZSoEABfeyll16Snj17ypIlSyKMTLdjxw558cUXNeAUHBwsEyZM0EwpIiKyKVmypAwaNMj+O/oJIVj/+eefy969e+Wnn35KtPI8x3VDmfaZM2dk8uTJ8s4772iJdt26dd36mq1bt5batWuLr2HQiYiIiIi8Qu7cufUEBA25T506JXny5NEgkLkinj9/fpfnyZs3rwadMMS3gRMM6zRHjx7Ve+tJEPo0gTVYhdHrunbtqgGnLFmyyKRJk3RUPCIiegBB//Lly0d4rEqVKnLz5k0ZM2aMBu8dn0/MdYM6depI9erVZc6cOW4POmXPnt3ee9CXsLyOiIiIiLwCGoCXK1dOf8YBv7lHQAnZSGXLlnV5nkceeUTvFy1apEGp/fv3y+7du/WxWrVqRQg+zZo1Sy5duqSj2f3888/6GMpCTDbVa6+9JteuXdOTlh9++IEBJyKiWDDfp7hQYMrd3n77bXnjjTc0ENSlSxf79+0nn3yiwR/M06xZM/0ONwYOHCg1a9a0DyZhfPTRRzoQhCsjtSVPnlySJUsW4eJDWFiYjB8/Xho1aqTrgf59U6ZMiTTvxIkTdXRT/N9p06aNLF++XMvpNmzY4LS8Dn/3+++/r4NTIAMK/8uQXXvhwgWZPXu2vl6FChWkc+fOcuLEiQivtXTpUi0FLFOmjG4DZOLeunVLEgMznYiIiIjIa/To0UO6d+8uc+fO1QN2BHcAmUU4EUBWEW758uWzH/Q/bB5o3769zJgxQ44cOSI1atTQgBJOVBBwMoGpl19+WdauXSuHDx/Wq93IckKGE+5ff/11e0DLjHaHExpzcmSMGzdOyzaIiMg5k1WKzFTj999/15FCv/nmGw3y4MIBeuxt3bpVg1GFChXSMue33npLv7+bN28uTz/9tH6vI6iD73XAvFjWk08+qYNCRAXLDw0Ntf+O/wcnT57UMmtkYmHZxuDBg/W7H/9nEATCiKXDhg3T/zWvvvqqTvPVV1/pvCi7xkWOVatWyZtvvvnQbbFw4UIpVaqUBsqQfTtkyBD9f4Xg17vvvqsXSRCYwuMIfMGCBQs0SIcgHF4D6z1q1Cg5dOiQ/n9M6JJFBp2IiIiIyGvgijYO3lF6gQBRjhw5tMdSt27d7KPQnT17VjOcYjoPZMuWTYNUw4cPly1btmiPJ1yR7t+/v30anEwgswlXo1H2gRMPPIaeTiZTatmyZfbpcRUe62KFkyEiIooc2EHZ88aNGzWwhO9Wk/EECBChwbi5ULBmzRoN3CCY8sQTT+hjyAZCEAajjDZt2lQqVaokuXLl0sCNCTohAHX+/PkIQSNnEDhCsMcKwZqiRYvKF198IY8++qg9QIbAVq9evez/U3CxAtN+++238vzzz2uA6LvvvpN27dppMMhMg3X95Zdfol0PbB/8/zIjny5evFj/bmQymaDc9u3b7c3NsU3x92Nb4N5Api4yojAABpq1JyQGnYiIiIjIqzRs2FBvziDjyGQdxXQeAycT33//fbTT4CQE2UpRQcNwIiJ6OGeBHX9/fw0QIXPHmpFTsGBBe8AJ1q1bp8/jooI1cFW/fn2ZP3++9tYrUaKEZkdNnz5ds5Ew/2+//aYBGFN2HRWsF4JccO7cORk9erRmr+Ie62KsX79eAz14Xcf1QPBsy5YtehEEWbFNmjSJ8BoIjD0s6IQMLhNwAoyEisEprFlgaGqOHoKACyvIiELWlXV90CsLJd8I1jHoREREREREREQ+zRrYQQAJGUHIRHU2EimyT60w8AOCPRUrVnS6bASKEHRCRhOCP8gOQvYPMoU6der00HXD66EfkoEgFQJYL7zwgpbSZcyY0b4egHI9Z86ePWsPGpl5jEyZMj10PZxtC2smryOzPtiuZts6bpeE5hVBJ9RdIqVs5syZGsFDlA51i9bontXly5e1UdbKlSv1zYs3AIY1TJkypX0a1HEiNRoNtxCpRD0kutAbFy9e1DpMRALxZka0tW/fvpp6TURERERERESucwzsxAYGgkDw5ccff3T6PPr6QYECBbQvH87/kUWFPksIHsUWMowQg0A5NforffbZZ/p4unTp9B6DRjgGxiBnzpz2HlWIMVizpDAghbuZ9UH8o2rVqpGet2ZNJRSvGL0O3dqREvfhhx9qHT2CUGj8GFVNPBqJHTt2TCZPnqz1lqhbRDqdNQWuT58+2jH+119/1WAT6i/RFNJAwy10yzfNKPGzaQJGRERERN4lLDzMI5dFRESxh4AKRmNDgggCV+Z24MABbdhtLS1DthMynVBah8yoqJJXHgblcciWQo8o9J6CypUr2xNfrOuBgBJiEVeuXJHixYtrkAyNzq2QdeVuCGohgwrJNdb1QfIMAmV79uyRhObxmU4ILKG2Hg23TO0hmoWZ1DjUQVpt27ZN3wAYKhH1j4B6UASp0NwLGxtNvFDT37FjR30eWU6YD9FJTIvop2lghpQ8QFAKI5/gTYOaSSIiIiLyHv5+/jJtxyo5e+NqnJaTLU16aVeuttvWi4iIYg+9nFABhXN03HDuv3PnTh0wArECaykbGo1jkAjECAYNGhSn18XgEsiUQmUVEliKFSumvw8cOFBHiUPzc2Q2IWaRO3du7R+FEU4Rj8C6ofoKATPEG3766SddJjKw3AWvhRH8kJWFn9HwHPENJPKg1M+xh1ZC8Pig0759+3RkEGvpG1LGMNQsGo85Bp02b94sWbJksQecADsVZXZo4oXoJIZVRKmcVbVq1eyRxhQpUmhqHIbVNSlp6AaP1DyTrkZERERE3gUBp5PX3F/OQERECQuBmvHjx2s2EUaJQ+kaEky6dOkSqUIJASiMFofWOY7NvF3JJOrQoYMmxiBo1L59e/n44491HVCVhSbeyDRCoAvVUwEBATofGnsjKwuNwydOnKg9opBYg3mj69HkitatW2s8AwNb4PWwfGR4YTQ7V7O84sIvHH+5B0MgCCOQYFhaBIMM1FKiAzx2rhUijpgW/Z+sELRCdLFVq1YaYMIbFNFRY9q0aboTkPFkXhfRQWQ2IWCVNWtWmTp1qss7adeuXfomK1y4sEvzExEREZFrcCyHq8ufr1kY56BTrnQZpVfNpjrUtYcfRhMRJZq7d+9qixpk+ljP45Oi0NBQLe1DQgsapRtoIYQ+0mvXrk305BbEVv755x/tQYWG7o4OHTqk/0td6cHl8ZlO+IcO1uERARvi6tWrTqd3nNZMjzc+NmZUy8PzgAOIvXv3SoUKFTRQdf/+fU2PQ9oeopnOOsjHBIZYxHKJiIiIKOEg4IQseXdC+YQ5TiUiosgCAwPt59hJ3XfffaftfF588UVt14MgDkreMOgZYhMmTpFYsJ8QHDty5EiU0ziLs/hE0MlERdHbyRohxUaxjkZnnd5Zg3FMj7QyE7VznMa6PHS2R1bTn3/+aQ8wjRs3TushZ82aJZ07d3bpbwkKCmKmExEREVECw9VZd0PbBWY6ERFFn+mE8++knulk4glIZEFvKfRYQsZTp06d5KWXXtI4gacECfPmzRtlppPLyxUPZ9LPzp07pxvAwO9o2uUoe/bssnTp0giPIcCEMjmUyCGqiOAT5rfC76gBNX2hcCBhzWjC0IJ4DKPixeWAx931mkRERESU8Jxd/CQiSqowMhsaZSMLFOfdCKignAw9jUxfI0cIvqC5Nc7XEfBA7yX0Z7ZCBtDp06d1pDr0cUIZGs75zTKRmYPnooLG3o6wTIxcjwsHRYsWdTmDJzby5csno0ePFk+F7Ynti/9tzoKEcbl447426fEEwwsi+LNhw4YIb04M9Ydu9Y7wGJp3WYNDZjjDSpUq6cZCEy3zmIHlm+EO8SbG/NZUQLyRMewgalKJiIiIiIiISGTdunXah/nAgQMasMAobpMnT5br169HOc+NGzfk33//1XNunKOjFQ0CUOfPn7dPg3IvBLEwsBimQduby5cvy/Hjx+3TIFjleDMBEvzsCIEmrB8zVROOxwedEHVER3g0+V62bJmOZochABEYaty4sb7x8MY0NZDoAo+gEqbBkInr16/XhuDNmze3ZzKhoz0aeU2aNEkjnJ988on2WkI0FjAtoNs8Xg+3Xr16aZpZy5YtE3FrEBEREREREXkO9CZCEAfnyhhhfsCAAfbAUlhYmNN5TOURKpFKlChhr3DCub2Z59KlS3q+j/NwJKOYEeqxXJPdhGooPGduaGeDjB0EnqyVUgZGuWM/voTl8UEneOONN+SZZ57RN2/btm019QvDDKL2Eal2GP5w0aJFOi3eXF999ZXkzp1bg0gIHNWpU0cGDx5sXx6mR5d4NAVv0aKFBqZQY2nexEgHRCd5fHCwDASp8Fp4LG3atIm2HYiIiIiIiIg8BTKVtmzZoj/j3Brn4xgxHhA8ctYgG4+boFFwcLDOg+CTec4EhUymFFrdmNIvU9qMwJMzqHpCoCpTpkyRWtugjA/ZVPHR54+8uKcTIMjUp08fvTlCcGn//v0RHsMbDPWk0UE2k8locgYBKASiiIiIiIiIiCgylMghyAOoRgIEe9B7CZwN8mV9zJTAmd5PWBYCWalTp7ZPZy2TQzIIglLOlovH0csZy3HsDQWmrA5JJo49nimJZzoRERERERERkWex9m2yNqA2I6A5651kglSADCbHn015nbl3No11GcaFCxfsSSiOzctRqofeUOgXbbKqKGEw6EREREREREREXguNyDHgmCnZc3wOZXcoq8uZM2cirWHS5RXldURERERERETkWZA5ZFhHfze9nJz1T7JmIVkzoRwzm3CPjCZrM3Lzs2MmEzKusCz0YEYJnmMGFAYoQwYU7hGEMllZ7O8U/5jpRERERERERESxhh7LJnBz6tQpe28lU3aHII8ja1DI9GZCMMmUzJnSPDMvgkSG+dlxuSidw3Jz58kT6fUwMh5GtTMZUJgOv+PmGKByVVh4mGvzhYVpP+ratWtL+fLl5aWXXpLjx4+LL2GmExERERERERHFGpqGlytXTrZv3y5z5syRatWq6b3JVLL2eTKQpYRR6Ezjb2RLXb582T6PGaEOzcQxzdWrV7UxOAJUZmQ7a4YVYDQ8bUbu7y/TdqySszeuSkLJlia9tCtX26V5x44dK9OnT5fhw4drI/aRI0dK165dZcGCBU4Ddt6IQSciIiIiIiIickmPHj2ke/fuMnfuXFm+fLn2VkLvJASGEERCeZspcStYsKDOgxHkjh07pkEnTG/K5jJnzmwvr0M5HIJRCDbt27fPPg2Wi2CXgbI6ZECZkjsEnE5euySe7t69e/L999/L22+/LfXq1dPHRo0apVlPixcvlqZNm4ovYHkdEREREREREbmkbt268tVXX0mxYsU0EwnlbJ07d9b+SoCyudDQUL0ZeC5v3rxaSoegEcrcsmXLphlNBh4rUKCABpkwDYJKGHkuj0MJnbOR7LzBvn37tCywevXq9sfSpUsnJUuWlE2bNomvYKYTEREREREREbmsYcOGerM2Ej969Kj+jGASbo4QYMEtOijPy58/f7TTBAYGSunSpcXbnDlzRu8RpLNCFph5zhcw04mIiIiIiIiIKAHd/q8/lWPvJmR/WUcC9HYMOhERERERERERJaAU/zVZNyP4GQg4mWbqvoBBJyIiIiIiIiJKcOjV5InLSgg5/iurO3fuXITH8buzckRvxZ5ORERERERERJTg/Pz85OKt6xISFrdm4EH+AZIpla1xubcoXry4NknfsGGDNlUHjOS3Z88ead++vfgKBp2IiIiIiIiIKFEg4BRy/8HIdklFsmTJNLj06aefSsaMGSVXrlwycuRIyZ49uzRu3Fh8BYNOREREREREROQTsqVJ7zWv98Ybb0hoaKgMGDBAR/yrUqWKTJw4UYKCgsRXMOhERERERERERF4vLDxM2pWrnSiv6+8X+5bZAQEB0qdPH735KjYSJyIiIiIiIiKv50rgx5tf1xtwyxARERERERERkdsx6ERERERERERERG7HoBMREREREREREbkdg05EREREREREROR2DDoREREREREREZHbMehERERERERERERux6ATERERERERERG5HYNORERERERERETkdgw6ERERERERERElom+//VY6dOggvoZBJyIiIiIiIiLyeuFhYV75utOmTZPRo0eLLwpM7BUgIiIiIiIiIoorP39/ubr0J7l/+VyCvWZAcFZJ37CtS/OePXtWBg0aJBs2bJD8+fOLL2LQiYiIiIiIiIh8AgJOoRdOijf4+++/JSgoSObPny9ff/21nDzpHesdGww6ERERERERERElsPr16+vNl7GnExERERERERERuR2DTkRERERERERE5HYMOhERERERERERkdsx6ERERERERERERG7HoBMREREREREREbkdR68jIiIiIiIiIp8QEJzVp1/P2zDoREREREREREReLzwsTNI3bJsor+vnH7dCsuHDh4svYnkdEREREREREXm9uAZ+vO11vQG3DBERERERERERuR2DTkRERERERERE5HYMOhERERERERERkdsx6ERERERERERERG7HoBMREREREREREbkdg05ERERERERERJQ0g05hYWEyZswYqV27tpQvX15eeuklOX78eJTTX758WXr37i1VqlSRqlWrygcffCC3b9+OMM3vv/8uTzzxhJQtW1aaN28u69ati/B8SEiIfPbZZ/bXbN++vezduzfe/kYiIiIiIiIiIl/iFUGnsWPHyvTp0+XDDz+Un3/+WYNQXbt2lXv37jmd/o033pBjx47J5MmT5YsvvpAVK1bI4MGD7c+vX79e+vTpI23atJFff/1VqlevLt26dZPDhw/bp8H0c+bMkWHDhsns2bMlY8aMGuy6fv16gvzNRERERERERETezOODTggsff/99xpIqlevnhQvXlxGjRolZ86ckcWLF0eaftu2bbJx40YZMWKElCpVSgNKQ4YMkXnz5snZs2d1mu+++04aNmwoHTt2lEKFCsm7776r0/7www/6PLKoEGj66KOPNNMJ0wwdOlSSJUsmu3fvTvBtQERERESUFCxZskSaNWsmpUuXlvr168v48ePdMs+BAwekc+fOUq5cOalWrZoMGDBAbty4EWEanAsUK1Ys0q1Hjx4RpsMF7Oeff16XVbNmTRk4cKBcu3bNDX89EZHv8fig0759++TmzZsaPDLSpUsnJUuWlE2bNkWafvPmzZIlSxYNFBkosfPz85MtW7ZoltTWrVsjLA/wz8csb82aNZI2bVqpU6dOhNdcvnx5pPmIiIiIiCju0O7i9ddf1wBRihQp5OTJk9ruIrrAU0zmuXTpkl5sxrT+/v4abJo5c6b07NkzwrL279+v9+nTp5ds2bLZb8HBwfZp/vzzT3nhhRf0vCIgIECXPWPGDG3tQUSJLyws3Kte98qVK/L+++9r7KFixYrStm1bjWn4kkDxcMhoghw5ckR4PGvWrPbnrJDN5DgtMpQyZMggp0+f1qsQt27dkuzZs0e5vKNHj0qePHk0kwr/sLBMBLn69u0bIZhFRERERETua6kRHh4uLVu21BYXU6dO1WoDHI8jSwnH9K7MgzYd6PlapEgRDTahDUeLFi1k9erVsnPnTu3xag06DR8+XDOmHOHiNXrF3r9/X6swkAGF+Z999lm9qI1zBgSpiCjx+Pv7yZLV++XytVsJ9prB6VJJo1rFXJq3V69ecv78efn8888lU6ZMMmXKFHnxxRe1DVDBggXFF3h80Mk0AHf8J5M8eXK5evWq0+md/UPC9Hfv3pU7d+5EuTw8D7j6gX9G+Cf2zjvvaJbTN998o2m0ixYt0jeDK/APEQEvIiIiIko4yHhPmTKlW5eJY04c25F74Dgc2UPw+OOP6/bFoD9od4GeqqhIqFChgkvzrFy5Uqdp0KCB7rO8efNKiRIl5O+//9bMpcKFC2tA6dChQzodAkfOjtkRYMJF7MDAQD0vwOshkLV27Vr7+4vH+kQPPp/4XCFIi1tU383IPnQ3BJwuXLopCS2qvzMqiDmgygrBcvP91r9/f/3Omj9/vmZxJuS6Y3/hew33jvDdif3lk0EnpMma3k7mZ/MmdnbwgGmcNRjH9KlSpdLgklme4/NmefhHgsATekeZzCb8XLduXY04oom5KzAiHkfAIyIiIkpYOMZD1ro7ITPecXRkct2JEyfsJ2w4DjfHzGnSpNEAEvooWc8FYjPPkSNH9HFMa6ZJnTq1PZCEx06dOmW/OI3MA5TpoawOwazHHntMHzfBKywfgxUtXLhQl4kRszt06KDnGkT0AM6rTWKHMwg4ufuCQGJCjMFZwCYq+M4YM2aMBr7N94+B0l3Hx+IT9lNoaKj9+9IZZ8k9PhF0MqVy586d06sSBn5HYz9HKJtbunRppJ2PWkmU0KHMDjsX81vhd5MOi2XgA2ItpcM/LJTc4Z+bq4KCgvQNRUREREQJx9Wrs9EpUKAAM53cyHpiigF+0KPVBIcQQEK/VWQnuTKPCQ5in5llmGnRlwmPWY/x8TOO23F+gObiWA7KXZDRBKi2+OmnnzT4hMwmjJSN15swYUK8vNeIvBE+nwjmIunDMWBs+NrnJbZBmRQpUugAZ1Zo8YOBzTCIWlTbLb4gBoKYi0nUsTKZoC4tVzwcRqvDF/qGDRvsQSf0ZdqzZ4+0b98+0vS40vDpp59qqlq+fPn0MYxmB5UqVdI3Nhp04bHWrVvb58PyK1eubF8Gony7du2SMmXK6GOIMmLnP/nkky7/LXhtXgGhmIzAgog3rqAiUNqmTRvp1q1bnOdBg030OsAIj/gCa9SokfYpw+fLwIEVpnGEdHSUmzrCMtFDAVl8y5Ytk9y5c8fpbyciIvIWvnR13hNYT66wbc0xszkpxcmc43F0TOcxv+NEykyDkysTdMJjOM/A8ROOi9CrCdNiVLo5c+boSNo4rkIgChBsRONwPIZzik6dOmlPJ2RNcdAhogdZTLjhM4ZbUhDXv3Pr1q3y3nvvSePGjZ32lYvvdTeZZ86CXXEJEHp80An/LBBcQiApY8aMkitXLhk5cqRmI2FnIKUVqWe4AoGNg6FLEVR66623ZPDgwXr1Ad3gmzdvbs9k6tKli/6TQJo1usTPnj1b02pR/w0IPtWoUUPeffddGTJkiGZH4YQeO+Lpp59O5C1CvsyMwIKDGbynzQgsEFXgKSbzmFFb0EQTB1Zm1Bb0JZg4caLTUVusXzbWUVsMpI7iSxEBJyIiIqK4sF4Es2YwmSwl6/OxnQeZT6h6sJaqmJ9x7ATop+LYMwrBJASdcD6BC3tmWkBPJzNKNvo64Rhq9+7dDDoRkUuWLl0qb7/9tsYyEPvwJe7v2hUPMDrEM888IwMGDNAhBBH8wYkyrjbgpLlWrVra4NtE4L766ivNuMA/ijfffFMDSwhAGZge2RxIi8XIFaj3HjduXIRyui+//FL/ibz22mv62jhJ//HHHzXwRRRfrCOwoPkl3vOAEVic9SqL6TzWUVuQGo5AKyLZZtQWwzpqC/oWmJsJyFohK8o6LxEREZGrcOxurqSjJMcEj8zAQfnz53d5HlMtgfMGw4xabaZBFQV6NFmHKrdeWEPAyXquYO3nZc2aIiKKralTp2oSwaOPPqpxCWflbd7MK4JO+ALv06ePZnSgNAgn06aMB/c4UcYJt4HR5ZCZhGkRUELAyXHHIfMJ9ZI4acYVDMerErgygvkw//bt2zWtlv2YKD5ZR2BBMBQHUa1atdJ79AlwFuCJ6TwILkGTJk00ZRJlq+h9YH3OOmqLKU2NCkpN0UDT1WZyRERERFbIxEbFAuDY3NybTO6yZcu6PM8jjzyi97hIjWCRyUoyF6Nh7ty5WjKHSoezZ89qq43JkyfbA1M5c+bUDARUQMDXX3+tx04YAc9ctHO2jkRE0UFywIcffijt2rWTzz//3CfPr7wi6ESUFPz777/2EVhQPmoOpszBzT///OPyPObelJgCDp4cpzGp5kjtRD8zNLZD5N0RehzgoA09D4iIiIjcAccVuHCGABB6rKLNBWDkaJyITZo0SSsYMFJcTOcBtOrAsRFGZUILDVysxvETAk4mUIRlYho0EUcvFSwLmU+4+I0hzPEaWB4uhAMqJtAvFhf7EKDCepn+sEREMXH06FGtwEKv3e7du8uFCxfk/PnzekMCga/w+J5OREmF9YvF2k/J/IwST1fnMffWpqdmGrMMc5XONAjHgRUymhB5v3nzpn4RwqxZszTrEAdqzZo1k9GjR7vhryciIqKkrm7dutomAxULCBBhFGu01jA9KnE8gywka0Pxh81jLrpNmTJF2wcgQxw9njBICoJJBkapnjZtmh7XoFoCr4UeTyh5qVmzpn06tN3A63/77bdy+PBhyZw5szRt2lRbehCRZwhOl8orXu9///uflvFiUCjcrFDFgu8sX8CgExHZM6WiGrUFtcWdO3fWkSNHjBihwStrnzQiIiIid0CWteMQ4gYCQLjFZh6jaNGi2i4jOmilgQDWwzzxxBN6IyLPExYWLo1qFUuU1/X3j90Iby+//LLefB2DTkQewhtGbUH/AgSekFqOK4JIQSciIiIiIvIEsQ38ePvregP2dCLyEN4wagua78PIkSOlWLFimppu4GeM+khEREREREQEDDoReQhvGLUFPRGstyxZstjXBT87y8YiIiIiik9h4WEevTwioqSM5XVEHgS9lNCwGwGg5cuXaymb46gtuOXLl08bYsZkHjNqy4wZM+yjtty7d8/pqC3z5s2zj9qCeVFWZx21ZeXKlRHWF9OabKeff/5ZM6+IiIiIEpK/n79M27FKzt6wZXrHRbY06aVdudpuWS8iImLQicijeMOoLURERESeBgGnk9cuJfZqEBGRA79w1OFQvNu1a5felylTJrFXhYiIiChJ+nzNwjgHJnKlyyi9ajZ12zqR5+xb4P4lcg8MWoSBiAoUKCApUqSIdtozN65IyP3QOL1eUECgZE+TIU7LSMruPGR/xSWewZ5ORERERERERETkdgw6ERERERERERGR2zHo5IWWLFkizZo1k9KlS2vD5/Hjx7tlngMHDkjnzp11NLRq1arJgAEDtK9PVNA4ulixYro8q+PHj8sbb7yhfYAqVqwozz77rDa4pvgTHhbmkcsiIiIiIiKipIuNxL3MunXrtLEzWnGlTZtWTp48KZ999pk+Z20cHdt5Ll26JB07dpTLly9rk2oEm2bOnCmnT5+WiRMnRlommlmPHDky0uMY7axLly4aeAoKCpLkyZPLjh075NVXX9VG1pUrV3bzFiHw8/eXq0t/kvuXz8VpOQHBWSV9w7ZuWy8iIiIiIiJKupjp5GXGjh2rwaOWLVvKpk2bNBsJkLl07949l+eZPn26BpyKFCkia9euldmzZ4u/v7+sXr1adu7cGWmZgwcPdpoFhZHREHDCaGmYd+PGjZoJFRYWptlWFH8QcAq9cDJOt7gGrYi8DTNHiYiIiHxHeFi4V73uxYsXpU+fPvLII4/oyOFICjl8+LD4EmY6eZG7d+9qUAdatGghfn5+0qpVK/noo4/k+vXrGhxyzCSK6TwIEEGTJk0kZcqUUrx4cSlVqpR2qcdzZcuWtS9z0aJFetKTLFmySIEu6+94LTADJGbKlCnetg0RUWwxc5SIiIjIt/j5+8mZpXsl5PKtBHvNoOBUkr1hCZfmffXVVzVBAxcxU6dOLV988YVeuFy8eLGel/sCZjp5kX///Vfu37+vP2fPnl3vcUKTIYNtaMh//vnH5XnMPTKUjJw5c0ZaLk6ihg4dqic/L7zwQqTXw9X4/Pnz60lUrVq1pEqVKvLnn3/q4+3atXPbtiAiiitmjhIRERH5HgSc7l64kWA3VwNcV69elVy5cun5NZI8ChUqJD169JBz587JwYMHxVcw6ORFkJlkpEiRItLPzk5aYjqPubdGU8001mV8/PHHmgKIiGy+fPkivR7mQXQ2TZo0egJ28+ZN+xV78zMRUWKLKgsU9yYL1NV5osoctT7nLHPUETNHiYiIiHxX+vTpNWO+aNGi9mz5yZMna7JI4cKFxVcw6EQxtnLlSpk3b55+KJxlOcGJEye0HCQwMFDLSdavXy/16tWTbdu2ybvvvpvg60xE5AwzR4mIiIjIUwwcOFCqV68uv/32m7bCwTGmr2DQyYsge8h6xd24fft2pOdjOw/qR+HOnTv2aczP6FuCLKVBgwZpiQhOktBfxJlJkyZphPbJJ5/UFMHg4GB57bXX9DmUmTDbiZIyT29aDb///ruWjuHzW7duXe01FFWpmTdj5igREREReYpOnTppS4amTZvqseHff/8tvoJBJy+SO3due4nFqVOn7MEj1IICroi7Ok/evHn1Ho1ujTNnztin2b17t86PXiIYPQknrP369dPn0UgXv2/YsMF+Fd+8JgQEBNh/tga1iJIS04AaASIEE0wD6ugCTzGZxzStxrQICpum1T179nS6zKiaVpteRG+++ab+k0O5F6adMGGCDBs2zA1bgKyYOUpEREREBsrpcJEZWU7o8zR16lTxFQw6eRGk2CGTAebMmWO/N6MoWUeYi+08GKLR9BdBUGr//v0aaAKUdeAEFKUi1htqUE1QCb9jGnO1HtkSaICLIJX5wKC8hH1IKKny9KbVyMD55JNP9OcRI0bI5s2b5fPPP9ffly1b5nPZTswcJSIiIqLEdOnSJS2nCw0NtT+G40MEoNBM3Fcw6ORl0M0eWURz587V/h5DhgzRx7t27apBH5yk1KlTRzp06BDjeaB9+/bal+TIkSNSo0YNPclF7xIEnHCyU6FCBb0yb7317dvX3tsEv2MalPikS5dOS0YaN24slSpV0pNgiCrzgsjXeUPTanyGETxBALl58+b2ZeJ1Vq1a5XQeb8bMUSIiIiJKTBcuXJBevXppxYIREhIie/bs0ZHsfAWDTl4GPVa++uorPSnByU6OHDn0jdq9e3d9HhkMKIk5f/58jOcBnGhOmTJFG9TiRAhX6hF4Gj16dKzWDydbs2bN0lrUzJkz64cGJ8GjRo2yn8gSJTXe0LQa2Y3mtZDphIAxAtD47PpalhMwc5SIiIiIElPRokU1YQTH6KhqQEsNJHZcu3ZNkzl8RWBirwDFXsOGDfXmDPq/4Babeaxv+u+//z7G64GgFG6OcKKEvjNE5HlNqxFwzpIlS6TXu3Llit4js2nHjh1aKoZAFbInMV9UfaC8GbJAEXxHFigywPAP3jFzFDd8pyEoH5N5TObojBkz7JmjCNpZM0dNZpkVglfIdkLQD8sFBJUWLFhgzxzFfkUTcWDmKBEREZFzQcGpvOb1Pv/8cz13fuutt/TYvXLlyjJt2jT7RWRfwKATEVESa1qNQIYjZOuYe2Q3PfHEExpYQcPq+fPnay8hZyOseTOTBTpmzBgNECELtG3bttKtW7cImaPWIWsfNo81c3T48OFaIonM0QYNGkj//v1dyhzFa23cuFGDgMgcRdAL+4eIiIiIIgoPC5fsDUskyuv6+T9oiRBTadOm1Z6ruPkqBp2IiLy8aTWylOLatNosD+V7JqCBktgPP/xQgy8Y0c7Xgk7AzFEiIiIi3+FK4MebX9cbMOiURISHhYmfv7/HLYsoKTANqJFFhAbSefLkiXHT6ofNg2wYBJ0e1rQa0LTayjSt/vHHH3WUDBPgQu8gBKkgMDAwUgNrIiIiIiKimGDQKYlAkOjq0p/k/uW4Db0YEJxV0jds67b1IkoKTAPq7du3a++eatWqxbhp9cPmQdNq9GFC02r0FUIDcmvTavQSsjYZN5lQCF4hkISG/+hFhCaGCDAhsDVhwgQtF1u2bJkGtBCAKlOmTAJtLSIiIiIi8hUMOiUhCDiFXjiZ2KtBlCR5etNqwGt9/fXXWs41btw4Lc2D5557zqeaGcZVWHiY+Pv5e9yyiIiIiIg8DYNOREQJwNObVsMbb7yhI6ah3A6ld7ly5ZLWrVtrMIoeQJBo2o5VcvaGrdTRVdnSpJd25Wq7bb2IiIg83ZIlS/S45ujRo5I1a1Zp06ZNhOMaV+fBUPPDhg2Tbdu26WivjRo10qHnnfXNhJ9//ll7XuJYx3oB7sSJE3rstW7dOr3Yh1YFnTp10j6XROQaBp2IiBKIpzethnbt2umNooeA08lrlxJ7NYiIiLwGAjk41jGtAnCBywyWEVXgKSbzXLp0STp27KijvOLiHS7kzZw5U/tdTpw4MdIycZFv5MiRkR5HSwEEtM6fP68tBxC82rNnj47ki2W98sorbt4iREkDc/qJiIiIiIgoXo0dO1aDR7jwtWnTJhkwYIA+Pn78eG0P4Oo806dP14BTkSJFZO3atTJ79mztR7l69Wrte+kIQ9MjMOUI8yHghKxvZD9t3rxZM8wB/S7RvoCIYo9BJyIiIiIiIoo3GB0XbQCgRYsWOkJvq1at9P769etOg0MxnQfBJWjSpImkTJlSihcvLqVKlYrwnIGBVxBQMr0xrdKlSyePPvqoPPPMM9q+AK+D3wFBKmeBKiJ6OAadiIg8WHhYmEcvj4iIiOhhMLquyRTCQCaAUrgMGTLoz//884/L85h762i9ZgAU63KRDTV06FBJnjy5vPDCC5FeD30sMZBKr1697I8huwrwmghKEVHssacTEZEH8/P3l6tLf9LRJ+MqIDirpG9oSxMn8nWe3qwWZSGffvqp/Pbbb9qsFlflsZzy5cu7aQsQEXkOZCYZ+O50/NlZFlFM5zH3yHJynMa6jI8//lguXryoQaUsWbI8dJ3XrFkjkydPtgekkPlEFJ+OHj2qpaQDBw6Msv+qN2LQiYjIwyHgFHrhZGKvBpHX8PRmtfD+++/Lr7/+qn1HcKKEIFbnzp1l/vz5kjdvXjduDSIiWrlypcybN08HX0GW04IFCx46Pf4nhISESMGCBaVHjx4Jtq4UN2HhYTrSsLe9bkhIiLz99tty69Yt8TUMOhEREZFPsTaeRVbS1KlTtaQCjWcR2HHWyyMm81ib1SLYdOzYMe0zYprVli1bNkbNajEkNwJO8MMPP2h2U4cOHWT79u06EiXmIyLyJdZsUPRqMm7fvh3p+djOkzp1ah157s6dO/ZpzM+4iHDz5k3NOEWQH9/rQUFB0a7rsmXLpGfPnhoEyJMnj15UwIUG8g4I/Kw+NEGu3j6TYK+ZPmV2qVW4a5yW8eWXX0aZNe3t2NOJiIiIfIY3NKvF6EqAkruqVavqNE899ZS9nIOIyNfkzp3bXp526tQpe/Do6tWr+nP+/PldnsdkhyLr1Dhz5ox9mt27d+v8YWFh8uyzz0qxYsWkX79++jyyWvH7hg0b7FmvJuCEDKdp06bZ+0OR90DA6dKtfxPsFtcA16ZNm+SXX36R4cOHiy9i0ImIiIh8hjc0q/3zzz/1HidB9evX12wqBKBMFlRoaKjTflPNmjWT0qVL2+dxhH5TyMoqV66cVKtWTYcWd8y0QgDtxRdflAoVKug0+HnPnj0Rpjl+/LiWlVSsWFFvKCvBNiIichW+U/HdBHPmzLHfm5Jmx0zR2MzzyCOP2IP9CErt379fA01Qq1YtDezje9t6S58+vT4fEBCgv2Ma9Ht68803NeCUI0cO+fHHHyN83xPFh2vXrsk777yj/7PxvvNFLK8jIiIin+HpzWpxFd00FEeph+kdhSG6AVfiUQpiTojc2W8KgTFMg5MyTIN7ZGht3rxZZs2apWWDWM7zzz8v586d06AZ1gelJjt27NCSQDRYJyJyBQLY3bt3l7lz5+r3IE62oWvXrhr0mTRpkt7y5csnU6ZMidE80L59e5kxY4YcOXJEatSooQM14EICAk4mMIUeTVYIXiHbCRcazHcyBndAmR4gmwoZr1ZYh4wZM8b7dqKkZfDgwXohCBeWfBUznYiIiIjiqVmts95RBq7O48omYBS7qFj7TSEF38yDbCecXIG13xTK92bPnq1BLdNvCv73v//pFXyciKGUBNMhwwq9TxYuXKjToJQEAafChQvr83/99ZeeAF64cEG+/fZbN28tIkpK6tatK1999ZWWsyHojawOBOcRVAIEyzEAw/nz52M8DyAbCUGqmjVraqAcPZ7wfTl69OhYrR8C7AaaOWNdrDeTEUvkLnPnztULP+g55suY6UREREQ+w5Ob1Vp7R5nfcSX9o48+sr8W5sXrPKzfFOYx/aYqV64cZb+pXbt26XO42o+TNJTTIVCFDAH0PDGj5JgMJkwPderU0b8bNwwVjgwAZANgGGciIlc1bNhQb84goxO32MxjINCPgRhiCkEpxyHpf//99xjPT+QOs2fP1szoevXqRXgcxxIoF50wYYL4AgadiIiIyGeYxrPIDELPJIw8FNNmtQ+bB81qEXR6WLNaQLNaK5TEOfYswXJM7yhkKZl1CQwMjFG/KcyDkjkEnaLqN4UgkrXfFJaNGzIFcECLvxmlfc8991yEckGTQQWmhAV/G7aLtbyQiIiIXPPpp59GuJAFjRs3ljfeeMM+wIgvYHkdERER+QxPblYbHBwcKRCFfk3onWSgPCQ++00ZBw8e1L8PmVUIXpn5zWh8uOKPxuQIjKHfk7P1ISIiItdly5ZNS9itN8iUKZNPNbH3ikwn1OailhcNMXGwU6VKFXn//ff1SqQzZtQY9FXAlcsnn3xSO8JbD8RwMPXll1/qKDEYDvPdd9+V6tWrO13e/PnzpU+fPlrniyuQRERE5Lk8tVktrmi2bdtWH2/QoIEeV6DcDcc5gAwkZ32g4oMpQ3n11Vd1Pfr27Svjxo2Tdu3aaX8oZHCZpqbWMkEzfDkRUUIJCw8Tfz9/j1sWea70KbP79Ot5G68IOqGBJg6Ahg8frgdtI0eO1IPABQsW2A8ErZCOhiuQkydP1oPG9957T3sWjBgxQp9fv369BpEQiMIVRVzBw+gvONAsVKhQpKuQQ4YMSbC/lYiIiOLGNJ4dM2aMBojQeBbBHjPSm2lWiwynmM5jbVaL4xH0WULvJQSP+vfvH6P1svaO6t27t5br4VgGTboBASc8Fh/9phyZUfUQ9MJx04oVKzSIhuVNnTpVPv/8cy3Nw4U5bBscCyHglC5duhj9rURE7oIg0bQdq+TsDVvJs6uypUkv7crVdtt6kWdCYLFW4a6J8rruCGju379ffI3HB51wAISrcW+//ba9wdaoUaOkdu3asnjxYmnatGmE6bdt2yYbN27U1HcTQMKBEoJU6F+AA8bvvvtOm9Fh2GBAlhPm++GHHyIEmHDlEcEppJojUEVERETewROb1eICmOkdhUATsot69uypQyXjMQR34qvfFPzyyy86Ss6jjz4qTzzxRITXwTEPRrbDxTxc4EMTU/SNMvMBMsOspYBERAkFAaeT1y4l9mqQF0isTDZm0EXN47fMvn37dDQYa+kbrrKVLFlShw12hIMpXL2zZixVrVpVD9hwVRIHVVu3bo1USletWrVIy0OaOQ7ArENyEhEREXlbvylABhdaBiCjC60IMB2ymqB06dKaLYXMqzJlymhpHYJYaGtggk4PC8gREREReV2mk7lKhzR3Kwzta56zQrq847S4aoerdbj6h3I7XGk0I8BEtTwMQYwrmSi9wzLdAQeIZmjihISAm7tHmsGBKv4eSnzcv74rPvYtcP+6jp833xYf/Yoc960pZ0NJP3opmcbcnTp1ktDQUO01hUAQMprMUMkPmwe3Vq1aaXDIsd8ULrIVLlxYjz+ef/55DTodPnxYM8bR3BwleOjZhGxwTIOR8DJmzCjnzp2TOnXq6PpjWThuQk+rxDiOcQd+dn0X/1f6Nn52vRdKwpHwgf9FZhRWZ/sXA1q4E16T+zf2sI+w7fD5ML0mrbBNXT1O8vigk+lZ4Ni7CendJrXccXpnfZ4wPd74pr+Bs+WZXgk4oEI5H25ISXdX0AlZU3v37pWEhi9qZIa509GjR+37hhIX96/vio99C9y/ruPnzXch8FKyVCkJDAhw2zJD79+XPX//rf//DYxI8+abb8rs2bO1XA6/I4MIwSEcI/zzzz8a8EFAyBwzPGweA72lELBClhOOa9C3skOHDhGmGThwoPz888+aSY73HVoIPPfcczrSnZkO/aamTZumwSlsFwzggv5WeG3cvBE/u76L/yt9Gz+73g0DZFj7ETpCwMndQUUT7KLYbzdcxMLFq6g4i7P4RNDJDPeLq2zWoYKxUZy9QTENpnWE6ZGibnoROE5jXR5GvitQoIC0adPGrX8LDtxwtdEXrtxi+zCC7Bm4f31XfI0Sxf3rOn7efHvfIuDkjma11oa1RYoUibR/S5QoYe8r6QhBIdwcRTePdZrGjRs/dBrTIzO6aR5//HHxJfzs+i7+r/Rt/Ox6L5xf40IFzr+t5/HxvX/xety/rgcJ0SPSWf/GQ4cOubhULwg6mVI5XPWzjuiC34sVKxZpeqR/L126NMJjCDChLwFK6FBmh+AT5rfC72gyDriSiCgeGnuCSQdE0/KXX35Zb67Ah8o6Uo43i480ZvIc3L++jfvXs3B/+HazWu5f38V969u4f30X923CQBaTuSF7NyFfl2LP7Ct8PpwFCeMSIPT4PVK8eHEdvnfDhg32x9CXac+ePZru7QiPoTfTsWPH7I9hNDuoVKmSbqyKFSvaHzOwfPQxAIyKt3DhQu2dgBsyn2D8+PFuz34iIiIiIiIi8iWo8gFv7QWY1Nz6bz+Z/eZOHp/phIwjNK789NNPtbFlrly5ZOTIkZrRhBRyZCFdunRJR3BBRA4jvCCo9NZbb8ngwYN1473//vvSvHlzeyZTly5dpFu3blofjCaZyGxCH4OPPvrIPiSwlWkwnjNnTvvwwUREREQJJSwsXPz9/TxuWURERM4guwnnzqbCCBU/UWXLhNy9J6FhzpuNx5h/mNwJtPVvptgPdob9hP0VH1lpHh90AozYgqZWAwYM0EbgyGaaOHGiRuFOnDghDRo0kI8//lhatmypb2QMBfzBBx/oqC6oR2zSpIn069fPvjwMHTxs2DAZO3asjBo1SvssjRs3TgoVKpSofycRERGRMwgSLVm9Xy5fi9sV4+B0qaRRrcjtCYiIiNzNjBjv2NrG0bW7t+V+HINOAf4BciM5SyddhYCT2V9JMuiEaFufPn305ih37tw6SosVRnUZM2ZMtMtE5hNuMVGtWrVIr0FERESUkBBwunDpZmKvBhERUYwgIQQ9mtFb2TqSq6NJW/+Uc3EcxCNrmvTSpfijcVpGUhUUFBSvfbe8IuhERERERERERN4HAY3oghq3w+/LtfuRR6CPjbTh96McJY8Sl8c3EiciIiIiIiIiIu/DoBMREREREREREbkdg05EREREREREROR2DDoREREREREREZHbMehERERERERERERux6ATERERERERERG5HYNORERERERERETkdgw6ERERERERERGR2zHoRERERETkBkuWLJFmzZpJ6dKlpX79+jJ+/Hi3zHPgwAHp3LmzlCtXTqpVqyYDBgyQGzduRJhm//798vrrr0utWrWkUqVK0qZNG1mxYkWEaY4fP67TVKxYUW89evSQf//91w1/ORERkXOBUTxOREREREQxtG7dOg3ohIeHS9q0aeXkyZPy2Wef6XPdunVzeZ5Lly5Jx44d5fLly5IqVSoNNs2cOVNOnz4tEydO1GmOHj2qQaZbt25JUFCQ3rZt26bLGDlypDz11FO6nOeff17OnTsnyZMnl7CwMFm2bJns2LFDfv31V8maNWuCbSsiIko6mOlERERERBRHY8eO1eBRy5YtZdOmTZqNBMhcunfvnsvzTJ8+XQNORYoUkbVr18rs2bPF399fVq9eLTt37tRppkyZogEnM83GjRvl0UcftS8Lpk2bpgGnwoUL6zR//fWX5MuXTy5cuCDffvttgmwjIiJKehh0IiIiIiKKg7t378qWLVv05xYtWoifn5+0atVK769fv24PDrkyD4JL0KRJE0mZMqUUL15cSpUqFeG5bNmySe3ateXZZ5+VdOnSaaYTfgdkRMGuXbv0vk6dOpImTRrJnDmztG7dWh9bvnx5vG8jIiJKmhh0oiTRx+DLL7+UYsWKRXnbsGGDm7YCERERJTXoi3T//n39OXv27HqPUrgMGTLoz//884/L85h7BJaMnDlzRniue/fuMmHCBC3DMzZv3qz3efPm1fsUKVLovTXrKlmyZHp/6tQpuX37tpu2BhER0QMMOpFbmJ4ECBDhoMb0JIgu8BSTeUwfA0yLVHLTx6Bnz572aUwfg8WLF8uVK1e0R4HpYzB//nydBlf0cLBmveFKIAQGBurVPiIiIiJXIDPJMMEd68+OF8tiM4+5R5aT4zTWZVihR9OiRYv0Z2Q/gcmO+v333/XYCxlQs2bNcro+RERE7sKgEyWJPgZdunSRlStXRriVKFFCn3vnnXekUKFCCbCViIiIiOIXAkn9+/fXn6tWrSrPPfec/tyuXTvNqLp48aJmmderV08v3Bko6yMiInI3Bp0oSfQxcITgFUrqKlSoECEVnYiIiCi2kFFtPcYxTMma9fnYzpM6dWq9v3Pnjn0a8zNGvLPCxTpcxEPWd5kyZeTrr7/Wi3VmeVOnTpUnnnhC8uTJI3Xr1pV+/frpczj+MhngRERE7sSgEyWJPgZWOLAzwxHjSiCv7BEREVFc5M6d2348gf5IJnh09epV/Tl//vwuz2OOZawX0s6cORNpufPmzZMhQ4ZoFnnFihVl8uTJkQJJOOYaNGiQLF26VLPB0WIAMIpd8uTJ3bhFiIiIbBh0oiTRx8AKfZ6QWo6U87Jly8biLyUiIiKKDBfOMOAJzJkzx36PABCykZwdb8R0nkceeUTvcWyDoBQGT9m9e7c+hgFU4NChQ5rhhHlLliypF+Mcs6sWLFig2U8orUMPTBxH/fLLL/pcw4YN423bEBFR0ma7vEHkI9DHYODAgZH6GFj9+OOPev/8888n+PoRERGRb+rRo4dmX8+dO1eWL18u165d08e7du2qo8RNmjRJb8gqQj/KmMwD7du3lxkzZsiRI0ekRo0a2vcS2eIIOJnAFMroTD/M48ePy+OPP25fL2QwYbRgtB7IlCmTnDt3TurUqaMBKsyDDPKXXnopwbcXERElDcx0oiTRx8DAgRhGbMEBGHoZEBEREbkDjiu++uorKVasmB7P5MiRQ3r16qVBJZO9ffbsWTl//nyM5zEtBhCkqlmzph7j4NgIg7CMHj1an0cA6q+//rJPjwwmvI65mVI8tDBABhQypwICAjTTCllPP//8s729ARERkbsx04nizPQkwBUz9CRAc8qY9jF42DzoY4AU8Nj2Mfjuu++cBrvWrFmj91WqVNGDLSIiIiJ3QZlaVKVqr7/+ut5iM49RtGhR+f77750+hwDStm3bYrR+GLn3hx9+iNG0RERE7sBMJ0oSfQyMrVu36r0ZAY+IiIiIiIiI4gcznShJ9DEwkGYOhQoVSrBtQ0RERERERJQUMdOJkkQfAwOj1gF7FxAREZEnCAsL98hlERERuQMznSjJ9DGAhQsXxnhaIiIiovjm7+8nS1bvl8vXbsVpOcHpUkmjWsXctl5ERETuwKATEREREVEiQsDpwqWbib0aREREbsfyOiIiIiIiIiIicjsGnSjRhbux/4A7l0VERERERERErmN5HSU6P38/ObN0r4Rcjlsvg6DgVJK9YQm3rRcRERERERERuY5BJ/IICDjdvXAjsVeDiIiIiIiIiNyE5XVEREREREREROR2DDoREREREREREZHbMehERERERERERERux6ATERERERERERG5HYNORERERERERETkdgw6ERERERERERGR2zHoREREREREREREbsegExERERERERERuV2gKzNdv35d1q9fL7du3ZLw8PBIzzdv3twd60ZEREREREREREkl6LRq1Sp544035M6dO04DTn5+fgw6ERERERERERElcbEOOn322WdSsGBB6devn2TLlk38/VmhR0REREREREREcQw6HT58WMaOHSuVK1eO7axERERERERERJRExDpNKWfOnHLjxg1JaGFhYTJmzBipXbu2lC9fXl566SU5fvx4lNNfvnxZevfuLVWqVJGqVavKBx98ILdv344wze+//y5PPPGElC1bVksC161bF+H5gwcPSrdu3aRatWpSvXp1LSs8depUvP2NREREREREROT7lixZIs2aNZPSpUtL/fr1Zfz48W6Z58CBA9K5c2cpV66cxjIGDBgQZQzn9OnTGg8pVqyYnD9/3v74l19+qY+Z2zPPPKM38/uGDRviL+jUvXt3+frrr+XEiROSkJBdNX36dPnwww/l559/1iBU165d5d69e06nR4Do2LFjMnnyZPniiy9kxYoVMnjwYPvzaITep08fadOmjfz6668aVEKACZlcJmjVpUsXSZEihUyZMkW+++47uXTpkr7m3bt3E+zvJiIiIiIiIiLfsW7dOnn99dc1QISYw8mTJ7WVUXSBp5jMg5hFx44ddVq0QkKwaebMmdKzZ89Iy8Nzb775ptP4Rpo0abSdkrllzJhRUqdOrc8FBgZK5syZ4y/otGDBAjl79qw0atRIatasKQ0aNIhwa9iwobgbAkvff/+9BpLq1asnxYsXl1GjRsmZM2dk8eLFkabftm2bbNy4UUaMGCGlSpXSgNKQIUNk3rx5uu6AIBLWFTukUKFC8u677+q0P/zwgz6/dOlSHZ3vk08+kaJFi2okceTIkRqU2rp1q9v/RiIiIiIiIiLyfWPHjtWB2Vq2bCmbNm3SbCRAACmqxJqYzINEHSTQFClSRNauXSuzZ8/W4NPq1atl586d9mUhKadFixayfft2p6+FBJyVK1fab3iNAgUK6HPvvPOOxlDiLeiUPXt2DdagHK1OnTpauma9oZzN3fbt2yc3b97U4JGRLl06KVmypG5sR5s3b5YsWbJE2BBYN4yst2XLFs2SQuDIujxA6plZHp7DTkUE0TBN069du+b2v5GIiIiIiIiIfNvdu3c1LgEI/CBO0apVK72/fv16hOBQbOdBcAmaNGkiKVOm1IQdJNdYn0N8BVVe//77r9SoUSNG67x8+XLZvXu3VKhQQRN34rWR+FNPPaUvZA3GxDdkNEGOHDkiPJ41a1b7c1bIZnKcNlmyZJIhQwatWUTQCFlMCKBFtbzcuXPrzQrRPfzdrgbWEJXE6yY0vBHxhnMn9MfC3+PL6+YtuA19V3zsW+D+dR0/b77Lkz9vfN/FnaduQ09dL2/iyZ9dijt+RnxbUt2/hw8flvv37+vP6dOnt8cI8POVK1e0fA4JNq7Mc/ToUX08ODjYPg3K43bt2iWHDh3Sx7CNMO0rr7yi8Q1kRAEedxavQMBr2rRp+nP//v11v8Vr0Ak1hO+//74GnxKKaQCOwJFV8uTJ5erVq06nd5zWTI8NdufOnSiXF1W/JvR1mjp1qqawoZ7RFSEhIbJ3715JaPggO75p4wpvZsfG7L62bt6C29B3xce+Be5f1/Hz5rs8+fPG913ceeo2TKj1Qib/rFmz9OIrLsKiauFhx/IxmQeD+vz44486+A6Oq3Fhtl27dpIqVapIy7t48aL06tVLj4dRTYBlGujD2q9fv0jzYDkTJkzw2s8u+e5nl9wjqe7fAwcORPgeNU2+AwIC7AEmx7hBTOdB1pPp7WSWYeIfSLDBY6j8MqV5e/bssS8X3+XWZuLGn3/+qXEXZEyh6XhsxTrohLK2hMxyAvN6qFO0vjYCRM4io5jGWR0kpsc/LwSXzPIcn3dcHqKkaET+zTffaCSwQ4cOLv8dQUFBUrhwYUlosY1ExgTqOd2V6eSp6+YtuA19V3zsW+D+dR0/b77Lkz9vfN/Fnaduw4RYL/Q5HT16tD6GxrAXLlzQQXnQiuKFF15wuoyYzIOeIT169NAr7Dh+xkkNTkxwPI1Bh6xwcvTxxx9rwAnQa8TahNYM5INjeJxrGHjtEiVKeO1nl3z3s0vukVT3711Logu+D/HdauIFJjPJ8bsvpvOYbZozZ077MpANFdV3KtoYWZfrrEH4oEGD9P6xxx5z6e8NdGX0uqFDh2oEEfWBzq5kuLuvkymVO3funOTNm9f+OH7HcH2OUDaHRuBWCDDhnyJK6HBlBeuN+a3wO3aWgX+MuOqycOFCvcewg3GBN4Cz7eWN4iONOSmsm7fgNvRt3L+ehfvDt3nq/vXU9fImnroNHddr4sSJ9sazw4YN08x9HMtjhGf09HBWHRCTeTDID46tcZKCkZGQrYQ+IyjTQAmHuRqOZrWYF71DrOtoPSY25SBt27aVvn37iifw1P1Lccd9m/T275IlS2TMmDH6XYN4AEawx3dZdGIyD7KP8B2JgcwQNMdga/gOQ3DH0enTpzVog+ARMkStfaPN96HJSELQH6PSLVu2zN7yxxoMcjYPqrHwGF4b3834DjfThIaG6r2Jg1iZhByz7RyfR1aVyWatWLGiuCLWjcQR5UJwBqPHIQCFJlLmhiyg2DaVigkEt7DxNmzYYH8MfZmQCuYswIXHkDqGf37WKzZQqVIlDf5gg5nHDCy/cuXK9t/Rlf2PP/7QHR7XgBMRERERUULylma1pmwkX758bt8GRJS0rVu3TlsE4XsGgaGTJ0/q+T36NcdlHpSvIfaBaREEQkYnAvA9e/aMtLwbN27Im2++ac9WQlKNyUg6deqU3qMk0LQOMr2brBB8im6e/Pnz671J0kGQyzB9q800sbFmzRq9R4aUqxVvsQ46ISpnvf3www/2m/nd3RBVa9++vXz66aca7cM/sLfeekszmho3bqw7BbWHJspXrlw5DSphGvxjXL9+vfahwoh7JpMJQwD+9ttvMmnSJE3p/eSTT7S+sVOnTvr8nDlzZNGiRboMjHyH5ZubeR0iIiIiIk+FYI85eTED6OAqtumn9M8//7g8j7m3VgmgnMP6HK60ly5dWk/UXn755SjXc//+/fahvjFgEUaR/vDDDz2uLwsyH5o1a6Z/U/369aM9aY3NPDixxQVunMNgNG30WjH9WhzhRBJZZKj2cOy9gt9RnYHth+2IYOHvv/8eh7+YyPuhh5zJ3ESvOtPLCJ9FZy15YjoPvq9QZoxsT2R4zp49W4NPCLpbA/orVqzQAP727dvtjyFQj8+7iTuY++jKAvE9HNU8adOmtWeXPvLII3qPWAa+Q/H9ilHnoFatWrHeflu3btX7ggULiqtiHXRCAOZht/jwxhtvyDPPPKM7HKm3aJiF1F/UMOLLFxsQGxYQAfzqq680GoggEqKKderUkcGDB9uXh+mRCvfTTz/pmwCBqXHjxkmhQoX0eZTUAYJRmNZ6M69DREREROSpTENZsF6hNj87C2zEdB5zby1lMdOYZRQtWlRPxOrWrRvlOiJbwARPEHzBSRseQ0nfa6+9Jp7CE7MlrNAWBIErnIRi++NcCSeamB4N4Sl6DCj6Jk/O9uzRo4cuc+7cuVqpNWTIkAiNweG5556L0FM6qnm6du1qL5VGsg4uEhw5ckRfE4EzXEhAHMOVJuBnz57V+zx58kiCBZ3wBz7sFh+w8fv06aNfyKiZxIfa1DfiHhE8bFAjU6ZMWoOJaRFQQsDJWq8IyHxavHixvnHwBY0PsYE6dSzT2c36OkREREREFJn15Ckq6DWCk3IcX6OiASd76AFlTtw2b94snsATsyWswQ+c+KKXFuZ98cUXtY2IafrrLOjEgMkDDCj6Lk/O9qxbt64myuAzg4wkEzSyBtsxiIP18+Q4D8r0MCoo2h4ZWJ8pU6ZIzZo1dZS61KlT63cQ+kS5AiOPgrM+VfEWdEJjLGc3fJHgi8h0Nici8tarSThIwAFvgwYNpHz58tK0aVMtxXVWX01EROSprCcJ1pNZU7bm7CQipvPgRAasbSfMzyj1iCk06MV5BEa3MxeUW7dubR/F7u+//5bE5snZEib4ceLECd3uOMlE9QZGEMTxjONJsXUeBkw8P6AIeBz7F6OVLV++/KEBRfKebM+GDRvK/PnzNUEG7xtkIz311FP25xGIR49pZ/Pgc/TXX39pwMlxFEC8LpJoduzYoe8XfL9G9b2McyaTXGNGxLNCBRiec7WJuEtBJ/zhjrcFCxZozyT808BwqkRE3no1CV/4WA6uEKBJH0p4MWLD8OHDGVQnIiKvEtPGs4nZrBb/0//3v/9Fynwxoy2Z4FNi8uRsiaiCH8iGwO+4ePbee+/FaJ6kGDDx5ICigTIqbEcEH3C+fevWrSgDiuR92Z7nz5+XESNG6HvE2g7Il8Q66JQrV65IN3wZoc8Sotho+kdE5K1Xk3BAZIYFnTdvnr5e79697QdHJsWUiIjI08W08WxiNqvFQD7o3Yo2GqaUbtq0aXpijQs/zkaqTmiemi0RVfDDCsdJ1oxuBky8J6Bohf2DLEN8NvDZiyqgSN6X7TlkyBC5du2altXFpW+STwWdooMyFU9IgSUiz+QNV5MCAwO1rA4ldTjIA5TzmQMD00yPiIjIGzys8SzKxzHgTmI1q8VrI8iFMqx27dpJ5cqV7a+H3kSm5C4piypbAlli0QU/MMDTnj17tPzGnDAzYOIdAcWo4POGz4qzgCJ5Z7bn4sWL9X7kyJEaT8F5iIGfv/zyywjTh4WHibu4c1nRCXTXgvCmRxYAGngTETkT3YEOspRwEIODTVfmiergaNeuXZEOjnBFFf/0kRHlCHXSuFnh4Mgc9CG7k4iIyFuYxrMYYAcnrGg8iwoFXIQxJ8a4oIL/rTGdx9qsFuXnuDiEq/44Qerfv3+s1g9BLAQt8HrINsZJdIECBTQAhcBWUsiWuHLlikvZEjdv3nQa/ECQA8tE426Us2GbYnAlBAfjI2ACGzZsEFcCJsh+SspiUn5l9eqrr8pbb70ln376qY7CjoAi+p5a9xNFztxEth0yNtG/KKbZng+bBwFUXPxGticC8jhncSXbM5tDxh/6splgIspSHb9f/P38ZfWhCXL1ti3A5ar0KbNLrcJdxSODTrji79ioChsGJ3/4Qn333XfduX5E5EM85WpSTA+OTHYU+kcBehCkT58+RvMRERF5CmcXVAz0TMQtNvM4NquNCdOs1hlcSELpvCmf9zQm8wEnnch8QAlMTLMlHjYPsiUQIIprtgQCf7iYFlUCQFQtDJJ6wMRTA4pRyZgxo96jZym2oTWgSM4hcxPvNWRuIrCNUjbHbE/c8uXLp4H0mMwDCIrPmDHDnu2Jz5gr2Z4rV66M8Dt6oJlsJ/TLdpbtiYDTpVv/is+W1yFN0/GGKB9GmZg4caL2dSIi8kSxPThCuXCnTp00aJU5c2YdXYeIiIiSFk/tjWV6ygBOinECjCCguRCHYAQkT57cvi4J3a/GMWCC5ZtBXkzAJDF5Q/kVBskZOHBglEPex0dA0ZeYzE2UrmE/IXOzV69eGlSyZntaSxUfNo8127NmzZqahIPPDMqMo9pPSVmsM52QQhsdfJBMCQwRkbdeTcIQo+glgYBTcHCwTJgwIcmngBMRESVVnpgtgRNhk02FAAeSAVBOZ46XTAYF2grgWCYxMrAQMEFADRlYGDnY0wIm3lB+hebreI8geNioUSPtWYpkD8eAInlvtqcVPqMxmc6bxDrTqUSJEk6b/QJGnHj88cfdsV5E5IO84WoSYPQ6HBwg4IRaahw84ruPiIgoqXB3g9mEaliblLIlUJZmAg4IbH3zzTfax8nAiL4Yih3HNIk1OqEJmODE3Aw45WkBE09vtl+vXj0NKCKYiMF0KlasKN99912kgCKRV2c64UsCXxiAL6SZM2dGqj0EpEeaDxkR+RbU3KOh6NGjRzXjp02bNhEaisZ0HscrQ+PGjdPvFfMPvHHjxtK3b197BhMOjnBFBwc6yDzC6HJoEO54cFSyZEkNiH/99df6nVWmTBltIh7bgyP8Q8eQpbgaiXX44YcfpFChQnHYckRERN7HXc1qE7phbVLLlogqmwq9kzCinAmYJFa/GhMwQQYWAiY4rjMN0D0lYOLpzfbRHgIBRRzjYqQzrAveMzgubt68uRu3BFEiBp1wEoYPFSCii6CTI39/fz0BfOWVV9y/lkSUqJAajQMpE+jBEL2muXZUgaeo5sFVHpSu4UBn2bJl9ibfQUFBehCC75d58+bpULrm4MikXmPEE9wOHz6sv+OKEw6OLl26pAEuwOshSG4ahePqU2wOjhAMM6Pd4bW6dOkS4XkEyRDgIiIi8nXe1qw2KWLAxHcDila4EIoBuzhoV8IJCwsXf38/j1uWzwadEEgywaTixYtr1Ds2J3FE5N3Gjh2rwRwEjIYNGyZTp06VoUOH6hDHGDzAWYZjVPMgODRq1Cg9AEEZG6DOf+nSpVrr/vTTT2uQCSM3AK6MHThwQA9aUEKHx5F+jqttZrSTadOmycWLF7UvAbKgkEmFgBGmw7DLsYFAmDXgjoMjT+o9QERERGTFgAmR+yFItGT1frl8zVbx5argdKmkUa1ikpTFuqcThg+3BpxwUmZKY4jI9+Azjitc0KJFC812RHo07pGl5KzH28PmQZ+k+fPn2+v4n3/+eb0Ch6A2yuIAI2LCmjVr9L5SpUryxx9/aJmdGSUTQwODKaNDc8Uff/xR1wk9E2D16tXRHhzhhvUx0DDcPO7shgwsIiIiophmOHjisojo4RBwunDpZpxul+MYtEqSo9cB0jCRjokTPqRsohxm1qxZUrBgwQgN1ojI+yH7CFlFYEamRIAIjREvX76spWiVK1d2aR5TxoYUbgOZSggimefQD8q6HMiVK5fem2lSpEgRKQvJZF+h+TgaYJqsKCIiIqKEwmwJ38XyK6J4Cjrt3btX2rVrp+UwzZo1k+nTp+vjKH1BCQ3SJ5HZQES+wfRcsgZ3rD8j8OzqPObeGhAy05hlOJsGo51Yp0Gj8f/973/y+++/y3PPPac9pBAIt64Pg05ERESUmNkSngSjCaJZvKcty5swoEgUT0EnDLtZunRpe30veqnAgAEDtKQGpS0MOhGRu0VXxotAOALgZ86c0WC4aUxuoKzPKqkeHBERERG5c3RCXxmZ0JcCikReH3RCg97PP/9chy035TPGE088IQsXLnTn+hFRIkP2ooHAsoGSNcfnYzsPRkK5cuWK3Llzxz6N+RnZStZpsRxzcLT5yD59LDBFmPy2a6j+/OLAR+S3advk+OGLkjVXeilRIZfMmbhREG9a8+9YCToToNMl9YMjIiIiIuDohETkkUEnlLVYTxCtcPLobBQrIvJeuXPn1kwhZBqhPxJGiEPw6OrVq/p8/vz5XZ4Ho9Hhe+P06dP2eZGtZJ0G8wKmuXo7nR4cnf1vmgxZk9kPlsJShkmD9rkkZRrbfFv/PKX3wVlTyvXQkyKh8biRiIiIiIiIKJJY15fUrFlTm4ibE0PAyeXNmze15K5GjRqxXSQReTA0ADejzM2ZM8d+j4ASspGso1nGdp5HHnlE7xctWqRBKYwOh9HpoFatWhGm2bZtm5w7eVXu3g6VvZsv6GMFywTr/e61Z+XjF1fJ+Pc2y+0bIXLnVqhs+9MWyCpWOXO8bh8iIiIiIiJyU6ZTnz59tFFvkyZNdHhzBJyGDx+uI0zhhBKld0TkW3r06CHdu3eXuXPnyvLly+XatWv6eNeuXTW7cdKkSXrLly+fTJkyJUbzQPv27WXGjBk6IiYC1hh9DmW7CDiZwBQC3RUqVNCg08jeC8U/QCTkbpikTh8kFerl0GkKlc0oqdMFyfXL9+SLnuslXMLlfki4pMuUXGo8acuUIiIiIiIiIg/PdMqRI4fMmzdPOnXqpEEmlMfcunVLmjZtqpkMphSGiHxH3bp15auvvpJixYppRhK+B3r16qVBJTPC3NmzZ+X8+fMxngeyZcumQSoElsLCwrTHU8uWLWX06NH2afz9/eXbb7+VVq1aSbIUgYJ+4gVKB0v7vuUkZWpbs/CUaYKk7dtlJX/JDOIf4CfJkgVI6RpZpfPACvocEREREREReUGm09ixY+Wxxx6Tt956K37WiIg8UsOGDfXmzOuvv6632MxjFC1a1D4aZlTSp08vw4YNk5ptU0XZ8DJ7vjQaiCIiIiIiIiIvzXRCxsGJEyfiZ22IiIiIKFEsWbJEmjVrJqVLl5b69evL+PHj3TLPgQMHpHPnztrrr1q1ajJgwADNkLXCQBP9+vWTqlWrSvny5eXFF1+Uw4cPR/m6WCZeE9m0PC4lIiLyoaBT4cKFtX8TEREREfmGdevWacYqgjkpUqSQkydPymeffRZt4Ckm81y6dEk6duyo06JcGsGmmTNnSs+ePSMs67XXXtM2DWjZAKtXr9ZWDqYfoBXKsd977z0JCQlx6zYgIiIiDwg6Pfroo9osHFegPvnkE+3ZYr19/fXX8bCaROSNwsPCE3sViIgohu0T0KsTffU2bdqk2UiAABIGeXB1nunTp8vly5elSJEisnbtWpk9e7YGnxBU2rlzp06zceNGvQUFBcmCBQv0udy5c2ufwF9++SXS6/7www/2eYmIiMjHejohsARr1qzRmyOMZvfqq6+6Z+2IyKv5+fvJmaV7JeSy7cq1q1LmzSiZqxVw23oRkWtQSjVmzBjNeM6aNau0adNGunXrFud5kCmDvm0YpRIZM40aNZK+fftKmjRpIpRfYbTcZcuWaUCjUqVK0r9/fylUqJB9GgQpcGHsr7/+kjt37kjBggV1xMzHH388HraG77h7965s2bJFf27RooUey2Hwho8++kiuX7+uAZ7KlSu7NA8CSIBRj1OmTKkjH5cqVUp27dqlz2GkUnM8iZFKCxSwfdejf+jEiRP1uZdeesn+usePH5cvvvhCR0GNKhhGREREXhx02rdvX/ysCRH5JASc7l6I2LsjtoIypHTb+hCRa0wpFTJb0qZNay+lgqgCTzGZx5RfIRsmVapU9vKr06dPa9DBWn5lsmECAwPt5VeLFi2SdOnSaakV+gYdOnRIp0Hwavfu3fLmm2/KzZs35ZlnnkmQ7eSN/v33X7l//77+nD17dr3HvsiQIYPul3/++SdS0Cmm8+DejFZq5MyZU4NO5jnTtsEsB3LlyqX3Zhpj4MCBOiIq9qt1pFMiIiLykfK6mMKBSIkSJeTvv/+Or5cgIiKiBOLp5Vfbt2/XhtJZsmSR5cuX6/TIloFZs2YlyDbyVshMMhCsc/zZsel3bOYx98hycpzGLMPZNMmTJ4/0OtiPCGTWqlVLm5cTERFREg46AQ40iYiIyLtFVUqFe1NK5eo8UZVfWZ9zLL9C2Z0JKJnnqlSpooGnP/74Q8v40JAaWVSOWTbknRBgHDFihL5HBg8enNirQ0RERJ4QdCKKi7WHtkmPKYPl6S97SJeJ/WTmpj88auhmnMwMHTpUGjRooNM0bdpUJk2aZC83ICLyFdGVUjkrgYrNPFGVX1mfi2n5FQJaCEhNmzZNHnnkEc2uwvczRjqjqFl7ZyFYaKCMzfH52M6TOnVqvUePLcP8jJJL67TRTTNkyBAdyQ5llnny5InjX0xEREQJhUEn8kg7ju+TYQvHybGLpyR5QJCcu35RJq+ZIzM2/R7lPNsO/51gQzejLATLmTJlipw6dUpLPg4ePKhNbgcNGhRv24WIKDF4S/mVceTIEe3xZL6vkSVDUUOpIgJ2gP9pJniECzCQP39+l+fJmzev3qNHl3HmzJkI05ggUnTTLF68WO9HjhwpxYoV0ws+Bn7+8ssv3bQ1iIiIyJ0YdCKP9NOGhRIu4dKoZA355ZXR0r1eG3181qY/JOR+qNN5pv71a4L1DkG/EASZMHrOvHnz9PV69+5tW8dZs+TixYsJsp2IiCgyjKKL0r62bdvKnj17pHv37vYMHIoMGWjI/gVccDH3pgE8RphzdR5knAEavmMf7N+/Xxu8A3ozWafB6IUIGCLIaIJMNWvWtGfCWW/o3WXgZ2fZWERERJT4GHQij3MvNET+PnlIf25QsrpeSW1cqqb4iZ/cvHdbDpw56nSeXcf2JVjvEIychCurKKkrWrSoPoZyPsAB99mzZ+N5KxF5rpiUuSZmaSw+o2hwXa9ePX29p59+Wv766y83/OW+yxvKr6wyZsyo85gsVlw0QECDotajRw/9nzl37lztj4VyNujatateYEH5eJ06daRDhw4xngfat2+vJZUIJtWoUUMvDKHsEgEnE5hCYAn/c5Gd9tRTT0nt2rXl2LFjkjlzZnn22Wd1mpUrV0a4/fzzz/b1wM9dunRJ0O1FREREMcOgE3mc01fPS1h4mP6cOU2w3qcISi5pU9pOTE5eOet8nrCwBOsd0rBhQz1p/fjjj+3TINsJAgIC7NMTJTUoXX1Ymasr87irNBa++uor+eKLL7SUB6+3b98+PXk2Ta/JO8uv8N4YOHCgjB492unfENUIe2RTt25d/WygdA37KUeOHNKrVy/NEgN85nBBxVqq+LB5zP9blKIjsIT/0wgyIvBk3U/4TH/77bd6sQj/uzEdpv/hhx8kffr0CbwliIiIyJ0YdCKPc/PugxKI5EHJHvwcGBTpeWfzJHTvEMBJK06SAVlRPEimpArB2IeVuboyj7tKY3Fi/P333+vP6MGG6fGZRebFuHHjEmQbeSNvKL9CoHHGjBm6f//++299bOLEifbvcLMuFDVcUJk/f75uf2T/IXhkAocIDGPfYHTAmM5jICMY+2XHjh36mcMFG8cMNfzfHDZsmD6P6TB94cKFo1xXfLaxPrjhZyIiIvJMDDoRxRFObpBJgYAUSgFQ2kOUFKGEymQLRVfm6so87iqN3bp1qwYnEJhCeSwCV3g9WL9+PUef9OLyK5RLoqwS7yns04oVK8p3332nz73xxhsSHGzLnCUiIiIiDw464Sr0zZs3nT6H8oXffvvNtmB/fz2B4EEexVaqZA8yle6Ghjz4OcSW8ZA6ecro50nA3iG4GouA05UrV/S9PmHCBMmaNauLfzmRd/v333/tQZvoylxdmcddpbHmPlOmTBp4si4HWVWmDIy8r/wKpc3ffPONvPDCC7rfsT+RYTNixAgNchERERFRwguM7QzoqYEyBWep9BghBlkeTz75pF7ZtPa7IYqp7Okza9NwjF53/tolyZE+i9wJuSvX79h6tOTKkM35PH5+WraBk0b0/4iqdwgCRHHtHQIYvQ4nMsjGwMg5uMqP0h+ipMpafhpdmasr87irNNbcO3stx/WhyFBKhZszKL/CLTbzOJZfRceUX+EWFVw0ePfdd/VGCQM9GP39/D1uWURERORFQSccvJkTcJzUDx482OlINbiCjFR3orhA0/Bi2QvIvjNHZOmetVI2TzFZumedBqFSJ0spRbMXcDpP8dyFZO/xQ9ozBCNbRdU7BOU66B2CgBGyLJz1DkHGkukdgswlx94hyKZCw2Jk9+GzgKvthQoVSsCtRERElPgQJFp9aIJcvW27OOOq9CmzS63CzEgjIiJKkkEn9MRAFocVTuatkNaO4anbtWvn3jWkJKlttSdl8LyvZNnedbL+yA65edeW5dSq8mMSFBAov25dorec6bPK8NZv63MdHm0p700Zqb1Dli9fbh+tyrF3CBrNmt4hKL+IqncIgk7oHYISHPSAsfYOQUDLlOmgx4jjUM1oSFyyZMkE3GJEic96MSK6MldX5kHJFbIU41oaa6Zx9lrW6Ygo5hBwunTr38ReDSIiIvLWoFP9+vX1BmgQikwnZnVQfKpcoIy81/RlmbZ+gRy/fEaypA2WJ8rUk9ZVmujzt+7elos3rkjKIFvpDFQtWl57h4wZM0aDSugd0rZtW+nWrVuk3iEYtQrNi3Ei26BBA+nfv3+k3iHoA7J06VI9OUUgCtOY3iHLli2zT4/n0cfEikNzU1KEEaRiUubqyjzuKo0101y4cEE/pwhIm2nws+nvRO7D8isiIiKipCvWPZ1wwh4dnOwXLFgwLutEpKoXrqA3Z9pVf0pvidU7BOV3RBQRGjxjWPrt27dHW+bqyjzuKo2tVKmSZi8iQxHDvKNh9a+//mqfH1m7ngKBNwTIEeRGgAzrjuD3wy76xGQ+bF803UbmJwJweO6tt97SEeCslixZooF8NGnH9mzTpk2EQD7gdbDd0ecOPbTKlCkjffr0sb8ey6+IiIiSxjHBggUL9Dzr8OHDkjFjRq0swQAibMGTtMU66IQ37qhRo2Tjxo36xjVldrhHCRKe37t3b3ysKxERebgePXroyGRRlbmiVBu3fPny2S9iPGwed5bGorwO5bDjx4+XAQMG6IEYmocjw9E6oponQN84/K/F3xEYGCirV6/W0TIReEuXLl2c5kNWKG6A4N6+fft0P2Cf4IAU1q1bp43BTQDw5MmT8tlnn+lz5iATgTsEmACZozgG+PPPP2XDhg0ye/Zs+0Uoll8RERElnWMCLPvcuXN6LLB161Y9xrMO3EJJS6xz1JH5MWvWLD1hwBVhvOlwVRNXjXGiMGTIELevJIZGRlS1du3a2jfqpZdekuPHj0c5/eXLl6V3795SpUoVqVq1qnzwwQcRenbA77//Lk888YSerDRv3lw/SLFdBhERRVS3bl09cClWrJh+Z6LMFVe4TEAHI8yhHPX8+fMxnsdaGovAEv4nIMCBLKXRo0dHKo1t1aqVZlBhOkyPRv+mNBZw9e7NN9/U10HPJ7wuXr9y5criKXCAaA4ScdUQB4koRcR2wwiycZkP29hkeyLohunRuxFBPPSjM8aOHasHl9jOmzZt0iAdIGBnSojxM+D/6ObNm2XlypW6XRHsmzp1arxuIyIioqTAW44J8BpomYBAF6ZB5jogMwptTSjpinXQadWqVRrlRArec889J9mzZ9eD/j/++EMP3A8dOuT2lcSbfPr06fLhhx/Kzz//rCcSuAIeVd+cN954Q44dOyaTJ0+WL774QlasWKF9qIz169drFBYpgSirqF69ukZokQYY02WQ5wlIGaT9PtzFncsiSkpQ4oqrXSh/++uvvzR4hIMQwP+P/fv36/+MmM7jWBq7Y8cOPSj6+OOPIzX+NqWxeB7TYfrChQtHmAbBqVdeeUUzcvB6eF30dvMka9as0XtkbhUoUEAztHAQaH3O1flwxRFBIRyENm3aVLcHAnXm/yMONNGrzhwgtmjRQvcFpsE9MsNQ6oj/xaVKldKyxNatW+tykEqPcknH3lpERETku8cE8N1332m7BHPRENlQgOlQjkdJV6zL65DNhDcuoN7TREZx1fmFF17Qq8X9+vVz2woisITXePvtt+11pSjvQ9YTenXgw2GFsgqcbCBl0NSqIvsKQSpcOcfVcnwgcILTsWNHff7dd9/V+XA1HNPGZBnkefyTB7J3CBH5BFwVBFzYMXLlyqX3ZuRMV+cz95kyZdKDTDAN1PE/Fw3dkQGGA03rspA9liFDBs0ExjKQGYYBF6wwP4J9pvk7ERERJY1jAjAldDhXR3kdfn/nnXekSJEibtselAQynYKDgzWiaUYDunjxoo4oBAjGOI7iFVeoKb1586ZmIxmoEcVw9Ejbc4T0/ixZskRojobyOERYEaHFlVlEdK3LAzSvNct72DLIs5neIXG5xTVoRUQUFyhDhJQpU9ofQ5NuMP+DXZ3P3Ft7K1h/xvPW13A2nXkdK6TdIyMYGU4ov3/mmWdi9TcTERGR9x8TIBCFgBMgcwqBK5yDU9IV66ATgjWo70S6HK5iopTBjPyDUgUEpdzJDGWNHhFWSNEzz1kh6OU4LRrRIhKLA2FkaiGF0BrxdVzew5ZBRETuxdJY74aDSfR3QMNQQGo9r2oSERElPaiAMgOK4BwaI9yiooiSrliX16HXEcrSUJKGJqE4sER6PQJRCOi8+uqrbl1B07zbjGBkjdJilBxn0ztOa6ZHPSrSA6NaHp6PyTJcZUb4iynHfiauwnIQiQ4IjnstrVkGtqMZudAd6xYUnCrOywpMl9JeGhdXZhl4L7jj70yK+9eX9i2+2zBCB3oNIdW4YsWKWvKL+vjo9i3m+/TTTyPMh35y1vmwDvhnjH/MyBzFc2jAWKdOnQj79q89R+S7ZRvl+IUrkiltamlZtZR0qFMxwuu+O+13WbnXlkpt1fOJmtKmRrl4+fy683tg58mFcvPupTgtK3XyjFI2V9N4++xiXXHFMFuaB43JXWWWgf6BGJ3PCkMWAzJ9zf9Bc6URPRmcDWxh1u1h85mrnHgfmGlMxjIgvd6k0QP+15reWWZ6LMP8jGkRcMIAHYAmoxjwA8+bfesN38vu3LdgluPO79PgdHH/PjXLcOd6JbX9y33rWfuXn13X14ufXc/bt0iC6NChQ5yOCczxWXwcE+A5zOt4nu54jovHMIItekihaTl6eaIfdFLfv+Fe/NnFNK6ev8Y66ISO9+h1ZOo/MfQ0hqNGyRpGgkNzMXcyaXs4YbOm8yH4Y00VtE7vrME4pkftqflgOU5jXd7DluEqjPC3d+/eGE2LD3jJUqUkMCBA3CE8LEzSN2zrlmWFhYW7dcjL8LBwyd6whNsyHNzVi+n+/VA5ePCg7jd3Syr711f27dChQ2XPnj1aMoThZteuXas97EaOHKlXc6LatxigwDpMLebDY9Zhar/88kv5+uuv9Wec2B84cEBHVzPD1GLf7kmdX/r/9IF9mNozV67L2MXrJWWZmvZhauHotwv0HuXBSGc2stR4XDK2bh0v+9fP389t+xfBIm/57LYrV9sty8P+xfvKpKEb6K2AICQeN/+b8DsgMOns/x/2LcreIbr5cBBoHsdr48AQqfDWg8Q7t+/YD1ovXbqkWUs4KDEXe/C7Wf7AgQPtASccKL/33nsRDkq87XvZXfvW7F93fd6wfxvVKua2z67b1iuJ7l/uW8/Zv/zsuoafXc/ctzhejOsxAfYt+ty665jg1q2b9mMCZDAhcIXzYnNMgMf//vtvDS6hYgiDi5jeUWZZuBDr7Dw4qe1fb//sOkvMiZeg04svvqgNta09kZo1a6a3+GDK3PBhsTYlxe8YLc8RyuaWLl0a4TEEkBCVRQkdSuQQOHL8MON30yD8YctwFT5UjqMoRQUfbJy0TtuxSs7eiJzRFduoLz7I7oyuLlm9Xy5fi3nWVnSRX3yYPS3zwojp/oqtpLB/fWXfoscbAk74/M6cOVP/8WPkS5QYY+Szzp07O923H/00QQNO/oEB0vKD3pIqfVqZNegzHab2tU8GS/nH60vI3Xvy43e2IefrvdhGilavJEvHTZEjm3fKux8PkS4D39Z9iwEa8Lc//fTT2jMHo3giw/Tbb7/VdcG64QrTiRMndFlz586NFAyzZp24Y//mzREsj1TIL2eW7pWQy3FbFrLhEJx013slPj+7EHLvnrjjsNrsj7T7Vsm6oT0iPLf+4L/y1g8LZeuWzbJt7GDJnDa1/D5npj5XMZ3IpZlfRJg+KG8xSVutiSRLm1t/R//Bryf/JmnTZZDZv9qCkWkzFZAZi7bJnTuBEhAQqAcYAz/6SipUqSszp9oGBclXqKRs2nlc922J/EVlz9H9MuXz7yTnM4Eyb8MS3T+pU6SSjAfvy/GjW+T3LX/JjF9n6LxPVH5UOhV7XE7M2ipJfd9a9+/VpT/J/csRjzliC1mKuLDgzu95fnZdx33refuXn93Y4WfXc/dt+OVbsnTo9AjPbzq4Q/r9MEK2btkia8cukIxpM8iiOfP1udLp8svxmQ96DqfMm1EyVyugAyv5Z7dlv2/Zulkm/dFH0gWnlF8XLNLHMhW6K7/tGip3UtyTgEB/PSYYOrabVHm0kEydtEqnKVgqs6w7OkkDHGXKlNFR6jA6HUaumzFjhv7dyHrCwF44FkXwAv2YcayMQbhwfo3jaKhVq5aUKOH8QnRS2r8hXvzZPXTokMuvEeugEzKa3FUWFBPFixfXNzOiqibohEgpTgIdyxGgSpUqWs6CcoV8+fLpYzjxA2QNYN1R4oLHEIU1sHzTdf9hy3AVXju2mVIISJy8FrdyE8Od2Uk4Yb1w6abblufOdfMmSWH/evu+NYMHYNRO88+ySZMmMnHiRP1e6NEjYrDA2LXJduIdnD+33EwVIDdDbkmWskXl+vL1cnjH35KlZnk5v/+IhN69J34B/pKqZH45deOKZKpYQoNOJ/celNPXLuuVJIyoCWjMjO8QBJo++eQTbdyIzCh8d+GfPP75IPMUt/jevxn+K3nEP8+7FyI3lU6K7xVX4cAo9IJtWGGjYgZ/KZ0jo+w+fUnaf/mzBAX4y+2Q+5IxVXJ5skAG+/QtJ/xP7999vrk0q9ZEsuUuKjlyF5bTJw7JVyP6/BdcuiupUqeTAsUfse/3CtUay+a1i2Tuz+Nl0a8/yr27tqBkuapN5NpNWxl6+9pPy3tHR8qS7atk7d4tcvOu7UCpVcXGEnbljtwKuy8/LLEFwmDtns2yYZ/tvQplcxeT99r3TNL7Nqr96yp3bkd+duOO+9a3cf/6Lm/bt6UzFJASOQrJ3tOH5aUv35XAgEC5E3JXMqRKJw0KVLXP03HCO3qx84NhH8qdrGckS+EQyV0knZw4eE0+6bVAAgL9JORumKROHyTFaqbQwZOgWpNcsnbhcfll3DqZ+8NGuXvrvuB0v+oTWe2DK6H1A9rqLFy4UFauXKnn44ByevR4BoxSh+QUZD+vWLFCj2FRmoesp1deeSVOFUO+vH+95bMblxhQrBuJY/jD+fPnx0v6ZFQpXAguIQi0bNkyPbFC6QmykRo3bqxvZGQOmF5N5cqV06ASpkE0dv369fL+++9L8+bN7ZlMKAn87bffZNKkSXL48GE9eUO6X6dOnWK8DCJKGlwdpvbq2fN6nyKDrRcOpAq2/VO+cc4WaLz5333ytKnF/79SSzNNWOh9uXHhsvz7779RDlNrXYf9+/fbszLx3YgrUghSrVu3zk1bghKSv5+ffPJ0NXmyVF5JGRQoYeEiVfJmkdGtakjaFA9Sm8/fuKO3O/ds/5NRVvlUmzekZPlaEpQsuQYi8xYsKS079JEUKR9kv9Wo30Kq12shadMHy/3QEMmcNbc0bf2a5Mr7oPl31aLl5b2mL0uBzLnlbug9yZI2WDrVaCHPVnlcnz949phcuGFLm4crt67LxRtX7Lert91zYEVERJSUoVRu0NOvSaNSNSVFEP63h0mFvCXk41a9JG2KB//b8b/3/JWL9vNitEB4rldpKVcnuyRLESBIjClQOlja9y0nKVMH2ed79JkCUu+Z/JIuY3IJvRcmWfOkltY9S0neYg/6LNWtW1cz71FphOx5VCP16tVLA1FGzZo1ZfLkyXoxFMcjSBx56qmn5KeffpKMGTMm2PYizxPrTCf0RELQCRHMQoUKRYpYIgLm7u70aF4eGhqqjUrxIUImErIMkMaHcpIGDRrIxx9/rM1L8fr4QHzwwQcaRML6IiuhX79+9uUhvW/YsGEyduxYGTVqlKaUoRE6/h7zNzxsGUSUNLg6TO2927Z/+AFBD/6p+wfZvnJD79gGJAj5797ZNLZl3I7xMLUm6IQrT7gogNHEdu3apVec8J1sMjnJeyC41LdRBb1FZdWbT+t98sKl7Y8huNSoWRe9RcXPz1+q1m6qt+hUL1xBb84Uz1FQfnvTVh5KRERE8QfBpTcbddJbVPA/OU3hLJK9UUn5bZct8xjBpWZdi+ktKghO1Xoqn96i07BhQ71Fp1q1ajJt2rSH/j2UtMQ66ISO+igzMRxrCeNj1AI0NcOIT7g5a2xuTrYM1JGOGTMm2mUiawm3qMRkGb4EjeCGDx+u2WTIlEAZYf/+/e2BuKjcuX1TVi75RY7s36aNyHLlLSp1GreRjJltvbjMe2LT6oWya+tKuX3zmgRnziE1Hm0hBYqUi7CsJUuW6DZHZgl6Z6GEyNok2VkPL6Nq1araeJkoqSpfvrxeecI9SocRfEK/KWSHIoiOK09EREREREQeHXTiib1vQp2udZSt1atXa5aXdZQtZ36b+bWcOLZf/P0DtDzo2OHdMnvKSOn4ylBJnsKWBbdh5Xy9QbLkKeXC2eOy4Jev5JlO70jmjOX1cZQAvf766/bRudCkGUPUgwk8OSttRGklMjpY9kjugKD6s88+G+k9BiZV2fqzGUbemaD/MpHuh4TaH7v/X1lyYApbplTgf2VSzqaBZClT2oelBdTGG2aYWvM8mozjZgQHB2v2J7I6MaJITMQkiOzM9Ts3ZcLKmbL+8HYJuR8qpXIVkW51n5U8GSMGn3/ZuEj+2L1SLt+6LnmCs0vHms2laoGysQo+A4bdHT9+vE6Dhum4qta7d2/JmTOnJHXuGNo3Xeqk2eODiIjIV6RPmd2jlkNJW6yDTh07dpRBgwY5zYDBFXVkIy1YYBsph7wDgk0m4IR9h+HWcfKK0kUMfYkGcc4g2IQbGtW26/6BpEqTXqaPHyzXrlyQXVtXSOUaj2sD263rbI1uGz31gpQoW10WzR4nh/ZukY2rf5Oy5WxBJ5Q64qTUnCRPnTpVh6nHiSWyNdDbC03rHNcb70dku2HIbqK4Qhkvhnp1Nkzt6dOnIwSnwAxF60y6rJn0/vblB6MT3rliK5VLk9VW1546U7De371+Q3s4ofmjmQY/p8kcrO9vM3LfqVOnJE+ePBGGrjfrsHbtWl0vlB9jGvP3PCw4FtsgsjMfLfxGdp04IIH+ARLgHyBbj/0t/WZ9JuM6DpE0/803ff0Cmb5hoe3vTpZSjl44IR/OHysjWr8tFTLHPPiMxpQ9e9qaUyMgjqF40dQSfflQ+o2geVIUfveOW4f2JSIiIu8TdjdUwsLDdMQ5ty0zPEz7ShG5KkbvHgx1uGnTJr3hRN/87HjDAf/x48ddXhlKHGvWrNF7lE0WKFBAMycee+yxCM858+9hW/ZEjtyFJDhTdkmePKUUKWHrG/PvEdtzp44f0sATTmKLla6mfURKlqulz504ulezlJC9YUYIa9GihZ5gYyhO3KOfDZq5O0IJIAJNODnFEPJm1ASKDMEJ9CNDCSJKr1588UVtoB+TrJfF87+XcSNfl6+HvyJzp4+SSxceBF4A23/jqgUy8Ys+8tWw7jJt/GA5enBHpGUhe6VZs2ZSunRpqV+/vgYTHSF7BUFHvA/Rdw2ZKwiyJCRTrmu9jRgxQp/DCHJHjhzRHkqLFy+2N0yMSq4StuFHL/9zQm6cvaj9m07v2KePZS5WUO+DC+bR4E74/TA5sXmXhIeFy4mNtvd7piL5tQkj+uZhcAOYM2eO/d4EZsqWtWUKYUAE7Gf0t8Nn6tKlSzJ79mx9rkaNGg/9261B5PYvD5Gub30u6TJklls3rmoQOSo7ju61BZwCAmVsh8Ey9aWRki1dZrl865pmNQFGWJmzdYn+/FbjzvLzK6OkZpGKehCD7CfDGnzG/xT08QO8X/CZh3nz5ul927Zt9f8R3lvob4X3dFyGcvV2Ybevi79/wo0sS0RERJ7n/u0QtweIGHCiuIrRJeGZM2fqgT6CALihwbYj08upadPom5KS74zOdfmSLdsjTTpbtgakTW/L7rh80ZYtcuW/+1Rp0unJLKT7bxqU71y5dD7a0bmQxYB1cGyCPH36dH0cIylgREXy7tJJT85eQWAJgTAEnTACB7bjrVu3JHPmzBFK8erUqaP3yATF4Aa5SxaV4AK55fLRE7Lik/G6De/fC9GR6vJWt22boBTJpUC9anJ42VrZ+ctvsmfuUluTcT8/KdLoQUCrR48eOjrI3LlzZfny5fZhatEkHFmAZj/jhr5sKDdDlhMaiiNTC48/jGMQGRBE3rLuDw0iI3PRmS2HbEGyEjkKSq5gW5lrrSIVZfaWxbL12B55pnIT2XvqsAaekAlVr1hVPXhpVLKmrDm4VXYc3yf3owk+f/TRR/bgM74HTPAJATmTAYYbev+hpJCIiIiIiDxHjMKWuNr8448/aiNaHNwjwwSjIVlvKIfCyeHIkSPjf63JM0bnumvrKRMYZJvW9nNQhOfummkCHwzxHRj04Oc7d27FeHQuAwEqvB/NSTfFvHQSASdk86BPEUono3L00J6HZr04lk6+3GeMFC5RSYdxRemkr2SvILjx7bffagAEwVBk5yEQhe89a4YdyvJwezBMrb9UeelZyVOtnAQmT6bbIHOxAvLIq+0kWaoHn7XiT9aTYk/UlZQZ0klYSKikzZlVKr/4jGQsaCuRi+kwtRhNBOtZsWJFDcBg+zVq1EiHqbUGlOMSRHbmxH/Zb5nTPJgvazrbfKeu2OY7+d99hlTpNCPKOg16QJ29En3w2RoAf+6553SfYGQUlBI2btxY90nfvn3Z242IiIiIyMPEKH0A2QkozQGc7JcqVUqbtxIlBmRyIFumSJEi9vclxax0ElA6OXHiRH0uqn5dh/bvfGjWS1Slk+jX9bDSSW/LXkFwCb3GcIuK4yiagOBSubZN9RbdMLVFGtfSW1yHqUVwCjdXxCSI7MzNO7bnklsCy8kCbfPd/G8+c588KPI0ZhlBMQw+I7MRmV8IwpmML2TCoe8WERERERF5llgXaOIkHyMhbd++XX9Hz5WXX35Z+7V8/fXX8bGO5EZoNIwyIOsN5U+ujM6VLJktWyM0xBYwsP6MUitIntx2whga+mBELgQqjBQpUsV4dC5j6dKleo8sDoqf0smL50/He+mkdR2YvUIxhfcIAk7oDbZhwwaZMWOGXgQZN26cZtsSEREREZHniHWjFPQUQbPaF154QZsSv//++5rJgHITHPSjjMdxeGvyzdG50gdn0fvr1y7ZH7t+7bLeB2eyBQrSB2fVe5RlIRCB4MSN/6bBzxkyZonx6FwGRumy9tAh95dO3rl9K0FLJ30xeyVbmvQesQxnrl65KBNH28ocjZs3rjw0iOxMqhS25+7dfxBYvvvffKn/my9VMtv+vhd6L9I0Ol2KlDEKPiOAOXr0aP0d7xcEL3FDL0EEoxCQRt8tIiIiIiLy0qAT+jqhTKZPnz7aFwYBAIwyhRGxvv/+e+0Tw6CT5zKjc1mtWrVKeyOZ0bmyZs0ao9G58hQooeVWp48fkssXzkiqtOnl0D5bKVXegqX0PkeewhpcQsBp3651UrJcTdm7w1bylbtAiQijcyF7DqNyoQmys9G5AKMj4n2HsqsSJUrEyzaixM1ewehrx44d09I/BLILFSrkdYEEjMrWrlztBBmmFsHZ4cOHa9kpyhQrVaok/fv31+0W5TLD7suN67bgr2EbRe++QxDZ9vPtm9d0dMLgzDmkxqMtpEAR22h6kDOjLcB8/tolGbt8uvy28y8pmMXWjypnBttzOdLbAtQXrl+WFl/2kBRByaVwNlswOSggULJlyCJZYxB8RhDSBCUxrX3d/f0jBKiIiIiIiMhLy+sQlGjevLl9xCmcIGCkJihTpkyEbBnyDmZ0Lox0hZN7ZJ3gpN/Z6Fy44eQW8hYsKTlyF9YT2Knfvi8TR/WWq5fOSarU6aR0BVsWUvLkKaVCtcb689IFP8i4kW/IgT2b9ISxSs0n7ctG1gIeQyYdyquGDBkSaXQuMFlaKBGzZs6Qe0snk6dIuNJJZ9krCEKakTBNOaU3cefQsg9bFkamQ5AWI+qBGZ3QBGecCc6YVXLnK2Zbvn+AZqiF/VcGaYLIyGTbvXWVPqZZioFB9tEJTx0/aF9W+YIl9f7vU4dk0U5bk/kzV8/rfcV8tudyZbSVVmKM0zBkuN29JVuP2UbLK5enuARYgs+Av8fcW4PPGTNmtL9vJ02aZM/c/N//bA3tS5cuHevtS0RERERE8SfWZ0YYztyUxCBDJmfOnPbyJ/Rv8YSmv5RAo3P5+ctTbd6QkuVrSVCy5HpyiEBUyw59JEXKB43ma9RvIdXrtZC06YPlfmiIZM6aW5q2fk1y5S0Sq9G54MKFC3pvegLRA+YE3Hozn8fYlk5mzJwt1qWTEFXpJCB7BZi94pmjE5qeXSaIPGFUb7l756Y+Vq9JuwijE86Z8qns2r5BnyuYPa8Ep0qnGVnhGlYSuXXvjo5U91hpW7bXn3vX218bQUZr0/FHCpWPcfAZJZevvvqqPrZw4UKd5tFHH5Vz585JlixZpH379m7dvkRERERElMDldSh9QnAAw5gj46VLly76OK40f/HFF1KrVvQjMJFniu3oXDMWbdN7BJcaNeuit6ggOFW1dlO9xXV0riZNmjgdJYzcWzpZsEhpWb18QYKUTmI6/Iz+T8heGTFihAaimL2SsKMTFi1ZRctlU6dJr9lrJrMNn9/SFetEGJ0Q+/zuf8HnMfMnyeVb1yRlUHK5E3pP922mNBlkaIs3JW0KW/B567E9el8uTzE5deW8To/R6+6FhsjVW9cjBZ/HjBmj71cEn9u2bRuhZBv/c/A43isHDx7UfmXVq1eXd955R/vTERERERGRFwed3nvvPe3nhBMDHOibTBT0YUHWE/o7EZFnlU4i6ITSSWTEoAzLWekkDBo0SMtlCxUto6WTp08c0qwXBJdQOuesdHLz2kVaOrly8S/aZNxZ6SS+J5C9snz5cntWk7V0Etkr6EuE7BVMg1I8ZMQweyXhRyf08w+Ql/t8Ljs2LZe//pgmqdOmjzQ6IeQvZCvPS5EsuTxVvr60r/6UfDh/rOw6eUCqFigreTPltE978oqtLLZusWryWGnbhYlhv42TNQe32p+LbfAZNyIiIiIi8rGgE3pq4Cq6o+nTp2vQiZKG4HSpPGo5FH3pJLKH0BsJwRwEotBo2rF0EkzpJOZD6eSqpTPk8L6tcj80VEsn6zRuG6l0EqWVu7etkFs3rmnpJEopnZVOMnvFt0YnvP1fD6l3Wr0ioZdsP0fl1n/LspbVmZ9v/vccERERERH5nlgHnaLCgFPSERYWLo1qFXPr8vz9H/TyocQtnTQSo3SS2SveJ0WmNBLyX/8tv6AAvQ9IESTJMz9oIi//fbyD0qawP+6f3Pbvxz9ZoAQFM/hMREREROSL3BZ0oqTD3QEiBpyIHg4N4K0lkYCG4Yk1OiEyoMLDwiV7wxL2x1LMTyvyj0jqgpklT+tK9sfTfJpWrly5IqnL55A8z9geD1hly5jLWiy3LgPL8uN3ARERERGRT2HQiYjipeyRpZPxMzqhFUoP0XQ9IUYnRF8n6+iEyVMHxzhIlDdvXg06RbeeDDgREREREfkeBp2IKN7KJ1k66dujE8bUI488Ijt37pRFixbp+v7777+ye/dufY4jnhIRERER+S4GnYgoAncGiRhw8v3RCWMCIxDOmDFDA2M1atSQe/fu6eiECDiVLVvWzVuFiIiIiIi8OuiEYbpXrFihJzdhYWERnsMJCYY/JyIi3x+dMCayZcsmU6ZMkeHDh8uWLVskderUGvzCehIRERERke+KddBp3rx50rdvXwkPD3f6PINORERJa3RCA4GlqBQtWlS+//77GC2HiIiIiIiSaNBp7NixWh4xdOhQyZ49uwaZiIiIiIiIiIiI4hR0OnXqlAwePFhy5MgR21mJiMgDcHRCIiIiIiLyyKBTgQIFIgx7TURE3oOjExIRERERUUKJ+ZjX/+ndu7eW2G3YsEGb1hIRkffg6IREREREROSxmU4fffSRXLx4UTp37uz0efR42rNnjzvWjYiIiIiIiIiIkkrQ6amnnoqfNSEiIiIiIiIioqQbdHrttdfiZ02IiIiIiIiIiCjpBp0AvZz2798v9+7dk/DwcH0sLCxMbt++LZs3b5a3337b3etJRERERERERES+HHRCA/GePXvK1atXnT6fOnVqBp2IiIiIiIiIiJK4WAedRo0aJcHBwfLhhx/K/Pnzxd/fX1q2bCkrV66Un376Sb777rv4WVMiIiIiIiIiIvLdoBPK6oYOHSqNGjWS69evy88//yx169bVW0hIiHzzzTcyfvz4+FlbIiIiIiIiIiLyCv6xnQG9m7Jly6Y/58uXTw4ePGh/7rHHHpM9e/a4dw2JiIiIiIiIiMj3g0558+bVbCcoUKCANg8/cuSI/h4aGio3b950/1oSEREREREREZFvB52aNWsmn376qUydOlUyZswopUuX1v5Oy5cvl6+//loKFy4cP2tKRERERERERES+29Opa9eucvnyZdmxY4e0b99eBg0aJC+99JL06NFD0qRJoz2diIiIiIiIKGoYDXz48OGybNkyuXfvnlSqVEn69+8vhQoVina+63duyoSVM2X94e0Scj9USuUqIt3qPit5MuawTxMeHi6/bFwkf+xeKZdvXZc8wdmlY83mUrVAWfs06Mc7bdo0mTVrlpw4cUIyZcokderUkTfffFPSp09vn+7AgQMybNgw2bZtm6RIkUJ7+/bt21fP/YiI3B50wmh17777rv33MmXKyNKlS7XErmDBgvzyISIiIiIieojXXntNNm7cKEFBQRIYGCirV6+WTp06yaJFiyRdunRRzvfRwm9k14kDEugfIAH+AbL12N/Sb9ZnMq7jEEmTIpVOM339Apm+YaH+nDpZSjl64YR8OH+sjGj9tlTIXF4fHzJkiMyYMUN/xuudPHlSpk+fLps2bZI5c+ZIsmTJ5NKlS9KxY0dNOkiVKpXcuHFDZs6cKadPn5aJEycmyHYioiRWXmeNzCMq/9NPP2lkHsGm1KlTu3ftiIiIiIiIfAyCTSbgtGDBAg045c6dW86fPy+//PJLlPPtOLrXFnAKCJSxHQbL1JdGSrZ0meXyrWua1QR3Qu7KnK1L9Oe3GneWn18ZJTWLVJSw8DDNfoKLFy9qhhNgZHIEmhBw8vPz04Gi0DoF8BgCTkWKFJG1a9fK7NmzNQkB67tz584E2FJElCSDTiihq1u3rrz66qsaIUek++OPP5bWrVvLtWvX3L+WREREREREPmLNmjV6X6FCBR2cCRfwMRK49TlnthyyBXpK5CgouYKzSarkKaVWkYr62NZjtlHE9546rIEnZELVK1ZV/P38pVHJmvrcjuP75H5YmFy5ckUaN26sJX3o2QsVK1aU4OBg/fnMmTN6j+ASNGnSRFKmTCnFixeXUqVKRXiOiMitQSc0EP/yyy+lS5cumo6JemFAf6fjx4/LF198EdtFEhERERERJRlHjx7V++zZs9sfy5Url97/888/Uc534sJpvc+cxhYcgqzpMun9qStn9f7kf/cZUqXTjCjrNOgBdfbKee0bhfM2ZDKhTxMcPnxYy+kgT548EdYlW7Zs9tfLmTPnQ9eTiMjloNOUKVOkW7du0rNnT3uUG5D5hKZzJhWTiIiIiIiIIkNvJED2kJE8eXK9v379epTz3bxz2zZtYDL7Y8kCg2zP3b0d4T55UORprMuwwmv27t3bHlSqXbt2lOtpglTRrScRkctBp1OnTknVqlWdPodG4hcuXIjtIomIiIiIiCgRoGdT586dZe/evRIQEKA9ntBEnIgoUUavy5Ejhw6XWaNGjUjP7d69W58nIiIiIiIiW3+kZ599NsJjaBgOd+7csT9mfk6bNm2Uy0qVwpZxdO9+iP2xuyH39D51cttzqZLZMpHuhd6LNI1O998yAOV0GDHvwIED2iB82LBhUrNmzQfTpk6t/Z9iu55ERC4HnZ555hnt6YS0ynr16uljt27dkv/973/y7bffaq8nIiIiIiIiEgkNDZWzZ219loxMmTLpCHIYkMkwzbvz588f5bJyZrT1Vjp/zdZ7CS7cuGJ7LoPtuRzps+j95ZvXtIdTUECgXLhxWR/Dz9ky2J6/efOmvPjiixpwCgwMlE8++USefPLJCK+XN29eDTrFdj2JiFwur3vppZekRYsW8umnn0rTpk31sY4dO2o/JwShunfvLu529+5d+eCDD6R69eo6wgPqjU2Tu6icOHFC1wWjMNSqVUtGjx4t9+/fjzDNtGnTpEGDBlK2bFl5/vnnZc8e24gPxtatW6VDhw46qgPqmt977z390iUiIiIiIoqJ3Llzy/79+yPcRowYoc+hguTIkSPaO2nx4sX6mDXTyFH5giX1fu/pw3Li0hm5dfe2rD20VR+rmM/2XMmchbWBeGjYfflz33oJCw+TZXvW6nPl8hSXAH/bKSDOr8z5z/DhwyMFnOCRRx7R+0WLFsnt27d13VHdAjjHIiJye6aTn5+fDBkyRDOa1q9fL1evXtXUyipVqkjRokUlPgwePFg2b96sGVaoLx40aJC88cYbOpKeMyEhIRq1R/T9559/ln///VcDRkgZxXzw66+/ajT/ww8/lJIlS8r48eP1b/r9998lY8aMOqIEltGqVSt9fdQ644sZDdR/+OGHePk7iYiIiIjI9yGwhIvpCDo99dRTEhQUpNUjmTNnjlCKV6dOHb3H+Q8ullcqVEZK5CikQadXp36gwaU7IXd1pLrHStuaf6dKnlJaVGgoMzf/IWOWTJEJK2bKzXu3xd/PT56t8rh9pLr58+fbz+9GjhypNwMX79u1a6cjlGPEcgTG0F7l3r17eiEfASdcuCcicnvQyShQoIDe4htSUefOnSvjxo2TypUr62Off/65NGnSRL+k8WXtCKV+aHiOL8j06dNrMAzpqwgyvfzyyxq4wvLwJYoveUD9csOGDWXmzJn6JYvXzJo1qwar8EVsvuzx5Xv8+HH7MKJERERERESxgYvhaE2CjKelS5dqZQcCUf3799fzF8OU5Zk+Sphv0NOvycRVs2TdoW0Scj9EKuQtId3qPidpU6S2z9exZnNJkSy5/LFrlVy+dU0KZM4t7as/JaVyFdHnly1bJuHh4foz7h3L/1B6B9myZdPRy5EJtWXLFu3xhOAX1pOIyG1Bp379+klMIUCDAI674MvNmtoJCHbhC3DTpk1Og07IiipVqlSEL2zMj7RVjMqAFNd//vlHy/UM1DEjqIVlIuiEYNSjjz5qDziZvw2Q3cWgExERERERuQrnKjhviu7cCeVsjhBcerNRJ71Fxd/PX9pUfVJvznTr1k1vMYEL+N9//32MpqUHcM6IYB0CfMgQQ8sWBOsKFSoU7XzX79yUCStnyvrD27UnFwKF3eo+K3kyPhiwC4HCXzYukj92r5TLt65LnuDsGmisnblGhOoftJOZNWuWtp5BHzFkzqEtjvU8+dVXX9XAp7MYAEY1JEqQoBNK0RBwQaAH0fXoWIM07oCoe3BwsCRPnjzC48hCMk3sHOHx7NmzR5oe0AQPASZwHGkP0+zbt09/dvZl8N1330mWLFmkWLFiLv0t+HJA2mxMYDumTPlgZAl3QB22uaJBiYv7l4g89XvAU9fL23jqdvTU9fImnroNPXW9vI2nbkdPXS9vktDbsEePHpoMgXNP3FavXq29kOfMmRNh5D/H9fpo4Tey68QBCfQPkAD/ANl67G/pN+szGddxiKRJkUqnmb5+gUzfsFB/Tp0spRy9cEI+nD9WPs+aSfJIJV0vtMTBawFe7+TJkzJ9+nTZsGGD/PTTT1rSCeb8F6Wd1nN9U/LpLTz1M+LnoesVW3g9V2M9MQo6Pf744/LXX39phBZlbWgyh0itOyDqihTNqKCHEsrhHCEIhTRUZ5B+mi5dukjTA+bBTgLH5Ua3TKS+Yht89dVX9g9obCHajEyrmMAbE72m3Al9qszfTu6HTDr0GUN2HkYpQXASjehz5coV7f69d+u27Jm7VM7uPiBhofclY8E8UqpFI0mTLXOED/mhJWvk2Nptcu/6TUmTLZMUe7KeZCtlS5GGgwcPyrx58/R9imF48RkoX768tG7dWtKkSWOfDuWp+AfoCOuKzzoRJQxP/Z731PXyNp66HT11vbyJp25DT10vb+Op29GsV1CwLegQF2YZSW3/JuS+xTmfCTjhPBKZRcgcwjH6N998I82aNXO6XrtO7LcFnAICZWz7QRKcKp28Nu1DOXvtgmY1PVO5ifbwmrN1iU7/VuPOUr/EIzJ80XhZc3CrTF8xVx5/+3ltQ4PEETMQGCp4MEohehSjnxcyoKpVq6bnzQhGAdbTMTgS03NXT+Dpn113SqzPrrO4jNuCTqNGjdI/6s8//9SRC9BwG5HQJ554QgNQJUqUEFchewrLjMqKFSs02OUIwaGoIoYpUqSINI8JJqVKlUqfB2fTOC4TgaL3339fezyh6Tj6PrkKwarChQvHaFp3Z4yZssSkdDUjoeEL3Xo1Y+fOnfrl7Xg1w3H/bvl+tlw8dEz8AvzFPyBAzu87Iuu+nir1+r4sQals79UDf6ySg/9bpT8Hpkgu106dk80TZ0r11zpIrvIZ9XFcsbBezbhw4YIsWbJEGz9ar2aYDEHHqxl4f8Tls0xEseOp3/Oeul7exlO3o6eulzfx1G3oqevlbTx1O2K9wsPCJHtD9xyrYVlJbf8m5L5FSR3gAnD9+vX1Z5w7Y0AqBH2sx9zW9dp6zDaaYIkcBSVXcDb9uVaRijJ7y2J9DkGnvacOa+AJmVD1ilXVUspGJWtq0GnbkT3a6D1Dhgx63orzgRdeeEHPf/GaX3zxhQ6QhXMV/L5jxw5df5TeYdR3b+bJn113S4zP7qFDh+K/kTiCMfig4IaMDpzMIlg0efJk7ZHUtGlTDUDFtrk4ToSjq2tFHfOVK1c0QGSNrJ07d04DVs6gtA6RXCtMD5jHlNXhMetrOy4Tf+drr72mgQRkh8Q1CwRvOAS9Eou70/rogY0bN+r7BO/nBQsWaBnm008/rZl8GBkEASlnTu0/rAEnBJvqvPuSJE+XRlaNnCC3Ll6RY+u2SeEG1eX+vRA58ud6nb7c880kd+UysvWHOXJ6xz45uGSNlClfThvlIzAKQ4cO1eymrVu3yvPPP6//2NatW6dZimgKaa5moOG+NQOKiLyfp37Pe+p6eRtP3Y6eul7exFO3oaeul7fxxO3o5+/vkevlbaLahjgHgJw5c9rP//Lly6f3GJQqqnPCk1dsDd0zpwm2P5Y1XSa9P/Xfc2YajFiIjCjrNCGhITqgFjJrUKFjhXMCBJwA58BYh2PHjtnmCwmR5s2baysaVGv07t07Qv/jpMpTPyMpE2G94hI8i75BUxRwotqiRQvtcYTa1BdffFFPcJEm2LJlS3EnlPGFhYXZG4qbdDL0eqpSpYrTefD4nj17NGhkrF+/XkdbKF68uEZyERxDPauBcigEDcwyEeRCQ3Fkq0ycOJFlRxStNWvW6D0a2+O9hc/IY489FuE5Z07stjWHDC6QW9JkzSRBKZJL9nLF9bEL+4/o/aWjxzXwhEyoXJVKiZ+/n+SuVk6fu3jwH/18IDDbuHFj/byYdF1crUA/NGt2E4KxiIojy4kBJyIiIiIi9zPnodbggGn3cv369Sjnu3XXVjKVPPBBskWyQFu1ws3/njP3yYMiTxPV8vEYAkkmEFa7du0IjeqvXbumCRg4r9i1a5d07drVaTsOonjNdIqK6ZGEelCk8pksCndB5hEyqAYMGKAjO+CDO2jQIKlataqmK5oAEUYHQK0ssqGQSjh69GjtzP/2229rpBmZSkgtNNlS+Pmjjz7SiHOZMmVk/Pjx+jc888wz+jyGMEWg67PPPpOCBQtq/a1hXofIGggFawN708sJIyVG5epZ2/sqRYYH5Xepgm2jSdw4d0nvb/53nzxtas2Isk6DHlA3LlyWQrULabqs49WMS5ds85rRFs0/FnxmEKTi1QyipCExRtCpWqBsrEbQiW6QDvzPx5DdREREFDvIbkIQCf2ZAgICtCrCnMvifBrn8qYPLIJPGLEOzcWRKYWqJqJECTohy+iPP/7QG+pAkZqHQA8yg2rWrCnuhl5KCDih1A1woIoglIFGaRgJ4Mcff9SGaIgiT5gwQRulPfvss3pAizIjjCBg4HFEfBGcQpZI6dKlZdKkSZIxo60/zsKFC/VAulevXpHWx7wOUVyvZty7fUfvAyzN6f2DbB/L0Du2PmQh/907m8a2jNsuXc3ASaD1agZqzCtXruzS309Eng3/P1EGjBJgM4JOp06dtEzeceANq7iMoDOi9dtSIbPt4hBG0JkxY4b+jNczI+hs2rRJe9Hh4NdZyTwu+OB7KqpyeiIiosSGigKcW1qZhAUkNRjmZ8der1apktnOJe7dD7E/djfE1oc4dXLbc6mS/defOPRepGkcl48L0Ph/j2oH9HLFObX1fB3tQHAzUCWByiVM9/fff8dqOxDFOehkDTRt375dT67RBR8nqzihjc/MHwS1EJHFzRkEgMzJtIEMpu+//z7a5aIsEDdn0O+GyBvxagYRWSHYZAJOjj3nfvnllyh7zu04ujdOI+gg+6lC2fLacw4ZTs56zmHUzeXLl2vPuZUrV0Zab1xQQt/IgQMHJsCWIiIiij20acG5shUyevH/D1UFhml3kT9//iiXlT19Fr0/f81WrQAXblzR+5wZbBdgcvw3zeWb1zQLOSggUC7csPVqCgoM0gvOgF6uONdFwAkXnD755BOtILJau3atrhdazJjKCPw9DwuOEbk96NS2bVvNaELmRt26dbWMB/cmk4MoKXHn1Yyg/0ZSvB9i+3K3/RxiH6XOdp8symkgmSW7ilcziOhhPecAPefQrxDPRRV02nJoZ5xG0NlxfJ/ct/Scw/ekY885fGeZg3ArlAAi0ISM48GDB9tL8IiIiDwNLo44JkCsWrVKLwKjIgcjSWfNmlUWL16sz0VXGVQuT3GZveV/svf0YTlx6YxkTJ1e1h7aqs9VzFdS70vmLKwXhELvh8qf+9ZLw5I1ZNmetfpchYIl9aIzoOoHfY4BJfaOASdAIAoXqhs0aKAj1iNQNXv2bH2uRo0abtpClNTFKOiEDwvevIULF9YDxKlTp+otqq7mKNMh8lXuvJqRLqttpInbl6/aH7tzxVaOlyarrdQzdSZbM/C7129oDyf/wAD7NPg5TWbb87yaQUTu7Dl34sLpuI2gcz9Uzl45L9UKVYlRzzkrlN5h3XCBy5QHExEReQsElnCxB+fRTz31lGYb37p1SwfzsV68RtsYQM/iopJBKuQrISVyFNKg06tTP9D/rbi4g/+zj5W2/T9MlTyltKjQUGZu/kPGLJkiE1bMlJv3bou/n5+0rfO0/f8sRtA25+cjR47Um4G2OO3atdPye9zQ8xHVQzgvQAsOnNuY1jZEcRWj0etwgoqrkilSpNCrjtHd0HuBKClczbDeRowYoc+Zqxno8RSTqxm5ShTW+8v/nJAbZy9q/6bTO/bpY5mLFdT74IJ5tIF4+P0wObF5l4SHhcuJjbYMhExF8mtGU2yuZvTr108+/vhjHQQAJ328mkHk21ztOXfzTtxH0DHLiEnPOQODkqB3IuAqMRERkbfB8TkGpmrVqpW2isE5Ms4JkJxhzd7FhWzcTIUEMoYHPf2aNCpVU1IEJZfw8DCpkLeEfNyql6RNkdo+Hwbs6FDjacmcNlju3g+RAplzy3tNX5Ey+W2jYCOIhHNzwL15HXPDxWpAX2asJ871kWSC8/1GjRrJTz/9FOFiFVG8ZzpxxBgi91/NQBpr7pJFJbhAbrl89ISs+GS8Bpfu3wvRkeryVrc14A1KkVwK1Ksmh5etlZ2//CZ75i61NRn385MijWwBLV7NICJv7zln4PsJjcaLFCmio9YRERF5IwSX0MICt6hYy/KOz9yi9wguvdmok96iguBUm6pP6s2Zbt266S0mkFWMG5FHjV5HRM6vZiDjaenSpZpFhEAUhiR3vJoB5mqGn7+/VHnpWdk7b5mc2bVf+zZlLlZASrVoJMlSPchKKP5kPQlMHiT/rtsmd6/dlLQ5s0qxJ+pKxoJ5oryaYeV4NWPcuHH2Mrx69epJnz59eDWDyAe4dQSdFHEfQSf1f8uISc85A9+hgCutREREROTdGHQiSqSrGQaCS+XaNtVbVPz8/aRI41p6c4ZXM4jI3T3ncmbMFrcRdAICJVuGLDHuOWftPWfNDCUiIkoKgoJTecQyiNyNQSciIiIf4c4RdMoXLCm/rFrg8gg6GIEnIBY95+D48eOamYXSuxIlSrhlmxAREXk69GzN3rCE25aFC9ZEnoJBJ6JElC1Neo9YBhH5Lld7zlUqVCZOI+g8W+XxWPWcA5OlhdH10MyUiIgoKXBnkIgBJ/I0DDoRJZKw8DBpV66225aFhoJERO7qOYf5MILOxFWzZN2hbRJyP0RH0OlW97lII+ikSJZc/ti1Si7fuqYj6LSv/pSUylUkVj3n4MKFC3qfIUOGeN0mRERERJQwGHQiSiTuDBIx4ERE8dFzLqFH0GnSpInT9SAiIiIi78QzVSIiIiIiIiIicjtmOhEREVEkHEWHiIiIiOKKQSciIiKKgKPoEBEREZE7sLyOiIiIIuAoOkRERETkDgw6ERERERERERGR2zHoREREREREREREbsegExERERERERERuR2DTkRERERERERE5HYMOhERERERERERkdsx6ERERERERERERG7HoBMREREREREREbkdg05EREREREREROR2DDoREREREREREZHbMehERERERERERERux6ATERERERERERG5HYNORERERERERETkdgw6ERERERERERGR2zHoREREREREREREbsegExERERERERERuR2DTkRERERERERE5HYMOhERERERERERkdsx6ERERERERERERG7HoBMREREREREREbkdg05EREREREREROR2DDoREREREREREZHbMehERERERERERERux6ATERERERERERG5HYNORERERERERETkdgw6ERERERERERGR2zHoREREREREREREbsegExERERERERERuR2DTkRERERERERE5HYMOhERERERERERUdIMOt29e1c++OADqV69ulSoUEF69+4tly5dinaeEydOSPfu3aVixYpSq1YtGT16tNy/fz/CNNOmTZMGDRpI2bJl5fnnn5c9e/ZEubxvvvlGihUr5ra/iYiIiIiIiIi8y9WrV6Vfv35StWpVKV++vLz44oty+PDhh853/c5NGbV4sjz3zZvS8qvXZOCvX8jxS6cjTBMeHi4/b/hNOk98V57+soe8NnWIbDy6M8pl3r59Wxo1aqSxiv+3dx/gUZRbA8dPGgkhtBCadAHpSBFQQLCAKCh2VKSIig1BRWzItYOo13JFv6teiigIiAKCIqJY6EWK0pEeeglIKOn7Pecss2waBtiE3eT/e559ZjI7OzuZd2d35+x5zztp0qR0940ePVo6duwoDRo0kHbt2snrr78uR48elbwWEEGnl156SebOnSvDhg2zA7d582bp169ftusnJydbw6vx48fb48eNGycffvihZ53JkyfLm2++KY899pg1TsWKFaVXr15ZBrP+/PNP+eCDD3LpvwMAAAAAAIHg0UcftRjC8ePH7W+NVfTs2VOOHDly2scN/va/8tOa+ZKQnGh/L9u2Wp776m05muDejvpi4TT5fME3sj/+kISHhMmWAzvk1an/J2t2bcxym++//75s37490/KPPvpIhgwZYsGwyMhIS8r59NNP5eGHH7bAVl7y+6DT3r17ZcqUKTJo0CC55JJLLCvpnXfekSVLlsjy5cuzfMwPP/wgu3btsqDSRRddZFG9/v37W8AqKSnJ0wjdunWTzp07S40aNaxBChcuLBMnTky3LX0hPfXUU/bcAAAAAACgYFq8eLHdwsLCZNq0aRZw0gSW/fv3y4QJE7J93B9b1srKHRskNCRU/q/7SzKm91tStliMHDp+RGasmm3raDBq0rIfbf6Ja+6R8Q+/K61qNpE0V5pMWDw9y+QYjXFkRfdNaXbTokWLPAk4uu/btm2TvOT3QaelS5fa9NJLL/Usq1atmpQtW9YCT1n5/fffpV69elK8eHHPMn28ppKtXbtWDh48KFu3brXueo7Q0FALLGXc5uDBgy1wdeONN+bCfwcAAAAAAALBvHnzbKplfzQuERUVJR06dEh3X1aWbnR3katT/kKpULKsRIYXltY1m9iyZdvcZX7W7tpkgafQ4BC5olZzCQ4KlvZ1W9l9f8Suk9S0tHS9u55//nlJS0uzAFhG3333ncVSbrrpJvtbk3JUeHh4ujhJXgiVAMh0KlmypB0cb2XKlJE9e/Zk+RhdXq5cuUzrq927d1uASZUvXz7TOuvWrfP8PXPmTPntt98sSvjLL7+c8/8SHx9vWVO//vqrZVxpvakBAwbYizWjoKAgy7xSScdPyJopP8neVRskLSVVoi+sJPVubi9RZWM862uK3MYf58m2+cslKf6YRJUtJbU6XSFl69VM19/TSaXT+TvuuENiY2OtXpZmfDnuvPNOWb9+faZ90gyzK6+88pyPAwAg/fu8r3i/z+P88tf29df9CiT+egz9db8CDccx/6Jt87e8at+NG93d3EqXLu3pXqfzasuWLZ5lGfdrxwF37aaYqJKe+8oUK2XTXYf32nTnyWmJyGKWEeW9TnJqiuw9vF+qntyvjz/+WDZs2CA333yzLFy40OIcGmPwfv7g4GCLjdxwww2WgFOsWDF54YUXLLaScT//iR4H/V8CMuikfQu1mHd2tOZSoUKFMi3XA6UFxrOSkJBgBzTj+kofo42kMm7Xe5sa7NIG0S56GvTyhbfeesuKlYeEhFjga/78+XLvvffa8iJFiqRbV1+YdevWtfmlI7+Wgxu3SVBIsASHhMj+dZtlwYdj5IpnH5KwyAhbZ8OMOfLXD3NsPjQiXI7s2ie/j5golz3aXSo0ivacBM7/rkXUNeDkRD01A0xpsXWtmaWio92Pc+gxcdYDAJwb7/d5X/F+n8f55a/t66/7FUj89Rj6634FGo5j/kXb5m951b56Tax0uXNt7NSF1gLjGa+XC5/cr2MJ7u2Eh56KQRQKdWcoHUs8kW4aHpZ5Hbv/5DZmz54tw4cPt4wlLRQ+Z86cTNf1Dr22d4qHa1aUlii64IILzup4ZBWXCYigk3aTmz49c/9Eh2YaOXWYvGlwKLtIZkRERKbHOMEkLaKl96us1tFtahTv2Wefleuuu07atGkjvrB69WoLOGnqm9aNKlWqlGUU7dy5U1atWiX33HNPuvWdKOKu9Zss4KTBpjbP9JbwYlEy563hcvzgYdm2YLnUuPoySU1Kls2/LLT1L+56g1S8pIEsGz1Jdv+xTv76cZ40aHSx3acZVfq/6b7MmDHD81z6oqtTp47Na6ExTdXTF/CsWbN88r8DADI721+LTsd5n8f556/t66/7FUj89Rj6634FGo5j/kXb5m951b5OsogmpjjX0E4vIU0ucZbl1n6lpaXJiBEj7JpdR9DTEkFO9zrv63pH1apVLUilMYC+ffta8ol2DTxd4k9WnAyvgAw66QGqXr16tvdrAx4+fNgCRN6RtX379lnAKivatU5Tzbzp+kof43Sr02Xez+1sUyOEmoW0bNkyK2KuUlJSbKoNlLE7Wk788ccfnsc7L4Rrr73WXjBazOuRRx7J8nE7VrlfwCWrVZSoMu7UunIX15bNPy+UA+s3W9ApbkusBZ40E6pC03oSFBwkFVtcbEGng39ttRem0oCavjhfeeUVT99P/VuPqwbjlFNUTF+czjIAQGDwdVo5/Iu/tq+/7lcg8ddj6K/7FWg4jvkXbZu/aeZSly5d0i3TguFOfMC5Xnaut4sWLZrtNXRkxMnSOanJnmWJye4kmCLh7vsiC51MjklJyrSOrRdR2IJGGlto27atda1zutEp7+t6z/Oe/FvjHJdffrmVDdLEHu1ydybOJXjm94XEmzZtao3oFBR30tw0ra1Zs2ZZPkaXa1aRk0amtJ+jRiVr165tWUYatdQq7g590WgBcn2sNojWc5o6daoFnfTWr18/W0/nr7rqqjP+P5zCXd61pipUqGBTLWqenb/3ul/UESWKepZFlnQX/jq6z53Gd+zkNLxoEcuI8l5Ha0AdPXDI89hPPvnEAnK33Xabp86VNydKq/urL2QdLbBHjx52PAEAAAAAKAg0RqBxB++bU3pHayg5nFrTmriRnQui3Qkz+4+4r93VgaOH3feVcN9Xvri7NtShY0eshpN7Hfe1fFhIqJQtUdriFEoDR7Vq1bKb9p5SmvnUvXt3C5bpqHV9+vSx+Yyy6kmWm/w+6KQBoE6dOsmgQYMsSKTDAvbv31+aN28ujRo18hw0jTg6B69du3ZWzOvxxx+3wuA//fSTFcHW+klOtpTOjxo1SiZPnmypYgMHDrRaUBqM0XpLVapUSXfTQJXSea1Qf6acQl3e0XCnzpQWGM9O0okEm4Z4VaQPDnMnqKUkuLsMJp+cZrWOexsnPF3nPvroI4mJiZGnn346y+dzgk56PI8cOWKZUHrcu3XrZsE+AAAAAADyu4oVK9r1sfftjTfesPu0NpJTL8kJBLVq5R5pLiuNLnTXm1q7e5PsiNsjxxNPyPyNy2xZkyru++peUMMKiKekpcov6xZKmitNZq2Zb/ddXKm2hAQHW9BLYyTeN+3Wp7REjt6vGVfffPONxUE06URpEokzul6LFi0kL5337nU58eqrr8qQIUPk0Ucftb+1zpIGoRza4JqN89lnn9kB1GCOFtbSbnCaDqcHv2vXrum6sOlyDfa899571n2vfv36FoTKWDw7v9BsMR1SUQNzOs1YaN3RunVrO14auLvmmmssgquj3GnXQz2mgwcPzvN9BwAAAADgfNPAkpbM0RiEltzRkjWaYKKJHd5d8Zza0C+++KLVT2pavYHUKV/dgk59xrxswaWE5EQbqa5D/ctt3cjwwnJz43Yy8fcZ8v6Pn8vw3ybKsaQTEhwUJF2aXWfrvP/++5n2SXtiabaT1qW+5ZZbbNmAAQPsul+v4ceNG2f7qPWp6tWrZ4k2eSkggk7aD/G1116zW1Y00ORk6Dg0I2nkyJGn3e59991nt5zQxnMa8J9oel12fT81m8rhzGskMjthJ4uepya70+vc88meUerc00LZrqMKFXb3/dQTQ7vMaYX77GjwzpsWI9OC6qNHj7biYwAAAAAAFERaP+njjz+2jCfNJNLByDQQpT2nNHkj4yh3CSev+fVxL974qIyY85Us2LhcklOTpXHlOvJA2zukaMSpkex7tLpJIgqFy4yVc+TQ8SNSLaaidLuss9SrUPOM9lMDSxpn0EwnzcjSnluaVKK9xpweV3klIIJOgdr305u+ALU/5Zn2/Sx2snj4iUOn+mImHHZ3x4sq487KKlLK3a80Mf6o1XAKDg3xrKPzUTElZeakien6fnrTvp/azVCLmi9YsMCymjQa62R9OUXUTxccAwAAAAAgv9Nre+2JpbfsZEyKURpcerx9T7tlJzgoWO5s3sluOfXzzz9nubxDhw52O9/8vqZTfun7qcMTnk3fzwp1atj00NYdcnTvQavfpKPSqZhaF9q05IWVrIC4KzVNdvy+UlxpLtmx+E+7r1TNqhZVzUnfT/1baz1p18Vhw4ZJamqq7NixQ2bMmGHrtWzZMlePGwAAAAAAyD/IdMojOgqcZhhpAOpM+n5WrHuRlKxWUQ5t2SG/vfmJBZdSk5JtpLrKl7kLqYdFhEu1K1rIplnz5c8J38maKT+5i4wHBUnN9q3OqO+nVrjXuk1ffPGFFR87ceKE1YPSbKyMXe8AAAAAAMDphZWM9IttnA8EnfKIZhtpN7Zp06adUd/PoOBgada7i6z9ZpbsWbne6jbF1Kom9W5uL4UiT42EV7vTFRIaHibbFyyXxCPHpOgFZaRWx7YSfWGlM9pPDSxpkXEtyq6j1em8BqeefPJJKVLkVF9TAAAAAABweq40l5RrV8dn2woKDpJAQtApD0VFRZ1V308NLl181/V2y46+8Gpe09pu59r386abbrIbAAAAAAA4e0E+DBIFWsBJUdMJAAAAAAAAPkemk58rG1XcL7YBAAAAAABwJgg6+bE0V5rcffHlPtuWDr8IAAAAAACQF4hC+DFfBokIOAEAAAAAgLxEJAIAAAAAAAA+R9AJAAAAAAAAPkfQCQAAAAAAAD5H0AkAAAAAAAA+R9AJAAAAAAAAPkfQCQAAAAAAAD5H0AkAAAAAAAA+F+r7TQIAAACB4++//5ahQ4fKrFmzJCkpSZo2bSoDBw6U6tWrn/Zx8QlJMmz2Kpm7aY8kp6ZJwwqlpF/b+lIluqhnHZfLJZ8t3iBTV22TQ8cTpUrJKOndqo60rFYu3baaN29u+5HRlClTpE6dOjY/bdo0GTlypGzatEmio6OlZcuW0r9/f4mJifHZsQAAwJfIdAIAAECB9uijj8qkSZPk+PHj9vfcuXOlZ8+ecuTIkdM+7vlvl8j3a2LlRHKK/b142z7p99U8iU9I9qwzauF6Gb5gneyLPyHhIcGy8cARGTh1sfy566Bnnd27d1vAKSQkRMqWLZvuFhYWZutMnTpVBgwYIGvWrJHw8HDZt2+ffP3119KtWzdJSEjIpSMDAMC5IegEAACAAmvx4sV20+COZhJpwKlixYqyf/9+mTBhQraPW7ZlpyzfcUDCQoJldPerZErvDlK+WKTEHU+Uqau22joJySkyftlGmx94TWP57uGOckXNCyTV5ZLPF2/wbGv9+vU2rV27tsyePTvdrUaNGnaf7ltQUJAFyJYsWWJBMrVlyxZZunRprh4jAADOFkEnAAAAFFjz5s2zaePGjaVatWoSFRUlHTp0SHdfVhZvjLVp/fLRUrlklBQJD7OAklqybZ9NV+6KkxPJqRIaHCTta1WU4KAg6Vi3st23LPaApKalpQs6ValSJdvn+9///icrVqyQBx980P7euXOnTTUQVaZMGR8cCQAAfI+aTgAAACiwNFNIlSt3qsZShQoVbLp1qztjKSvbD7jrL5WOivAsK1essE1jDx87OT1q0+jIcAkNCU63TlJqmuw5HC+lvYJOf/75p1x22WXWXe7SSy+1ulKVKlXybD8iwv1cl19+uXWv07+ffvppqVmzpo+OBgAAvkWmEwAAAAqso0fdgaHChd3BIKU1k1R8fHy2jzuWkGjTiNCQU487OX8s0V3T6Wiiu9ZTeFjmdez+hCSbOkGnHTt2WCFzrS31888/S9euXSUuLi7d8x46dMgCTio4OFh27dolaSczpgAA8DcEnQAAAIDz6Nprr5Xrr79ePv/8c6vP9M0331gQTINL48ePT7dukSJFZNGiRVZEvFChQjJ8+HAZPXr0edt3AABOh+51AAAAKBD27NkjXbp0SbdMC4Yr7xHgnPmiRYtmu60iEYVsmpiaeupxye55re9k00Lur9qJKWmZ1lFRJ7fRt2/fdNvWguKtWrWSn376SVavXp3uPg006a1EiRIWqBozZozMnDlTevXqldPDAABAniHoBAAAgAIhJSVF9u7dm25ZqVKl5ODBg7J79+50wSlVtWrVbLdVIbq4TfceOeFZtv+oe75SiSLudYq7p3HHEiQ5Nc1GunPWKRQSLOVKFLXufToanWY13XzzzRZQcvZVFStWzLrPvf322xIbGyuPPfaYVK9ePd2+aJc8AAD8EUEnAAAAFAgVK1b01E9yzJkzR+6//35Zvny5bN682UaC08whpdlG2Wl6YQUZM2e5rNodJ9vj4qVUkQj5baM7cNWsins0uQYXRFugSQNOM9fFynV1K8v0Ne5R75pUipGQ4GBJTk6WPn36SGpqqvz999/ywAMPWHbT/PnzbT0tLK61m/TvNWvWSFhYmLzxxhsWPPv+++9tnebNm+fSEQMA4NxQ0wkAAAAFlgaWGjdubMGfzp0728hw27Ztk5iYmHRd8dq0aWO3WbNm2d/Nq1eS+uWjJSXNJT3H/CI3D/9Bdhw+ZiPVda5fxdPNrktjd1bSGz+ukE7/nS4/b9gpwUEi3ZtdZMtLliwp3bt3t3nNZmratKnceuutlr2k89qFTg0YMMCCT99++600a9ZM2rdvbxlaOtJe79698/y4AQCQEwSdAAAAUGBpIOfjjz+2QE9kZKR1ZdNAlBbnLl7c3YVOaWaR3px6T8HBQfLmjS2kU73KUjgsVNJcIs0ql5b3bm0pRU/WalIPtKojvVvWljJFC0tiappUjykmg69vLg0rlPKs8/TTT8tzzz0nNWrUsOCXBrx69Oghn3zyie2f0n369NNP5ZJLLrFlUVFRFiQbN26cREdH5+kxAwAgp+heBwAAgAJNg0tDhgyxW3YydstTGlx6tn1ju2UnOChIejSvZbfshISEyD333GO302nRooWMHTv2tOsAAOBPyHQCAAAAAACAz5HpBAAAAJyhkJJl/GIb+GdaoH3o0KFWj8uplTVw4MBMowBmFJ+QJMNmr5K5m/ZYMXjtEtmvbX2pEl3Us47L5ZLPFm+Qqau2yaHjiVKlZJT0blVHWlYrl25bWuxd9yOjKVOmSJ06dWz+iy++sG6dO3futFpdd999t3WzBIBARtAJAAAAOAOutDQp3u4un20r6GTdJuSORx99VBYvXmwj/4WGhsrcuXOlZ8+eMn36dClWrFi2j3v+2yWyfMcBCQ0OktDgYFm8bZ/0+2qejOlxtRSNCLN1Ri1cL6MWubteRhUKlY0HjsjAqYvl/dtbSZOYCrZ89+7dFnDSbpRar8ub7pP66KOP5N1337X5IkWKyNatW2Xw4MFy+PBh6devX64dGwDIbXzCAQAAAGfAl0EiAk65S4NNTsBp2rRpFnCqWLGi7N+/XyZMmJDt45Zt2WkBp7CQYBnd/SqZ0ruDlC8WKXHHE2Xqqq22TkJyioxfttHmB17TWL57uKNcUfMCSXW55PPFGzLVA6tdu7bMnj073U2Lx584ccKCTuq1116TZcuWyTPPPGN/a5F73VcACFR8ygEAAADIl+bNm2fTxo0bS7Vq1WzUvw4dOqS7LyuLN8batH75aKlcMkqKhIdZQEkt2bbPpit3xcmJ5FTLhGpfq6IVje9Yt7Ldtyz2gKSmpaULOlWpUiXL5/rrr78s8KQ6depk0169etloiikpKRacAoBARdAJAAAAQL60ZcsWm5Yrd6rGktZLUtqFLTvbD7jrL5WOivAsK1essE1jDx87OT1q0+jIcAkNCU63TlJqmuw5HJ8u6PTnn3/KZZddZgGwhx9+WGJj3YGtiIhTz5GYmGjToKAg6wqoNm/efM7HAQDOF4JOAAAAAPKlo0fdgaHChd3BIBUeHm7T+Hh3UCgrxxLcwZ+I0JBTjzs5fywx2b3txBT38rDM69j9CUnpgk47duywQubHjx+Xn3/+Wbp27SpxcXFStWpVq+PkdKc7duyYjB07Vo4cOfKP+wkA/o6gEwAAAADkkmuvvVauv/56+fzzz2Xp0qXyzTffWBBs3759Mn78eClUqJCnWPioUaOkSZMm8sorr3iKjANAIGP0OgAAAAABb8+ePdKlS5d0y5wi3AkJCZ5lznzRokWz3VaRiEI2TUxNPfW4ZPe81neyaSH3pVRiSlqmdVTUyW307ds33ba1oHirVq3kp59+ktWrV9uye+65x4JPX331le3f7bffLjNmzJAVK1ZIiRIlzvRQAIDfIOgEAAAAIOBp0e29e/emW1aqVCk5ePCg7N69O11wSmm3tuxUiC5u071H3AW+1f6j7vlKJdxd4SoUd0/jjiVIcmqajXTnrFMoJFjKlShq3fuWLFliWU0333yzBZacfVXFihXzbF+zoW677TbPOiNGjLBpzZo1z+m4AMD5RPc6AAAAAAGvYsWKVj/J+/bGG2/YfcuXL7eC3BoEmjlzpi3TbKPsNL3QXWx81e442R4Xb3WcftvoDlw1q1LGpg0uiLZAU0qaS2aui5U0l0umr3EXB29SKUZCgoMlOTlZ+vTpIy+88IJ8+umndp9mN82fP9/mtbC40wWvWbNmnnWmTp1qWVpaf6pNmza5dswAILcRdAIAAACQL2lgSUeL0+BP586d5fLLL5dt27ZJTExMuq54GtjR26xZs+zv5tUrSf3y0RZQ6jnmF7l5+A+y4/AxG6muc/0qnm52XRpXt/k3flwhnf47XX7esFOCg0S6N7vIlpcsWVK6d+9u82+//bY0bdpUbr31VisorvOa3aRuuukmzzqXXHKJPPXUU/b3448/LsWLu7OuACAQ0b0OAAAAQL4UHBxsI8JpxpPWUEpMTLRA1MCBA9MFc5xueU69p+DgIHnzxhby4ZzVMnvjbklKTZNmlUtL37b1pejJWk3qgVZ1JLJQiExduU3ijidK9Zhicv9ltaVhhVKedZ5++mkpX768TJw4UWJjYy3gdd1118ljjz1m+2fbeeABC4xNmjRJDhw4IBdddJHce++91iUPKKj+/vtvGTp0qAWDnUCtnrvVq7uDvdmJT0iSYbNXydxNe6zrq56P/drWlyrRp+q4uVwu+WzxBpm6apscOp4oVUpGSe9WdaRltXLptqXnrAaDNTsxLS1NGjVqJM8++6zUqFHDs87cuXPlww8/lLVr10pUVJQNBjBgwACpXLlyLhyVwBPk0qONXLdy5UqbNmjQ4HzvCgDAj8RN/I+kHNh5TtsIjakg0bc/5rN9Qv5v39iJSyXxgHso+bMVHhMllW5v6rN9gm/Qtvn73MW5o20Dh2YJLl682EZyDA0NlRMnTkjp0qVl+vTp6eqhZWzfRz76UpbvOCChwUESGhwsCSmplqU4psfVUjTCPRDAyAXrZNSi9TYfVShUjialSEhQkLx/eytp0rChte/OnTutqL/WhdOurho60eBXmTJl5Ntvv7XAtdZs69mzp6SmplrASQPbGkCOjo6WadOmWZC5oMczAqJ7nTbcyy+/bH2eNT32ySeflLi4uNM+ZseOHfLggw9alLF169by3nvv2QvB29ixY+Xqq6+Whg0bSteuXWXNmjXp7tc+3y+++KJceumlFlV96KGHLNIJAAAAAAByhwabnICTBm80m0jrtmmtswkTJmT7uGVbdlrASeutje5+lUzp3UHKF4u0TMSpq7baOgnJKTJ+2UabH3hNY/nu4Y5yRc0LJNXlks8Xb/Bs691337WAU9u2bW1f5syZI2XLlrUMLKcumwafNBil3WY1AKVZWZGRkRav+Pnnn3P9OAWCgAg6vfTSS/YiGzZsmIwePdqKAPbr1y/b9TWyeN9999n8+PHj7fHjxo2zlDfH5MmT5c0337S0Vk1j1Rdwr1690gWzdHjTRYsW2eM0QBUfHy8PP/ywpdUBAAAAyJ9CSpaxbJZzuek2AJydefPm2VSTTqpVq2ZZRB06dEh3X1YWb3QniWhNtsolo6z2mgaU1JJt+2y6clecnEhOtUyo9rUqSnBQkHSs6+4Ktyz2gKSmpVnCinbJVffcc49ERERIiRIl5IcffpA///zTusgqTY75448/bLAA7S6rI1VqPEJpgAoBUNNJ+1dPmTJFPvroIyuqp9555x0b4UFHodAXYUb6Qti1a5d8+eWXlvKmfaI1QqlBJs1W0mFIdXvdunWzgoJqyJAh0q5dO+trrRlSGmxasGCBfPPNN1KrVi3PC6p3796ydetWufDCC/P4SAAAAADIba60NCne7i6fbSvoZN0mADm3ZcsWm5Yrd6rGUoUK7lEl9Xo8O9sP/G3T0lERnmXlihW2aezhYyen7i7I2uUuNCQ43Tpav23P4Xg5un27dedTmzZtskSWPXv2WE+qf/3rX+nqSml8Qd15550Wo9CugJqsohlSCIBMp6VLl9pUu7g5NNKpUUNNX8vK77//LvXq1UtXHFAfr93ltLiXBqD0heoMUar0haFBLWebmlmlwSon4KS0WNgvv/xCwAkAAADIp3wZJCLgBJwdvXZXhQu7g0FK6yop7YGUnWMJiTaNCA059biT88cS3RlIRxNT3MvDMq9j9yckyeHDhz1/Dx482Lr1afaTJqZo8or+ndH69e4aUUFBQZY8o2WCEABBJ20sHWrUeYE5tHiXRhqzosu9I6LO+mr37t2ex+koEtltUyOrVapUkS+++EI6depkw6vqkKXOyBYAAAAAACD/8R5v7corr7SeUFqjSeMMWpJHy+9kXH/mzJny448/WpxBS/i89dZb52HP/c95716nBb+1mHd2tOaSk67mTYNQ2UUOdajTjNXsnaCVPsZJk8u4Xe9tamR19erVcujQIetWp/79739Ljx49ZOrUqZmCYDmhL8Tjx4+f8eMAAPmP/grm/eudL+jnG4PS+gd/bV9/3S+cO9oWOD3OEf+liR16ne3twIEDnuty5xr6yJEjNtX6Thmvq532LRLhvsZP9BpELCHZPa/1nWxayB0GSUxJy7SObT+ikEQULer5W0vypKSkSNGiRS0ApfWita5Txn0oUqSI3bSouBYh17I//fv3l/xAX+d6jAMy6KTd5HTIw+z89ttvNixhRhocyu5NQ4t8ZXyME0zSSvJ6v8pqHWeb2t1O/9Yi4k43vQ8++MAynjTC6RQOOxNaUEy79wEAoJ83devW9ek2NUvX+WEF55e/tq+/7hfOHW0LnB7niP/SrmpagNubJpFokEkHEXOuoZ3R5kuVKpXputpp3wrR7mv3vUdOtcv+o+75SiWK2LRCcfc07liCJKem2Uh3zjqFQoKlXImiUrxKFYsJaLBp48aNnp5TOnKd0oCT7oPWgN6+fbsl0jivL+d/0dfG2nx0/Z9VMlBABJ10CETvIlxZ9YvU/pQaIPL+J7Uhs6sGrylvGzacGurQWV/pY5xudbrM+7m9t6nb0HnvulAxMTFWsV6zs872f9W6UAAAnO2vRaejNQ/5xdU/+Gv7+ut+4dzRtsDpcY74rzp16lgBbm/z58+XPn36yF9//WUBJb0WX7Fihd2nA4DpY7Jq36YXVpAxc5bLqt1xsj0uXkoViZDfNu62+5pVcQeOGlwQbYEmDTjNXBcr19WtLNPXuEe9a1IpRkKCgy32oDWg58yZI7/++qt06dLFRrFfuXKlraf36T4MHz7c6jxpgknHjh0tcUX3XbVo0SLTfgYqDbydrfMedPonTZs2tcbVguJO4W+NKGsKXrNmzbJ8jC7XEe80FU9T79TChQst1a127dr2AtI3CO2X6WxTI5hagLxr166ebUyePNkCUU5UU+e1u53WejobeiJophUAALnB190G4F/8tX39db9w7mhb4PQ4R3LPVVddZSPVazBKAz6awKHZRRp8uvvuuz3X1W3atLHpiy++aNlGzatXkvrloy3o1HPMLxZcOpGcaiPVda5fxdPNrkvj6jL297/kjR9XyAe/rZKjSSkSHCTSvdlFnn146qmnLA6xatUqC3QpTYbRBBXtDqj78MQTT1iQSWMJus9abFwDUJqppY+PzCfX/+cStPX7QuKabaSFvAcNGmRBIu07qf0imzdvLo0aNfI0vKbkOd3l9AVRunRpK/y9bt06+emnn+Sdd96Re++915MtpfOjRo2ywJJG7QYOHGi1oG677Ta7X7vPVa1a1WpK6YtMU/n0eTVYdcUVV5zHIwIAAAAAQP4VHBwsH3/8sdVH0sCNJqK0atVKRo8ena43kiaj6E2v5d2PC5I3b2whnepVlsJhoZLmEmlWubS8d2tLKXqy3pN6oFUd6d2ytpQpWlgSU9OkekwxGXx9c2lYoZRnHR3JXguG6/OGhIRYLKFDhw422JgOdqZ0xPvx48dbGR4t46PraPBJl2k8ASJBrgDIB9SI5pAhQ6wQlxPN1CCU09AajNJI42effWYpbGrbtm1WAFwjjvqi1GBS37597cXrGDFihD1Gu+/Vr1/ftumd/qaBrKFDh1o6nR4mfbHpOtl16zsdJw2vQYMG53w8AAD5R9zE/0jKgZ3ntI3QmAoSfftjPtsn5P/2jZ24VBIPuIejPlvhMVFS6famPtsn+AZtCwTm+zJ8g/bNHecSz/D77nVKI5uvvfaa3bKigSat/eRNu8CNHDnytNu977777JYdzZZ6++23z3KvAQAAAAAACq6ACDoBAAAAAACcTkjJMn6xDZxC0AkAAAAAAAQ0V1qaFG93l8+2FeRVmgdnj6MIAAAAAAACmi+DRAScfIcjCQAAAAAAAJ8j6AQAAAAAAACfI+gEAAAAAAAAnyPoBAAAAAAAAJ8j6AQAAAAAAACfI+gEAAAAAAAAnyPoBAAAAAAAAJ8j6AQAAAAAAACfI+gEAAAAAAAAnyPoBAAAAAAAAJ8j6AQAAAAAAACfC/X9JgEAKJj+/vtvGTp0qMyaNUuSkpKkadOmMnDgQKlevfppHxefkCTDZq+SuZv2SHJqmjSsUEr6ta0vVaKLetZxuVzy2eINMnXVNjl0PFGqlIyS3q3qSMtq5ez+RYsWSY8ePbJ9jkcffVT69u1r89OmTZORI0fKpk2bJDo6Wlq2bCn9+/eXmJgYnx0LAAAAgEwnAAB8RAM7kyZNkuPHj9vfc+fOlZ49e8qRI0dO+7jnv10i36+JlRPJKfb34m37pN9X8yQ+IdmzzqiF62X4gnWyL/6EhIcEy8YDR2Tg1MXy566Ddn+hQoWkbNmy6W7eQaRy5dzBqalTp8qAAQNkzZo1Eh4eLvv27ZOvv/5aunXrJgkJCblyXAAAAFAwEXQCAMAHFi9ebLewsDDLJNKAU8WKFWX//v0yYcKEbB+3bMtOWb7jgISFBMvo7lfJlN4dpHyxSIk7nihTV221dRKSU2T8so02P/CaxvLdwx3lipoXSKrLJZ8v3mDLGzduLLNnz053u+uuu+y+9u3by+23327zum9BQUEWIFuyZIkFydSWLVtk6dKluX6cAAAAUHAQdAIAwAfmzZvnCf5Uq1ZNoqKipEOHDunuy8rijbE2rV8+WiqXjJIi4WEWUFJLtu2z6cpdcXIiOVVCg4Okfa2KEhwUJB3rVrb7lsUekNS0tEzb1a5zH3/8sRQtWlReeuklz/L//e9/smLFCnnwwQft7507d9pUA1FlypTx2fHIr90nn3vuOWnevLk0atRI7rvvPjvO/0S7Tw6ZuUw6/ne6tP/gW3ly8gLZFhefbh3tPjl60Xq5dcRMuWrYNOk15heZv2WP537tPlmrVq1sb8OGDcvyubXbpN7/7LPP+uAIAAAAnBmCTgAA+IBmCnl3Y1MVKlSw6dat7oylrGw/8LdNS0dFeJaVK1bYprGHj52cHrVpdGS4hIYEp1snKTVN9hxOH8BQ//73v62u1EMPPZSpVlNERIR1x7v88svlkUcesb//9a9/Sc2aNc/6/y8IAqH7pLdffvlFvvvuO5/9/wAAAGeKoBMAAD5w9Kg7MFS4sDsYpLRmkoqPzxwUchxLSLRpRGjIqcednD+W6A5KHE10ByvCwzKvY/cnJKXbpga5NOCg2VZ33nlnls976NAhq+ekgoODZdeuXZKWRcYUAqv7pPfr0TvDDQAA4Hwg6AQAQD4zZswY667VuXNnCzxlpUiRItZlS4uIaxbN8OHDZfTo0Xm+r4EiULpPOt566y3Zs2ePtS0AAMD5QtAJAIAzpBfzbdq0SXdbsGCB3ec9Apwzr4GB7BSJcAcFElNTTz0u2T2vAQqbFgp1r5OSlmkdFXVyG46ffvrJptdcc022z6vBiBIlSkj9+vXl+uuvt2UzZ87Myb9fIAVS90ktEK/ZVzVq1DjtawAAACC3EXQCAOAMpaSkyN69e9PdSpYsafft3r07XXBKVa1aNdttVYgubtO9R054lu0/6p6vVKKIe53i7mncsQRJTk1Lt06hkGApV+JUUGvz5s22D9rNr1mzZumeS7vPaQZMv379siyArUEMBHb3ycTERBk0aJDNv/LKK9YdEAAA4Hxx/3QKAAByTGv5rF+/Pt2yOXPmyP333y/Lly+3wI+OBOdkDrVq1SrbbTW9sIKMmbNcVu2Ok+1x8VKqSIT8ttEduGpWxT2aXIMLoq0mkAacZq6LlevqVpbpa9zdtppUipGQ4FO/IS1btsymtWvXltDQ9B/zWrtp/vz5smbNGgtGvPHGGxYw+/777+1+HZUNgdd9UkfVGzp0qMyaNUuOHTtmQdGOHTtK06ZNZeLEidluJz7hmAyfPVEWblohyakpUq9CTXmgbRepFF3es44+z4TF02XGqtly6Hi8VCpZTnq0ukmaV2to92sXzR49epy2+Hrfvn1tXvftgw8+sOLmus/Vq1e3+6688kqfHp/8xLttNSisbTpw4EA7dqdD2wIA/AWZTgAA+IAGlrTeT3JysgUDdGS4bdu2WdenLl26eNZzuuPpRaRqXr2S1ftJSXNJzzG/yM3Df5Adh49ZV6vO9at4utl1aey+yHzjxxXS6b/T5ecNOyU4SKR7s4vS7YcGkVR2F6UDBgyw4NO3335rmVBahPrgwYPWVax37965dnwCSaB1n3RG1XMCTk7A4J9G1Rv87X/lpzXzJSHZnY21bNtqee6rt+Vognt0PvXFwmny+YJvZH/8IQkPCZMtB3bIq1P/T9bs2nhGo+rpfmlQduTIkVZ8PSQkRFavXm377gRK4bsRE2lbAIC/IOgEAIAPaCBHCzvfeuutEhkZaV3ZNBClxbmLF3d3oVNOdzwnYBEcHCRv3thCOtWrLIXDQiXNJdKscml579aWUtQr2PBAqzrSu2VtKVO0sCSmpkn1mGIy+Prm0rBCqXT7oQEkpfWasqL79Omnn8oll1xi+6yZMhokGzdunERHR+fS0QksgdR90ntUvTvuuCPd60Dvnzx5sv2t01q1annu/2PLWlm5Y4OEhoTK/3V/Scb0fkvKFouRQ8ePWOaL0oDFpGU/2vwT19wj4x9+V1rVbCJprjTLkDmTUfX0+TUAocFNDbhq3SknC8bJtINvRkykbQEA/oTudQAA+IgGl4YMGWK37GTslqc0uPRs+8Z2y46OaNajeS27nc4LL7xgt9Np0aKFjB079rTrFGSB1H3Se1S9SpUqWTaK1pjSzBjNVNGskxMnTliQqlixYp7tLN34p03rlL9QKpQsa/OtazaRr5fOlGXb1shtl1wra3dtsuBEaHCIXFGruQQHBUv7uq1k3l/L5I/YdWc0qt6MGTNsesMNN8gFF7hH7/vPf/5jARUNfuKfR0xUOmLiiBEj7L7sMhNpWwCAP+GTAAAAIEC7T3qPqterVy/LRtEulKpUqVJy7bXX2rxO9T7HjgPuwFdMlDuDS5Up5s6a23XY/Rw7T05LRBazrBnvdbRO0N7D+3M8qp4TxEtNTZW7775bGjRoYFmBv/7661m1R0FwtiMm0rYAAH9CphMAAOdRSMkyfrEN5Kz7pBZf15pKOkqcBqK0qHPG7pMqY/fJD+esltkbd0tSapp1n+zbtn6m7pORhUJk6sptEnc80bpP3n9Z7X/sPnn2o+q5u++Fh57ah0Kh7hpTxxJPpJuGh2Vex3sbORlV7/DhwzYdPny4ZV9pFsxff/0lffr0sWWnyxYrqGhbAEB+QNAJAIDzxJWWJsXb3eWzbQXRlSVXBUr3SW868pnezseoelnR7ldaj0iPpQYlNPvqww8/JDDh52hbAMDZIugEAMB54ssgEQGn/E8Ll3t35VNaVPpsRtWLjHBnzySlJnuWJSYn2bRIuPu+yEIR7nVSkjKtY+ud3EZ2o+p500DFoUOH7L7SpUvbMv1fNDChI50VdLQtACC/IugEAAAQAN0nnVH1vGndJu1yd6aj6l0Q7S4wvf9InGfZgaPublIXlHDfV764O4Bw6NgRq/MTFhIqB44esmU6X7aE+/6sRtXLqEaNGjaqmRY49/xfISE2pdg0bQsAyL8IOgEAAARA90lfjqrX6MK6MmHONFm7e5PsiNsj0UWKy/yN7pHxmlSpa9O6F9SwItMpqSnyy7qF0q5uS5m1Zr7dd3Gl2qcdVS+jK6+80gIT33//vfTs2dOCJlOmTHFv6+KLpaCjbQEA+RVBJwAAgADtPumMqqeBCa23o0WcNeMkq1H11IsvvihXX321NK3eQOqUr26BiT5jXrYAREJyoo1m1qH+5bZuZHhhublxO5n4+wx5/8fPZfhvE+VY0gmrP9Wl2XWnHVUvo65du8pXX31lwZNOnTpZ1ozup+5v3759fXac8hPaFgCQH5DzCgAAEOCj6ukQ9ZGRkZKWlmbBitGjR2caVU9vp0bVC5YXb3xU2tdrJRFh4eJypUnjynXk9Vv7S9GIIp7H9Wh1k3RveaPEFC0pianJUi2mojx//cNSr0LN046ql5EGIsaOHSu33HKL7Zd2J2vSpImMHDlSmjZtmktHJ7DRtgCA/CDIpUNRINetXLnSpg0aNDjfuwIAAAq42IlLJfHA0XPaRnhMlFS6naCCv6FtgdOLm/gfSTmw85y2ERpTQaJvf8xn+wTk53gGmU4AAAAAAADwOWo6AQAAFDBhJSP9YhvwPdoWAOBPCDoBAAAUIK40l5RrV8dn2woKDvLJtnDuaFsUNH///bcMHTpUZs2aJUlJSVZHbODAgdkWvnfEJyTJsNmrZO6mPZKcmiYNK5SSfm3rS5Xoop51tArNZ4s3yNRV2+TQ8USpUjJKereqIy2rlfOsk5ycLMOHD7cRG3fv3m2jTHbs2FEeeeQRiYiIyPS8Osrj448/LtWqVZMZM2b4+GgA/onudQAAAAWILwMJBCX8C22LgubRRx+VSZMm2YiJau7cudKzZ085cuTIaR/3/LdL5Ps1sXIiOcX+Xrxtn/T7ap7EJyR71hm1cL0MX7BO9sWfkPCQYNl44IgMnLpY/tzlLq6v3nvvPbtt3brViurHxsbaAACvvfZapuf866+/5JVXXvHhfw8EBoJOAAAAAICAsnjxYruFhYXJtGnTLOBUsWJF2b9/v0yYMCHbxy3bslOW7zggYSHBMrr7VTKldwcpXyxS4o4nytRVW22dhOQUGb9so80PvKaxfPdwR7mi5gWS6nLJ54s3eLb1zTff2PTdd9+VRYsWWQBKzZw507OOZmB9/vnn0qVLF4mLi8u14wH4K4JOAAAAAICAMm/ePJs2btzYuqtFRUVJhw4d0t2XlcUbY21av3y0VC4ZJUXCwyygpJZs22fTlbvi5ERyqoQGB0n7WhUlOChIOtatbPctiz0gqWlpnoCSCgpyZwY6A8NHR0d7nm/cuHGezCfdV6CgIegEAAAAAAgoW7ZssWm5cqdqLFWoUMGm2t0tO9sP/G3T0lGnai6VK1bYprGHj52cHrVpdGS4hIYEp1snKTVN9hyOt/m77rrLplqnqUWLFvLEE09ITEyMvPrqq55tBwcHS7t27eSrr76SVq1a+ei/BwIHhcQBAAAAAAHl6FF3YEhrKTnCw8NtGh/vDgpl5VhCok0jQkNOPe7k/LFEd02no4nuWk/hYZnXsfsTkjw1pVauXGmZVYcPH7ZlKSkp6brRde3aVbp3736O/y0QuAIi0ykxMVFefvllueyyyywl8cknn/zH/rA7duyQBx98UJo0aSKtW7e2/rWpqanp1hk7dqxcffXV0rBhQ3szWLNmTbr7t2/fLg899JBccsklto0XXnjhtG9gAAAAAICCYcCAARZw0kynpUuXyuDBgy34pNerej2qQkJOBauAgigggk4vvfSSFYYbNmyYjB49WjZv3iz9+vXLdn0duvK+++6z+fHjx9vjtS/thx9+6Fln8uTJ8uabb8pjjz1mIx5o0blevXp5glm6jd69e0toaKgVotOglRaHGzRoUB78xwAAAAAAtWfPHmnTpk2624IFC+y+hIQEz3rOfNGiRbPdVpGIQjZN9EpISEh2z2t9J5sWcncISkxJy7SOioooJKtWrZIZM2ZYLSlNdtDpbbfdJjVr1rRryV9//dVX/z4Q0Pw+6LR3716ZMmWKBXs040izkt555x1ZsmSJLF++PMvH/PDDD7Jr1y4LKl100UXWh7Z///4WsHKKvX300UfSrVs36dy5s9SoUUOGDBliqZkTJ060+zdu3Gh9gfv27SvVq1e357777rtlzpw5efr/AwAAAEBBpl3W9LrQ+1ayZEm7b/fu3emCU6pq1arZbqtCdHGb7j1ywrNs/1H3fKUSRdzrFHdP444lSHJqWrp1CoUES7kSRT11o7R4uFNI3KnhpE6cOLV9oCDz+6CTpimqSy+91LNMRycoW7asBZ6y8vvvv0u9evWkeHH3G4rzeO33u3btWjl48KC9SWh3PYdmNGlgydmmvonpG8aXX35pgSrNgNJI9sUXX5yL/y0AAAAAwJv2Slm/fn262xtvvGH3aSKC9oTRa72ZM2fastMV7G56obvY+KrdcbI9Lt7qOP220R24alaljE0bXBAtYSHBkpLmkpnrYiXN5ZLpa9yj3jWpFCMhwcFSpUoV+/vYsWPyxRdf2PzChQtlw4YNNl+/fv1cPCJA4PD7QuJOFNspCucoU6aMJ5KdkS73HsXAWd+JhGuASZUvXz7TOuvWrbN5fbxmV/373/+2N5G0tDTLmvLuonemNAp+/Pjxs348AAAAAECs1q8mBPzxxx9yww03SFhYmGUXlSpVyv52rrs6dOhg04EDB8p1110nzatXkvrloy3o1HPMLxZcOpGcaiPVda5fxdPNrkvj6jL297/kjR9XyAe/rZKjSSkSHCTSvdlFtk6DBg2kbdu28ttvv8krr7xivXGc4ubNmze3fct47afd7hTXhQg0GTP6AiropAXWtJh3drTmUqFC7n633jQIpQXGs6J9eYsVK5ZpfaWPcVIdM27Xe5ua3aQR9Guuuca61R06dMi662mRuJEjR55VQTh9k9FMKwAAAADAuenTp48lCGhvFb3W0kCQjhS3c+dOu6l9+/Z5BolSwcFB8uaNLeTDOatl9sbdkpSaJs0ql5a+betL0ZP1ntQDrepIZKEQmbpym8QdT5TqMcXk/stqS8MKpdI9vyYyaAkWfZ4SJUpIixYt5I477sjyum///v021WtOrgsRaLKKywRE0Em7yU2fPj3b+zVy7NRh8qYnqvfwmN4iIiIyPcYJJkVGRtr9Kqt1nG1++umnVjhc980JMGnfYA1C/fLLL1Yn6kxp9F3rRwEAAAAAzl2zZs1Oe79TB9g7S0ODS8+2b2y37AQHBUmP5rXslh3tCfPMM8/YLSf+9a9/2Q0INFrz+myd96CTBmK0UHd2NNtIh53UAJF3ZE0jyRqwyop2jXP60nqvr/QxTrc6Xeb93N7b1FpSdevWTZfRpP12taufUzTuTOkbnQa9AAAAAACBLbskCCC/CTrLrnV+EXT6J02bNrV6ShoEcgp/b9myxWo9ZRfV1uU64p32qdWhK52ibkWKFJHatWtb8EqLkWsmk7NNHRFBC5B37drV/tbg07Jly9L1XdTn1ADY6UZDAAAAAAD4p5CSZfxiG0BB4fdBJw3+dOrUyYp6DxkyxKLJL774ohVna9Soka2jWVB///23jVanASXt+vbee+9Z/aUBAwZY3Sgt7Hbvvfd6sqV0fvDgwZa9pH1/P/nkE6sFddttt9n9Wsdp8uTJlv7Yq1cviY+Pl9dff92CVlowDgAAAAAQOFxpaVK83V0+21ZQsN8PBg+cd0EuTeXxc1rZXwNOP/zwg/3dpk0bC0JpVzelGUs9evSQzz77zAq3qW3btsnLL79s2UsajNJgUt++fSXY641hxIgR9hjNXtIhLXWbderU8dy/YsUKC1atWbPGgl2tW7eWp556SqKjo8/4f1i5cqVNNcAFAAAAAAAQCM4lnhEQQaf8gKATAAAAAAAoSPEM8gEBAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzob7fJLKSnJwsLpdLVq5ceb53BQAAAAAAIEeSkpIkKChIzgZBpzxytg0EAAAAAABwPuMZZxvTCHJp+g0AAAAAAADgQ9R0AgAAAAAAgM8RdAIAAAAAAIDPEXQCAAAAAACAzxF0AgAAAAAAgM8RdAIAAAAAAIDPEXQCAAAAAACAzxF0AgAAAAAAgM8RdAIAAAAAAIDPEXQCAAAAAACAzxF0AgAAAAAAgM8RdAIAAAAAAIDPEXQKcFOnTpUuXbpIo0aNpHHjxnLrrbfK+PHjs1z322+/lauuuuqcns8X28hox44dUqtWLVm0aJHkFX0ufU597oLctgkJCfL222/bY/U5brnlFpk1a5YE8nGeNGmSPae/y4v2PXHihLz66qvSunVrufjii+Xuu++WFStWiK9w7p5d2/r6vPv444+le/fu4kucu+e3fQ8fPiwvvPCCtGnTRpo0aSJ33XWX/P777wF9rIcNG+bz7w+B2LYHDx6Up556Si699FLbxgMPPCCbNm3y2f/AuXv27evrz0y+M+evtuU7c/5uX74z5zIXAtbEiRNdjRo1sunmzZtdmzZtcn322WeuevXquYYNG5Zu3R9//NHVoEED15VXXnnWz+eLbWQlJSXFtW/fPldiYqIrryxcuNB10UUXuWJjY10FuW2ff/55V9u2bV2//vqra+vWra4PP/zQVbt2bTs+vqBtqm2rbZxXvv76a2tbf5ZX7du/f3/XNddc41q0aJG170svvWTPu2fPHp/8H5y7Z9e2vjzvxowZY4/t1q2bT/8Pzt3z2769evVyXX/99a4lS5bY87z88suuhg0b2vP5wokTJ6x989L777/v8+8Pgdi2d9xxh+v22293/fHHH66NGze6+vbt62rdurXr+PHjPvk/OHfPvn19+ZnJd+b817Z8Z87f7ct35txF0CmA3Xzzza5XX3010/K33nrL1axZM5uPj493PfPMM3Zidu7c+aw+/HyxDX/jTyfh+Wpb/YKrj/3mm2/SLe/Ro4frqaeecgWqQPgAzYv21Q+3Z5991jV//nzPsiNHjtixmT59uitQBfq566vzTr8EPfjgg/aF6Nprr/V50Ol8yA/nri/aV7/s6nH4/fffPcvS0tJc7dq1c7333nuuQOXvQae8aNvDhw/bhc369es9y9auXWvtrUGoQJUfzl1ffWbynTl/ti3fmfN3+/KdOffRvS6ABQcHy/Lly+Xvv/9Ot1xTtSdMmGDzmk63e/dumThxorRr1+6snscX2/jzzz+la9eulhLZrFkz6du3r+zatSvLdMPU1FR59913Lb1R0yj79esngwcP9nQf0fXq1q0rv/32m1x//fVSv359ufbaa+Wnn37yPJ8ek0GDBsnll18u9erVk8suu8z+1tTJQJAXbRsUFCQfffSRdd/I+NxHjhzJ8Xa0HTTFWFNR9Tg/++yznv3OmNapx//FF1+UFi1aWJeR559/Xp588kl7jJPm2759e89U21a3vXTpUs/z6evmiSeesOfSttX9f+uttyQtLU0CRV60b0hIiLz++ut2nNTRo0flk08+kSJFith5lVOcu75tW1+dd6tXr5awsDBLOddz72xw7vpn+5YsWdLO1QYNGniW6Xb1diavkSlTpkinTp1sO3o+6bmYlJSUZZeKuLg4a5tLLrnE2vjf//639OjRw7rEKZ3ec889tl/6v+k2u3Xrlq5b2IYNG+TBBx+09wlt/6uvvlpGjhwpgSIv2rZ48eLWPeeiiy7yHPdPP/1UypUrJzVq1MjxvnLu+r59ffWZyXfm/Nm2fGfO3+3Ld+Y8kAeBLeSS77//3tI6NeW+d+/ero8//th+KdNfRHPrV8az2YZGjy+99FLXO++849q+fbtr1apVrltuucXVs2dPu1+jrxqFddJThw4d6mrRooVr5syZlnr+yiuvuGrVquX5Jd+J2nbq1Mki0lu2bLH09CZNmriOHj1q6zz00EMWGV+xYoVtX3+Z0F8oRo0a5XeRX39pW6XPoc+rXXZy4uDBg6769evb+jt27LBf5q+66irXwIEDszzO2k5XX321a968efZLr/6tbau/Cjq/uGg7adeD5cuXuzZs2ODq2rWr/cLv/O/6y+F9991nvw7r60nbVJ9DU9kD5VebvG7f//73v3ZM9Fh/9dVXOX4c527ut+3ZnHcZ6flzpplOnLuB075qxowZdmx++eWXHK2vx1jbQ/d3586drtmzZ9svwtodJOOxTk1Ndd1222123mnb6Xl+9913W/vqe4/SqW7vgQcesG3/+eeflmHXvXt3TxZAq1atXE8//bSd+3puv/nmm/Yca9as8WzDn7M+8rptBw0aZMdHz8M5c+bk+HGcu7nfvmf7mZkR35nzb9sqvjPnz/blO3PuIOgU4PRN5oknnnA1b97cXlR60/6o3mn55zvopOnkehLpm6x+uVV6Muq+ZzwJ9YurvqmMGzfO83h9U9ETKuNJ6LxheqenL1u2zP7+/PPPXevWrUu3H/qm/Nxzz/ndSegvbat9pLWuRJcuXVxJSUk5eoxeTOh+/fzzz55l+qGn7ZHxOGub67xe/DgSEhLsQsX7A9T7IkVpO+uyvXv3Wh2SESNGuHbt2pVuP1q2bOn64IMP0m3D3+Vl+2p3ndWrV1sqsn5we7fX6XDu5n7bns1554ugE+du4LTv0qVLXY0bN3Y9+uijOX6MHnu9uNHgkEPntR5GxmO9YMECm/euF7V//36rR+MddNL3An1PcHz66af25da5mNILAeeLsPMa0e1Onjw5IIJOed22f/31l2vlypXWpUPfO/UCJSc4d3O/fc/2MzMjvjPn37blO3P+bV++M+eO0LzIpkLu0XQ8vWma5Lp16ywFb8yYMdK7d2/58ccfpVSpUud7Fy2d/P7777cRAd5//30bsaVt27Zy3XXXZVpXU/V1dAjvVEZNaW3atKn9f94uvPBCz3xUVJRNk5OTbaqpjT///LNMnjxZtm7dKhs3brS0Ru/H+Lu8bNtly5bJI488Yin+mj6s3XZyok6dOpby+dBDD0np0qWlVatWcsUVV1iab0Zr1qyxqaacOsLDw6Vhw4aZ1q1evbpnvmjRop62jYiIsC4dM2bMsBTWbdu2yfr16+XAgQMBlSqc1+1bpUoVm2qa7tq1a2XUqFFy5ZVX/uPjOHdzt23P9rzzBc7dwGhfTaMfMGCAda3QLm85pan22l633XabVKxY0dpXu7tpen5W7avnuvc5FhMTI9WqVUu3ni7T9bzb1zlvo6Oj7dzV0bp0e9u3b/ec94HUvnnZtk53Ou1O8ccff9jzaPeOf8K5m/vte7afmb7A567/ty3fmfN3+/KdOXdQ0ylA7dmzR15++WWbOv1d9eR4+OGHrT7AsWPHZMmSJeIv9EuznhSPP/64ZtfZCanDXTr1JRyhoe44qK7zTwoVKpRpmT5O35C0rsRrr71m2+vYsaMNKa5f2gNBXrftzJkzrVZHzZo15fPPP7d6ImdC61N8//339kZ76NAhGwr6vvvuy7K/tMrJB112bXv8+HG588477UO+WLFicvPNN8sXX3xhH/yBIq/aV7ejXzR06HVvWktk7969Od4O527utO25nne+wLnr3+2rX6i1HoR+2dXjphccOaXrfvbZZ/ZF9I477rAvo3qhM3DgwCzb92zb1rF//37p3Lmz1bEpW7asfRHW5w4UedW2WsPpu+++k5SUFM8yfS4NQO3bty/H2+Hc9X37zp071yefmb7A567/ti3fmfNn+/KdOfcRdApQ+gLUL3daRDYjfWNxfpX0B5s3b7ZCeBqFvuuuuyz6O3z4cIvyZozmanRZI/MrVqxIt1x/BcwpjUrPnj1b/vOf/9jJr1+EK1eubL+85uTkLkhtq2+MWmBQf2kZMWKE5xeSnNJ2GTJkiEXUnSKz+vfChQvl4MGD6dbV4nkaxfduW30T1oLIOaUfLLq+XkxpwT19g9Wovz5XILRtXravfhj179/fPkS96a9dOS1Yy7mbO217ruedL3Du+nf76oWBflm9++675Z133jltwCcr+ivwBx98YF/Otdiqc9ynT5+ead3atWtLfHx8uqLgejGkv4rnlGY46Zf1cePGWQaA/nLvFH0NhPbNq7bVDAN9X16wYIFnmf5irVkN3tkKp8O5mzvtW758+XP+zPQFPnf9t235zpx/25fvzLmP7nUBSlPZNUquLzSNzmo1e30j0bS6//u//7ORDnQUGn+gvwLoL3uaRqhffjVKrb+AOun83lHlwoULW9V+PVE19VS/hH355Zd2EjZv3jxHz6dfDDXiq78k6HHS7WuUX3+JzRhpLshtqxcEzzzzjI12oCNieI8KoanCJUqU+Mdt6H7pxZGu36VLF0lMTLSLmqpVq2b69adSpUqWYqoXUq+88oq1r0bk9dcL/WDNCefXGf3w6dChg40Qoxdk+qU9ENo2L9tXvwxpm+jz6HHTD6Lx48fbuaTTnODc9X3b6q+jOqLRuZx3vsC567/tu2XLFrsQ0cCN/oqpgQqHfknNyYWOPteHH35o+6fd6nQ/fv3113RdNRy63zqS0tNPPy3/+te/7Dl0dCMd/eZM2lfX1y/s2j1Av3w7XcUCoX3zqm31V3MdPUp/mdabvpfquaSjX+lFaE5w7uZO++rn1Ll+ZvoCn7v+2bZ8Z87f7ct35txH0CmAaeqevlHpi3Ts2LH2Ir/gggvsTUq/qPoLPQn/97//WUqpntA6RKT2YdU+svrGkTGV8bHHHrM3RGfIR+1aoF+a9c05JzS1f+jQoTbEsx4XPZn1Vwn9Qqe/UgSCvGhbjY7rF119g8s4BKy+4Wna8D/RN0k9zvqLun6Q6hus9mHW9tb5jPTDU79oa5cRjcLfcMMNdhGU0/7w2pf9ueees5Ta9957z9paf7nRXzlWrlwpgSKvzl3tSqMfdpqarBeu+mVJj11WdV2ywrnr+7adNWvWOZ93vsC567/t+8MPP9h5pHUq9OZNu0foOfJPWrZsabWCRo4caUMyayBJa0s4Q21npK8FvbDRc0275mn3OA0c5bR99UJAf1HXfdOhpitUqCC33367HQ9tX/3V19/l1bmrF336nqoZE5phpj8y6PPpc+UE527ufe6e62emL/C5659ty3fm/H/u8p05dwVpNfFcfg7gjOiXbP2lVKO2jnvvvdciz/rrLwKTvonOmTPHPmCdQnhKf33RlNA+ffqc1/3DuePczZ84d/M3rTOkF1KtW7f2XMzor6T6C7J2FbjpppvO9y7iLHHu5n987uZPnLv5348F7Nwl0wl+R/tJ6y8Amuqvb7T666L2d9ZfbBG4tF+2/nqgvwhpzQ8tkvjVV1/Jrl277FdyBD7O3fyJczd/0/R8zbrRgrOakaS/vOq5rInDd8kAAAgUSURBVO2e8Rd9BBbO3fyPz938iXM3/xtRwM5dMp0KME2l/6fRZbQmhKbp5+Y2MtKhHjVdUEeK0RRKLeCmo+5kNaQocq9d9JgvWrTotNuYNGlSpmG1/6nondYK0cJ8mnaqRW41bbZZs2Y53gY4d/MzX5x3nLv+yxdto79yx8bGnnYb+hxnUnxcv+hq9wsdTlu7eejoN1qYVIvZImc4d/M3PnfzL74z52+cu/6BoFMBT6nXegKnU6ZMGSt2lpvbgO/5ol10iFB9Ezwd7VOd077l8B3O3fzLF+cd567/8kXb6C/dmo10OloENafFZuEbnLv5G5+7+RffmfM3zl3/QNAJAAAAAAAAPpe5VD4AAAAAAABwjgg6AQAAAAAAwOcIOgEAAAAAAMDnCDoBAACcR74ur0m5TgAA4C8IOgEAAOSCDRs2yBNPPCGtWrWS+vXrS+vWrW3I63Xr1nnWWbp0qTzwwAM+eb6kpCQZMmSITJs2zSfbAwAAOFcEnQAAAHzsr7/+kjvuuEMOHz4sgwYNkpEjR8rTTz8tu3btki5dusiKFStsvYkTJ8qmTZt88pz79u2T0aNHS0pKik+2BwAAcK5Cz3kLAAAASGfUqFFSsmRJ+d///iehoae+brVr106uvfZa+b//+z/55JNPzus+AgAA5DYynQAAAHzswIEDVlspLS0t3fLIyEgZOHCgXHfddfLss8/K5MmTZefOnVKrVi2ZNGmS7Nixw+Y1aKXBqYsvvli+/vpre+xPP/0kXbt2lcaNG1t3Pb1/7Nixdp8+7uqrr7b55557Tq666irPc/7+++/SrVs321bz5s3lmWeekbi4uHT7tXz5crn77rulUaNGcsUVV1jG1D333GP7qG699Va58847M/2fuk6vXr1y4QgCAID8gKATAACAj2ngRrvSaaBGA0Pahc4p8K3BoptvvlkeeeQRadu2rZQuXVomTJhgj3EMGzZMevfuLW+++abVhPr111+lT58+Uq9ePcuS0vsrVaokr7zyivzxxx9SpkwZ+eCDD+yxDz/8sGd+yZIlFhiKiIiQ9957zwJeixcvlh49ekhCQoKto/um66h33nlH+vbta1lYWm/Kcdttt1lgatu2bZ5lu3fvlkWLFsktt9ySR0cVAAAEGrrXAQAA+JhmJO3fv19GjBhhgSGl3e20mLgGfBo2bCiVK1eW6OhoKVSokGUYqePHj9tUM6E0u8jx7bffWqDq+eef9yzTjKcWLVpY4EezmOrUqWPLdbt169a1+bfffluqVasmH3/8sYSEhNgyXbdTp06WQaXZTXpf0aJFZfjw4VK4cGFb58ILL0yX2XT99dfL0KFD5ZtvvpF+/frZMp0vUqSItG/fPtePJwAACExkOgEAAOSCxx57TObMmWOBH80UioqKspHltJD4Z599dtrHOgEkx/33329Bn2PHjsmqVatk+vTpFixyRq3LyokTJywLSrOpNMtKC4zrTTOkqlevLvPmzbP1Fi5cKG3atPEEnJyAVoUKFTx/a1DqmmuukalTp3qWadfAjh07WhYVAABAVsh0AgAAyCXFixe3LCG9qTVr1shTTz0lb731ltxwww3ZPk5rP3nTGkwvvvii1XUKCgqSKlWqyCWXXGL3Od32Mjpy5IjVlNJi5nrLKDw83LPtUqVKZbo/JiYm3d8aONOgk9aI0qyprVu3yhtvvJGj4wAAAAomgk4AAAA+tHfvXusap5lOt99+e7r7tNvbE088YfWZYmNjc7zNAQMGyObNm+XTTz+1LCTtkqeZTF9++WW2j9Gubxqg0npN2p0uIyezqVy5clb4PKODBw9aNzuHFiHXrnszZsyQ4OBgu8/pFggAAJAVutcBAAD4kGYIhYaGyhdffCGJiYmZ7tfgkWYZabaSBm9yQot6a/c2reGkASc1e/Zsmzoj5Dk1mxzanU+DXPp8DRo08Nxq1qxphci1FpRq1qyZdQP03lfNyNIR8bxpAEuLhmu21c8//2w1pgAAAE6HTCcAAAAf0uDPSy+9ZNlMmvGkxbq1hpJmJmkdJR3NTrOgtOtdsWLFLMvot99+y1THyZsWHtd6UDp6nWYmLVu2zEaY00CQbtepu6QWLFhgz6cFw/v37y8PPPCAPPnkk9K5c2dJTU2VkSNHWq0nHT1PPfTQQ1YjSutG3XvvvdYt7z//+Y8FxHT73jTopAErdeONN+biUQQAAPlBkCu7QgAAAAA4a6tXr7bR6zRLSesmaYaSZh51797dspbUhg0bLAClXe10VDgtzH311VfL66+/bgEex86dO+XVV1+1ekqqatWqNgqe1lg6fPiwfPXVV7Zci41PmDBBwsLCLMClUw1CffDBB1aAXP/WwFXfvn09NaGUbvfNN9+UtWvXWn2nBx98UP773//afg4aNCjd/6X7pdlcGvQCAAA4HYJOAAAABZgGpTQY5R2E0mynli1bytNPP23BLe96VVdeeaW8//770q5du/O0xwAAIFDQvQ4AAKCAZ2RpEEm74mkWlGZOjRo1yrrrOaPuaQbUrFmz5IcffrAsq6uuuup87zYAAAgABJ0AAAAKMK3jlJSUJOPGjZPdu3dLZGSkjVSnXfyio6NtHS0yroGosmXLyjvvvJPjAugAAKBgo3sdAAAAAAAAfI6fqQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAA4HMEnQAAAAAAAOBzBJ0AAAAAAADgcwSdAAAAAAAAIL72/xbSolxnrJmMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_mean_return_by_strategy_and_regime(df):\n",
    "    \"\"\"\n",
    "    Plot mean strat_return grouped by strategy and prev_regime.\n",
    "    \"\"\"\n",
    "    # Compute mean strat_return per strategy and regime\n",
    "    grouped = df.groupby(['strategy', 'prev_regime'])['strat_return'].mean().reset_index()\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    # Create barplot with strategy on x-axis and hue=prev_regime\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=grouped,\n",
    "        x='strategy',\n",
    "        y='strat_return',\n",
    "        hue='prev_regime',\n",
    "        palette='Set2'\n",
    "    )\n",
    "\n",
    "    plt.title('Mean Strategy Return by Regime')\n",
    "    plt.xlabel('Strategy')\n",
    "    plt.ylabel('Mean strat_return')\n",
    "    plt.legend(title='Prev Regime')\n",
    "\n",
    "    # Add value annotations on top of bars\n",
    "    for i, bar in enumerate(plt.gca().patches):\n",
    "        height = bar.get_height()\n",
    "        if height:  # Avoid annotating empty bars\n",
    "            plt.gca().text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_mean_return_by_strategy_and_regime(df_joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee6d165a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWEAAAfACAYAAACgtp8kAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3QeYVNX5x/F3d+l9ESmxIigILkUEG9hARcX6VxMjdpSoEcVORAUlioqo2BvBHsVeMCoxKhpFQKIbERVFg0iV3tnd+T/vSWbdd8+wzOzOnXLn+3meeS7M3r1z5zdnZs6+99xz8yKRSEQAAAAAAAAAAIHID2azAAAAAAAAAABFERYAAAAAAAAAAkQRFgAAAAAAAAACRBEWAAAAAAAAAAJEERYAAAAAAAAAAkQRFgAAAAAAAAACRBEWAAAAAAAAAAJEERYAAAAAAAAAAkQRFgCqKRKJZOS2MlUuPEcAAICaoH+ZmFx4jgDCgyIsgKQ67bTTpEOHDvK73/1ui+sMHTrUrXP11VdLJlm+fLncfPPN0q9fP9ljjz2kV69ecsYZZ8g777xj1lu4cKGcd955Mn/+/KQ87sSJE+WWW26RTHsNK946duwoe+65p5xwwgnyyiuvJLzNGTNmuMzSbcKECbL//vtLly5d5L777kv69ivnVvk2ZsyY8nUPOeSQKtfV90nldS+77LItPvbJJ5/s1rn77ruT/rwAAEgn+peJo3+ZOtnUv1y2bJnZtvYt9f7x48cnfb8B+GrFuA8AaiQ/P1/+9a9/uc5k69atzc/WrVsn//jHPyTTbNiwQU499VQpLS11nbmddtpJVq9eLW+++ab88Y9/lD/96U+uw6z++c9/yvvvv5+0x77//vtdhzyTdOrUSa6//vry/2su+npqJ/PKK6+UZs2ayYEHHpjQHwLfffedpNOaNWvcHyMHHXSQnH322bL99tsH8jgnnniinHTSSTF/1qpVK/N/zfCCCy6IuW5hYaH3vtL3zsaNG6Vu3brmZz/99JN8/vnnNd53AAAyFf3LxNC/TI1s6182adKk/N/aFidPniy77babPPvss3LWWWdJXl5ekvccQEUUYQEE0sGaM2eO/O1vf5MzzzzT/Ew7yPXr1zcdgEyg+6qduLfeekt23nnn8vt11IJ2oMeNGycDBw6UgoICyQWNGjWSbt26efcfcMABsu+++8qLL76YUCc5E6xcuVLKysrca9qzZ8/AHkf/MIyVXSzNmzePe10dKTJ9+nT54IMP5NBDDzU/mzRpkuy+++7y1VdfVWufAQDIdPQvsx/9y8zqX77++utuec0117iDAZ988ol7HQAEh+kIACRdgwYNXAdKO56VabHo8MMPl1q17DEg7bw89NBDrrikp2rpOk888YRZR4+W6zoDBgxwp/to50JPS9MOQ5Seiq3beO+99+Too48u39bLL79c5T4vXbq0fD8qGzx4sDuavGnTJtc5HDZsmLu/b9++5ae86ak/N910k+vA6L5pZ0bNnj3bjXTYZ599pHPnztKnTx8ZNWqU63hHf09PO3vppZfcqUA6olH9/PPPcumll7oRDF27dnXbnTVrltmvxYsXu1PvdB3t9F133XVyxx13uG0qPSqv+6JHuSvS06R69Ogh69evl0TpCMw6deqYo+Rbe+00I31++jz1OWqGU6dOdf/WZeVT1fQWFSvX6O9+/PHHbsSB5qOngN12222ujcSijxnNRUed6O9XbJN6Glz37t3ddjRH7VBXblP33HOPy7p3797m56myww47uHy39L466qijUr5PAACkCv1L+pf0L5PrhRdecEVXbUc6Svuvf/1rSh8fyEUUYQEE4sgjjyw/Zazi6To6ik87uZWNGDHCjQY45phj5IEHHpD+/fu7ztG9995bvo7Od6QdvN/+9rfyyCOPyI033igrVqyQiy++2HT4lixZIjfccIOcfvrprvOmpwVdddVVVZ6upJ1X7bhrZ0w7Q7rvmzdvdj/Tztk555zjRljoqUbnn3++u1/Xq3iqz1NPPSVFRUVuH/WUIe3E6iloum+jR4+Whx9+2BXKtAP5+OOPl29j2223dX9U6GlALVu2dHM1aef/yy+/lGuvvVZuv/121xHVbUWfg3bYdV8/++wz1+nTuca0Q15xPifdBz11vfIfKzrnlr4++nyqushBSUlJ+U238/3337s/ENauXSvHHnts3K+dZqTPT5+nPkfNMBGVc426/PLLXWdfH1PblLYJPS0tFn1MzVrp66f7oXSb+seI/sGlz+HCCy90o1W0ox79Qyb6R4ueIqh/hGgGTZs23eL+6mtVMbuKt63lXNW6Sl+36JQEUfq66GtPERYAEHb0L+lf0r+sfv+yom+//VaKi4vluOOOc//X5d///vfyAwcAgsF0BAACoZ0S7YRVPGVML0CwzTbbuI5NRXPnzpXnnnvOdVaik+vr0WA9Gv7ggw/K73//ezc/ZvTIfMUj2Xrk/KKLLpKvv/66/LQb7ZT++c9/Lj+dRk//Ovjgg10np127djH3V49cawdo5MiR7si03urVqyd77bWX65gdccQR5af37Ljjju7fevp3xXmffvOb37iOW9SHH37o1rnrrrvc6Vdqv/32k48++sgdbdfnqqfW6ZH/iqcNPfbYY67z/8wzz8h2221XfpqWdmx1W9qZe/XVV12nVY9g6+gApUex9VSoKH2uevRdO8XROaS0U/3DDz+4TntVpk2b5kZWVKSvh84Zpfugecb72mle+vz0ecZ7GlVFlXONjm7Q56SdWqWvtc5ppSNUYl20Qx9fXwul+6P7oaMNdL40vaCVjk6I0ueof5BotrpU2nHVP7S0PWyNdry3dFEGHV2h+xKlI2i2NIrm+eefd38cVKTtUEdkVJySQEda6OusOQEAEGb0L+lf0r+sfv9Si8TRrHQ/dA7e6Eje448/3rVP7X/+4Q9/2Or+AKgeirAAAqEdTP1Sr9hJfuONN1xns/KE73q6lx6x1fUrHqXV/2snRq98qp0/PWKv9Ei+dhB//PHH8osw6JH7iip2xqIXb9CLNlTlsMMOc50/3R+9OIJ2xnSpnV29gIJ2DquarD7aCYvSzqLedMSDzmGm+/vNN9+4/ddOz5ZoR0q3pZPsR/PQi1FoR1k7x9HMoqenR2lHXPe/4ilY//d//+dGO+ipWtrh1tO22rZt6zrPVdEOsv7BoPSPkzvvvNM9D13usssuCb92NVE516jKz0Ff5629xhXpaBRtN5VHzmhHWLP69NNPyzvJVe1HZdrp1lssleeq09cr2tGvrH379jH/YNC2re+rikXYivsJAEBY0b+kf0n/svr9y+jBAs1cX/Po3MR6a9iwoTuQocVvLXxr2wCQfBRhAQRGO8Q6X5WeMqYjCrTzd8kll3jr6VF5taXTqRctWuSWesqMdtx0qaMgtEgVHf2nHbWKKp4KFe1EVF4nltq1a7tTx/QWfWydY0tPIdKj4NEj9Fuaq6zyaUNjx451pztp561Nmzbu1LPKV7aPlYd2qCuPFIjSkRjLly93oz4qq3yfjm7QU7d0tIKe8qad/eiIgqpoR6ziKEydF0tPB9M5snT+q+jR9nhfu5qonGvFP8Qq0tc5ntc4KjrvVosWLbyf6X2V5zrTTOKhp/xVHsG6JfrHUrzrVnxf6R9segqfjhTRkSd6ih4AALmA/iX9S/qXNetfapv75Zdf3KhXvVU2ZcqUrLtAGpAtKMICCIweWdeOhY5W0I6OnlpV8ch65aO3eppUrI6IdoR1vq9Bgwa507p0xIMeLddOkZ4Cph3YmtJTjPQIvs59VZGOFtBTz95++2032qCqTnJlOl/YhAkTXMdeR0E0btzY3V9x3qlYdD2doP/KK6+M+XM97Ur3S4tvlWmHqiLNUwt02jnW06C0s15xvq14aadRT6nS+dE0j+iokXheu1iiIz4qX6hC5wOLtzNaU9F5t3Tuq4qjL6LzvulIkEykr6ee7qcdZP2DUU8TjPUHEwAAYUT/kv4l/cua0akIdD8084q02KwHOPQCXRRhgWAwxhxAYLQzp6e5aCdWO2lbOpodnQdJj77rUdvoTU+r0hF/ejRcTw/TpV4MQUcoREcf6NyYW7rqbCL09CDtzM+bN8/7mY42VNrJVPGenqOnSum+6ilb0Q6yHrnXU8Yq7m/l7WkHWR9TO+0V89DRBnq0uqCgwK2jV7r96quvyn9PTyXSwlxl2inXx9SOrM4Zph3s6tDOto7geP31192pVPG+drGeY3QOs4oX1tCRA1Vd3CLZdPSFtlF9PhVNnz7dXShhzz33lEykr5+eLqbttar3FQAAYUT/kv4l/cvq00Kwvp76vtl7773NTQ/s6+uhByGSMdoYgI+RsAACpacrDR482HWShg8fHnMdHX2gpyJF55bS0QzaSdQLGejoBr3wgR5h146VXqlUrzKrN+18R0+hqXj12urQCzLoXFfaodSOuM4HpfusIw31irA66kJvFY/O64Ug9L4tXYxBTw3TCfR1xILOIaangOnFBHSeqIr7q9ubNWuW63jq7+gcZ9oh1qWenqUXjdB5P3WOJr1yqtJ5pnS7Ot+Tjh7QbfzlL39xIxUqjw7Qgp12uHX7mmlN6JVy9bXSU+h0/q94Xrvoc9QRAdqp07mv9Pf09Dm9wq2+rtELLVR1Rd1k01O19NQ53Qc9TVBHoegfHtq51z9u9AIF1aEdf50PLBZ9fvrco/SPiS2tq38MbelUMj0VU0fVaG46CgYAgFxC/5L+ZfQ50r/0+5dV0Qt26Ty7Wzp4cdxxx8nEiRNdu9CL0wFILoqwAAKlR8a1g6Qdoi11JpUWlLSTpKe/aCdDT6/WDrbO8aXFKD3Srx3OW2+91XUK9ZQi7Ww9+eSTcu6557qjy9Gre1aHdui006f78Nprr8nDDz/sTsnZaaed3FxX2nGOnuKkR4r1eekpUzoPmXZWY9E/DvQI/uOPP+46YpqBnqoV7RCuWrXKZaMdYZ1XSx9HO7p69F9z0O2PGDHCzf2pnU09ZSh6qpn+kfDoo4+6+3Qd/b92VrXjFx1ZUflqwlrwq+lFDPS0Kr16sP7hoFfXHThw4FZfO3XCCSe4DrJ26ocMGeI6p3oVXn3eeuVbPR3tjDPOcCNSYu1/ULRzqY+t7UivGKv56QgA3fctzRW2NVuaX0t17NjR/QEUpZnoLRZt89quY9F91NdeX9foKBgAAHIF/Uv6l4r+Zez+ZVV07t1dd921fAR2ZVpc13arhdgLLrigPGsAyZEXSWSWaQBARvj2229dh1JHQVa8oq52ovUqrvfcc0/5ffoxr0e79Uq6OtIAAAAAqIz+JQAEi5GwAJCF9PQ5HbHx+9//Xg499FApLS11p5T9+9//lssvv9ytoxeb0As36ClvOheZjjAAAAAAYqF/CQDBYiQsAGQpvdCDnjKmFxvQj/JOnTrJ+eef70YkKJ3vSU8T04s06FxfRx99dLp3GQAAABmM/iUABIciLAAAAAAAAAAEKD/IjQMAAAAAAABArqMICwAAAAAAAAABoggLAAAAAAAAAAGqFeTGc8nMmTPdxOW1a9dO964AAADktM2bN0teXp50795dshH9SgAAgPD1K7NiJKxeeXHcuHHSp08f6datm5x77rkyb968La6/fPlyueyyy6Rnz57Sq1cvGTlypKxfv77856WlpW57Bx98sHTp0kVOOOEEee+992q0j9pR5hpnv9IsNmzYQCb/Qx4+MrHIwyIPizx8ZGKRR7j6Zdm+/8lG+7bIw0cmFnlY5GGRh49MLPIIrl+WFSNh77vvPnn66adl9OjR0rp1a7nttttk0KBB8tprr0mdOnW89YcMGeKKrhMmTJBVq1bJNddcI+vWrZNbbrnF/fyuu+6SiRMnys033yzt2rWT119/XS644AJ57rnnZI899qjWPkZHKhQVFdXw2YbDggUL5KGHHpLzzjtP2rRpI7mOPHxkYpGHRR4WefjIxCIPq7i4WLIZ/UqL9m2Rh49MLPKwyMMiDx+ZWOQRXL8y40fCbtq0ScaPH+8KqwcddJB07NhR7rjjDlm4cKG8/fbbMU/f+vTTT13BtXPnzrLvvvvKDTfcIK+88oosWrSofCixFmZ1ezvssIOcf/750rBhQ/nkk0/S8AwBAAAAAAAAhFnGF2Fnz54ta9eudcXUqCZNmkinTp1k2rRp3vrTp0+Xbbfd1o1wjdIpCXT+hhkzZrj/X3XVVTJgwAD3bx1i/cQTT7iRs3vvvXdKnhMAAAAAAACA3JHx0xHoiFdVeQh0y5Yty39WkY52rbyuTlnQrFkzN6S6oldffVWuvPJKN7fDRRddxClfAAAAAAAAAHKvCBu9oFbluV/r1q0rK1eujLl+rHlidf2NGzea+/TCXS+//LJ89NFHMnbsWGnevLn8/ve/r/a+ajFX557Ff7PYfffdyeR/yMNHJhZ5WORhkYePTCzysDQHPQsqm/Fa/or2bZGHj0ws8rDIwyIPH5lY5BFcvzIvkuGXO3vrrbfcfLCff/651KtXr/z+iy++2M0Xe//995v1b7zxRvniiy/chbcq0ukMBg8eLGeeeWbMx7nuuutcMfbvf/97tSfq1f0BAABA+ulB+Ww9y4l+JQAAQPj6lRk/EjY6tcDixYtlxx13LL9f/9+hQwdv/datW8vkyZPNfdqJXbFihZvCoKSkRN577z03p+xvfvOb8nV0Wy+++GKNr2Tbvn37Gm0jLDTn1atXS+PGjaVWrYxvZoEjDx+ZWORhkYdFHqnNpLS01G0/m+g+6xz6eqHRgoICCTt9zat6nnPmzJFsF0+/Mhvbaq6176211ergO8FHJhZ5WORhkYePTCzyCK5fmfFpduzYURo1aiRTp04tL8KuWrVKZs2aJQMHDvTW1ykGxowZIz/++KPstNNO7r5PP/3ULXv06OE6Qddee62ceOKJctlll5X/no60rWkBVYcnN2jQoEbbCAudf/eRRx6R8847z5ujNxeRh49MLPKwyMMij9RkoicH6XzzeuA2G4tU0c5ythWpqkvn+9eD77FOD8v2qQi21q/M5raai+27qrZaHXwn+MjEIg+LPCzy8JGJRR7B9StrZcOQXy22amFV52zdbrvt5LbbbnMdmcMOO8x1ypYtW+Y6ZTpdQdeuXWXPPfeUoUOHyogRI9z8FTrVwHHHHSetWrVy2zz77LPlnnvukd12280NJ3777bfl9ddfl7vvvjvdTxcAAKRJtKilZ85o8SubCnnRs3602BNrbvwwic5PpmdFqVz84yCb22outW/aKgAAyKoirNI5YXU49PDhw2XDhg1utOujjz7qTtP66aefpG/fvnLzzTfLCSec4DqhWmAdOXKknHHGGe6CXP3795dhw4aVb++cc85xv6tFV63w77LLLjJu3Di3HQAAkHv0oG60qLXNNttItsnPz3eni+kB6WwqUlVX/fr13VKLW/qaZePoyFxtq7nWvnO5rQIAgCwswmpn5YorrnC3yrbffnv5+uuvzX3aIdWialUdOb1A15Yu0gUAAHLL5s2b3ZJphbJH9LXS1y6XClu01eyTq20VAABY+ZX+DwAAkLPCflp3mOT6a5Xrzz+b8FoBAACVF9HJilBjxcXFbqlzzAIAgOyi0x3NnTtX2rZt6055Rna/ZtneL6tq/2mr2YfXDACA7JXMfmVWTEcAAACQTqeddpp8+umn5j6dX75FixZy8MEHyyWXXCJNmzbNmH3TkXd6CvTOO+/s5sg/9thjk/64Ore+zsNfeVoopBdt1UdbBQAAmYAiLAKxdOlSeeWVV1xHWjv9uY48fGRikYdFHhZ5ZEYmnTp1kuuvv778/zq/45dffiljx46Vr776Sp555pm0nXa8++67y8UXXyyNGzd2FzDSizctXLhQJkyYIFdeeaW7qvyBBx6Y1Mc86aSTpE+fPkndJsLfVivvWzxtVfdfL0amP9OCcq63Vb4TfGRikYdFHhZ5+MjEIo/gUIRFILSz/NNPP5VfPCLXkYePTCzysMjDIo/MyKRRo0bSrVs3c1/Pnj1l7dq17oKgn3/+uffzVGnYsKF06NDBdZQrXj3+gAMOkH333VdefPHFpBdhW7du7W7IPJncVmPt29baqs6epu/16s6iFra2yneCj0ws8rDIwyIPH5lY5BEcLswFAABQA3vssYdb/vzzz+WnXF9++eUyZMgQV2w666yz3P0bN26UW2+91RWY9HeOPvpomTRpUvl2rr32Wtl///3dyMCK/vznP8vee+9drY5w3bp1XVG24qjHsrIyeeihh+TQQw91+3H44YfLE0884f3uo48+Kn379pUuXbrI7373O3n33XddoXfq1Knlp3jr/6P0eV933XVy3333uVGHXbt2lXPPPdeNpnjhhRfc43Xv3l3OPPNM17GvaPLkyXLCCSe4ubY0g1GjRsm6desSfr4IZ1s98sgj5bDDDpMBAwbQVgEAQNZiJCwAAEAN6AV31A477FB+35tvvinHHHOM3H///a6QpCP4LrzwQvnss89cwatdu3byzjvvyNChQ2XTpk1y3HHHuVO+nnvuOVc42m+//dx29Hd1W0cddVSVp2Hr9rUgVlJSIvn5+e7f8+fPl3vvvdeNfqw4z+aIESPcaMPBgwe7QtO0adPkpptuklWrVrl9VDp/pv7uOeecI/vss49MmTLFzSW6Na+//rp07tzZFeP0FPMbbrhBBg4c6ApsV111laxfv94Vv/R+La6p1157zRUCtdCnj6H7fccdd8icOXPkL3/5C1eWD2Fb1XYaFU9bHTRokLuo1bfffktbBQAAWYsiLAAAQBwqF49WrlzpLjKkxSstZkZHGSotQo0cObJ8aoCPPvrIFYe0YKOj+pSOwNNCz5gxY9wIvx49esh2223nikPRwpYWuZYsWbLVixXNmDFD+vXrZ+7TgtBuu+0md911l7sgU7QIp8WzSy+9VM477zx3X+/evd26Dz74oPz+9793RaiHH35YTj31VFdwiq6j+/rss89WuR+ajxbFohd+evvtt93z1tGD0cLfv/71LzfPWDRTff6ahS6j9CJNOgrx/fffl4MOOmirrw2yp61q0V+Ln4m0VW0LOkr1iCOOcHMe01YBAEA2YjoCBEIvnHD88ce7JcgjFjKxyMMiD4s8MiOTaPEoetPikxaItKB1++23m1Fwu+yyi5mb9eOPP3Y/19O7tfgTvR1yyCGucKUj/PTnOiJRi0A64lC98cYbrsijp0tv7WJHTz75pEycONGdYq0FLf29O++8U/r371++3ieffOKKSfq4lfdDT0HXYq4WnjZs2GB+T2nxbWt01GS0qKV0jtrCwkIz8lJfs9WrV7t/f//9924UYuX90flLde5QLQgiXG1V9+f55593t3jbqtL2oGirfCfEQiYWeVjkYZGHj0ws8ggOI2ERiPr167t5ufBf5OEjE4s8LPKwyCMzMtHikY4YVFqE0lF4bdq0KS8OVb5QVkV6ZXctKO25554xt7148WLZfffd3ShCHa2oI/J0xJ2OzjvjjDO2um+6D1oMitJCmBbJzj77bHc6d/Pmzcv3Q+kp47EsWrSovDAV/Z2obbbZJq79qKxBgwZbXD+6P5prNNvKuSBcbVUfT+dTjaKtJo7vBB+ZWORhkYdFHj4yscgjOBRhEQid0+vLL790fwRU7tznIvLwkYlFHhZ5WOSRGZlULh4lonHjxq7A8/jjj8f8+U477eSWOu+ldnp1bk2d21XnvtQC1dZo0UwzqVevnhQUFLhRfTqf5cUXX+zmvNTRj6pJkyZu+dhjj8XM7Te/+U35vKG//PKLGyUZtWzZMkm26P5ceeWV0qtXL+/nFUcqIhxttbJ42qr+MagjbnXErj5WrrdVvhN8ZGKRh0UeFnn4yMQij+AwHQECoR1x7ZTrEuQRC5lY5GGRh0Ue2Z+JFm30CupaLNXiWPT2zTffuIsKVZy/U0cY6uhCPb1bRyNWPD16S3S7Ou9nxavV6ynaOkJR5+3U+UDVXnvt5ZbLly83+6FFK52PU0f7dezY0RXi9GJMFelIx2TTwpmOWtQr0Ffcn1atWrli3KxZs5L+mEhvW41la21VR97qHLS6pK1m3+dfKpCJRR4WeVjk4SMTizyCw0hYAACAgOn8mjpdwAUXXOBuOh/lF198IePGjXPFp4qnU+vFkEaPHi2TJk2S66+/vkaP+6c//cmNThw1apS89NJL0qFDB/f/a6+91l3ZXecI1dGEehGm7bff3s3NqSNp9Wr0um86AlGLcloYe+aZZ9w2oyMRk0Efa+jQoW4kpP5bL8qkHX6dK1RPN698ASfkZlv9z3/+49qnFmR1P2irAAAgG1GEBQAACJgWgx566CE3gk+v7K6nT+sIurPOOksuvPBCs64WufQK73qhn8oXHKrO6L3TTjtNxo8f7wpTAwcOlJtvvtntw1//+ld3oSEd3afFtEsuucQVl9TgwYPdSEi9wvyjjz7q5u3Uq8/r71Y1b2Z1nHTSSe5Ut0ceecQ9nm5fR1XqFeirO7IS4Wqrzz33HG0VAABkPYqwAAAAW/HEE0/UeF0t2AwbNszdtuaBBx5I6PF0vsylS5fG/PlVV13lblG1atVyxbTKBbUoPd1cTws/7rjj5Pzzzy+//6mnnnIFumix6aKLLnK3ivtRmY6SrKzy7yktrOkN4W+rVdlSWz333HNd+9b5Y3Ve2CjaKgAAyCYUYREI7SDr6WsVO8q5jDx8ZGKRh0UeFnn4yMTSglPdunWTcvq1Fr4efvhhd0EkLWwVFha6+UDvvPNOV+yKXqAISHf7ztW2yuefj0ws8rDIwyIPH5lY5BGcvIiev4MaKy4udsvqXokWAACkz4YNG9zcqHrF93r16kmumzdvnowdO1amTp3q5r3UK9Hr/Jx66nft2rUl01+zbO+XVbX/tNVwtVUAAJDZktmvZCQsAlFWViabN292nd9kXhQhW5GHj0ws8rDIwyIPH5lYekxdb3l5ee5WU3oat16sC8j09p2LbZXPPx+ZWORhkYdFHj4yscgjOKSJQOhVYnVuLV2CPGIhE4s8LPKwyMNHJpZ2lPXCRboEwob2bfH55yMTizws8rDIw0cmFnkEhyIsAAAAAAAAAASIIiwAAAAAAAAABIgiLAAAAAAAAAAEiCIsAAAAAAAAAAQoL6KXGkWNFRcXu2VRUVG6dyUjlJaWyoYNG6RevXpSUFAguY48fGRikYdFHhZ5BJ+Jbmvu3LnStm1bt81so905vZKtXsG28tXjw6qq1yzb+2VV7X+2t9VcbN/Jfs34TvCRiUUeFnlY5OEjE4s8JLB+Za0abwGIQd+oDRs2TPduZAzy8JGJRR4WeVjk4SMTSwtTdJIRVrRvi88/H5lY5GGRh0UePjKxyCM4TEeAQCxbtkyeeeYZtwR5xEImFnlY5GGRR3gzKYuUZdXj6mjEcePGSZ8+faRbt25y7rnnyrx585K+f8g86Wqr0cdevny5lJSUxP87IW6rYfn8SyYyscjDIg+LPHxkYpFHcBgJi0Bs3LhRvvnmGznooIPSvSsZgTx8ZGKRh0UeFnmEN5P8vHx56vMpsmjNypQ9ZqtGTeXUrn2q9bv33XefPP300zJ69Ghp3bq13HbbbTJo0CB57bXXpE6dOknfV+R2W63YXrUAq4XVeIW5rYbl8y+ZyMQiD4s8LPLwkYlFHsGhCAsAAJBGWtSavyrzRxps2rRJxo8fL5dffnl5p/yOO+5wIw3ffvttGTBgQLp3EQGjrQIAAFQf0xEAAABgq2bPni1r166Vfffdt/y+Jk2aSKdOnWTatGlp3TegItoqAADIRBRhAQAAsFULFy50yzZt2pj7W7ZsWf4zIBPQVgEAQCaiCItANG7cWA477DC3BHnEQiYWeVjkYZGHj0xSb/369W5ZeT7NunXrurnDgCDpVZr1as3xCHtb5fPPRyYWeVjkYZGHj0ws8ggOc8IiEI0aNTKngOU68vCRiUUeFnlY5OEjk9SrV69e+Xyb0X8rLWrVr18/jXuGXNCgQYO41w17W+Xzz0cmFnlY5GGRh49MLPIIDiNhEQgdgfDll1+Wj0TIdeThIxOLPCzysMjDRyapFz21e/HixeZ+/X+rVq3StFfIFRs2bJCysrK41g17W+Xzz0cmFnlY5GGRh49MLPIIDkVYBGLFihXy/PPPuyXIIxYyscjDIg+LPHxkknodO3Z0IyOmTp1aft+qVatk1qxZ0rNnz7TuG8Jv9erVUlJSEte6YW+rfP75yMQiD4s8LPLwkYlFHsFhOgIAAABslc6vOXDgQBkzZow0b95ctttuO7ntttukdevWbt4wIFPQVgEAQCaiCAsAAJBGrRo1zZrHGzJkiBuNOHz4cHd6uI4qfPTRR6V27dpJ3UdkplS31Zo8Jm0VAABkGoqwAAAAaVIWKZNTu/ZJy+Pm5yU+K5Venf6KK65wN+SWdLXV6GPHOx9sFG0VAABkGuaERSBq1arlTvnSJcgjFjKxyMMiD4s8wptJdQqhsWzevFmWL1/ulql8XOSOdLaZ0pJSyc/Pl7y8vLTtQyYJy+dfMpGJRR4WeVjk4SMTizyCkxeJRCIBbj9nFBcXu2VRUVG6dwUAACRIT1eeO3eutG3bVurVq5fu3UENX7Ns75dVtf+01ezDawYAQPZKZr+SYRAAAAAAAAAAECCKsAjEggULZNSoUW4J8oiFTCzysMjDIg8fmVibNm2Sn3/+2S2BsKF9W3z++cjEIg+LPCzy8JGJRR7BoQiLwJSWlqZ7FzIKefjIxCIPizws8vCRCYBcxeefj0ws8rDIwyIPH5lY5BEMirAAAAAAAAAAECCKsAAAAAAAAAAQIIqwAAAAAAAAABCgvEgkEgnyAXJFcXGxWxYVFaV7VzLC5s2bZfny5VJYWCi1a9eWXEcePjKxyMMiD4s8gs9kw4YNMnfuXGnbtq3Uq1dPsk1ZWZmbu6ugoEDy83PjGHtVr1m298uq2v9sb6u52L6T/ZrxneAjE4s8LPKwyMNHJhZ5SGD9yuzrxSAr6Bu1ZcuWvGH/hzx8ZGKRh0UeFnn4yMTSwpRmkcoC1YMPPiinnXZayh4Puaum7TtsbZXPPx+ZWORhkYdFHj4yscgjOBRhEYgVK1bIq6++6pYgj1jIxCIPizws8ghvJpGysqx83KeeekruvPPOpO0PMl+62mr0sVeuXCklJSUJ/24Y22pYPv+SiUws8rDIwyIPH5lY5BGcWgFuGzls/fr1MnPmTOnZs6c0a9ZMch15+MjEIg+LPCzyCG8mefn5snLyM1K6fHHKHrOgsKU07XdKtX530aJFcv3118vUqVNl5513Tvq+IXOlo61WbK+bNm2S+vXrx/17YW6rYfn8SyYyscjDIg+LPHxkYpFHcCjCAgAApJEWtUqWzpds8OWXX7pT03R0xL333ivz52fHfiM5aKsAAADVRxEWAAAAcTnkkEPcDch0tFUAAJBpmBMWAAAAAAAAAAJEERaBaNiwoey///5uCfKIhUws8rDIwyIPH5kAuUXngy0oKEj3bmQEPv98ZGKRh0UeFnn4yMQij+AwHQEC0aRJE+nXr1+6dyNjkIePTCzysMjDIg8fmQC5pVGjRunehYzB55+PTCzysMjDIg8fmVjkERxGwiIQGzdulB9++MEtQR6xkIlFHhZ5WOThIxMgt2zatEnKysrSvRsZgc8/H5lY5GGRh0UePjKxyCM4FGERiGXLlsljjz3mliCPWMjEIg+LPCzy8JEJkFtWrlwpJSUl6d6NjMDnn49MLPKwyMMiDx+ZWOQRHKYjAAAASKOCwpahfjyERzraDu0VAACEBUVYAEDWKYuUSX5eftLXBVItUlYmTfudkpbHzcuv2fti9OjRSdsfZL50tdXoY9dkKgLaKgAAyAQUYQEAWUeLqk99PkUWrVlZ5XqtGjWVU7v2Sdl+AYmqaSE0avPmzbJixQpp1qyZ1K5dO2WPi9yRzjazuaRESktL0/b4AAAAyUARFoHIz8+Xxo0buyXIIxYyscgj8Ty0ADt/VW7MU0T78JGJjyIVwiovL8+913UJPv9iIROLPCzysMjDRyYWeQQnLxKJRALcfs4oLi52y6KionTvCgDkhLEfvb7VIux2TZrLpfsPSNk+IXtt2LBB5s6dK23btpV69eqle3dQw9cs2/tlVe0/bTX78JoBAJC9ktmvpKwNAAAAAAAAAAGiCItALFq0SMaOHeuWII9YyMQiD4s8LPLwkYk/J+zChQvdEggb2rfF55+PTCzysMjDIg8fmVjkERyKsAiEXsF29erVNbqSbZiQh49MLPKwyMMiDx+ZWDq7lGbBLFMII9q3xeefj0ws8rDIwyIPH5lY5JHjRVh94ceNGyd9+vSRbt26ybnnnivz5s3b4vrLly+Xyy67THr27Cm9evWSkSNHyvr16832HnnkETn88MPd9o466iiZOHFiip4NAAAAAAAAgFySFUXY++67T55++mm58cYb5a9//asrog4aNEg2bdoUc/0hQ4bIjz/+KBMmTJC77rpL3n//fRkxYkT5zx988EF3u/jii+XVV1+V008/3f385ZdfTuGzAgAAAAAAAJALMr4Iq4XW8ePHu8LqQQcdJB07dpQ77rjDzQv19ttve+vPnDlTPv30U7nlllukc+fOsu+++8oNN9wgr7zySvl8Fs8884ycffbZcuSRR8qOO+4ov/3tb+XYY49lNCwAAAAAAACA3CvCzp49W9auXeuKqVFNmjSRTp06ybRp07z1p0+fLttuu620a9eu/D6dkiAvL09mzJjhRtFqgfb44483v5efny+rVq0K+NnkjubNm8sZZ5zhliCPWMjEIg+LPCzy8JGJVatWLWnRooVbAmGj7Xqbbbahff8Pn38+MrHIwyIPizx8ZGKRR3AyviejI15VmzZtzP0tW7Ys/1lFOtq18rp16tSRZs2ayYIFC1yxtWJBV/3888/yxhtvyO9+97tAnkMuqlu3ruy8887p3o2MQR4+MrHIwyIPizzCm0lZWUTy8/NqvB3t32h/J+jHXbFihbta7nvvvSdr1qyRDh06uHn499prr4S3hdxsq9WT597ziQhzWw3L518ykYlFHhZ5WOThIxOLPHK4CBu9oFblPyy0UaxcuTLm+rH+CNH1N27c6N2/dOlSd6EvPbp+/vnn12hf9Yqt69atq9E2wkKvpKdTQ3Tv3l0aN24suY48fGRikUf8eeiZDfXr109oe/rdkM1X1aZ9BJ+J9hH0bJnS0lJ3S5WCggJ558OvZfmq1PUfCps0kEN7d6jW8xw6dKjrO912221u5O2TTz4p55xzjrzwwgvStm1bSSXdf33N9P1d+eq9+n7Xz4pstqV+ZS611YrtVd/z9erVcwccwtRWq4PvBB+ZWORhkYdFHj4yschDAutXZnwRVjtb0blho/+OdkBj/RGu68S6YJeu36BBA3Pf999/L+edd57rGD3++ONumoOa2Lx5s3z11Vc12kZYaIF86tSpriDetGlTyXXk4SMTizziz0M/+3VKmkTMnTu3/KBeNqJ9pCYTPdU51gHboGgxSduzFrWWLlsrqab9pUQKQv/5z3/kn//8p5urf4899nD36cjCDz74wF3ctKYHsxOlr1VJSYnrz8WSyMjgTFRVvzLX2qrasGGD+yNIi8Fha6uJ4jvBRyYWeVjkYZGHj0ws8giuX5nxRdjo1AKLFy92F9GK0v/raUWVtW7dWiZPnuz9kaGnJOkUBlE6P6x2wFq1aiWPPPKIW9ZU7dq1pX379jXeThjotBBTpkxxIw2SkW22Iw8fmVjkEX8e1TkKqdvJ5pGwtI/gM9EiiU5PpGfOVDzoG2aJdia1j3X//ffLnnvuaX5XC3Q6f386ctNipPYPK5+qPmfOHMl2W+pX5mJbjdLnHM+8sNnUVquD7wQfmVjkYZGHRR4+MrHIQwLrV2Z8EbZjx47SqFEjV4WPFmH1AlqzZs2SgQMHeuv37NlTxowZIz/++KPstNNO7r5PP/3ULXv06OGWX3zxhQwaNMiNpNIOWk1HwFYsDFQebZurop1bXZIJecRCJhZ5BJtHotMXZBraR/CZaHFGbzrKLp6RdmGQ6PMsLCyUQw45xNz31ltvuVGHBx54YMpz08eLjtCsXFTL9qkIqupX5mJbrZhJPM85m9pqdfCd4CMTizws8rDIw0cmFnlIYP3KjC/C6tFrLbZqYVWvzLbddtu5uZ30CPdhhx3mphJYtmyZm6dCG0jXrl3dUW+dB2rEiBFuLq3rrrtOjjvuOFfB11OBLr/8cjcH7OjRo91ogiVLlpR3kLj6GwAAwNZ99tlnMmzYMNcfO+igg9K9O8AW0VYBAEAmyPgirBoyZIgrng4fPtzNB6WjXR999FF3mtZPP/0kffv2lZtvvllOOOEEV6G+5557ZOTIkXLGGWe4U3769+/vOl7RUbA6Slb169fPPI4WeN999920PMew0SP9Oolzto8+Sxby8JGJRR4WeVjk4SOT9NKpn/Sgth741gPlQNASuShX2Nsqn38+MrHIwyIPizx8ZGKRR3DyItk8SV4GKS4udsuioqJ07woA5ISxH70u81ctq3Kd7Zo0l0v3H5CyfUL20oO8egE3nfsq1fNFPjdpZkovdtSieUM5+cju1f59vcr8n//8Z3eQ+5ZbbknbBbCqes2yvV9W1f7nUlutaXvNhrYKAAAyWzL7lYkfTgbivKKvXjxNlyCPWMjEIg+LPCzy8JFJejz99NNy4403yqmnnipjx45NW1ELuUff62VlZXGvH+a2yuefj0ws8rDIwyIPH5lY5BEcirAIxNKlS91Fz3QJ8oiFTCzysMjDIg8fmaSejuS76aab5NBDD5XBgwe77HVefb2tXr063buHkFuxYoWbniweYW+rfP75yMQiD4s8LPLwkYlFHjk+JywAAEBYFTZpkBWPp1eX1xER77zzjrtVdPzxx7sLniLcUt1Wq/uYtFUAAJCJKMICAACkSVlZRA7t3SEtj5ufn5fQ7/zhD39wN+SmdLXV6GMnMhUBbRUAAGQipiMAAABIk0QLoVuio/70VOt45+5K1uMid6SzzZSUbJbS0tK0PT4AAEAyUIRFYAoKCtK9CxmFPHxkYpGHRR4WefjI5FeRSMQVYHUJIPz4/PORiUUeFnlY5OEjE4s8gpEXobeeFMXFxW5ZVFSU7l0BgJww9qPXZf6qZVWus12T5nLp/gNStk/IXhs2bHAX82nbtq3Uq1cv3buDGr5m2d4vq2r/aavZh9cMAIDslcx+JSNhAQAAAAAAACBAFGERCJ2X7sEHH3RLkEcsZGKRh0UeFnn4yKRmc8IC2YT2bfH55yMTizws8rDIw0cmFnkEhyIsAlFSUiILFy50S5BHLGRikYdFHhZ5+MjEYk5YhBnt2+Lzz0cmFnlY5GGRh49MLPIIDkVYAAAAAAAAAAgQRVgAAAAAAAAACBBFWAAAAAAAAAAIEEVYBKJZs2Zy4oknuiXIIxYyscjDIg+LPHxkYtWqVUuaN2/ulkDYaLsuLCykff8Pn38+MrHIwyIPizx8ZGKRR3DoySAQ9evXl86dO6d7NzIGefjIxCIPizws8ghvJpGyiOTl59V4O/n5+VKvXr3AH/eXX36R0aNHy5QpU2Tjxo3Ss2dPueqqq6Rdu3YJbwu52VarI0/y3Hs+EWFuq2H5/EsmMrHII7E8yiJlkp8X3/i0RNbNVLQPH5lY5BEcirAIxJo1a6S4uFiKioqkUaNGkuvIw0cmFnlY5GGRR3gz0aLWwslfyebl61L2mLULG0jrfrtX63cvvPBCKSsrk4ceekgaNmwod911l5x55pny9ttvJ1wkQ3ZJR1ut2F7XrVsndevWlYKCAsn1thqWz79kIhOLPBLLQ4uqT30+RRatWVnldlo1aiqndu0j2Y724SMTizyCQxEWgVi9erXr5O688868ackjJjKxyMMiD4s8wp2JFrU2Ll0jmW7lypWy3XbbyeDBg2W33XZz911wwQVy7LHHyrfffitdunRJ9y4ixG117dq1bjqCeIqwYW+rYfr8SxYyscgj8Ty0ADt/1TLJBbQPH5lY5BEcirAAAADYqqZNm8rtt99e/v9ly5bJhAkTpHXr1tK+ffu07htQEW0VAABkIoqwAAAASMi1114rzz33nNSpU0fuv/9+adCgQbp3CYiJtgoAADJFds8oDQAAgJQ744wz5IUXXpABAwa4uTe//PLLdO8SEBNtFQAAZAqKsAiEXjhB5+DSJcgjFjKxyMMiD4s8fGSSXnpK9x577CF//vOf3dybTz75ZLp3CSFXu3Ztyc9P/E+XMLZVPv98ZGKRh0UeFnn4yMQij+AwHQEC0bx5cznllFPSvRsZgzx8ZGKRh0UeFnn4yCT1dF7Njz/+WA4//HB3gSSlRTEtci1evDjdu4eQa9asWdzrhr2t8vnnIxOLPCzysMjDRyYWeQSHkbAIRGlpqbuKrS5BHrGQiUUeFnlY5OEjk9RbunSpXHrppa64FbV582aZNWuWtGvXLq37hvDT93okEolr3bC3VT7/fGRikYdFHhZ5+MjEIo/gUIRFIHSUwZgxY0Ix2iAZyMNHJhZ5WORhkYePTFJPT0s74IADZNSoUTJt2jT55ptv5Oqrr5ZVq1bJmWeeme7dQ8jp6FYtpMYj7G2Vzz8fmVjkYZGHRR4+MrHIIzhMRwAAAJBGtQsbZM3jjR07Vm6//XYZOnSorF69Wvbaay956qmn5De/+U1S9xGZKdVttSaPSVsFAACZhiIsAABAmkTKItK63+5pedy8/LyEf69x48YyYsQId0NuSVdbjT52WVlZQr9DWwUAAJmG6QgAAADSpDqF0Fj0NO0lS5bEfbp2sh4XuSOdbWZzyWbmpQMAAFmPIiwAAECW0wsWaQE23gsXAQAAAEitvAi99aQoLi52y6KionTvSkbQU8b0j8HatWtLfj61fvLwkYlFHonnMfaj12X+qmVVbme7Js3l0v0HSLajfQSfyYYNG2Tu3LnStm1bqVevnmQb7c7pLS8vz91yQVWvWbb3y6ra/2xvq7nYvpP9mvGd4CMTizws+pUW7cNHJhZ5SGD9SuaERSD0jVq3bt1070bGIA8fmVjkYZGHRR4+MrGytTgFxIP2bfH55yMTizws8rDIw0cmFnkEh5I2AvHLL7/Ik08+6ZYgj1jIxCIPizws8vCRiVVSUuKy0CUQNrRvi88/H5lY5GGRh0UePjKxyCM4FGERiE2bNsl3333nliCPWMjEIg+LPCzy8JGJf9rYxo0bE76CPJANaN8Wn38+MrHIwyIPizx8ZGKRR3AowgIAAAAAAABAgCjCAkCOKiuLBLIuAAAAAACwuDAXAOSo/Pw8eefDr2X5qnVVrlfYpIEc2rtDyvYLAAAAAICwYSQsAtGkSRM54ogj3BLkEQuZZEYeWoBdumxtlbetFWnDlEemjg7m/eIjE6ugoEAKCwvdMlXmzp0r3bt3lxdffDFlj4ncpO26adOm1W7fYWurfP75yMQiD4s8LPLwkYlFHsFhJCwC0bBhQ+nVq1e6dyNjkIePTCzyyIw8MnV0MO0jvJmURcokP6/mx8S1OFW/fv2UPe7mzZvl8ssvl3XrUn+QBtndVqsjLz/PveerI4xtNSyff8lEJhZ5WORhkYePTCzyCA5FWARi/fr18u2338quu+6a0B+FYUUePjKxyCNz8oiODs4ktI/wZqJFrQ/nPCIr1y9M2WM2rd9aercfVKNt3H333dKoUaOk7RMyXzraasX2qu/5unXrSn5+YoXgMLbVsHz+JROZWORhkYdFHj4yscgjOExHgECsWLFCXnrpJbcEecRCJhZ5WORhkUe4M9Gi1rJ1/0nZraZFtGnTpsmzzz4ro0ePTloGyA6pbqsV2+uaNWukpKQkof0Na1sN0+dfspCJRR4WeVjk4SMTizyCQxEWAAAAcVm1apVceeWVMnz4cGnTpk26dwfYItoqAADINBRhAQAAEJcRI0a4CxwdffTR6d4VoEq0VQAAkGmYExYAAABb9fLLL8v06dPltddeS/euAFWirQIAgExEERaBqF27tmy//fZuCfKIhUws8rDIwyIPH5mk3gsvvCC//PKLHHTQQeb+66+/XiZNmiSPPPJI2vYN4VerVi3Jy8uLa92wt1U+/3xkYpGHRR4WefjIxCKP4FCERSBatGgh55xzTrp3I2OQh49MLPKwyMMiDx+ZpN6YMWNkw4YN5r7DDjtMhgwZIsccc0za9gu5obCwMO51w95W+fzzkYlFHhZ5WOThIxOLPIJDERYAAABb1apVq5j3b7PNNlv8GZAOtFUAAJCJuDAXArFgwQIZOXKkW4I8YiETizws8rDII9yZNK3fWpo32DFlN308IBvaasX2umTJEtm0aVO6I8gIYfr8SxYyscjDIg+LPHxkYpFHcBgJCwAAkCZlkTLp3X5QWh43P6/mx+K//vrrpOwPMl+62mr0scvKymq0DdoqAABIN0bCAgAApEkyCqFq8+bNbqSgLlP5uMgd6WwzJZtLpLS0NG2PDwAAkAz0wAEAALJcJBJxBVhdAgAAAMg8FGEBAAAAAAAAIEB5EYZMJEVxcbFbFhUVpXtXMkJJSYmsWrVKmjRpIrVqMfUwefjIJDPyeG7STFm6bG2V67Ro3lBOPrK7ZFoeYz96XeavWlbldrZr0lwu3X9A1mfC+yX4TDZs2CBz586Vtm3bSr169STbaHdOT9cuKCiQvLw8yQVVvWbZ3i+rav+zva3mYvtO9mvGd4KPTCzyyJx+ZSaiffjIxCIPCaxfSZoIhL5Rmzdvnu7dyBjk4SMTizws8rDIw0cmlham6CQjrGjfFp9/PjKxyMMiD4s8fGSSWB6JXOA1WReDDQuSQCCWL18uL774oluCPGIhE4s8LPKwyCN1mWTrCUI6YkGz0GWuyNbXKlly6flne/tO9mvFd4KPTCzysMjDIg8fmSSWhxZVn/p8ihtBXtVN16EAa1UrjdWrV8s777wjr7zyirz88sveDdDTrnTIti5BHrGQiUUeFnlY5BF8JrVr13bLdevWSTYqKyuT9evXu2WuiL5W0dcuV2R7W83F9p3stsp3go9MLPKwyMMiDx+ZJJ7HojUr3RQeVd10HVgJn9czZcoUGTJkiHsxYh3V1dOFjjvuuEQ3CwAAkDY612SzZs1k8eLF7v8NGjTIqrknN23a5EYJav8sWwtV8dL+pxa19LXS10xfu1yS7W01l9p3rrdVAABQwyLs7bffLrvssosMGzZMWrVqJfn5DC0GAADZr3Xr1m4ZLW5lE71okZ6ppBdRyJVCjxa1oq9ZrsnmtpqL7TuX2yoAAKhBEfa7776T++67T/baa69EfxUAACBj6WjCNm3aSMuWLWXz5s2STbQY97e//U1OPvlkt/9hp6d1Z2MxLlmyua3mWvvO9bYKAABqUIT9zW9+I2vWrEn015BjGjVqJAceeKBbgjxiIROLPCzysMgjtZlowSTbiiaFhYXuALku69Wrl+7dQYpkY1utDtq3xXeCj0ws8rDIwyIPH5lY5JFBRdjBgwfLvffeK0VFRbL99tsHs1fIeo0bN5aDDjoo3buRMcjDRyYWeVjkYZGHj0ws8kCY0b4t8vCRiUUeFnlY5OEjE4s8gpPwhK6vvfaaLFq0SA499FDZf//9pW/fvubWr1+/YPYUWWXjxo0yZ84ctwR5xEImFnlY5GGRh49MLPJAmNG+LfLwkYlFHhZ5WOThIxOLPDKoCKuTymuh9bjjjpMDDjhAevXqZW49e/YMZk+RVZYtWyZPPfWUW4I8YiETizws8rDIw0cmFnkgzGjfFnn4yMQiD4s8LPLwkYlFHhk0HcExxxwj3bt3Zz4mAAAAAAAAAAhiJOxFF10kb7/9dqK/BgAAAAAAAAA5KeEibJMmTRgFCwAAAAAAAABBTUcwePBgGTVqlMydO1c6duwoDRo08NZhXlgUFBRIYWGhW4I8YiETizws8rDIw0cmFnkgzGjfFnn4yMQiD4s8LPLwkYlFHsHJi0QikUR+QQuvZgN5eeX/1k3p/7/66qvk7aGIlJWVyT333CMTJ06U1atXuyLvddddJzvssEPM9ZcvX+4KxR988IHbn6OOOkquvPJKqV+/vrfujBkzZODAgTXe5+LiYrcsKiqq0XYAIJWemzRTli5bW+U6LZo3lJOP7C6ZZuxHr8v8VVVPFr9dk+Zy6f4DciYTAOHol2X7/gNAtgmqXwmEVS69Z4qT2C9LeCTs448/Lql23333ydNPPy2jR4+W1q1by2233SaDBg2S1157TerUqeOtP2TIEFm/fr1MmDBBVq1aJddcc42sW7dObrnlFq8Ae8EFF7giLwAAAAAAAABkxJywvXr12uotmTZt2iTjx493hdWDDjrIjcS94447ZOHChTEvEDZz5kz59NNPXcG1c+fOsu+++8oNN9wgr7zyiixatMitU1JSIjfffLOcccYZst122yV1f/FfmrUWy6OZ5zry8JGJRR4WeVjk4SMTizwQZrRvizx8ZGKRh0UeFnn4yMQij+AkPBL25Zdf3uo6xx13nCTL7NmzZe3ata6YWvHiYJ06dZJp06bJgAF2aPP06dNl2223lXbt2pXfp4VhnZZAR74eeeSRblSs/u4jjzwiP//8swwbNixp+4v/0tHFmjOjjP+LPHxkYpGHRR4WefjIxCIPhBnt2yIPH5lY5GGRh0UePjKxyCODirBXX311zPu1yKmT9uotmUVYHfGq2rRpY+5v2bJl+c8q0kp95XV1yoJmzZrJggULyou4L774ovt3dJkMOieuNlSIbNiwoXxJJuQRC5mkNw/9zI41T3ZVdJqXBKcRDySPoPY9kzPh/eIjE4s8rOh1CrIZ/cpf0b4t8vCRiUUe6e9XZjLah49MLN4zwfUrEy7C/v3vf/fu0xdFR6A+/PDDcu+990oy6YulKs/9WrduXVm5cmXM9WPNE6vrb9y4UYK0efPmpF+ULFtFX5u5c+fKsmVVT9acC8jDRybpzUO/OPWMgkTovkU/k9OZR1D7nsmZ8H7xkYlFHr5Y/cFsQr/yV7Rvizx8ZGKRR/r7lZmM9uEjE4v3THD9yoSLsFuaQ3XXXXd1ncUbb7zRXUQrWerVq1c+N2z030oLqrGq77qOrluZrt+gQQMJUu3ataV9+/aBPka20BHJU6ZMkbZt20qrVq0k15GHj0zSm0d1juTpvqXqCGZVeQS175mcCe8XH5lY5GHNmTNHsh39yl/Rvi3y8JGJRR7p71dmMtqHj0ws3jPB9SsTLsJWpUOHDnL77bcnc5PlUwssXrxYdtxxx/L79f/6eJW1bt1aJk+ebO7TouyKFSvcFAZB0sYYdKE3W2ix/uyzz3Zv2GwfiZIM5OEjk+zLI9HTTjIpj6D2PVWZZEP7SDUyscjDyvapCBT9yl/Rvi3y8JGJRR7Z2a9MFdqHj0ws3jPB9Svzk7UhLXQ+//zzss0220gydezYURo1aiRTp04tv2/VqlUya9Ys6dmzp7e+3qdzxf7444/l93366adu2aNHj6TuG7ZM36g77LADH2D/Qx4+MrHIwyIPizx8ZGKRB8KM9m2Rh49MLPKwyMMiDx+ZWOQRnISLsIcccoj07dvX3A4++GDp1auXvP7663L66acndQf1RR84cKCMGTPGzUc7e/ZsGTp0qBvxethhh0lpaaksWbKkfOLgrl27yp577unW+eKLL+STTz6R6667zl0sjGHlqaOF8rfeesstQR6xkIlFHhZ5WOThIxOLPBBmtG+LPHxkYpGHRR4WefjIxCKPDCrCarG18m2fffaRk046SR599FE588wzk76TQ4YMkRNPPFGGDx8up5xyihQUFLjH0rmyFixYIL1795ZJkyaVDxO+5557ZPvtt5czzjhDLrnkEjnggANkxIgRSd8vbNnatWtdAVyXII9YyMQiD4s8LPLwkUlieZRFyuLeViLrAqnA+90iDx+ZWORhkYdFHj4yscgjOAnPCTt69Ogqf65TAego1WTSousVV1zhbpVpsfXrr7829+mUCOPGjYtr2yeccIK7AQAAhFV+Xr489fkUWbTmv1e73ZJWjZrKqV37pGy/AAAAgFyR8EjY3Xff3Z3mH8v06dPliCOOSMZ+AQAAIIm0ADt/1bIqb1sr0gIAAOSaeM8S4mwiJGUk7Pjx42XdunXu35FIRCZOnCgffPCBt97MmTOZuBcAAKSVdoB15GfS1y2LSH5+XtLXBQAAQHafUcTZREhaEXbjxo1untXonKtahK0sPz9fGjduLOeff35cD4xwa9Cggey1115uCfKIhUws8rDIwyKPxDIJ6tR7Laq+8+HXsnzVfw9Mb0lhkwZyaO8Okkq0EYQZ7dsiDx+ZWORhkYdFHtXLJHpGUS6gjaS5CKuF1WhxtWPHjvLcc89Jly5dAtwtZLumTZvKUUcdle7dyBjk4SMTizws8rDII/FMguooawF26bLMu0gBbQRhRvu2yMNHJhZ5WORhkYePTCzyyKA5YWfPnm0KsDpKVqcoACravHmzLFiwwC1BHrGQiUUeFnlY5OEjE4s8EGa0b4s8fGRikYdFHhZ5+MjEIo8MKsKq77//Xi655BLp1auXdO/eXWbNmiUjR46UJ554Ivl7iKy0dOlSeeihh9wS5BELmVjkYZGHRR4+MrHIA2FG+7bIw0cmFnlY5GGRh49MLPLIoCLsV199JSeeeKJ8+eWXcvTRR5ePgi0oKJCbbrpJXnrppSD2E0AOSeSqklyBEgAAAAAAhGJO2IpuueUW2WOPPWT8+PHu/0899ZRbDh8+3E1N8Pjjj8vxxx+f/D0FkDOCuqgOAAAAAABAVhRh//Wvf8nYsWOlVq1aUlpaan525JFHyuuvv57M/QOQo3Lp6pNATemIcD14kex1AQAAkFvoVwIZVIStW7eubNiwIebPVqxYIXXq1EnGfiHL5eXlubagS5BHLGRikYdFHonlkYujx2kjFnkgzGjfFnn4yMQiD4s8LPqVPtqIRR4ZVITdf//9Zdy4cbLnnnvKtttu6+7TF2bt2rVuioL99tsviP1ElmndurUMGzYs3buRMcjDRyYWeVjkkXgeuTZ6nDZikQfCjPZtkYePTCzysMjDol/po41Y5JFBRdgrrrhCfvvb30r//v2lY8eOrgA7evRomTt3rrtIl05VAAAAAAAAAAD4r4Qn72jTpo288sorcsYZZ7ii64477ijr1q2TAQMGyIsvvig77LBDoptECC1ZskTuu+8+twR5xEImFnlY5GGRh49MLPJAmNG+LfJILBOdszJeiaybyWgjFnlY5OEjE4s8MmgkrL4Qhx9+uAwdOjSYPUIolJSUuDesLkEesZCJRR4WeVjk4SMTizwQZrRvizwSyyQX57ekjVjkYZGHj0ws8sigIuyDDz4onTt3lnbt2gWzRwAAAAAAJEmuzW8JAAjJdATt27d3878CAAAAAAAAAAIYCXvwwQe7i29NmTJFOnToIA0aNDA/1wt1XXjhhYluFgAAAAAAAABCKeEi7D333OOWH330kbtVRhEWqrCwUH73u9+5JcgjFjKxyMMiD4s8fGRikQfCjPZtkYePTBLLQy9ApnPlxiORdTMV7cMiDx+ZWOSRQUXY2bNnB7MnCJV69eq5kdL4L/LwkYlFHhZ5WOThIxOLPBBmtG+LPHxkklgeuXaxsrC1j5oW0cOWRzKQiUUeGVSEjVdpaansscce8vzzz7sLeSG3rFmzRmbOnCndu3eXRo0aSa4jDx+ZWORhkYdFHj4yscgDYUb7tsjDRyaJ55FLFysLW/vQouqHcx6RlesXVrle0/qtpXf7QaHPIxnIxCKP4AR6XkEkEgly88hgq1evlnfffdctQR6xkIlFHhZ5WOThIxOLPBBmtG+LPHxkYpFH+PPQAuyydf+p8ralIm0Y86gpMrHIIzjZPbkLAAAAAAAAAGQ4irAAAAAAAAAAECCKsAAAAAAAAAAQIIqwCOxqep06dXJLkEcsZGKRh0Ue4c5Dr9Rb03XDlklNkQfCjPZtkYePTCzysMjDIg8fmVjkEZxaAW4bOaywsFBOOumkdO9GxiAPH5lY5GGRR7jzqOlVfcOYSU2RB8KM9m2Rh49MLPKwyMMiDx+ZWOQRHIqwCERpaamsXbtWGjZsKAUFBZLryMNHJhZ5WOQR/jyiV/WtrjBmUhPkgTCjfVvk4SMTizws8rDIw0cmFnkEh+kIEIjFixfLHXfc4ZYgj1jIxCKPcOdR09Pvw5ZHMpBJePNIxnQVCJcwte9kIA8fmVjkYZGHRR4+MrHII4NGwk6bNs3NDaEV8cpWrVolU6ZMkaOOOkry8/Pl+OOPd8OYAQDIZck4/R7IFbxfAAAAEEYJF2FPP/10efbZZ6VLly7ez2bNmiXDhg1zRdi8vDy5+eabk7WfAADk9On3QC7h/QIAAICcLMJeddVVsmDBAvfvSCQiI0aMkEaNGnnr/fDDD9KiRYvk7yUAAAAAAAAAZKm45oQ9/PDDXfFVb1HR/0dvOv1At27dGP0KAAAAAECOKSuLJHU9AMjJkbCHHHKIu6nTTjvNjYRt165d0PuGLNa6dWu55ppruJLe/5CHj0ws8rDIwyIPH5lY5IFYImVlkpefn/R1U432bZGHj0wyI4/8/Dx558OvZfmqdVtcp7BJAzm0d4eU7hftwyIPH5lY5JFBc8I+8cQTVf78+++/l1122aUm+4QQ0DmBa9VKuHmFFnn4yMQiD4s8LPLwkYlFHohFi6orJz8jpcurvrpxQWFLadrvFMlUtG+LPHxkkjl5aAF26bK1kkloHxZ5+MjEIo/gJHy4e+XKlW4k7JFHHin9+vWTvn37upuOlN1nn33cRbmAX375RSZMmOCWII9YyCSxPMoiZXFvK5F1MxXtwyIPH5lY5IEt0QJsydL5Vd62VqRNN9q3RR4+MrHIwyIPizx8ZGKRR3ASLm3fdNNN8sYbb0ifPn3cqNf69evLzjvvLDNmzJBVq1bJDTfcEMyeIqts2rRJfvzxR7cEecRCJonlkZ+XL099PkUWrVlZ5XZaNWoqp3btI9mO9mGRh49MLPJAmNG+LfLwkYlFHhZ5WOThIxOLPDKoCDtlyhS56KKLZPDgwTJ+/Hj59NNP5c4775S1a9fKwIEDZc6cOcHsKQDkOC3Azl+1LN27AQAAAAAAgp6OQEe7du/e3f1bL87173//2/27YcOGcvbZZ8t7772X6CYBACGSa1MnAAAAAACQ9JGwhYWFsnr1avdvnYZA54hYsWKFNGvWTFq1aiWLFi1KdJMAkNW0kKjTBSR73Wylz+/DOY/IyvULq1yvaf3W0rv9oJTtF5Cp+AwBAAAAwi/hIuy+++4rDzzwgHTs2FF23HFHadq0qbz00kty1llnyT/+8Q9XpAW0XRx99NFuCfIIeybJKDqGKQ+lWSxb959q/37Y8qgp8gh3JnyGAFVLZvuOlJVJXn5+0tdNJd7vPjKxyMMiD4s8fGRikUcGFWGHDBkip59+ulx11VXy5JNPurlhb7nlFleY1akKLrzwwmD2FFmlQYMGsueeeyZlW2HoLCczj7AIWyY1LTqGLY+aIg+LPMKfCZ8hQGrat/YTV05+RkqXL65yvYLCltK03ymSiXi/+8jEIg+LPCzy8JGJRR4ZVITdfvvtZdKkSfLDDz+4/+sI2BYtWshnn30mXbp0keOPPz6I/USWWbduncyePduNmNY3cK53lpOZR1iQiUUeFnlY5OEjE4s8EGbJbt/apyxZOl+yFe93H5lY5GGRh0UePjIJdx5lcU7nlYppvxIuwp5zzjkyaNAgNy1BlA5T1hsQtXLlSnnttdekTZs2dJYDyCMMyMQiD4s8MiOPsrKI5OfnJX3dZKCNWOSBMKN9W+ThIxOLPCzysMjDRybhziM/jqm/UnW9koSLsDriNS8vdX9kAQCA9NCi6jsffi3LV62rcr3CJg3k0N4dUrZfAAAAAJCqqb/SVoTt06ePvPrqq9KjRw+pXbt2MHsFAAAyghZgly5bm+7dAAAEIAzXXgAAIFskXIStW7euK8K++eab0q5dO29oso6Sfeyxx5K5jwAAAMhAmTxlBYDcuPYCAAChLcIuXLhQunfvXv7/SCRifl75/8hNderUkZ122sktQR6xkIlFHhZ5WOThI5PMyIMpK5AKvN+DzSPbr72gaCMWeVjkYZGHj0ws8sigIuwTTzwRzJ4gVLbZZhs588wz070bGYM8fGRikYdFHhZ5+Mgkc/JgygoEjfe7RR7hziSRq3Nvad0w5ZEM5GGRh49MLPLIoCLs6aefLtdff72biqCy2bNnyxVXXOGuoobcpiOiS0tLpaCggAu5kUdMZGKRh0UeFnn4yMQiD4QZ7dsij3BnEs9VvLd2Je8w5ZEM5BHuPJJx4CJsmdQUeQQnrpY6ffp0mTZtmrt9+umn5f+ufNO5YufNmxfg7iJb6LQVf/7zn90S5BELmVjkYZGHRR4+MrHIA2FG+7bII/yZRK/iXdWtqiJt2PKoKfIIdx7RAxdvFI+q8qbrbKlYG7ZMaoo80jwSduLEifLKK6+4CrjeRo4c6a0TnQt2wIAByd9L1FikLCJ5cV4MI5F1AQAAAAAA0n3gAghFEXb48OHyf//3f67QesYZZ8h1110n7du3N+vk5+dLkyZNZNdddw1qX1EDWlRdOPkr2by86gtn1C5sIK377Z6y/QIAAAAAAEBmTM+ANBdhGzduLL169XL/fvzxx6Vz587SsGHDAHcLQdAC7Mala9K9G0DalJVF3JW8k70uAAAAAABhmFcaGXRhLi3G6rywderUkW7dusnPP/8sN9xwg8yfP1/69+8vF154YTB7CgA1pEXVdz782l3JuyqFTRrIob07pGy/AAAAAABIBqZnCFER9uWXX5Zhw4bJ2Wef7YqwOjXBjBkzZP/995cHHnhAateuLeedd14we5sDImVlkpefn/R1U61ly5YydOhQRkz/D3lkTiZagF26bK1kGtqIRR4WefjIxCIPhBnt2yIPH5lY5GGRh0UePjKxyCODirATJkyQ448/Xq644gpZsmSJ/POf/5TLLrtMzjnnHBk/frw8++yzFGFrQIuqKyc/I6XLF1e5XkFhS2na7xTJVAUFBW6O4EwW7wXIknGhsmzII9XIxCIPizws8vCRiUUeCPMFX2nfFnn4yMQiD4s8LPLwkYlFHsFJeBjl999/L8cdd5z79/vvv+8u1tW3b1/3/6KiIlmwYEHy9zLHaAG2ZOn8Km9bK9Km2/Lly2XixIlumekXK5s3ccYWb/rzmv7hkC15pBqZWORhkYdFHj4yscgDmdaHoh8VHPLwkUl489ALB9V03XTlodeYCGLdmgpT+0gWMrHII4NGwmo1fM2a/17cacqUKfKb3/xGdt55Z/f///znP1JYWJj8vUTW2bBhg8yaNUt69+4tmSxVFyvLljxSiUws8rDIwyIPH5lY5IEwX/CV9m2Rh49MwptHMi4ylK48MvV6FGFqH8lCJhZ5ZFARdu+995Z77rlH5syZI3//+9/lrLPOcve/9dZbctddd/EiAQAAAFkkv35jNwpLCwYAkGmy+SJDmXo9CgBZUoS95ppr3HywWojdd999ZfDgwe7+m2++2Y2K1flhAQAAAGSHvLr14h6xtWObQtmn+3/PggMAAECARdjmzZvLo48+6t3/9NNPuyIsAAAAgHCO2GrWpH7K9gcAACCnL8y1JRRgUVHjxo3lkEMOcUuQRyxkYpGHRR4WefjIxCIPhBnt2yIPH5lY5GGRh0UePjKxyCODRsIC8WjUqJH06dMn3bsRyjwiZWWSl5+f9HVTjTZikYdFHhZ5+MjEIg+EGe3bIg8fmVjkYZGHRR4+MrHIIzgUYRHY1fR+/PFH2WmnnaRevXqSrQrq15aySJm7Kmc8trRuMvPQourKyc9I6fLFVa5XUNhSmvY7RTJVWNpIspCHRR4WefjIxCIPhBnt2yIPH5lY5GGRh0UePjKxyCM4mTlErpKysjIZN26cq8R369ZNzj33XJk3b94W11++fLm7QFjPnj2lV69eMnLkSFm/fr1Z580335QjjzxSunTpIscdd5x8/PHHKXgmuUNfg7/+9a9umc3y69ZyRdUP5zwibxSPqvKm62ypWJvsPLQAW7J0fpW3rRVp0y0sbSRZyMMiD4s8fGRikQfCjPZtkUdmZFJWFglk3WSgjVjkYZGHj0ws8sjxkbD33Xefu/DX6NGjpXXr1nLbbbfJoEGD5LXXXpM6dep46w8ZMsQVXSdMmCCrVq2Sa665RtatWye33HKL+/knn3wiV1xxhVx55ZWy//77y/PPPy/nnXeevPzyy9KuXbs0PENkupXrF8qydf9J924AAAAAyAD5+XnyzodfuwvaVaWwSQM5tHeHlO0XACBkRdi5c+fK+++/7wqbOkq1ory8PLnwwguTtX+yadMmGT9+vFx++eVy0EEHufvuuOMONyr27bfflgEDBpj1Z86cKZ9++qlMmjSpvKB6ww03uKLtpZdeKq1atZKHH35Y+vXrJ6effrr7+VVXXeV+77HHHnPrAgAAAABQFS3ALl22Nt27AQAIaxH2lVdekauvvloikdinVCS7CDt79mxZu3at7LvvvuX3NWnSRDp16iTTpk3zirDTp0+Xbbfd1oxo1SkJdL9mzJgh/fv3l88++8w9h4r23ntvV9QFAAAAAAAAgLQWYXVqgP32209GjRrlpgbQ4maQFi5c6JZt2rQx97ds2bL8ZxUtWrTIW1enLGjWrJksWLDATU+gI3h13+PZXiK0MK3brizejHQ9nfRYL6i0NdF1dMLkLRXEK2+3dmGDrW43uk48242Ktd7mzZtlm222cctszqRWk/pu2bS+bS+xRNfRqTAqP36m5xHddryveSLrJtpGdNv169eXVo2abnW70XUSec31lLCtia6TyHaDbCNBZEIe2ZUJecTfRsgju9tIsvLQ/wfdRw3alvqVKp7nlkifIb9Jc7eM57Vs0vC/F+iIp19Zt3WTBC9wWiobN2yiH5Xl/ezotulX/hffCRZ55Ga/MqjPhUxqI+SR3Zk0TVG/Mi+SyDeeiBQVFclDDz1kRqYGSUfe6tytX331leTn/9qB0/sWL17s5n2tSOd//eGHH+Spp54y9+tUBieffLKccMIJcuCBB7rfq/gcdF7Y6667TmbNmlWt/SwuLnZTJ1RWu3Zt6dS5s9QqKIhrO5GyMsmr8Dy3NsG7zkUU33Yjkhfnuol0lktLS+TLL2e5N2e8si0T8khtJuSRukzIIxyZkIdFHtmfSbLy0IPw2m/NRlvqVyb6eqb7tXTbpX1XOxPy8PGdEI42Qh6Zmwl5+PjezZ02UpqCfmXCI2Hbtm3rRpSmilaslXZEo/9WGzdudNX3WOvH6rTq+g0aNJC6deuWb6/yz2NtLxHaGNu3b2/u02q5Ns6nPp8ii9as3OpRglO79knoCFgik8Enst0P5zziLka1tSMFvdsPkl133TWho9fZmEkiz69yG8iGPHZsUyj7dN9ZFk7+SjYvr3rd+js2lxZ7tw20jWzetEni+RqIPseVk5+R0uWLtzqCo2m/UxLKLp48dCRQ6367JzR6PNE2EkQm5BGuTMjDIo/szSRZecyZM0eyXax+ZSL9hkT6DEGOXMzmflSdOnXj34/8vKT2o7K5n12dfuUX81+XtRuXVbluw7rNpct2A+hXZvl3gm6zbiLvrYjIho3hzSMT20gQedTesYM03rt/0j9DMuk9U508phf/R1av3Vjluq22aSSddm2TdXlkaxtpH3C/MuEi7GWXXSY33nijbLfddtKtW7fyomZQolML6KjXHXfcsfx+/X+HDv5VJnWagcmTJ5v7tOC6YsUKN+WATkugxVj9/Yr0/3rRrprQBqbbjkU7QfNXVd2xiKpYbE7mZPCJbFc7hcvW/SeudWMVr3Vqh7/85S9y1llneVM/ZGsmNZHpeTT737QL+gG2cemaKtet3ax+ytpIvPQDvWTp/KRnF08e1dluLMnMI5FMyCM7MiEPH58h4W4jNc0j26ci2Fq/MpF+Q6r6OmHtRyUiiH5UNvazE+lXFtSv7UYoaXE1Hrou/crwfCfEQ0fQ5UoeYe5XFjTbNpDPkKhMaiPx5JFfv7Eb9blX0a81rq3J1jwSbSOJSFUmyexXJlyE/fOf/yy//PKLnHnmmVvcueqe0h9Lx44dpVGjRjJ16tTyIqzO66qPMXDgQG/9nj17ypgxY+THH3+UnXbayd336aefumWPHj3c/u25557uvpNOOqn893T7e+21V9L2O9fpEQYtfic420VokYePTCzysMjDIg8fmVjkgTCjfYc3j9L1m+M+bVZtad0wZZIM5GGRh0Ue6c+kbP3quE+7z5U2Etm4wRWm9YzlMEu4CHvMMcdIKum8C1ps1cJq8+bN3Qjc2267zVXjDzvsMCktLZVly5ZJ48aNXWW7a9eursg6dOhQGTFihJtEWOd6Pe6448pHumo1/7zzzpNOnTrJAQccIC+88IKbc1YLzACA8EnkoiMAAAAAgNQpy/DCdNqKsH/84x8l1YYMGSIlJSUyfPhwN4+DjnZ99NFH3VxZP/30k/Tt21duvvlmd9EtHel6zz33yMiRI+WMM85w0yX0799fhg0bVr693r17y0033ST33Xef3HHHHW7OhwceeEDatWuX8ucGAAiWTgavc3Ile+J4AAAAAAACK8JGL2L19ddfm+HJZWVlsn79epk+fbpcfvnlkkwFBQVyxRVXuFtl22+/vduXirbZZhsZN25cldvUkbF6AwCEWyJFVQqwAAAAAICMKMLq3KkXX3yxrFwZ+2qbDRs2THoRFtmnRYsWbsoHXYI8YiETizws8sjOPPTqo8lYJ0yZpAp5IMyypX3H8/lW638XnGlav+oLnVT182zJI5XIxCIPizwyJ4/CJlv/nGzSMPUXlKSNWOSRQUVYPX2/sLBQbrzxRnn11VclPz/fTQPwwQcfyDPPPCMPP/xwMHuKrKJTRbRp0ybdu5ExyMNHJhZ5WOSRfXlEyiLSut/uca+bV8M5n7Ihk1QiD4RZ2D4DyyJl0rv9oLjWi3UhqmzII9XIxCIPizzSn0emX3SJNmKRR3ASPu9ST/3XeWEPPfRQOfjgg2XBggVy4IEHyrXXXisnnnii3H///cHsKbKKjpR+4403tjhiOteQh49MLPKwyCP78kikqFrTAmy2ZJJK5IEwy4b2ncjnWqzCaiLrZUMeqUYmFnlY5JH+PDL9oku0EYs8MqgIq3O/tmrVyv17p512km+//bb8Z4cffrjMmjUruXuItNBToJo32LHKW1WnSa1bt87ND6xLkEcsZGKRh0UeFnn4yMQiD4QZ7dsiDx+ZWORhkYdFHj4yscgjg6Yj2HHHHd1o2L322kvatm3rLsb1/fffyy677CIlJSWydu3aYPYUKRPvKVLRdeM9mo9w2dpcZvGuAwAAAIRdKudNBwCEpAh79NFHy5gxYyQSicjAgQNljz32cPPDnnbaafLAAw9I+/btg9lTpEwiRVUKsLmnbGMJhXoAAAAgQ+dNBxA+HMjJ0SLsoEGDZPny5fL555+7Iuz1118v5557rlxwwQXSqFEj5oQFQq50/eacKdTzRQcAAJD5VzbPdKmeNx1AuHAgJ4eLsPn5+XLVVVeV/7+oqEgmT55cPiWBFmKBhg0byj777OOWII9szCTVX3SZnkeqkYdFHj4yscgDYUb7zow8MvnK5rQRizws8rDII/sySfWBnEzPI6eKsFF6lTSdqHfx4sXuglxafOUFQlSTJk1cu0B25ZHKkZ+Znkmqv+gyPY9UIw+LPHxkYpEHwoz2nRl5JHplc/qV6UMeFnlY5OEjE4s8MqwIq1MOPPjgg7JhwwbJy8uTLl26yJ133ummKRg/frx7wZDbNm3aJIsWLZJWrVpJnTp1JNdleh6bNpWkfORnpmeSauRhkYdFHj4yscgDYUb7zr486FemF3lY5GGRh49MLPIITsKTNT755JNy9913y1lnnSXPPfecu0CX0vlh582bJ3fddVcQ+4ks88svv7iCvC6R+Xms27A55SM/Mz2TVCMPizws8vCRiUUeCDPad/blQb8yvcjDIg+LPHxkYpFHBhVhn3jiCTnvvPPk4osvls6dO5fff+CBB8oll1wi7777brL3EQAAAAAAAABypwj7888/S69evWL+TC/MtXTp0mTsFwAAAAAAAADkZhG2TZs2MnPmzJg/+/e//+1+DgAAAAAAAACo5oW5TjzxRDcnbL169eSggw5y961bt07eeustd7EunSsWyM/PlwYNGrgl4sujVaOmW91OPOtkC9qIRR4WeVjk4SMTizwQZrRvizx8ZGKRh0UeFnn4yMQijwwqwp577rny008/yZgxY9xNnX766W559NFHy+DBg5O/l8g6ehW9K664It27kTV5lEXK5NSufeLalq6bn5f9H4a0EYs8LPKwyMNHJhZ5IMxo3xZ5+MjEIg+LPCzy8JGJRR4ZVITNy8uTG264wY14/eSTT2TlypXSuHFj6dmzp+y2227B7CUQcokUVcNQgAUAAAAAAMgl1a7mtG3bVk455RT5wx/+IKeeeioFWBiLFy+WcePGuSXIIxYyscjDIg+LPHxkYpEHwoz2bZGHj0ws8rDIwyIPH5lY5JHmkbDDhg1LaKTsTTfdVJN9QgiUlpbK8uXL3RLkEQuZWORhkYdFHj4yscgDYUb7tsjDRyYWeVjkkZ151C5skJR1wpRJqmRLHrVT2EZSWoR96aWXXHFV54XY2sS8uh4AAAAAAACQqEhZRFr32z3udfPyqUPlmkiWtpG4irBHHHGEvPfee7Jp0ybp37+/HHXUUdKjR4/g9w4AAAAAAAA5I5GCWaYU15BaeVnaRuIqwt5xxx2yfv16+cc//iGTJk1yF+Vq0aKFHHnkka4gu/vu8VWfAQCpUVDYskY/BwAAAAAAKS7Cqvr167uiq97WrFkj77zzjivITpgwQbbffnsZMGCAK8jqBbuA5s2buwu26RLkEQuZBJdHpKxMmvY7Ja718rYyxUy60D6CzSOeInymF+ppIxZ5IMxo3xZ5+MjEIg+LPCzy8JGJRR4ZUIStqFGjRnL88ce724oVK1xB9s0335QHHnhAdtttN3nxxReTv6fIKnXr1pX27dunezcyBnn4yCS4POItrGZqAVbRPoLLI94ifXTdTG0ntBGLPBBmtG+LPHxkYpGHRR4WefjIxCKP4NT4L6uNGze6qQo2bNjgrpw2f/785OwZstrq1avdPMK6BHnEQiYWeVjkEVweiRRVM7UAq2gjFnkgzGjfFnn4yMQiD4s8LPLwkYlFHsGp1l9XixYtkscee0xOOeUUOfjgg2XcuHGy4447upGwH330UfL3EllHp6x4//333RLkEQuZWORhkYdFHj4yscgDYUb7tsjDRyYWeVjkYZGHj0ws8siA6Qi08Pq3v/3N3f71r3+5OWK1ADto0CDp06eP1KlTJ8DdBAAAAAAAAIAQF2F1xOvnn3/u5oU48MAD5a677nJL/T8AAAAAAAAAoIZF2JkzZ0pBQYGbmHfZsmXy5JNPulsseXl5bqoCpEZhkwZJWQcAAAAAAABAGouwPXv2LP93JBKpct2t/RzJU1YWkUN7d4h73fz8PEmVevXqSVFRkVuCPGIhE4s8LPKwyMNHJhZ5IMxo3xZ5+MjEIg+LPCzy8JGJRR5pLsI+8cQTAe4CqiuRomoqC7CqsLBQTjjhhJQ+ZiYjDx+ZWORhkYdFHj4yscgDYUb7tsjDRyYWeVjkYZGHj0ws8ghOfoDbRg4rKSlxU1foEuQRC5lY5GGRh0UePjKxyANhRvu2yMNHJhZ5WORhkYePTCzyCA5FWARiyZIlcvfdd7slyCMWMrHIwyIPizx8ZGKRB8KM9m2Rh49MLPKwyMMiDx+ZWOSR5ukIAGQvLt4GAAAAAACQXhRhgRDL5Iu3AQAAAAAA5AqKsECIZfLF25KpoLBlUtYBAASrdmGDGv0cQHxaNWqalHUAAEDyUIQFkNUiZWXStN8pca+bl89U2ACQDpGyiLTut3tc6+Vl8YFBIN3KImVyatc+ca+bn0ffCACAVKAIi0C0adNGrr/++nTvRsYgj+AySaSomskFWNqIRR4WefjIJNg8gjjDIN7CKgVYVMb7PbE8EimqhqUASxuxyMMiD4s8fGRikUdwKMICAAAEIJ5T6zPx9HvOMAAAAACSj14zArF06VJ59NFH3RLkEQuZWORhkYdFHtmXSfTU+x1O6lHlTdfRdTMpj7CcYYDwyPT3e6qRh49MLPKwyMMiDx+ZWOQRHHrOCMTmzZvlp59+ckuQRyxkYpGHRR4WeWRfJomcUp+M0+8zPQ+gJmjfFnn4yMQiD4s8LPLwkYlFHsFhOgIAAAAgy2ztyvZb+zkAAABSiyIsAAAAkEX0ivandu0T13phufASAABAtqMImyLxjEZgxAIAAKlXUNgyKesAqRJvYZUCLAAAQOagCJtBoxWi64ahw9ysWTM5/vjj3RLkEQuZWORhkYdFHsFlEikrk6b9Tol73Uy9EBVtBGFG+7bIw0cmFnlY5GGRh49MLPIIDkXYFEikqBqGAqyqX7++dOnSJd27kTHIw0cmFnlY5GGRR3CZJFJUzdQCrKKNIMxo3xZ5+Mgk2Dyy/YwR2odFHj4yscgjOBRhEYi1a9fKl19+KZ07d5aGDRtKriMPH5lY5GGRh0UePjKxyANhRvu2yMNHJsHlEYYzRmgfFnn4yMQij+Bk3ickQmHVqlXy5ptvumVVc+Bu16R5lbewzJMbTx65hkws8rDIwyIPH5lY5IEwo31b5OEjk+DyCMMZI7SPYPPQUdC1WmxX5S2TR0or2ohFHsFhJCzSIhfnyQUAAAAAICzCMFIaSCXeAUiLXJwnFwAAAACAsAjDSGkglXgXAAAAAAAAAECAKMIiEHXq1JF27dq5JcgjFjKxyMMiD4s8fGRikQfCjPZtkYePTCzysMjDIg8fmVjkERzmhEUgttlmGxk4cGBaHruwSYOkrBOWPDIVmVjkYZGHRR4+MrHIA2FG+7bIw0cmFnlY5GGRh49MLPIIDkVYBKKsrEw2b94stWvXlvwUzv1SVhaRQ3t3iHvd/Py8wPcpnXlkMjKxyMMiD4s8fGRikQfCjPZtkYePTCzysMjDIg8fmVjkERzSRCAWLVoko0ePdstUSqSomqoCbDrzyGRkYpGHRR4WefjIxCIPhBnt2yIPH5lY5GGRh0UePjKxyCM4FGEBAAAAAAAAIEAUYQEAAAAAAAAgQMwJCwAAAACAiBQUtkzKOgByE58hqApFWAAAAABAzouUlUnTfqfEvW4eF6wBUAGfIdiavEgkEtnqWtiq4uJitywqKkr3rmSE0tJS2bBhg9SrV08KCgok15GHj0yyL495E2fIxqVrqlynbotGssNJPXIij1Rmki15pBKZWOQRrn5Ztu9/Otr32I9el/mrllW5ne2aNJdL9x8g2Y73u49MLPIINo9lE++SkqXzq1ynVovtpPlJFye0XfqV6UMm2fmeycZ+GSNhEQh9ozZs2DDdu5ExyMNHJhZ5WORhkYePTCzyQJjRvi3y8JGJRR4WeVjk4SMTizyCw9hnBGLZsmXyzDPPuCXIIxYyscjDIg+LPHxkYpEHwoz2bZGHj0ws8rDIwyIPH5lY5BEcirAIxMaNG+Wbb75xS5BHLGRikYdFHhZ5+MjEIg+EGe3bIg8fmVjkYZGHRR4+MrHIIzgUYQEAAAAAAAAg14uwWn0fOXKk7LvvvtK9e3e57LLLtjos+qeffpLBgwfLnnvuKb1795Y777zTTS4cy+uvvy6HHHJIQHsPAAAAAAAAIJdlRRF2xIgR8uGHH8rdd98tjz32mHz//fcyZMiQLa6/efNmOeecc9y///rXv7rf1/ks7r33Xm/dyZMny5/+9KdA9x8AAAAAAABA7qolGW7RokXy8ssvywMPPCB77bWXu2/s2LHSv39/mTlzphsZW9lbb70lP//8szz33HPStGlT2W233eSXX36RW2+9Vf7whz9InTp1ZM2aNTJq1Cg3CrZdu3ayevXqNDy78GrcuLEcdthhbgnyiIVMLPKwyMMiDx+ZWOSBMKN9W+ThIxOLPCzysMjDRyYWeeRwEXbGjBluuc8++5Tf17ZtW2nVqpVMmzYtZhF2+vTp0rlzZ1eAjdLf18LrV199JV27dnXTFSxYsEAmTpzoRsO+9NJLKXpGuaFRo0Zu+gj8F3n4yMQij+zMo3Zhg6SsE5Y8UolMLPJAmNG+LfLwkYlFHhZ5WOThIxOLPIKTFSNhCwsLpW7duub+li1bysKFC2P+jt7funVrb32lhVctwnbs2NFNbaC0CIvkWr9+vZs2YpdddpH69etLriMPH5lY5JF9eUTKItK63+5xr5uXnxfqPFKNTCzyQK6371aNfh18sSXxrJMNeL/7yMQiD4s8LPLwkYlFHiEuwuqI1L59+27x5xdffLGbPqAyLcrqBbti2bBhgzRp0sRbX23pd5IhEonIunXrAtt+NtHi+fPPPy+nn366G7Wc68jDRybZk0deXl7CX776xa2fiWHMo2IuiQh7HqlGJhZ5+O+3RN+jmYZ+ZXztW19n7eef2rVPXNsqKytzfw/U5DM53Xi/+8jEIo9g8oj2iQsK/zvAqyrRdeLpE6e6r0378JFJsO+ZVP4dmen9yrQXYfUFnTRp0hZ//v7778umTZu8+7XztKUXs169et7vRIuvDRrU/LTQqi4IptMdQGTlypVuOXfuXFm2bJnkOvLwkUn25KGftZ06dUrod/R56BdoGPNIB/LwkYlFHr5YB/GzCf3K+Nt37dq1pVat+P6sKSkpcdlmM97vPjKxyCOYPPSzZo/OnaRpv1PiWr+stES+/fbbrX7mpLqvTfvwkUkweaTj78hM71emvQirH2R6Yawt+frrr2XFihWuqFrxSS9evHiLFXmdiuCbb74x9+n6KsijGvpc2rdvH9j2s+3IyZQpU8rn78115OEjk+zJozpH/fR51HTkZ6bmkQ7k4SMTizysOXPmSLajX/kr2rdFHj4yscgjuDw2btKCavwHcuL5HE91X5v24SOTYPJIx9+Rmd6vTHsRdmt69OjhThvSC3RFJwbWyrg2ip49e8b8Hb3/5Zdfdhfi0gmF1SeffCINGzZ0c8EGRRtYkCNts4mORo4uyYQ8YiGTcOdR07mDwpZHTZGHj0ws8rCyfSoCRb/yV7Rvizx8ZGKRR/jzqElfO4x51BSZZE4e9TNwDtpk9ivzJcNp1f2oo46S4cOHy9SpU+WLL76QSy+9VHr16iXdunVz6+go2SVLlpRPQdCvXz/Zdttt5ZJLLpHZs2e7C2+NHTtWzj777Kw/NS1b6ClhOiI53lPDwo48fGRikYdFHhZ5+MjEIg+EGe3bIg8fmVjkYZGHRR4+Mgk2D50juVaL7aq8xTPXchjkRTJtnG8MelGCm266Sd566y33/wMOOMAVZQsLC93/tTirEwY//vjjsvfee7v7fvzxRxk5cqRMnz5dmjZtKieeeKJcdNFFkp/v153vvvtueemll+Tdd9+t9j4WFxe7ZVFRUbW3AQCZbN7EGbJx6Zoq16nbopHscFKPlO0TAISxX5bt+w8ASBx9bYRRpKxM8mLU4Wq6brb2y7KiCJsN6CwDCDs6hgCyRbb3y7J9/wEAiaOvDYS/X5Z5JWaEwoIFC2TUqFFuCfKIhUws8rDIwyIPH5lY5IEwo31b5OEjE4s8LPKwyMNHJhZ5BIciLAJTWlqa7l3IKOThIxOLPCzysMjDRyYWeSDMaN8WefjIxCIPizws8vCRiUUewaAICwAAAAAAAAABoggLAAAAAAAAAAGiCAsAAAAAAAAAAcqLRCKRIB8gV3AVW2vz5s2yfPlyKSwslNq1a0uuIw8fmWRfHqm8Yms25JFK5OEjE4s8wtUvy/b9Tzbat0UePjKxyCM780hVXztb8kglMrHII7h+Wa0abwGIQd+oLVu2TPduZAzy8JGJRR4WeVjk4SMTizwQZrRvizx8ZGKRh0UeFnn4yMQij+AwHQECsWLFCnn11VfdEuQRC5lY5GGRh0UePjKxyANhRvu2yMNHJhZ5WORhkYePTCzyCA5FWARi/fr1MnPmTLcEecRCJhZ5WORhkYePTCzyQJjRvi3y8JGJRR4WeVjk4SMTizyCQxEWAAAAAAAAAAJEERYAAAAAAAAAAkQRFgAAAAAAAAACRBEWgWjYsKHsv//+bgnyiIVMLPKwyMMiDx+ZWOSBMKN9W+ThIxOLPCzysMjDRyYWeQQnLxKJRALcfs4oLi52y6KionTvCgAEYt7EGbJx6Zoq16nbopHscFKPlO0TAISxX5bt+w8ASBx9bSD8/TJGwiIQGzdulB9++MEtQR6xkIlFHhZ5WOThIxOLPBBmtG+LPHxkYpGHRR4WefjIxCKP4FCERSCWLVsmjz32mFuCPGIhE4s8LPKwyMNHJhZ5IMxo3xZ5+MjEIg+LPCzy8JGJRR7BoQgLAAAAAAAAAAGiCAsAAAAAAAAAAaIICwAAAAAAAAABogiLQOTn50vjxo3dEuQRC5lY5GGRh0UePjKxyANhRvu2yMNHJhZ5WORhkYePTCzyCE5eJBKJBLj9nFFcXOyWRUVF6d4VAAjEvIkzZOPSNVWuU7dFI9nhpB4p2ycACGO/LNv3HwCQOPraQPj7ZZS1AQAAAAAAACBAFGERiEWLFsnYsWPdEuQRC5lY5GGRh0UePjKxyANhRvu2yMNHJhZ5WORhkYePTCzyCA5FWASirKxMVq9e7ZYgj1jIxCIPizws8vCRiUUeCDPat0UePjKxyMMiD4s8fGRikUdwKMICAAAAAAAAQIAowgIAAAAAAABAgCjCAgAAAAAAAECA8iKRSCTIB8gVxcXFbllUVJTuXckIGzdulAULFkibNm2kbt26kuvIw0cm2ZfHvIkzZOPSNVWuU7dFI9nhpB45kUcqkYePTCzyCFe/LNv3P9lo3xZ5+MjEIo/szCNVfe1sySOVyMQij+D6ZbVqvAUgBn2j7rzzzunejYxBHj4yscjDIg+LPHxkYpEHwoz2bZGHj0ws8rDIwyIPH5lY5BEcpiNAIFatWiWTJ092S5BHLGRikYdFHhZ5+MjEIg+EGe3bIg8fmVjkYZGHRR4+MrHIIzgUYRGItWvXykcffeSWII9YyMQiD4s8LPLwkYlFHggz2rdFHj4yscjDIg+LPHxkYpFHcCjCAgAAAAAAAECAKMICAAAAAAAAQIAowgIAAAAAAABAgCjCIhD169eX7t27uyXIIxYyscjDIg+LPHxkYpEHwoz2bZGHj0ws8rDIwyIPH5lY5BGcvEgkEglw+zmjuLjYLYuKitK9KwAQiHkTZ8jGpWuqXKdui0ayw0k9UrZPABDGflm27z8AIHH0tYHw98sYCYtAbN68WRYvXuyWII9YyMQiD4s8LPLwkYlFHggz2rdFHj4yscjDIg+LPHxkYpFHcCjCIhBLly6V+++/3y1BHrGQiUUeFnlY5OEjE4s8EGa0b4s8fGRikYdFHhZ5+MjEIo/gUIQFAAAAAAAAgABRhAUAAAAAAACAAFGEBQAAAAAAAIAAUYRFYAoKCtK9CxmFPHxkYpGHRR4WefjIxCIPhBnt2yIPH5lY5GGRh0UePjKxyCMYeZFIJBLQtnNKcXGxWxYVFaV7VwAgEPMmzpCNS9dUuU7dFo1kh5N6pGyfACCM/bJs338AQOLoawPh75cxEhYAAAAAAAAAAkQRFoFYsmSJPPjgg24J8oiFTCzysMjDIg8fmVjkgTCjfVvk4SMTizws8rDIw0cmFnkEhyIsAlFSUiILFy50S5BHLGRikYdFHhZ5+MjEIg+EGe3bIg8fmVjkYZGHRR4+MrHIIzgUYQEAAAAAAAAgQBRhAQAAAAAAACBAFGEBAAAAAAAAIEAUYRGIZs2ayYknnuiWII9YyMQiD4s8LPLwkYlFHggz2rdFHj4yscjDIg+LPHxkYpFHcPIikUgkwO3njOLiYrcsKipK964AQCDmTZwhG5euqXKdui0ayQ4n9UjZPgFAGPtl2b7/AIDE0dcGwt8vYyQsArFmzRr5+OOP3RLkEQuZWORhkYdFHj4yscgDYUb7tsjDRyYWeVjkYZGHj0ws8ggORVgEYvXq1fL222+7JcgjFjLJvjxqFzZwR9+ruuk6uZJHKpGHj0ws8kCY0b4t8vCRiUUeFnlY5OEjE4s8glMrwG0DAEIiUhaR1v12j3vdvPy8wPcJAAAAAIBswUhYAMBWJVJUpQALAAAAAIBFERYAAAAAAAAAAkQRFoGoW7eu7Lbbbm4J8oiFTCzysMjDIg8fmVjkgTCjfVvk4SMTizws8rDIw0cmFnkEJy8SiUQC3H7OKC4udsuioqJ07woAAEBOy/Z+WbbvPwAgcfMmzpCNS6u+Gr1eCHeHk3qkbJ8ASFL7ZYyERSBKS0tl7dq1bgnyiIVMLPKwyMMiDx+ZWOSBMKN9W+ThIxOLPCzysMjDRyYWeQSHIiwCsXjxYhkzZoxbgjxiIROLPCzysMjDRyYWeSDMaN8WefjIxCIPizws8vCRiUUewaEICwAAAAAAAAABoggLAAAAAAAAAAGiCAsAAAAAAAAAAaIICwAAAAAAAAAByotEIhHJcBs3bpTRo0fL3/72N9mwYYMccsghcs0110jz5s23+Ds//fST3HjjjTJt2jRp0KCBnHjiiXLRRRdJQUGB+7lu595775U33nhDli9fLm3btpULL7xQ+vbtW619LC4udsuioqJqPstwKSsrk82bN0vt2rUlP59aP3n4yMQiD4s8LPLwkYlFHuHql2X7/icb7dsiDx+ZWOSRnXnMmzhDNi5dU+U6dVs0kh1O6pETeaQSmVjkEVy/LCvSHDFihHz44Ydy9913y2OPPSbff/+9DBkyZIvra2M555xz3L//+te/ut9/5plnXNE1atSoUfLaa6/J9ddfLy+//LL069dP/vjHP8rUqVNT8pzCTt+odevW5Q37P+ThIxOLPCzysMjDRyYWeSDMaN8WefjIxCIPizws8vCRiUUewcn4RBctWuSKpMOHD5e99tpLunTpImPHjnUjXGfOnBnzd9566y35+eef5dZbb5XddtvNFVgvvfRSV8DdtGmTrF+/3m1T7zvwwANlp512kgsuuEB69eolL7zwQsqfYxj98ssv8uSTT7olyCMWMrHIwyIPizx8ZGKRB8KM9m2Rh49MLPKwyMMiDx+ZWOSRw0XYGTNmuOU+++xTfp9OHdCqVStXiI1l+vTp0rlzZ2natGn5ffr7a9aska+++kry8vLkgQcekAMOOMD8nlb5V61aFdhzySVa7P7uu+/cEuQRC5lY5GGRh0UePjKxyANhRvu2yMNHJhZ5WORhkYePTCzyyPGRsIWFhW4odEUtW7aUhQsXxvwdvb9169be+mrBggVSr1496d27tzRr1qz851988YV88skn0qdPn0CeBwAAAAAAAIDcVCvdO6AX0KrqYlgXX3yx1KlTx7tfi7J6wa5Y9KJbTZo08dZXsX5H55jVi3LpVAcnn3yyVJde42zdunXV/v0w0dcguiQT8oiFTCzysMjDIg8fmVjk4ffJ9MynbEa/8le0b4s8fGRikUd25aHfV/Xr10/od3SKxepeYz3T80gHMrHII7h+ZdqLsDqtwKRJk7b48/fffz/mEGgtpm7pg0pHulb+nWjxtUGDBub+zz77zM0HqyNndYoCvfpbdekFwXS6A4isXLnSLefOnSvLli2TXEcePjKxyMMiD4s8fGRikYcv1kH8bEK/8le0b4s8fGRikUd25aF1jU6dOiX0O/pctBAbxjzSgUws8giuX5n2IqwWPdu1a7fFn3/99deyYsUKV1St+KQXL17sCrixaEH1m2++Mffp+qri77z99tty+eWXS9euXeW+++6Txo0b1/i5tG/fvkbbCAs9WqKvV8eOHb3Cdy4iDx+ZWORhkYdFHj4yscjDmjNnjmQ7+pW/on1b5OEjE4s8siuP6oyw0+vkVHckbKbnkQ5kYpFHcP3KvEh137kpnBP2wAMPlL/85S+y7777llfj+/fvL88++6x069bN+5033nhDrrnmGvnwww+lUaNG7j5d95ZbbnHzvmpjevfdd+Wiiy5yUyGMGTOmxlXt4uJitywqKqrRdgAAACA53S/L9v0HACRu3sQZsnHpmirXqduikexwUo+U7RMASWq/LOMvzKUjV4866igZPny4TJ061V1A69JLL5VevXqVF2B1lOySJUvKpyDo16+fbLvttnLJJZfI7NmzZfLkyTJ27Fg5++yzXbFVh1ZfddVV0rlzZ1es1f/r7+tNR92i5vTUCH2tqnuKRNiQh49MLPKwyMMiDx+ZWOSBMKN9W+ThIxOLPLIzj9qFDVyRtaqbrpMreaQSmVjkEZyML8KqG2+80Y2C/eMf/yjnnHOO7LLLLjJu3Ljyn8+cOVN69+7tltGLcD3yyCNSVlbmLrQ1cuRI+f3vf+/mflUffPCBrFq1Sj7//HM54IAD3O9Gbzo6FjWnxeyXXnqJovb/kIePTCzysMjDIg8fmVjkgTCjfVvk4SMTizyyL49IWURa99vdjXKt6qbr6LphzyPVyMQij+CkfU7YeOgcFKNGjXK3WPbee283d2xFO+20k4wfPz7m+kcffbS7AQAAAAAApFNefl4g6wLILFkxEhYAAAAAAAAAshVFWAAAAAAAAAAIEEVYBKJ27dqy/fbbuyXIIxYyscjDIg+LPHxkYpEHwoz2bZGHj0ws8rDIwyIPH5lY5BGcvEgkUrNZneEUFxe7ZVFRUbp3BQAAIKdle78s2/cfAAAgLIqT2C9jJCwAAAAAAAAABIgiLAKxYMECGTlypFuCPGIhE4s8LPKwyMNHJhZ5IMxo3xZ5+MjEIg+LPCzy8JGJRR7BoQgLAAAAAAAAAAGiCAsAAAAAAAAAAaIICwAAAAAAAAABoggLAAAAAAAAAAHKi0QikSAfIFcUFxe7ZVFRUbp3JSOUlJTIqlWrpEmTJlKrVi3JdeThIxOLPCzysMjDRyYWeYSrX5bt+59stG+LPHxkYpGHRR4WefjIxCKP4PplpIlA6Bu1efPm6d6NjEEePjKxyMMiD4s8fGRikQfCjPZtkYePTCzysMjDIg8fmVjkERymI0Agli9fLi+++KJbgjxiIROLPCzysMjDRyYWeSDMaN8WefjIxCIPizws8vCRiUUewaEIi0Bs2LDBDdnWJcgjFjKxyMMiD4s8fGRikQfCjPZtkYePTCzysMjDIg8fmVjkERyKsAAAAAAAAAAQIIqwAAAAAAAAABCgvEgkEgnyAXLFZ599JhplnTp10r0rGaG0tLT8anoFBQWS68jDRyYWeVjkYZGHj0ws8rA2bdokeXl5sueee0o2ol9p0b4t8vCRiUUeFnlY5OEjE4s8gutXUoRNkpkzZ7rOcu3atdO9KwAAADlt8+bNrrPcvXt3yUb0KwEAAMLXr6QICwAAAAAAAAABYk5YAAAAAAAAAAgQRVgAAAAAAAAACBBFWAAAAAAAAAAIEEVYAAAAAAAAAAgQRVgAAAAAAAAACBBFWAAAAAAAAAAIEEVYAAAAAAAAAAgQRVgAAAAAAAAACBBFWAAAAAAAAAAIEEVYAAAAAAAAAAgQRVgAAAAAAAAACBBF2Gp49dVX5eSTT5Zu3bpJ9+7d5f/+7//kr3/9a8x1X3/9dTnkkENq9HjJ2EZlP/30k3To0EGmTp2askz0sfQxH3/88Wo9nw0bNsjtt9/uflcf44QTTpC///3vSdn/ivun2aSqjbz44ovuMauTx/r16+XGG2+U3r17S9euXeXUU0+Vf/3rX5KJbWRreURf2/3339895oABA2r02j744INy2mmnSTIls33Em8l5553nHrO67X3FihVy3XXXyQEHHCB77rmnnHLKKTJ9+nRJlmj7TYZ428hee+0lHTt2rFYev/zyi1xxxRWyzz77uMfQfL/77jvJxs+Q6Ptf89DHrOn7P9O/Z+LNo1evXu4xTzzxxITzyKbvmHgzOfPMM91jVvc7Ipu+Z9L1OiQD/Uof/UqLfqVFv9JHv9KiX2nRr6xeJhdeeKF7zC5dulQrkzB9zySjjWTT90ygr0EECZk4cWKkW7dubvn9999Hvvvuu8jjjz8e6dy5c+Tuu+82677zzjuRoqKiyMEHH1ztx0vGNmIpKSmJLF68OLJx48aUZfLJJ59Edtttt8gee+xRredzzTXXRA488MDIe++9F/nhhx8i9957b6Rjx45uu8mgWWgmmk2q2sgNN9zgMqlOHpdeemnksMMOi0ydOtXlMWLECPe4CxcujGRSG4knj+hr++CDD7o8br755mq/tk8++aT73YEDB0aSKVntI5FMevbs6fKobns/66yzIgMGDIhMmzbNPc7IkSMjXbp0cY+XDOvXr3eZ1FQibeSyyy6L9OnTp1p5/Pa3v42cdNJJkc8//zwyZ86cyEUXXRTp3bt3ZN26dZFs+wyJvv9vu+0210Zq8v7P9O+ZRPKYMGGCy+Pyyy9POI9s+Y5JJJN99923/DOkOm0kW75nEhHti8ybNy+SCehX+uhXWvQrLfqVPvqVFv1Ki35l9TPRtqF5aLuoTiZh+p5JRhvJlu+ZoPuVFGETdPzxx0duvPFG735tjPrFplavXh256qqrXKM95phjqvUBlIxtZFomZ599tmugRxxxRMLPR7/MNItXXnnF3H/66adHrrjiiki2tpHdd9+9Wp1l/YC5+uqrI//85z/L71u1apXb1qRJkyLZlEfF17bih1iir61+eA8ePNh9kPfv3z/pneV0ZDJ8+HCXR1QimegXm/7u9OnTy+8rKyuL9OvXL3LnnXdGsrWNjBs3rvz9kkgeK1ascF/8X3/9dfl9X331lctIO8/ZlEfF9/8LL7zgnkN13v/Z8j2TSB7Rz5DoaxtvHtn0HZNIJrfcckv5Z0iibSSbvmeyuQhLv9JHv9KiX2nRr/TRr7ToV1r0K6ufyaOPPlr+GZJoJmH6nklGG8mm75mg+5VMR5Cg/Px8mTlzpqxcudLcr6cfPPvss+7fOhR5wYIFMnHiROnXr1+1HicZ2/jiiy/k97//vRtO3rNnT7nooovk559/jjlUu7S0VO644w43NFyHoA8ZMkT+/Oc/l596o+t16tRJ3n//fXdKzx577CH9+/eXyZMnl2cyb948GT58uPTp00c6d+7s9n3fffd1w8718ZYtW+a2pacGJSovL08eeOABd/pLRfrYq1atins7uv96GoAOf9d9u/rqq8tfy8pDyXW/r7/+etl7773dKTfXXHONXHbZZe53oqfMHHrooeVLzUS3rb8XbSOa99ChQ91jjR8/XmrVqiW33Xab/Oc//3Gv7wUXXCDVUVBQIDfffLPbrlqzZo089NBD0rBhQ/f6ZVIb0X2L5qG3aBvRPNQNN9wgd911V41f2y+//FJq167tTqXQ17c6UtE+ZsyYUf6e+frrr8vbh75nXn75ZTnssMP04Jhr75VPyUokk8LCQtcmioqKzPtIb4nkqvt01FFHue3o66av+aZNm8qfY8V91Pe4Ph89TUVzGTNmjJx++uly9913u5/rUk+P1v3S11u3OXDgQNm8eXN5G/nmm29k8ODBrj3+5S9/kXr16rlTTWv6/m/atKk7HWi33XYr39cJEyZI69atpX379ln1GTJ27Fj3OkTf/6o67/9s+Z7Z2meIZqynR1bMQ0+fSiSPbPqOieczRJ+PfkdE23Z1viOy6XtG+yJRFduIZqL7r//XvDMR/Ur6lfQr6Vcq+pX0K+lXZs73jLZJ/UzU+9TatWsTziRM3zPJaCPZ9D0zOeB+JUXYBA0aNEhmzZrl3kzaQdaGow2hcePG0rZtW7eOzivz2GOPye67717tx6npNrTBRb9wtPOgXwraOP/0pz/FXF+/1LSzr2/aF154Qbbddlt54oknvG1qR0/fzDrPi37pXHXVVa4Rayb6Jf/mm2+6D13t/Ohj6Zwnul19PtE3f3XoF6a+eZo1a1Z+n+b+ySefuDdEPPTL8Y9//KOb32TSpElyzz33yLRp0+TWW2+Nub4+t48++si9cfUP+tWrV8sbb7xh1tEvGv2Z5vLSSy9J/fr13YdqtI3om1n/rVn87W9/c23mkUceca+Fvr6/+c1vpKb0w71Hjx7y8MMPu9emTZs2GdVGFi1aVJ7HEUcc4T7kLrnkEnnrrbfcB9hrr73mvgArvrazZ89O6LVVOteOdsZ22GEHqY5UtQ99H5xzzjkuk2OPPVY+/vhj107uvPNOd79++f/zn/907b1BgwbVbu9NmjSRAw88UOrUqVN+n2b+448/xr0NfR30NdIvN/3dm266SV555RXXhisrKytz7Um3rz/XL22d4+fTTz816+ncYfoHg352Pv30024+Lf3daBvR/BcvXuz+iNI2dPTRR7sv/m222aZG7/+Krr32WvcFqq+XfhFXzDlbPkPeffdd9/v/+Mc/3DLR9382fc9s7TNE/6CLFqt0P5Rmmkge2fQdE89nSLR9RFXnOyKbvmc0S/0DSWk+mo3mr21k2LBhpo1kGvqV9Csrol9Jv5J+5X/Rr/TRr0zt90xFxxxzTMKZhO17JhltJFu+ZwLvVyY01hbOzJkzI0OHDo306tXLDT3Wm85tUfH0jKiKpzhUV3W2oadIdOjQwc1jVFpa6u77z3/+4/Zd6XDp6PwmOlRe5/N55plnzOklOiw9eupNdJi1zvFS+ZSLzz77zG1X1+/Ro4fJ5Mgjj4wMGzbMbGPUqFE1zkTnKdE5d04++eTIpk2b4vqdWbNmucd/9913y+/75ptv3POouH+ajWal//7ggw/K192wYUNk//33d6dZqOhQfN1ulOYTfYwhQ4a4XCu3kf322y9yzz33mG3UJA89PejLL790pwvoHDMVn1+mtJFnn33WvWe6du3q5aFzKVVuIzqPYSKvbWX6GiV62lgq28eiRYvcXDjHHntsZK+99jKZ6CkfldtHddp7ZTNmzIh079498sc//jHu39H91bn2vvjii/L79N86V1DF/VMff/xx+b5GLVmyxM0JpZ9hSpfa5rTtRekcnnqqjra7Cy+80HvPRLf70ksvlW9Ds6hJHt9++22kuLjYnRKjj/fvf/87az9DovPdJfr+z7bvmXg/Q/SUL/3ZddddV6M8Mv07JtHPkOp8R2Tb94z2RdQTTzwRmT17ttmPWN8zmTIdgaJf+V/0K+lX0q+kX0m/kn5lJn7PaA41zSQs3zPJaCM/5Hi/slb1y7e5S4cy602PsukRPT0C++STT8q5554r77zzjjuylm56ioSOrtCrz40bN85dtVGPXuoR48r0Ko565b6Kw8B1+LwendDnV9Euu+xS/u9GjRq5pZ7yoVekfv75593Qbc2guLjYHbnUjKKnaSTLZ5995k630tM99CiKnioUDz0qp0d2/vCHP7ijIHr62kEHHeSG4lemRzuUDnOPqlu3rrsyYmXt2rUr/7eOXFH6nPVomuaqp76899577rQmvQKgnhKkuSTLTjvt5JY6lP6rr75yj3fwwQdnVBvZeeed3dUWS0pK3NGnt99+W/7973+X5xH9nW+//bb8lKdEXttkSGX7iL5nnnvuOXdU84MPPnDtQ08n1Lahp2dUpKdcJNreK9L35eWXX+5OS9EjgvHSo7T6HPVK89tvv73LpG/fvu5UjViZaJuq+Pq3aNGifCRXxft0vYqZaB7atvQIox6J1dEOH374oWtbZ5xxhlsv+p7Ro7dLly51p5pUN4/oaWI6WuHzzz93n996ekw2foZonkpf30Te/8mQiZ8hrVq1ckv9PtZTkqqTRzZ8xyT6GaLfD4l+R2Tb94xmEv281NEaOrrjhx9+kDlz5ri2UPF3Mg39yv+iX/lf9CvpVyr6lfQrK+eh6Fem53tm1113dTlUN5Mwfc8ko43slOP9SqYjSMDChQtl5MiRbhmdz0Mbzvnnn++GQuuQZR0enin0jaENRk/R0TeONlYdyh6ddydK5/lQus7WVDwFJSo6DFyHhutpJfpHsH7I3Hvvve7n+sWWLNrJ0rl/9INQO13aqUqEzt2jpxzom3f58uVyxRVXuFN1Ys1ZouLp1FbMJDo/mZ72sm7dOvem1dOi9ANT51bRjCueklBd2tb09IAVK1aY+6OnaWVKG1myZIlbRk8N0veKnqaiH356KlLFjrK+tqNHjy5/nRJ9bZMh6PYRpaeIzZ07V373u9+506f0j4mLL77YnZKhovPa6B8UqrrtXWlHULPWLzb90tcv43jpujpvln7p/Pa3v3VfPNoJiHXKh2ZSnTyicxrp56q2l+OOO851lPU0wCuvvNKsq21ET//Q9phoHvre1NNx9A+2KP0M146zvl+z6TNEOyDaAajp+z8ZMuEzRN8/8+fPT0oemf4dE+9niJ6Kq98R2oaqm0m2fM9ERf9A0L7IqFGj3PaOPPJIefDBB12hIBPRr6RfGQv9Sot+pUW/0qJf6aNfWfPvGX3e+plY+QBGGPuWqWoj2fI9k4p+JUXYBOiLo/PqROecqzxPTsUjA+n2/fffu7kvdPTEKaec4o4U6FweekSgcuVfj0TonCU6z05FeiQvHnqU5NFHH3VHXfXoib4xdN6U6BGkWI26OvTNph8EevRHHy961CZe+nz0Q1Y7Z9FJ3PX/Oi+LduYq0qOheqSkYib6xtajQVWJHtXSI2r6ha/ra2dDJ4HWo1hK52aJ58OgKvqBcOmll7oPsop0npl4J4NPRRuJvvY6F5Ue5arYRnTeKqXZRycAjx6pih6BSqVUtI8oHaVw3333mfahH+otW7Z0P9e5ebS9P/PMM+7/1WnvSufG0i8mPYKp818l+l7U0Vg6ikCLAjofUHRfdf9jzQOlbVvbT5R2FPSIclWiX5D6uarz8OgXsz5v7Qgdfvjh5uiuthH9w0I/ZxPNQ/9o1/eMzpUWpUc4dbsVjwZnw2eIdgh1TqKavP+TIVM+Q7SdaaGqpnlkw3dMvJ8hepEDbe86qqO6mWTL90xFlduI9kV23HFHNxqspt+7QaBfGRv9yl/Rr7ToV8ZGv/JX9Cst+pXV+57R94y+vpXnIA5j3zJVbSRbvmdS0a9kOoIENG/e3B2B0BdBK/l65TT9UtejAvrFp1eh06s3ZgI9wqJH53QItn7J6ZE5PeoYPa2j4hEI/ZDRyam1Eeswd/3i0NNZtIHqMP2t0Stc6pebvun16Kg+pn4BaSYV/5CoCT2qqRMk6xXpdNLkilcR1g+OeEYB6GulnQddX09h2rhxo/vS1y/fykekdBJ+HdauHQ2dyF1z0aMeelRVn+eWRD9YdUi9vkmVfojpm1VPhdGfa4ei8pGaROl29DloW9TTGnT7OsG2vma6zJQ2Ej09SCfC1qPfeoROf0+vVKpHIHUftEOlE+rra6udOi2m6BE5XT/e1zYZUtE+onSkQrQjrKMUdDJ4vSLl/fffX/76anvfbrvt3Ii26rR3HRGhX9J6uooewas4cki/kOLpBOhj6RFhzUZPF9P90E5LxdNcovTzT6/aqaMM9AIF+hg6ybleObKqTLRYpLQt66gKPQL71FNPuf3TbLTt6Ta0UKFtRB9bv7yjo2HizUM7VTrZvB7J1Ju2TX3N9DQ17dTEI5M+Q/T0JM1MLzCh9LVO5P2fDJn0GaL5aB7R11K/fxLJI1u+Y+L9DNHt6T5Ei3vaaU30OyJbvmcq0j+k9Q9wHTGifTbdvo7U0s+Lmn7vBoF+ZWz0K39Fv9KiXxkb/cpf0a+06FdW/3tGXxP9rFH6vtHcwti3TFUbyZbvmVT0KynCJkiHPWuj1xdQP9C1AeiVSLXB6xdSptAGql80OnxdG7te9U2PBuubS9/MlYeB6ykrevROr1ipX0z6paVfjvpG3xqd10eHq2uD1KHr+kefdor0CKY+5pQpU2r8fPQIhH6p6ZtGv/Aq0jdR5avcxaJvPL3KqR6B1Q8zfdPqPCKak/67Mv0A0y/V6OlN+oGjX9TxzOGiR0r0aJJ2+PTDTz/4oh88Oty+8uik6tBTd/QDR09l1I6QfsBrBzTWvErpbiN6yoR2iDU7nXtHb5qHHqXXuZj09dXXVt9f6qSTTkrotU2GVLaPs846S4qKitzj6Wl0+rrpB7zO2aOjFnSEh7Z3vSm9smZUvJno0Up9vXSOI71VdPzxx5efoleV/fbbz81vpV/AepVN7QDrvDtbuiK1Ph/90tfOp7Z9PZ1Fiz/xZKKPo5+ruq7Oo6XvGW3feqqhniqm29E2Ej16Gc0kkTaioza0vesRae1MaHFDP8fjvZp0Jn2G6ClD+lpEOy16FDmR938yZMpniHay9Eq2ug/6flJ6NDyRPLLtO2ZrnyH6HaOPqx1vvYqtjhBL9Dsi275nlJ5OqJ9tmou+t7XTraNP9DMpelXfTEO/0ke/0ke/0qJfadGv9NGvtOhXJv49o8U+PUCqP9M52jWLMPctU9FGsul7JtB+ZdyX8EKovf3225FffvnF3HfWWWeVX/Ut1+iVBPUqeatXrzb36xUCo1cGzDW0kV/RPnzaNvTKlhWv9rlx48ZIt27dyq9Am0toIz4+Q35F+4iNNhIevJYW73kfbeRXtA8f/UqLNuLjM8SijWRPG2EkLBydo0SPrugpH3oUQUcV6VwjeqQyF+kcR3qERo9S6RxCemRMj7LrHFN6umAuoo38ivbh0xEXOhJAT4nTOXr0qKO2Gc2q8tHfXEAb8fEZ8ivaR2y0kfDgtbR4z/toI7+iffjoV1q0ER+fIRZtJHvaSJ5WYtO6BzlGT6nQeSuqonPl6OkaQW6jsp9++skNtdZ5k/RUOJ0cWa9WqfP+BC0Zz0f3derUqVVu48UXX5S2bdsmNBGzzj2kQ+11qLtOIq+nNfXs2VOCRBtJ/msbpvaRrOejc/7o/EZV0cdI5KIL+qWmV+j9+uuv3SkyeuVIPbVFJ4oPEm3E4jPE4jvGRxsJD15LH+95izZi0Wfw0a+0aCMWnyE+vmcs2khiKMKmmE4Mr3PGVEXn7tE57oLcRiZJxvPReUr0jVUVnZ8nnvlQ0o02kvzXNkztI1nPR4+K6qiCquiE6fFcECLdaCMWnyEW3zE+2kh48Fr6eM9btBGLPoOPfqVFG7H4DPHxPWPRRhJDERYAAAAAAAAAAuRfUg0AAAAAAAAAkDQUYQEAAAAAAAAgQBRhAQAAAAAAACBAFGEBICSSPcU3U4YDAADkJvqVAJB8FGEBIMN98803MnToUNl///1ljz32kN69e8sll1wis2fPLl9nxowZct555yXl8TZt2iQ33XSTvPbaa0nZHgAAADID/UoASB+KsACQwb799lv57W9/KytWrJDhw4fL+PHj5corr5Sff/5ZTj75ZPnXv/7l1ps4caJ89913SXnMxYsXy2OPPSYlJSVJ2R4AAADSj34lAKRXrTQ/PgCgCn/5y1+ksLBQHn74YalV69eP7H79+kn//v3lvvvuk4ceeiit+wgAAIDMR78SANKLkbAAkMGWLl3q5tAqKysz9zdo0ED+9Kc/yRFHHCFXX321vPTSSzJ//nzp0KGDvPjii/LTTz+5f2tnWzvVXbt2lRdeeMH97uTJk+X3v/+9dO/e3Z2Gpj9/6qmn3M/09/r27ev+PWzYMDnkkEPKH3P69OkycOBAt61evXrJVVddJcuWLTP7NXPmTDn11FOlW7ductBBB7mRD2eeeabbR/V///d/8rvf/c57nrrOWWedFUCCAAAAUPQrASC9KMICQAbTDqeeIqYdTO3Q6qlh0QsbaCf3+OOPlwsuuEAOPPBA2XbbbeXZZ591vxN19913y7nnniu33nqrm/vrvffekwsvvFA6d+7sRjvoz3fYYQe54YYb5PPPP5eWLVvKPffc4373/PPPL//3tGnTXIe2Xr16cuedd7qO+qeffiqnn366bNiwwa2j+6brqLFjx8pFF13kRlPovGJRJ554outQ//jjj+X3LViwQKZOnSonnHBCilIFAADIPfQrASC9mI4AADKYjixYsmSJPProo65Dq/Q0Mr2IgnZUu3TpIjvuuKM0b95c6tSp40YKqHXr1rmljmjQUQJRr7/+uutgX3PNNeX36ciFvffe23VYdTTC7rvv7u7X7Xbq1Mn9+/bbb5e2bdvKgw8+KAUFBe4+Xfeoo45yIyF0lIL+rHHjxvLII49I/fr13Tq77LKLGaEwYMAAGT16tLzyyisyZMgQd5/+u2HDhnLooYcGnicAAECuol8JAOnFSFgAyHAXX3yxTJkyxXVY9Yh/o0aN3BVm9QIKjz/+eJW/G+34Rg0aNMh1VteuXSv//ve/ZdKkSa6TG716bSzr1693oxl0VISOltALK+hNRzq0a9dOPvroI7feJ598IgcccEB5RznaEd9uu+3K/6+d6cMOO0xeffXV8vv0lLcjjzzSjYYAAABAcOhXAkD6MBIWALJA06ZN3dF+valZs2bJFVdcIbfddpscffTRW/w9neOrIp1r6/rrr3fzd+Xl5clOO+0ke+21l/tZ9HS0ylatWuXmDtOLOOitsrp165Zve5tttvF+3qJFC/N/7fBrZ1nnAtPRDz/88IPccsstceUAAACAmqFfCQDpQREWADLUokWL3ClfOmLhpJNOMj/T07mGDh3q5uGaN29e3Nu8/PLL5fvvv5cJEya40QR6qpmOSHjuuee2+Dt6Spd2rHVeLj1NrLLoCIXWrVu7Cz5U9ssvv7jTx6L04gt6Strf/vY3yc/Pdz+Lnu4GAACA5KNfCQDpx3QEAJCh9Eh/rVq15Omnn5aNGzd6P9dOr44W0FEH2umMh17MQE/b0rm6tKOsPvjgA7eMXik3OjdXlJ6mpp1zfbyioqLy26677uouwKBzfqmePXu609sq7quOrNAr41akHW+9WIKOmnj33XfdXGIAAAAIDv1KAEg/RsICQIbSTuuIESPcqAQduaAXKdC5snSEgc6XpVe11dEMekpZkyZN3GiB999/35uvqyK94ILO+6VXsdURBp999pm70qx2YHW70fm11Mcff+weTy+UcOmll8p5550nl112mRxzzDFSWloq48ePd3N66VV01R/+8Ac3F5jOD3b22We7083uuusu15HX7VeknWXtaKtjjz02wBQBAABAvxIA0i8vsqXJWgAAGeHLL790V7HV0QY6P5aONNARBKeddpobfaC++eYb13HWU8j06rB6QYK+ffvKzTff7DqmUfPnz5cbb7zRzZuldt55Z3c1XJ1La8WKFfL888+7+/UiC88++6zUrl3bdcx1qZ3ne+65x114Qf+vHe6LLrqofO4vpdu99dZb5auvvnLzeA0ePFjuv/9+t5/Dhw83z0v3S0dlaGcdAAAAwaNfCQDpQxEWAJAU2pnWTnTFzrOOWthvv/3kyiuvdJ3yivOSHXzwwTJu3Djp169fmvYYAAAAmYh+JYAwYjoCAEDSRlZo51dPMdPRDDoC4i9/+Ys7DS169V0dyfD3v/9d3nrrLTda4pBDDkn3bgMAACDD0K8EEEYUYQEASaHzdW3atEmeeeYZWbBggTRo0MBdsVZPXWvevLlbRy+uoB3oVq1aydixY+O+8AMAAAByB/1KAGHEdAQAAAAAAAAAECAOFQEAAAAAAABAgCjCAgAAAAAAAECAKMICAAAAAAAAQIAowgIAAAAAAABAgCjCAgAAAAAAAECAKMICAAAAAAAAQIAowgIAAAAAAABAgCjCAgAAAAAAAECAKMICAAAAAAAAQIAowgIAAAAAAABAgCjCAgAAAAAAAECAKMICAAAAAAAAQIAowgIAAAAAAABAgCjCAgAAAAAAAECAKMICAAAAAAAAQIAowgIAAAAAAABAgCjCAkANRCKRjNxWpsqF5wgAAFAd9CsTkwvPEUC4UIQFkHSnnXaadOjQQX73u99tcZ2hQ4e6da6++mrJJMuXL5ebb75Z+vXrJ3vssYf06tVLzjjjDHnnnXfMegsXLpTzzjtP5s+fn5THnThxotxyyy2Saa9hxVvHjh1lzz33lBNOOEFeeeWVhLc5Y8YMl1m6TZgwQfbff3/p0qWL3HfffYE9zt/+9jf3fPv06ePaUu/eveXiiy+WL774wqw3depUl68uq1L59ejUqZPsvffecvbZZ8s//vGPwJ4HAADpRL8ycfQrw9OvPOSQQ8rb9a233iq77767rF692qyzbNkyl6felixZEvNn9957b/n2NP/LLrtsi4958sknu3XuvvvupD8fINfVSvcOAAin/Px8+de//uU6la1btzY/W7duXUYWjTZs2CCnnnqqlJaWuk7dTjvt5Do5b775pvzxj3+UP/3pT67jrP75z3/K+++/n7THvv/++13HPJNoke/6668v/7/moq+ndjavvPJKadasmRx44IEJ/UHw3XffSTqtWbPG/VFy0EEHueLl9ttvn/THKCkpcR1b/QPrmGOOkWuvvVYKCwvl559/lueee879ETlmzBg58sgjE972iSeeKCeddJL79+bNm11H+4UXXpA//OEPcs0118jpp5+e9OcDAEC60a9MDP3K8PQrK9p3333l0Ucfde8FPcgfNWXKFGnQoIFs2rRJPvzwQzn++ONNsVpHDOtggIrvJ33PbNy4UerWrWse46effpLPP/880OcB5DKKsAAC62jNmTPHjQY888wzzc/0S79+/frSpEkTySS6r9qZe+utt2TnnXcuv19HL2hHety4cTJw4EApKCiQXNCoUSPp1q2bd/8BBxzgOoEvvvhiQp3lTLBy5UopKytzr2nPnj0DeYwHHnjAtSVtL4cffrj52dFHHy0XXnihjBw50o1EqFevXkLb1j88K78mWsy96KKL3OgI3WbQfwAAAJBq9CuzH/3Kmttrr72kdu3a8tlnn5kirBZedVSxtistyFYswk6bNs29N3QkdpSuO336dPnggw/k0EMPNY8xadIkN9r2q6++Cvz5ALmI6QgABEKPxmpHSjuglemXuxanatWyx4G0E/PQQw+5zoB2FHSdJ554wqyjR811nQEDBrjTfrQzpyMLP/nkk/J19NQZ3cZ7773nil7Rbb388stV7vPSpUvL96OywYMHywUXXOCOMGsncdiwYe7+vn37lp8ipAWwm266yY1q0H3TkYlq9uzZbsTDPvvsI507d3adplGjRrmOUvT39PSzl156yZ36o0eglY6cvPTSS91Ihq5du7rtzpo1y+zX4sWL3Sl4uo52/q677jq544473DaVHp3Xfal82pKeLtWjRw9Zv369JEqPmNepU0fy8vLifu00I31++jz1OWqGWzoNX09Z01tUrFyjv/vxxx+7kQeaj54Kdtttt7k2Eos+ZjQXHX2iv1+xTerpcN27d3fb0Ry1Y125Td1zzz0uax1NUPHnUZqnjlDo37+/V4CNjjy45JJL3DQCv/zyiySLtgEdGfv8888nbZsAAGQK+pX0K3OxX1mZHmzQbWoRNkpHuX700Uey3377uWK2/rtim9Niq7aVisX+HXbYweW6pffTUUcdtdV9AVA9FGEBBEZH6EVPHat42o4eddXObmUjRoxwowL0FG4dTaiFLO0kRecwUnoat3b0fvvb38ojjzwiN954o6xYscLNtVmx46enad9www3u9GztxOnowKuuuqrK05a0E6sdeO2UaadI910LW0o7aeecc47r/OgpR+eff767X9fTTnTUU089JUVFRW4f9dRx7czqqWi6b6NHj5aHH37YdWy0I/n444+Xb2Pbbbd1f1w8++yz0rJlSzd/k/4R8OWXX7rT2W+//XbXodJtRZ+Ddtx1X7Ujpp0/nXNMO+bjx48v3x/dBz3VqHInS+fe0tdHn8+WaKdOT62P3nQ733//vftDYe3atXLsscfG/dppRvr89Hnqc9QME1E516jLL7/cdfr1MbVNaZvQ09P+n737AJOqOv84/u7SuyBS7AgqllURsUTs2DFRI4kFeyGxYNcYiYIau6hobFFibyR2zV8lJsYYCyLqKtjRoFJEei87/+d3kln33TssO7tzp34/z7PPhdm7M3d/c2bm3XPPOTcVPaayFj1/Og7RfeqPEv3hpd9BI1U1akUFe/IPmuQfL5oqqD9GlEGHDh0ij6HphJoWmap9J6lI1+Oss846likbbbSRrb322mHKGQAAxYi6krqy1OrKVNShqusLKENRR7pO7KsjV21O7ffDDz+sfn3oOVRHcG16vpJLEiTp+dD+dMIC8WE5AgCxUXGiYqzm1DGtk7nmmmuGAqemyZMnh/UyVbQkF9lXMaGz4nfeeacdeeSRYV3N5Bn6mme0dQZd07E/+eST6mlOKk5///vfhzPComlge+yxRyh2evbsucrOMRVCmiquM9T60nRxTf1Rgbb//vuH/Tp16mTrr79++Lem69Sc/q2OMBVwNacHaZ+bb745TMMSnanWWWqdddfvqil2GgGg+00e/3333ReKqEceeaS6s07TtVQw6b5U1D3zzDOhWNKaoMkpRirMNCUqSb+rzpirOE6uJari+quvvgrFe100fUkjLGrS87HJJpuEY1Ce9X3ulJd+P/2eqaairU7tXJOjHPQ7qbgVPddjx44NI1VSXbxDj6/nQnQ8Og6NOtC6aboAgUYpJOl31B8mylZbUbGrP7jUHlZlypQpYVtz2qHoD53aI2E0KlZfmdK5c+fqUTcAABQb6krqylKrK1PRcen5UmepnictP9C1a9fwGKo1tbauTkyoo1/PjUbypuqEVfvTSN+aSxJoFKyeX+UDIB6MhAUQGxWamqZT82z5888/Hz70a045Ek370hly7V/zLLn+rzO0yRF+OnOvs/Q6o6/pNSpmVDQmz+DXVLMoS17EQaMU67LPPvuEYktnvjUdScWmRjdqCvnQoUPDMdYlWYwlqWh88MEHQ0Gvtcz+9re/heJMx1/7eGvSdCjdl4qqZBbqsFPBrONJZpacTpSkgjxZxCb9/Oc/D1klr7ir6Vs9evQIRVZdVChreru+dFZfxZ3+6LjpppvCiIR0n7vGqJ1rUu3fQc/z6p7jmjQqRc9D7RE0Koj1R8rbb79dr+NISjXlUPTHhfKs+VVzJE4m6Dmo/boCAKBYUFdSV5ZaXZmKOlfbtGlTvSSBOuaTnax6TtVxrudblJWeU33Vpo5Wtemaryd1wtY1mwtA4zESFkCsVBhr3SpNHVPBqKJAhWdtOjsvq5r+Mn369LCtrKwMIwq01WiIXr16VZ+trV3I1pwSlRxxuLpiV7TgvabzJBe812NrrS1NJVIhXbsYrb1mWe1OuZEjR4ZpTyriunfvHoqn2lciTZXH119/HRkxkKQRGbNnzw6jP2qrfZtGOWgKl0YtaOqbrsqbHFlQFxV4mqqVpPWxNC1Mf0RoHSyNAEgea32eu8aonWtS7Qtb6Xmuz3OclFx/S6NIa9Nttdc8UyZ1SbZF/WGy8cYbV9+uURs1R5LUnPqWKXqN6Q8aAACKFXUldWUp1ZWpaIkLrSOrTlitO6uOX9WZNTvq1aa19IE6y1ONgq35etJAAXVuawSyRjTX7BAHkHl0wgKIlc6wq8DQWVYVPJpiVfMMe1LyiraaLpWqIFFBrHWNTjrppDC9SyMftA6miiNNBVMh21iaaqQz+VoDqyaNGtAUtJdeeimMOqirWK5N64bde++9oRjSaIh27drVqxNO+6nAuuCCC1J+X9OvdFwqlmqrfcEn5amCSkWyOulUtNdcd6u+VDxqapXWSVMeGj1S3+culeSoldqjR7UuWEOK0oZIrr+lafxqTzVp/bdUIwfqokJXfwipvddcn0zPlb7ionap401OcQMAoBhRV1JXllJduSoa7ap8tMSDlhtILpORrEW19rBG3WrtWI30XhU9j1pGQksa6ESE7jdVRzyAzGE5AgCxUlGnEYAqZlWsreqsdnI9JJ2F11ny5JemV+kMrc6Ka50qbXVRBI1USI5C0FpGdU0Fry9NE1JRn1zXsyadHZbkSMP6ruWpaUA6Vk3dShbKOoP/6aefuuOtfX8qlPWYKt5r5qFRB5rGpSucah9d8XbSpEnVP6ez3iqkalNxrsdUwaa1wxraIahiTSM5nnvuueopVfV57lL9jsm1zGpeYEMjCOq6yEWmaRSG2qh+n5o0ckAXTNh2223Tuj89x8cff3y4YrLWqUtFz0OmaW0wjd445JBDMn7fAADkC+pK6spSqitXRZnr/tS+dBJC6xvX7KTW86znVR206lhdFT1vWk9Z91PX6wlA5jASFkDsNG1pyJAhoVgaNmxYyn00CkFTknTFVk3lVkGhYlEXNNAoB60ZpTPtKrB0xVJNxdGXinAVGVLzKrYNoQszaGF+FZYqyLUulI5ZZ4Z1ZViNvtBXzbP06mjTbau6KIOmiGndK41c0LpLmgqmiwpovaiax6v709VNVYDqZ3TBCRXG2mqaloorrdOkCxXoCqqiNZt0v7qAgEYR6D7+9Kc/hRELtUcJqMBSQab7V6aNoSvm6rnSVDqtA1af5y75O2pkgEaYaA0s/Zym0WltVD2vyQsu1HVl3UzTxQs0hU7HoOmCGo2iP0BU5OuPnIZ0amqNN/0BoIt66I8LXexAVybWCAhdhVZFroremqMWRG255h8+SbpIRHIEh+5X085E66PpDy89B1oPTFdtTq5RBwBAsaKupK4spboyFXXeaySxRnCffPLJke9rSYJHH300dF4n21ZdSxJotLby0uhqAPGiExZA7HS2VgWACqNVFZWiAkDFkooGdTZpOowKba31pTP0OuOvwvPaa68NxaE6plR06QIFKkB0llmL9jeUCjsVfzqGZ5991v74xz+GdaA22GCDsOaVCujkVKcddtgh/F6aOqX1yFS0pqI/EnQm//777w8FmTLQlK1kYThv3ryQjQpira+lx1HBq1EAykH3P3z48LBWk4pOTddKTjnTHwv33HNPuE376P8qWlUAJkdY1KTp8RpFUHNt0obQ9CpdRVh/QOgqu4MHD17tcydat0qFsop7dVSqSNUITv3eugKuiklNmdLIlFTHHxd1luqx1Y4ee+yxkJ86T3Xsq1ozrC76fa+55prwx8yYMWPClWf1R0KyvV588cV28MEHR/4o0PpuqehYkp2wyQtaiP6Q07Fq1IXaTO1OXQAAihF1JXVlKdWVq6IRrhpxqw7X2nTbAw88ENrU6ujY9Jzr+UyOrgYQn7JEOitNAwDyxmeffRYKS521rnlVYBXTGhF56623Vt+mt3pNMVJRphEHAAAAQBJ1JQDEj5GwAFCgNI1OIzd0RVRNede6T5pa9uGHH9p5550X9tFFJ3QBB01905pkGmkAAAAA1ERdCQDxYyQsABQwLaSvqWO66IDezjfffHP79a9/XT01SeuGanqRLtagNb8OOuigXB8yAAAA8hB1JQDEi05YAAAAAAAAAIhReZx3DgAAAAAAAACljk5YAAAAAAAAAIgRnbAAAAAAAAAAEKOmcd55KZkwYUJYvLxZs2a5PhQAAICStnz5cisrK7M+ffpYIaKuBAAAKL66siBGwurqi6NGjbJddtnFttlmGzv55JNtypQpq9x/9uzZdu6551q/fv1s++23txEjRtjixYurv79y5cpwf3vssYdttdVWduihh9o//vGPRh2jCmWucfYjZbFkyRIy+R/yiCITjzw88vDII4pMPPIorrqs0I8/02jfHnlEkYlHHh55eOQRRSYeecRXlxXESNjbbrvNHn74Ybv66qutW7dudt1119lJJ51kzz77rDVv3jyy/9ChQ0On67333mvz5s2ziy++2BYtWmTXXHNN+P7NN99sY8aMsauuusp69uxpzz33nJ166qn2+OOP25ZbbtmgY0yOVKioqGjkb1scpk6danfddZedcsop1r17dyt15BFFJh55eOThkUcUmXjk4VVWVloho670aN8eeUSRiUceHnl45BFFJh55xFdX5v1I2GXLltno0aNDx+ruu+9uvXv3thtvvNGmTZtmL730UsrpW2+//XbocN1iiy1sp512sssuu8yefvppmz59evVQYnXM6v7WW289+/Wvf21t2rSxN998Mwe/IQAAAAAAAIBilvedsB9//LEtXLgwdKYmtW/f3jbffHMbN25cZP933nnH1lprrTDCNUlLEmj9hvHjx4f/X3jhhTZw4MDwbw2xfuCBB8LI2R122CErvxMAAAAAAACA0pH3yxFoxKvUHgLdpUuX6u/VpNGutffVkgVrrLFGGFJd0zPPPGMXXHBBWNvhjDPOaPSUL92Plj3Af7PYbLPNyOR/yCOKTDzy8MjDI48oMvHIw1MOOgFfyHguf0T79sgjikw88vDIwyOPKDLxyCO+urIskecr7WoZAXWUTpo0ycrLfxy4q9tmzJgR1n2tScsMfPXVV/bQQw+527X0wC9+8Yuw9muSOmXnzp1rr7/+uo0cOTL87JFHHtngNSK0dAIAAAByTyfhC3VNVepKAACA4qsr834kbMuWLcNWhWjy37J06VJr1apVyv1TFa3av3Xr1u42jZjVl9aZ/frrr+2ee+5pcCds8iIKvXr1avDPF5MVK1bY/PnzrV27dta0ad43s9iRRxSZeOThkYdHHlFk4pGH9/nnn1uho678Ee3bI48oMvHIwyMPjzyiyMQjj/jqyrxPM7m0gEa9rr/++tW36/+bbrppZP9u3brZ2LFj3W3qlJ0zZ05YwkCN6R//+EdYU3bttdeu3kf39cQTTzTqWDU8uXZHb6nSKOO7776bq+n9D3lEkYlHHh55eOSR3UxWrlwZLuJZSFTnPP7442HWj+qdYqcOyiZNmqzy+4W+FIFQV/6I90CPPKLIxCMPjzw88oiirvSoK+OrK/O+E1ajVNu2bWtvvfVWdSfsvHnzbOLEiTZ48ODI/v369bPrr78+jGzdYIMNwm1vv/122Pbt2zcE+7vf/c4OO+wwO/fcc6t/7v3332e0AQAAJUwrNGm9eRWehUYF/s477xxqJF3QtBRovX+dfC+GDlcAAFBcqCsLyxpZqiubFsK6C+psVcdqp06dbJ111rHrrrsuhLPPPvuExjFr1qwwTFpLEWy99da27bbb2tlnn23Dhw8PiwhfcskldvDBB1vXrl3DfZ5wwgl266232iabbBLWdHjppZfsueees1tuuSXXvy4AAMiRZKGsM/4agVhInXvJWT8qIFU7FbPkRSI0K0oYxQMAAPINdWVhSGS5rsz7TlgZOnRoWEZg2LBhtmTJkjDaVeu3asjwN998Y3vttZddddVVduihh4aGrQ7WESNG2LHHHmstWrSw/fbbzy666KLq+zvxxBPDz6rTVcPON9poIxs1alS4HwAAUHp0UjdZKK+55ppWaHTxUq3ZpRPSxV4sS/K6ACqY9ZzVNYUMAAAgm6grC0urLNaVBdEJqwDOP//88FXbuuuua5988om7TY1cnap1NajjjjsufAEAACTX6mINzsKRfK703NEJCwAA8gV1ZeFpnaW6siyhsbdotMrKyrDV8gYAAKCwaKbN5MmTrUePHuGsPwr7OSv0uqzQjx8AgFJGXVl4lmSprixv9D0AAAAAAAAAAFaJTljEYubMmWHdXm1BHqmQiUceHnl45JH7TI4++mjbdNNN3deWW25pu+++e1iHfu7cuVk5jvoeW+/evcOFSrVe/tNPPx3L42ptfT0WEDfeAz3yiCITjzw88vDII4q6su5jo64ssTVhUXi0joYumpZcC6XUkUcUmXjk4ZGHRx75kcnmm29ul156qTuGjz76yEaOHGmTJk2yRx55JGdXvt1ss83s9NNPtw4dOoSLj+qCELoq77333msXXHBBuLrtbrvtltHHHDRokO2yyy4ZvU8gFd4DPfKIIhOPPDzy8MgjirrSo66MD52wAAAA9dC2bVvbZptt3G39+vWzhQsXhguCvv/++5HvZ0ubNm1CMd+5c2d3Fdtdd93VdtppJ3viiScyXix369YtfAEAACA91JWlWVeyHAEAAEAjaPqYfPfdd9XTuM477zwbOnRoKJ6PP/74cPvSpUvt2muvDUWrfuaggw6yF154ofp+fve739nOO+8cRhvU9Pvf/9522GGHBo3OaNGiRSiea46kqKqqsrvuusv23nvvcBz77ruvPfDAA5Gf1bS8vfbay7baais7/PDD7ZVXXgnTxN56662U08b0e19yySV22223hZEMW2+9tZ188slhat9f/vKX8Hh9+vSx4447Low2qWns2LFhipsueKAMrrjiClu0aFHavy8AAEAho64s7rqSkbAAAACNoCupynrrrVd921//+lf76U9/arfffnsoThOJhJ122mn27rvvhiK6Z8+e9vLLL9vZZ59ty5Yts4MPPth+9rOf2eOPPx6K0Z/85CfhfvSzuq8DDzwwTAdbFd2/iuwVK1ZYeXl5+Pe3335rf/jDH8KICt130vDhw8MIhiFDhoTiddy4cXbllVfavHnzwjHKrbfeGn72xBNPtB133NFee+01O+uss1abxXPPPWdbbLFFKPA1be2yyy6zwYMHh6L9wgsvtMWLF4eCWrerYJdnn302/HGhPx70GDruG2+80T7//HP705/+lLOpeAAAANlGXVncdSWdsIiF1gg55JBDwhbkkQqZeOThkYdHHvmRiQpSFaNJumjC22+/HQpiFZ3JkQuiwlYXVkhO4Xr99ddDwaki8IADDgi36ay+isfrr7/eBg4caH379rV11lknFJzJYlmF8/fff++K3VTGjx9vAwYMcLepyNxkk03s5ptvtj322KO6sFdBfs4559gpp5wSbuvfv3/Y984777QjjzwyFLZ//OMf7aijjgpFbHIfHetjjz1W53EoHxXaWkNMXnrppfB7a0RC8o+J9957r/qiDspUv7+y0DZpww03DCMbXn311XCRCpQ23gM98ogiE488PPLwyCOKutKjrowPyxEgFq1atQrDzLUFeaRCJh55eOThkUd+ZKIz+zobn/xSQauiU0XyDTfc4M6sb7TRRm4NrTfeeCN8X1PGVFAmv/bcc89QDH/22Wfh+xrloMJSoxjk+eefD4WjpmDVRcfz5z//OXxp2paKZP3cTTfdZPvtt1/1fm+++WYoUPW4tY9D09pUdKuYXbJkifs5UUG/OhqJkSyURWuJdezY0Y3m0B848+fPD//+8ssvw8iG2sejNdG0Vpr+yAB4D/TII4pMPPLwyMMjjyjqSo+6Mj6MhEUsNERdV/bTi1eLOpc68ogiE488PPLwyCM/MtFjaRSCqLDVmf3u3buHoq622sc0Z86cUKRuu+22Ke97xowZ4Uq0GpmgERA6y6+z+Drjf+yxx6722Fq3bh0K9JYtW4b1r1Rcq/A+4YQTwhSxTp06VR+HaBpaKtOnT68udpM/k7Tmmmuu9jhSZaFjW5Xk8SjXZLa1cwF4D/TII4pMPPLwyMMjjyjqSo+6Mj50wiIWWv9Da43oDAVv7OSRCpl45OGRh0ce+ZGJHkeFaEO0a9cuFI33339/yu9vsMEGYdujR48wEkO/m9bg0u+pond1VIhrGpumqzVp0iSMFNAaWWeeeWZYR0sjKqR9+/Zhe99996XMbe21165ei+yHH34IBXjSrFmzLNOSx3PBBRfY9ttvH/l+zdEPKF28B3rkEUUmHnl45OGRRxR1pUddGR+WIwAAAIiZCkFdlVVFrQru5Nenn34aLlRQc00wjVrQiAVNGdMIh5pTrtKhaV8a9aC1wLTGmGy33XZhO3v2bHccKoS1xpdGEPTu3TsU97rAQ00aPZFpKsY1EkJXta15PF27dg0F/sSJEzP+mAAAAIWMurJw60pGwgIAAMRMa3ZpPapTTz01fGmNqw8++MBGjRoVCtqaU7R0gYWrr77aXnjhBbv00ksb9bi//e1vw4iHK664wp588knbdNNNw/9/97vfhavFat0xjVDQhR3WXXfdsN6XRjycdNJJ4di0NpoKfRXbjzzySLhPjaTIFD2WruSr0RX6ty70oFEaWn9MU9g0VQ8AAAA/oq4s3LqSTlgAAICYqcC86667wqgAXS1WU7J0Vv7444+30047ze2rwllXjdXFA2pfxKAhIwKOPvpoGz16dCh2Bw8ebFdddVU4hkcffTRcvEAjBlSgn3XWWaFglSFDhoTRFbpq7T333BPWAtMVbfWzda3F1RCDBg0KU9juvvvu8Hi6f43U0FVtGzpaAwAAoFhRVxZuXVmWUBJotMrKyrBt6JoexUZvAlp3ZP/996/XgsvFjjyiyMQjD488PPKIPxNdtVVn7rV2li5CUGg07Uxrd2mtq6ZNmzb6vjTVbIcddggXiEh66KGHwsiHt956q3rNrVyq6zkr9Lqs0I8/03gP9Mgjikw88vDIwyOPKOpKj7qyZWx1GZ2wGUKxDABA4Sr0YjnTdJXb5s2b269//Wvr2LFjWGPspptusgEDBoRRC/mATlgAAJCPqCs96sofsRwBYlFVVWXLly8PV9PL5BofhYo8osjEIw+PPDzyiCITT+fU9VVWVha+GuuOO+6wkSNH2vDhw8NaWrq67bHHHhumkwHZxuvdI48oMvHIwyMPjzyiyMSjrowPrQux0KLHWvxZW5BHKmTikYdHHh55RJGJpz8ctA6XtpmgNbN0UYV///vf9uGHH4Yr2J5++unhjxMg23i9e+QRRSYeeXjk4ZFHFJl41JXxoRMWAAAAAAAAAGJEJywAAAAAAAAAxIhOWAAAAAAAAACIEZ2wAAAAAAAAABCjsoQueYZGq6ysDNuKiopcH0peWLlypS1ZssRatmxpTZo0sVJHHlFk4pGHRx4eecSfie5r8uTJ1qNHj3CfhUblnK7sqyv6ZuIqtoWgrues0OuyQj/+TOM90COPKDLxyMMjD488oqgrPerKlrHVZU0bfQ9ACnrjatOmTa4PI2+QRxSZeOThkYdHHlFk4qlA5g8pFCte7x55RJGJRx4eeXjkEUUmHnVlfFiOALGYNWuWPfLII2EL8kiFTDzy8MjDI48oMvFWrFhhc+bMCds4aVTEqFGjbJdddrFtttnGTj75ZJsyZUqsjwnwevfII4pMPPLwyMMjjygy8agr40MnLGKxdOlS+/TTT8MW5JEKmXjk4ZGHRx7Fm0lVoioj99O0aVNbY401wjbOx73tttvs4Ycftssvv9weffTRUDyfdNJJtmzZsgbdH1BKr/dMIY8oMvHIwyMPjzyKNxPqyvzHcgQAAAA5Ul5Wbg+9/5pNXzA3a4/ZtW0HO2rrXdL+ORXEo0ePtvPOO8923333cNuNN94YRi+89NJLNnDgwBiOFgAAAPVBXZn/6IQFAADIIRXK387L/+lvH3/8sS1cuNB22mmn6tvat29vm2++uY0bN65oi2UAAIBCQV2Z31iOAAAAAKs1bdq0sO3evbu7vUuXLtXfAwAAAFZnWonWlXTCIhbt2rWzffbZJ2xBHqmQiUceHnl45BFFJtm3ePHisG3evLm7vUWLFgW/hhryG693jzyiyMQjD488PPKIIpPsW1yidSXLESAWbdu2dcPKSx15RJGJRx4eeXjkEUUm2deyZcvqNbyS/xYVyq1atcrhkaHY8Xr3yCOKTDzy8MjDI48oMsm+liVaVzISFrGd1fjoo4+qz26UOvKIIhOPPDzy8MgjikyyLzldbMaMGe52/b9r1645OiqUAl7vHnlEkYlHHh55eOQRRSbZ171E60o6YRGLOXPm2J///OewBXmkQiYeeXjk4ZFHFJlkX+/evcNIkbfeeqv6tnnz5tnEiROtX79+OT02FDde7x55RJGJRx4eeXjkEUUm2de7ROtKliMAAADAamnNrsGDB9v1119vnTp1snXWWceuu+4669atW1hHDQAAAKiP5iVaV9IJCwAAkENd23YomMcbOnSorVixwoYNG2ZLliwJIxXuuecea9asWUaPEQAAAOmjrsxvdMICAADkSFWiyo7aepecPG55WfqrUjVp0sTOP//88AUAAID8QV2Z/1gTFrFo2rRpGEauLcgjFTLxyMMjD488ijeThhSsqSxfvtxmz54dttl8XCAbiuX1ninkEUUmHnl45OGRR/FmQl2Z/8oSiUQi1wdRDCorK8O2oqIi14cCAADSpClQkydPth49eljLli1zfTho5HNW6HVZoR8/AACljLqy8CzJUl1JdzUAAAAAAAAAxIhOWMRi6tSpdsUVV4QtyCMVMvHIwyMPjzyiyMRbtmyZfffdd2ELFBte7x55RJGJRx4eeXjkEUUmHnVlfOiERWxWrlyZ60PIK+QRRSYeeXjk4ZFHFJkApYPXu0ceUWTikYdHHh55RJEJsoFOWAAAAAAAAACIEZ2wAAAAAAAAABAjOmEBAAAAAAAAIEZliUQiEecDlIrKysqwraioyPWh5IXly5fb7NmzrWPHjtasWTMrdeQRRSYeeXjk4ZFH/JksWbLEJk+ebD169LCWLVtaoamqqgprmTVp0sTKy0vjHHtdz1mh12WFfvyZxnugRx5RZOKRh0ceHnlEUVd61JUtY6vLmjb6HoAU9MbVpUuXXB9G3iCPKDLxyMMjD488osjEU4FcKkUySg+vd488osjEIw+PPDzyiCITj7oyPqSKWMyZM8eeeeaZsAV5pEImHnl45OGRR/FmkqiqKtjHvfPOO+3oo4/OyPEApfB6zxTyiCITjzw88vDIo3gzoa7Mf4yERSwWL15sEyZMsH79+tkaa6xhpY48osjEIw+PPDzyKN5MysrLbe7YR2zl7BlZe8wmHbtYhwFHNOo+HnroIbvppptsu+22y9hxAcX+es8U8ogiE488PPLwyKN4M6GuzH90wgIAAOSQCuUVM7+1QjB9+nS79NJL7a233rINN9ww14cDAACAGqgr8xvLEQAAAKBePvroo7Bumqbsbb311rk+HAAAABSoj0qwrmQkLAAAAOplzz33DF8AAABAY+xZgnUlI2ERizZt2tjOO+8ctiCPVMjEIw+PPDzyiCIToHTwevfII4pMPPLwyMMjjygyQbYwEhaxaN++vQ0YMCDXh5E3yCOKTDzy8MjDI48oMgFKB693jzyiyMQjD488PPKIIhNkCyNhEYulS5faV199FbYgj1TIxCMPjzw88ogiE6B08Hr3yCOKTDzy8MjDI48oMkG20AmLWMyaNcvuu+++sAV5pEImHnl45OGRRxSZAKWD17tHHlFk4pGHRx4eeUSRCbKFTlgAAAAAAAAAiBFrwgIAAORQk45divrxAAAAkB3UlfmNTlgAAIAcSVRVWYcBR+TkccvKGzch6uqrr87Y8QAAAKBxqCvzH8sRIBbl5eXWrl27sAV5pEImHnl45OGRR/Fm0tiCNWn58uU2c+bMsM3m4wLZUCyv90whjygy8cjDIw+PPIo3E+rK/FeWSCQSuT6IYlBZWRm2FRUVuT4UAACQpiVLltjkyZOtR48e1rJly1wfDhr5nBV6XVboxw8AQCmjriw8S7JUV9JdDQAAAAAAAAAxohMWsZg+fbqNHDkybEEeqZCJRx4eeXjkEUUmnqaLTZs2rd7TxoBCwuvdI48oMvHIwyMPjzyiyMSjrowPnbCIRVVVlc2fPz9sQR6pkIlHHh55eOQRRSaeVpdSFqwyhWLE690jjygy8cjDIw+PPKLIxKOujA+dsAAAAAAAAABQ6p2w6oEfNWqU7bLLLrbNNtvYySefbFOmTFnl/rNnz7Zzzz3X+vXrZ9tvv72NGDHCFi9e7O7v7rvvtn333Tfc34EHHmhjxozJ0m8DAAAAAAAAoJQURCfsbbfdZg8//LBdfvnl9uijj4ZO1JNOOsmWLVuWcv+hQ4fa119/bffee6/dfPPN9uqrr9rw4cOrv3/nnXeGrzPPPNOeeeYZO+aYY8L3n3rqqSz+VgAAAAAAAABKQVkizxd5UEfrjjvuaOedd54deeSR4bZ58+aFUbG///3vbeDAgW7/CRMm2OGHH24vvPCC9ezZM9z2r3/9K3TaqjO2a9eutuuuu9oRRxxhv/71r6t/7re//W3ouH3ooYcadJyVlZVhW1FR0YjftngsXbrUpk6dat27d7cWLVpYqSOPKDLxyMMjD4884s9kyZIlNnnyZOvRo4e1bNnSCo1OUOviCc2aNbPy8oI4xx7rc1bodVmhH3+m8R7okUcUmXjk4ZGHRx5R1JUedWXL2OqyppbnPv74Y1u4cKHttNNO1be1b9/eNt98cxs3blykE/add96xtdZaq7oDVrQkQVlZmY0fP972228/u+aaa0KwNalhqXMXmaE3rg033DDXh5E3yCOKTDzy8MjDI48oMrFIHcMfUihWvN498ogiE488PPLwyCOKTDzqyvjkfSfstGnTwlZnJGrq0qVL9fdqmj59emTf5s2b2xprrBHObKgx1ezQle+++86ef/75MIK2MTSoeNGiRY26j2KhKwtqVHKfPn2sXbt2VurII4pMPPLwyMMjj/gz0QgInfVfuXJl+MqWsrJyKy8vs2yrqkpYIpH+FYDnzJljN910U5hdtGDBAtt0003t7LPPtr59+1q26XnSc6Z1/2tfzVg1mU7AFzLqyh/xHuiRRxSZeOThkYdHHlHUlY1DXVlEnbDJC2qpI7Um9crPnTs35f61903urxdCbTNnzgwX+lpzzTXd8gQNoeHakyZNatR9FAs9N2+99VZ4Ljp06GCljjyiyMQjD488PPLITiZNmzZNWSvERSeGW7VqZS//6xObPS97nW0d27e2vftvaosXL4sUmatzzjnnhNpJS0KpdnrkkUdCHaW1+7M9gkTP1YoVK+zLL79M+f1U9WAhoa78Ee+BHnlEkYlHHh55eOQRRV3ZcNSVRdYJm1yLQWvD1lyXQQGpgaXaP9UFu7R/69at3W0K95RTTgk93vfff39Y5qAxtF5Gr169GnUfxUIjkl977bWw7IPW4S115BFFJh55eOThkUf8mahO0MwYnbTN9tpdKpRnzlpo2ZZuMam1899880178MEHbdtttw23XXrppfbGG2/Yyy+/bGeccYZlm/7AWX/99SNT5j7//HMrdNSVP+I90COPKDLxyMMjD488oqgrG4+6skg6YZNLC8yYMSOEkaT/a6hybd26dbOxY8e629Qpq2HOWsIgSevDauSrXmB33313Rl5oGp5cu6O3VCXfaLQlE/JIhUw88vDIwyOP+DPR6AF9NWnSJHyVgnR/z86dO9tdd91lW2+9tftZ5aZpfNnOTY+XHPVR+w+cQl+KQKgrf8R7oEceUWTikYdHHh55RFFXNh51Zf3k/WXOevfubW3btg1Dw5N0Aa2JEydav379IvvrNq0Vq171pLfffjtsk+tKfPDBB3bSSSfZxhtvbA899BBnfwAAaUtUJWLZF8hXmjG02267uZEOL774Yqi5dtlll5weGwAAAApH+xKtK/N+JKyekMGDB9v1119vnTp1snXWWceuu+66MOJ1n332CUsJzJo1KyyerN5q9aJrKLMW8x0+fHi4oMEll1xiBx98cOhs1RoP5513Xlhv4uqrrw7DxL///vvqnm89BhpPZw+0qHWqJSNKEXlEkYlHHoWXR1l5mU0bO8mWz657zaVmHVtbtwGbFX0e2UYmuffuu+/aRRddFOqx3XffPdeHgyLG690jjygy8cjDIw+PPKLIJPfeLZG6siyhy3zlOXW0jhw50p544glbsmRJGO2qjtV1113XvvnmG9trr73sqquuskMPPTTs/8MPP9iIESPCmh5ay2G//fYLT6b+rSf2iCOOSPk46uB95ZVXGnSMlZWVYVtRUdGI3xQAUEimjBlvS2cuqHOfFp3b2nqDsn+FT6RH9cXkyZPDWmDZXrvr8RcmZHXtrs6d2tgvDujTqPvQ0k86qa0T37fffntk7axcP2eFXpcV+vEDQCGpSlRZeVl5xvdF6aKuTM/YEqor834kbHKE6vnnnx++alNH7CeffOJu0yjXUaNGpbwvPam190c8V/SdPXu2dezYMVxYotSRRxSZeOThkYdHHlFkkju6gIKuYquT3Ndcc03GrhYLrAqvd488osjEI4/08lCn6kPvv2bTF8yt8366tu1gR21d+NOkaR9RZJI7D5ZYXckpHMRi5syZ4QyGtiCPVMjEIw+PPDzyiCKT3Hj44Yft8ssvt6OOOirMUir2Qhn5gde7Rx5RZOKRR/p5qAP223mz6vxaXSdtoaB9RJFJbjxcgnVlQYyEBQAAQG5pitaVV15pe++9tw0ZMsT9oaJpW1qfHwAAAFidySVaV9IJCwAAkEMd27cuiMfTFWs1Xe/ll18OXzUdcsgh4YKnAAAAyB3qyvxGJywAAECOVFUlbO/+m+bkccvLy9L6mV/96lfhCwAAAPmHujL/sSYsYr2gGn5EHlFk4pGHRx4eeRRnJukWrKuikQTff/992GbzcYFsKYbXeyaRRxSZeOThkYdHHsWZCXVl/itLJBKJXB9EMaisrAzbioqKXB8KACBLpowZb0tnLqhznxad29p6g/pm7ZjQMEuWLAlrU/Xo0SOsQ4XCfs4KvS4r9OMHgEIz8vXnwsW36rJO+052zs4Ds3ZMKFzUlYVnSZbqSkbCAgAAAAAAAECM6IRFLDR0/c477wxbkEcqZOKRh0ceHnlEkUnjpo0BhYTXu0ceUWTikYdHHh55RJGJR10ZHzphEYsVK1bYtGnTwhbkkQqZeOThkYdHHlFk4ml1KRXKrDKFYsTr3SOPKDLxyMMjD488osjEo66MD52wAAAAAAAAABAjOmEBAAAAAAAAIEZ0wgIAAAAAAABAjOiERSzWWGMNO+yww8IW5JEKmXjk4ZGHRx5RZOI1bdrUOnbsGLZAseH17pFHFJl45OGRh0ceUWTiUVfGh0QRi1atWtkWW2yR68PIG+QRRSYeeXjk4ZFHFJl45eXlIZO4/fDDD3b11Vfba6+9ZkuXLrV+/frZhRdeaD179oz9sVG6eL175BFFJh55eOThkUcUmXjUlfFhJCxisWDBAnvjjTfCFuSRCpl45OGRh0cexZtJoipRUI972mmn2ddff2133XWX/fnPf7aWLVvacccdZ4sXL874MQLF9nrPFPKIIhOPPDzy8MijeDOhrsx/jIRFLObPn28vvfSSbbjhhta2bVsrdeQRRSYeeXjk4ZFH8WZSVl5m08ZOsuWzF2XtMZt1bG3dBmyW9s/NnTvX1llnHRsyZIhtsskm4bZTTz3Vfvazn9lnn31mW221VQxHCxTP6z1TyCOKTDzy8MjDI4/izYS6Mv/RCQsAAJBDKpSXzsz/kRcdOnSwG264ofr/s2bNsnvvvde6detmvXr1yumxAQAAgLoy39EJCwAAgLT87ne/s8cff9yaN29ut99+u7Vu3TrXhwQAAIAC9LsSqitZExYAAABpOfbYY+0vf/mLDRw4MKzn9dFHH+X6kAAAAFCAji2hupJOWMSiRYsWYV0PbUEeqZCJRx4eeXjkEUUmuaVpYltuuaX9/ve/D+t5Pfjgg7k+JBQxXu8eeUSRiUceHnl45BFFJrnVq4TqSpYjQCw6depkRxxxRK4PI2+QRxSZeOThkYdHHlFkkn1aq0tXDt53332tadP/lpDl5eWhcJ4xY0auDw9FjNe7Rx5RZOKRh0ceHnlEkUn2zSrRupKRsIjFypUrbeHChWEL8kiFTDzy8MjDI48oMsm+mTNn2jnnnBMK5qTly5fbxIkTrWfPnjk9NhQ3Xu8eeUSRiUceHnl45BFFJtk3s0TrSjphEQudubj++uuL+gxGOsgjikw88vDIwyOPKDLJPk3T23XXXe2KK66wcePG2aeffmq/+c1vbN68eXbcccfl+vBQxHi9e+QRRSYeeXjk4ZFHFJlk3yYlWleyHAEAAEAONevYumAeb+TIkXbDDTfY2WefbfPnz7ftttvOHnroIVt77bUzeowAAABIH3VlfqMTFgAAIEcSVQnrNmCznDxuWXlZ2j/Xrl07Gz58ePgCAABA/qCuzH8sRwAAAJAjDSlYU9EaWt9//33YZvNxAQAAkB+oK/MfnbAAAAAFLpFIhEJZWwAAAKChqCvjU5Yg1YyorKwM24qKilwfSl6oqqoKL9pmzZpZeTl9/eQRRSYeeRRmHlPGjLelMxfUuU+Lzm1tvUF9SyKPbMp0JkuWLLHJkydbjx49rGXLllZoVM7pq6ysLHyVgrqes0Kvywr9+DON90CPPKLIxCOP9PMY+fpz9u28WXXezzrtO9k5Ow+0Qkf7iKKu9KgrW8ZWl7EmLGKhN64WLVrk+jDyBnlEkYlHHh55eOQRRSZeKRXJKD283j3yiCITjzw88vDII4pMPOrK+HDaA7H44Ycf7MEHHwxbkEcqZOKRh0ceHnlEkYm3YsWKkIW2QLHh9e6RRxSZeOThkYdHHlFk4lFXxodOWMRi2bJl9sUXX4QtyCMVMvHIwyMPjzyiyCQ6jW7p0qVhCxQbXu8eeUSRiUceHnl45BFFJh51ZXzohAUAAAAAAACAGNEJCwAAAAAAAAAxohMWAAAAAAAAAGJEJyxi0b59e9t///3DFuSRCpl45OGRh0ceUWTiNWnSxDp27Bi2QLHh9e6RRxSZeOThkYdHHlFk4lFXxodOWMSiTZs2tv3224ctyCMVMvHIwyMPjzyKN5OqRGYueKAiuVWrVvUuljPxuJMnT7Y+ffrYE0880ej7Akrh9Z4p5BFFJh55eOThkUfxZkJdmf+a5voAUJwWL15sn332mW288cbhxVvqyCOKTDzy8MjDI4/izaS8rNz+9fndNnfxtKw9ZodW3ax/r5MadR/Lly+38847zxYtWpSx4wKK/fWeKeQRRSYeeXjk4ZFH8WZCXZn/GAmLWMyZM8eefPLJsAV5pEImHnl45OGRR3FnokJ51qL/ZO0rE4X5LbfcYm3bts3I7w+U0us9E8gjikw88vDIwyOP4s6EujK/0QkLAACAehs3bpw99thjdvXVV+f6UAAAAFDAxpVYXUknLAAAAOpl3rx5dsEFF9iwYcOse/fuuT4cAAAAFKh5JVhX0gkLAACAehk+fHi4aMJBBx2U60MBAABAARtegnUlF+ZCLJo1a2brrrtu2II8UiETjzw88vDII4pMsu+pp56yd955x5599tlcHwpKDK93jzyiyMQjD488PPKIIpPse6pE68qyRCKRyPVBFIPKysqwraioyPWhAACyZMqY8bZ05oI692nRua2tN6hv1o4JDbNkyRKbPHmy9ejRw1q2bJnVx36+8opwYYNs6dR6fTuwYljaP3f00Ufbu+++a82bN6++TVex1f932GEHu/vuuy1fnrNCr8sK/fgBoNCMfP05+3berDr3Wad9Jztn54FZOyYULurK1Tu6ROtKRsICAABgta6//vpQoNa0zz772NChQ+2nP/1pzo4LAAAAheX6Eq0rWRMWsZg6daqNGDEibEEeqZCJRx4eeXjkEUUm2de1a1fbYIMN3Jesueaa4XtAXHi9e+QRRSYeeXjk4ZFHFJlkX9cSrSsZCQsAAJBDHVp1K+rHAwAAQHZQV+Y3OmEBAABypCpRZf17nZSTxy0va/yEqE8++SQjxwMAAIDGoa7MfyxHAAAAkCOZKFhl+fLl9v3334dtNh8XAAAA+YG6Mv+RFAAAQIFLJBKhUNYWAAAAaCjqyviUJUg1IyorK8O2oqIi14eSF1asWGHz5s2z9u3bW9OmrHpBHlFk4pFHYeYxZcx4WzpzQZ37tOjc1tYb1Lck8simTGeiq7NOnjzZevToYS1btrRCo3Ju5cqV1qRJEysrK7NSUNdzVuh1WaEff6bxHuiRRxSZeOSRfh4jX3/Ovp03q877Wad9Jztn54FW6GgfUdSVHnVly9jqMl5xiIXeuDp16pTrw8gb5BFFJh55eOThkUcUmXgqkPlDCsWK17tHHlFk4pGHRx4eeUSRiUddGR+WI0AsZs+ebU888UTYgjxSIROPPDzy8MgjikyiIziUhbZAseH17pFHFJl45OGRh0ceUWTiUVfmWSfs/Pnz7eWXX7ann37annrqqcgXoKHcGrKtLcgjFTLxyMMjD488spdJoa7SVFVVZYsXLw7bUlGozxXSx3ugRx5RZOKRh0ceHnlEUVd61JXxSXt88WuvvWZDhw4NjTPVQWrY8sEHH5yp4wMAAIhds2bNwnbRokXWqlWrXB8O6kHPVc3nDgAAIB9QVxaeRVmqK9PuhL3hhhtso402sosuusi6du1q5eWsaAAAAAqbLjywxhpr2IwZM8L/W7duXVAXIli2bFmYMqaT5MU+akGDAFQo67nSc6bnDgAAIF9QVxaORJbryrQ7Yb/44gu77bbbbLvttovniAAAAHKgW7duYZssmAuJrmCr5aJ0Zd9S6ZRUoZx8zgAAAPIJdWVhWSNLdWXanbBrr722LViwIJ6jQdFo27at7bbbbmEL8kiFTDzy8MjDI4/sZKIRCt27d7cuXbrY8uXLrZAsXLjQZs2aFY6/TZs2Vuw0VaxU/igA74G1kUcUmXjk4ZGHRx5R1JUedWV8yhJprj6rK8aNHj3a7rjjDlt33XXjO7ICo0WcpaKiIteHAgDIkiljxtvSmXWfmGzRua2tN6hv1o4JQOHXZYV+/ABQaEa+/px9O29Wnfus076TnbPzwKwdE4Diq8vSXtD12WeftenTp9vee+9tO++8s+21117ua8CAAY0+KBS+pUuX2ueffx62II9UyMQjD488PPKIIhOPPFDMaN8eeUSRiUceHnl45BFFJh55xCftTlitkaCO1oMPPth23XVX23777d1Xv3794jlSFBQNXX/ooYfCFuSRCpl45OGRh0ceUWTikQeKGe3bI48oMvHIwyMPjzyiyMQjjzxaE/anP/2p9enTx1q2bBnPEQEAAAAAAABAKY+EPeOMM+yll16K52gAAAAAAAAAoNQ7Ydu3b88oWAAAAAAAAACIazmCIUOG2BVXXGGTJ0+23r17W+vWrSP7sC4smjRpYh07dgxbkEcqZOKRR3p5VCWqrLysfucR09k3X9E+osjEIw8UM9q3Rx5RZOKRh0ceHnlEkYlHHvEpSyQSiXR+QB2v7g7Kyqr/rbvS/ydNmpS5I9Qf0FVVduutt9qYMWNs/vz5oZP3kksusfXWWy/l/rNnzw4dxf/85z/D8Rx44IF2wQUXWKtWrSL7jh8/3gYPHtzoY66srAzbioqKRt0PAKB+Hnr/NZu+YG6d+3Rt28GO2nqX2I5hypjxtnTmgjr3adG5ra03qG9sxwCg+OqyQj9+ACg0I19/zr6dV/dFiNZp38nO2Xlg1o4JQPHVZWmPhL3//vst22677TZ7+OGH7eqrr7Zu3brZddddZyeddJI9++yz1rx588j+Q4cOtcWLF9u9995r8+bNs4svvtgWLVpk11xzTaQD9tRTTw2dvACAwqIO2NUVywAAAAAA5IO052duv/32q/3KpGXLltno0aNDx+ruu+8eRuLeeOONNm3atJQXCJswYYK9/fbbocN1iy22sJ122skuu+wye/rpp2369OlhnxUrVthVV11lxx57rK2zzjoZPV78l7JWZ3ky81JHHlFk4pGHRx4eeUSRiUceKGa0b488osjEIw+PPDzyiCITjzzik/ZI2Keeemq1+xx88MGWKR9//LEtXLgwdKbWvDjY5ptvbuPGjbOBA/10gHfeecfWWmst69mzZ/Vt6hjWsgQa+XrAAQeEUbH62bvvvtu+++47u+iiizJ2vPgvjS5Wzowy/i/yiCITjzw88vDII4pMPPJAMaN9e+QRRSYeeXjk4ZFHFJl45JFHnbC/+c1vUt6uTk4t2quvTHbCasSrdO/e3d3epUuX6u/VpJ762vtqyYI11ljDpk6dWt2J+8QTT4R/J7cAAAAAiluiqsrKysszvi8AAEDGO2H/9re/RW5TD7lGoP7xj3+0P/zhD5ZJWttVaq/92qJFC5s7d27K/VOtE6v9ly5danHShcmUBcyWLFlSvSUT8kiFTDzyqH8eOumX6kKLddFnQ5rXoaxTto+B9hFFJh55eMmLxRYy6srMt+/ke/fcsY/Yytkz6ty3Sccu1mHAERn//MgEXu9RZOKRR2HVldlG+4giE4884qsr0+6EXdUaqhtvvLEtX77cLr/88nARrUxp2bJl9dqwyX+LOlRTvVlqH+1bm/Zv3bq1xUm//6RJk2J9jEKR7CCfPHmyzZrFhXPII4pMPPKofx5679eSNOnQ/SRP6mVCto+B9hFFJh55RKU6KV9IqCsz376T793qgF0x89ucfH5kAq/3KDLxyKOw6spso31EkYlHHvHVlWl3wtZl0003tRtuuCGTd1m9tMCMGTNs/fXXr75d/9fj1datWzcbO3asu02dsnPmzAlLGMSpWbNm1qtXr1gfo1Ao8/XWWy+sz1vofwRlAnlEkYlHHvXPoyFnIXv06JHxkbDZPAbaRxSZeOThff7551boqCsz377z4fMjE3i9R5GJRx6FVVdmG+0jikw88oivrmyaySfpz3/+s6255pqWSb1797a2bdvaW2+9Vd0JO2/ePJs4caINHjw4sn+/fv3s+uuvt6+//to22GCDcNvbb78dtn379rU46Q087tG2hUI5aB1e/Bd5RJGJRx7x5pHuNLM4NOYYaB9RZOKRh1foSxEIdWV+tO98+Pyojdd7FJl45FH8dWVj0D6iyMQjj/jqyrRXmt9zzz1tr732cl977LGHbb/99vbcc8/ZMcccY5mkXnd1tqpjVevRfvzxx3b22WeHEa/77LOPrVy50r7//vvqNSu23npr23bbbcM+H3zwgb355pt2ySWXhIuFde3aNaPHhlVTR/mLL74YtiCPVMjEIw+PPDzyiCITjzxQzGjfHnlEkYlHHh55eOQRRSYeecQn7U5YdbbW/tpxxx1t0KBBds8999hxxx2X8YMcOnSoHXbYYTZs2DA74ogjrEmTJuGxNE1r6tSp1r9/f3vhhReqe6hvvfVWW3fdde3YY4+1s846y3bddVcbPnx4xo8Lq7Zw4cLQAa4tyCMVMvHIwyMPjzyiyMQjDxQz2rdHHlFk4pGHRx4eeUSRiUce8Ul7OYKrr766zu9PmzYtjFLNJHW6nn/++eGrNnW2fvLJJ+42LYkwatSoet33oYceGr4AAAAAAAAAIC9Gwm622WZhmn8q77zzju2///6ZOC4AAAAAAAAAKJ2RsKNHj7ZFixaFf+sqgGPGjLF//vOfkf0mTJjAldMAAAAAAAAAIN1O2KVLl4Z1VpNrrqoTtrby8nJr166d/frXv67PXaIErqa33XbbcVXf/yGPKDLxyMMjD488osjEIw8UM9q3Rx5RZOKRh0ceHnlEkYlHHvEpS2hoaxp69+5tjz/+uG211VbxHVUBqqysDNuKiopcHwoAlISRrz9n386bVec+67TvZOfsPDC2Y5gyZrwtnbmgzn1adG5r6w3qG9sxACi+uqzQjz/fzRpzs62Y+W2d+zTtvI51GnSmFbtEVZWVlZdnfF+g0ORDXQmg+OuytC/M9fHHH0dGyWoJAo2QBZKWL19uM2fOtM6dO1uzZs2s1JFHFJl45OGRh0ceUWTikQeKGe07vjzUqTp37CO2cvaMOvdr0rGLdRhwhOUr2ohHHh55eOQRRSbp5VGVqLLysvqdlEtn31LQoCS+/PJLO+uss2z77be3Pn362MSJE23EiBH2wAMPZP4IUZD0gr3rrrvCFuSRCpl45OGRh0ceUWTikQeKGe073jzUAauRwXV9ra6TNtdoIx55eOThkUcUmaSXhzpVH3r/tTCCvK4v7UMHbCNHwk6aNMmOOuooW3PNNe2ggw6yhx9+ONzepEkTu/LKK61t27Z2yCGHpHu3AAAAAAAAAPLc9AVzV7uEBzLQCXvNNdfYlltuaaNHjw7/f+ihh8J22LBhYWmC+++/n05YAAAAAAAAAPiftMcFv/fee3bcccdZ06ZNI+vAHnDAAfbVV1+le5cAAAAAAAAAULTS7oRt0aKFLVmyJOX35syZEy7SBaiDngu2/Yg8osjEIw+PPDzyiCITjzxQzGjfHnlEkYlHHh55eOQRRSYeecSnLJFIJNL5gXPOOSdciOvee++1tdZay7bYYgt74oknbIMNNggjZNddd1278cYbrdRUVlaGbUVFRa4PBQBKghZ7X906ROu072Tn7DwwtmOYMma8LZ25oM59WnRua+sN6hvbMQAovrqs0I8/380ac3O42FRdmnZexzoNOtNKAXkA+VFXAoWklF4zlRmsy9JeE/b888+3X/7yl7bffvtZ7969Q8/41VdfbZMnTzb1544cObLRBwUAyC+JqoSVlZdlfF8AAAAAAEpB2ssRdO/e3Z5++mk79thjQ6fr+uuvb4sWLbKBAweGEbHrrbdePEeKgvL999/bbbfdFrYgj1TIpLDyUKfqtLGTwsjPur60TyY6YPM9j2wjjygy8cgDxYz27ZFHFJl45OGRh0ce6WdSlaiq1/3Ud798RxuJT9ojYfVE7Lvvvnb22WfHc0QoCitWrAgvWG1BHqmQSeHlsXz2otVOvS+lPLKJPKLIxCMPFDPat0ceUWTikYdHHh55pJ9JeVm5PfT+azZ9wdxV3kfXth3sqK13sWJAG8mjTtg777wzrAPbs2fPeI4IAAAAAAAAyBPqgF3dGqhAxpcj6NWrV1j/FQAAAAAAAAAQw0jYPfbYI1x867XXXrNNN93UWrdu7b6vC3Wddtpp6d4tAAAAAAAAABSltDthb7311rB9/fXXw1dtdMJCOnbsaIcffnjYgjxSIROPPDzy8Mgjikw88kAxo3175BFFJh55eOSRXh66uJTWQK2PdPbNZ7QRjzzyqBP2448/judIUFRatmwZRkrjv8gjikw88vDIwyOPKDLxyAPFjPbtkUcUmXjk4ZFHennU5yJUxXYhKtqIRx7xie2UxcqVK22zzTazjz76KK6HQB5bsGBBWLJCW5BHKmTikYdHHh55RJGJRx4oZrRvjzyiyMQjD4880s8jeRGqur5W10lbSGgjHnnEJ9Zx44lEIs67Rx6bP3++vfLKK2EL8kiFTDzy8MjDI48oMvHIA9mUqErEsu+q0L498ogiE488PPLwyCOKTDzyyKPlCAAAAACUrrLyMps2dpItn72ozv2adWxt3QZslrXjAgAAyGd0wgIAAABIizpgl85kmiIAAEB9Ff5l7AAAAAAAAAAgj9EJi9iuprf55puHLcgjFTLxyMMjD488osjEIw+kkqiqimXfbKN9e+QRRSYeeXjk4ZFHFJl45BEfliNALDp27GiDBg3K9WHkDfKIIhOPPDzy8Mgjikw88kAqZeXlNnfsI7Zy9ow692vSsYt1GHCE5Svat0ceUWTikYdHHh55RJGJRx7xoRMWsVi5cqUtXLjQ2rRpY02aNLFSRx5RZOKRh0ceHnlEkYlHHlgVdcCumPmtFTLat0ceUWTikYdHHh55RJGJRx7xYTkCxGLGjBl24403hi3IIxUy8cjDIw+PPKLIxCMPFDPat0ceUWTikYdHHh55RJGJRx551Ak7bty40COeyrx58+z555//7x2Xl9shhxwShjEDAAAAAAAAQKlKuxP2mGOOsS+++CLl9yZOnGgXXXRR+HdZWZldddVVtvbaazf+KAGgxFUlqmLZF0Bp4D0EAAAAKIA1YS+88EKbOnVq+HcikbDhw4db27ZtI/t99dVX1rlz58wfJQCUuPKycnvo/dds+oK5de7XtW0HO2rrXbJ2XAAKA+8hAAAAQAF0wu677772pz/9yd2mztiatFjvNttsY0cddVRmjxAAEKjz5Nt5s3J9GAAKFO8hAAAAQJ53wu65557hS44++ugwErZnz55xHxsKWLdu3eziiy/mSnr/Qx5RZOKRh0ceHnlEkYlHHihmtG+PPKLIxCMPjzw88ogiE488ctwJW9MDDzxQ5/e//PJL22ijjRpzTCgCWhO4adO0m1fRylUeVVUJKy8vy/i+mUAb8cjDIw+PPKLIxCMPFDPat0ce6WWida61JEt9pLNvIbeRUsuE14xHHlFk4pFHfNJOde7cuXbjjTfa22+/bcuWLatelkDbRYsWhe9PmjQpjmNFAfnhhx/s2WeftYMOOsjWXHNNK3W5ykOdqi//6xObPW9Rnft1bN/a9u6/qWUTbcQjD488PPKIIhOPPFDMaN8eeaSXSSmuib26NlJqmfCa8cgjikw88sijTtgrr7zSnn/+edtll13CqNdWrVrZhhtuaOPHj7d58+bZZZddFs+RoqCog/7rr78OW+Q2D3XAzpy10Aopk1I7Oy+8Zjzy8Mgjikw88kAxo3175JF+JqW2JnZ92kgpZcJrxiOPKDLxyCOPOmFfe+01O+OMM2zIkCE2evToMCL2pptusoULF9rgwYPt888/j+dIAZSMUjs7DwAAAAAAilvaw8c02rVPnz7h37o414cffhj+3aZNGzvhhBPsH//4R+aPEqgnrWsax77IvuTZ+bq+VtdJC6A0aYR8HPsCAAAAQNZGwnbs2NHmz58f/q1lCLRWxJw5c2yNNdawrl272vTp0xt8MEAxr4EKAMgORtMDAAAAKPhO2J122snuuOMO6927t62//vrWoUMHe/LJJ+3444+3v//976GTFlC70CLO2mZbPq6Bmss88hWZeOThkYdHHulnUkpr3QltBMWM9u2RRxSZeOThkYdHHlFk4pFHHnXCDh061I455hi78MIL7cEHHwxrw15zzTWhY1ZLFZx22mnxHCkKSuvWrW3bbbfN9WHkDfKIIhOPPDzy8Mgjikw88kAxo3175BFFJh55eOThkUcUmXjkkUdrwq677rr2wgsv2LBhw8L/NQL2uuuuswMOOMCuvPJKO/300+M4ThSYRYsW2bvvvhu2II9UyMQjD488PPKIIhOPPFDMaN8eeUSRiUceHnl45BFFJh555FEn7IknnmgTJkwIyxEkaZjypZdeaoccckimjw8Fau7cufbss8+GLcgjFTLxyMMjD488Ci+TRBoXf0xn30LNA2gM2rdHHlFk4pGHRx4eeUSRiUceebQcgXrDy8rK4jkaWKKqysrKyzO+LwAAyJ6y8jKbNnaSLZ9d9wiCZh1bW7cBm2XtuAAAQHZUVSXChaMzvS+AEuqE3WWXXeyZZ56xvn37WrNmzeI5qhKmTtW5Yx+xlbNn1Llfk45drMOAI7J2XAAAID3qgF06c0GuDwMAAOSAOlVf/tcn4cLRdenYvrXt3X/TrB0XgALqhG3RokXohP3rX/9qPXv2DAv21qRRsvfdd18mj7HkqAN2xcxvc30YAAAAAACggdQBO3PWwlwfBoBC7YSdNm2a9enTp/r/iYRfx6z2/1GamjdvbhtssEHYgjxSIROPPDzy8Mgjikw88kAxK4T2rbWdtQxJpvct1DyyjUw88vDIwyOPKDLxyCOPOmEfeOCBeI4ERWXNNde04447LteHkTfII4pMPPLwyMMjjygy8cgDxawQ2nc214EuhDyyjUw88vDIwyOPKDLxyCM+aV/V6ZhjjrEvvvgi5fc+/vhjO+iggzJxXChwGhG9YsUKRkb/D3lEkYlHHh55eOQRRSYeeaCYFUr7Tq4DXdfX6jppiymPbCITjzw88siPPHTxsTj2zQTaiEcbyfFI2Hfeeac6/LffftvGjRtns2bNiuz397//3aZMmZL5o0TB0bIVd911l51yyinWvXt3K3XkEUUmHnl45OGRRxSZFF4e9Z2C3dip2ig+hdC+s4k8osjEIw+PPPIjj3y+UBltxKON5LgTdsyYMfb000+Hi27pa8SIEZF9kp20AwcOzPxRAgAKQpNWzawqUWXlZfWbaJHOvshv2VwPEYWpPtO1MzFVGwAA5CcuVIZSbyP16oQdNmyY/fznPw8drccee6xdcskl1qtXL7dPeXm5tW/f3jbeeOO4jhUAkOfKWzQNnar/+vxum7t4Wp37dmjVzfr3Oilrx1bM8qHjO5vrIaJwJadrAwAAlDJNp9fIz0zviyLohG3Xrp1tv/324d/333+/bbHFFtamTZu4jw0AUKDUATtr0X9yfRglQ52qD73/mk1fMLfO/bq27WBHbb1LbMdBBxsAAACweqUw9R4N7IStSZ2xWhe2efPmts0229h3331nl112mX377be233772WmnnZbuXQIAgEZSB+y386LrtQMACnPZHpbsAYDiVuxT75GBTtinnnrKLrroIjvhhBNCJ6yWJhg/frztvPPOdscdd1izZs3C4r0obV26dLGzzz6bEdMx5JGoqrKy8sIvyGkjHnl45OGRRxSZeOSBYlZM7bu+y/bUtWRPMeWRKWTikYdHHh55RJGJRx551Al777332iGHHGLnn3++ff/99/bvf//bzj33XDvxxBNt9OjR9thjj9EJC2vSpElYIxiZz0MdsHPHPmIrZ8+oc79m629q7XbYz/IVbcQjj+LNIxMXKyumPDKFTIozDy7uh2Ju35latqcY82gsMvHIwyMPjzyiyMQjjzzqhP3yyy/tt7/9bfj3q6++Gi7Wtddee4X/V1RU2E033ZT5o0REeat2eb2Q8+zZs23s2LE2YMAA69ixo5W6TOehDtgVM7+tc58ma6xl+Yw24pFH8eaRiYuVFVMemUImxZkHF/dDMbfvTCGPKDLxyMMjD488osjEI4/4pD10QL3hCxb896Ibr732mq299tq24YYbhv//5z//4QnKkrIWLasXcn78hQl1fmmfbF9Jb8mSJTZx4sSwBXmkQiYeeRR/HslRT3V9rarTqZjySI50rK9V7VtMmWRCseXRmNcLik+xte/GIo8oMsmPPDTwJ5P7ZQrtwyOPKDLxyCOPRsLusMMOduutt9rnn39uf/vb3+z4448Pt7/44ot28803W//+/eM4TqwCCzkDAAoJIx0BACjdq71zpXcApSztTtiLL744rAerjtiddtrJhgwZEm6/6qqrwqhYrQ8LAAAQ13qIAAoDa/wCpYdBQgCQwU7YTp062T333BO5/eGHHw6dsECx4Y8HAEBc6KRCMWPkOwAAQCM6YVeFDljU1K5dO9tzzz3DttBl4o+HYsojU8jEIw+PPDzyKN5MMtVJVSx5oDg1duQ77dsjjygy8cjDIw+PPKLIxCOPAuiEBWpq27at7bLLLlYsGvvHQ7HlkQlk4pGHRx4eeRR/JnzOAKtG+/bII4pMPPLwyMMjjygy8cgjPsxnQyx0Fb1PPvmEq+n9D3lEkYlHHh55eOQRRSYeeaCY0b498ogiE488PPLwyCOKTDzyKPFO2KqqKhs1alToid9mm23s5JNPtilTpqxy/9mzZ4cLhPXr18+23357GzFihC1evNjt89e//tUOOOAA22qrrezggw+2N954Iwu/SenQc/Doo4+GLcgjFTLxyMMjD488osjEIw8UM9q3Rx5RZOKRh0ceHnlEkYlHHiXeCXvbbbeFC39dfvnloSGoU/akk06yZcuWpdx/6NCh9vXXX9u9995rN998s7366qs2fPjw6u+/+eabdv7559vhhx9uTz75pO200052yimn2BdffJHF3woAAAAAAABAKWjQmrCTJ08OHZuLFi0KHaI1lZWV2WmnnZap4wsdraNHj7bzzjvPdt9993DbjTfeGEbFvvTSSzZw4EC3/4QJE+ztt9+2F154wXr27Bluu+yyy0Kn7TnnnGNdu3a1P/7xjzZgwAA75phjwvcvvPDC8HP33Xdf2BcAAAAAAAAActYJ+/TTT9tvfvMbSyQSKb+f6U7Yjz/+2BYuXBhGqya1b9/eNt98cxs3blykE/add96xtdZaq7oDVrQkgY5r/Pjxtt9++9m7774bfoeadthhh9CpCwAAAAAAAAA57YTV0gA/+clP7IorrrBu3bqFzs04TZs2LWy7d+/ubu/SpUv192qaPn16ZN/mzZvbGmusYVOnTrV58+aFEbw69vrcHxqmadOmoTNc28ZKVFVZWXlBrJyRlTyKBZl45OGRh0ceUWTikQcao7xVO6uqSlh5ebx1fUPRvj3yiCITjzw88vDII4pMPPKIT9qJfvfdd2F91dodnXFJXlBLHak1tWjRwubOnZty/9r7JvdfunRp9dXdUt2fvt8YGh2sDt6a1Emt+y5PoxOxSccuq92nvH2nsO3YvvVq903uo999VSOYax9zffZLSrVvmzZt7Ljjjgv/rp1J8jHqQ/u1bNnSFr4z1lYumFPnvs26rGetNt8ho5kkH79DK99pn0pyH7XB2veZ6Txy2UZ0DM1bNLfysvq16arESlu6ZFm9M9H9t2rVyrq27bDa+07uE0fbru++cecRZybp/I5qd806rr4tNW3fKmzjfM3kQxvJdibkUf82Qh6F3UYylYf+H/dAgbilqiuT6vO7pVMzNFlr7dAB+07lf2z+wrrr4a5rtrXNN+6eN+07rjoquU99P08z/Zov5Dziqrka8rdHPrz/xblvQ/4Wi7OuVHta3d8e+fa3aa7zyEUm5BFPGyGP/MykLI2/11f1t3om68qyRDrPjpn99Kc/DU/GoYceatnw4osvhgttvf/+++EJSTrzzDPDerG33367218X7/rggw9szJgx7nYtZzBkyBD72c9+ZjvuuKPdddddtttuu1V//6GHHrKRI0eGJQsaorKyMuWFwpo1a2abb7GFNW3SJOOjPtMZsZCoSlhZPfetSlTVu0Np5coV9tFHE2358uVWX4WWCXlkNxPyyF4m5FEcmZCHRx6Fn0mm8tAJ94qKCitEq6or030+c/1chvulfTc4E/KI4jOhONoIeeRvJuQRxedu6bSRlVmoK9MeCXvuueeGjs511lnHttlmmzDKM07JEbczZsyw9ddfv/p2/X/TTTeN7K9lBsaOHetuUxE7Z86csOSAliVo3bp1+Pma9H9dtKsx1Bh79eoVuX35smVW3yYd10g9dWBPGzvJls9OPaIiqdX6nazzDj3sX5/fbXMXT1vtGfr+vU6yjTfeOHIcWhbi0UcftcMPPzySq45HL9iH3n/Npi+IjmaufebkqK13iW1Ezuoy0YiGbgM2q/fjS6o2UCx5ZCuT+r5mksc9d+wjtnL2jLqPe/1Nrd0O+9nL//rEZs+r+3dcv3tH27HPhnmTRxyZpJOHzjTu3X/T2M6+5kMe+Z4JeRTWe0i+5VFomWQij88//9wK3arqyvrWDXHVDHHum091VPK1kOvXfCHmkU4dlfzb44Nvn7OFS2fVuW+bFp1sq3UGpv23R67f/xqSR5x/i8WViUZLdxhwRL1nGpJH7jIhj3jaCHnkZybN0vx7Pe66Mu1O2N///vf2ww8/VA9NThXGxIkTLVN69+5tbdu2tbfeequ6E1bruuoxBg8eHNm/X79+dv3119vXX39tG2ywQbjt7bffDtu+ffuG49t2223DbYMGDar+Od3/dttt16hj1X2rgzdfqXEunbmgzn2arfHfKVJ6wc5a9J963a+GotemF4Q6v7VdVSYqDL+dV3exVfP+cpVJJh6/2PLIVib1pTf0FTO/rXOfJmusFbYqlGfOWljnvmv8b6pgOvIpj/pkkk4eNY8xW7KdR75nQh6F9R5S8xizhTbiFfpSBPWpK+tbN2SzHcYll3VUPrbvfM8jWUfVp65s0qpZGKGkztX60L4N/dsj13Vlvv0tlulMaj52fZBH7jIhj9y/h9R83GLPI9eZZOIzOpN1ZdqdsFqOIJs05FedrepY7dSpUxiBe91114URr/vss4+tXLnSZs2aZe3atQuhbr311qGT9eyzzw5r12r9iksuucQOPvjg6h78448/3k455RTbfPPNbdddd7W//OUvNmnSpNDBDADLlq0I0xt0xizTUyEAAADwXysXL6/3tFlJZ1T580QAAQAASURBVF8AAPJN2p2wp59+umWb1oRdsWKFDRs2LAwh1mjXe+65J0zT+uabb2yvvfayq666KqxTqx7qW2+91UaMGGHHHntsWC5hv/32s4suuqj6/vr3729XXnml3XbbbXbjjTeG4cZ33HGH9ezZM+u/G5CUzsLWiNeiJcvT6lSlAxYAAJSC+lwwpX2bwh99DQBAXnTCytKlS+2TTz4Jw5OTaypUVVWFq3e+8847dt5552X0IJs0aWLnn39++Kpt3XXXDcdS05prrmmjRo2q8z41MlZfQD7Q1CqtyVXffRkFAAAAgGzSBVO09i0AAMhSJ6zWTj3zzDNt7tzUC723adMm452wKDydO3cOSz5ouyqlNPJzdXmU4jSs+rSRUkIeHnl45BFFJh55oJjlsn3XZ+RnffYphjzqe8XqXMhVJvk6MpjPBI88PPKIIhOPPPKoE1bT9zt27GiXX365PfPMM1ZeXh6WAfjnP/9pjzzyiP3xj3+M50hRULRURPfu3Vf5/VIb+bm6PEoRmXjk4ZGHRx5RZOKRB4pZrtp3OiM/tW+2Oil5vec+k8TSJXk9Mpg24pGHRx5RZOKRR3zS7tnS1H+tC7v33nvbHnvsYVOnTrXddtvNfve739lhhx1mt99+ezxHikZr1rG1tejcts6vpg24KnwqGin9/PPPr3LEdKmN/FxdHqWITDzy8MjDI48oMvHIA8UsV+07nU7VbI4S5fWe+0yqFs/P65HBtBGPPDzyiCITjzzik3bvltZ+7dq1a/j3BhtsYJ999ln19/bdd1+bOHFiZo8QGZG80vt6g/rW+dV5hx4ZebxFixaF9YG1BXmkQiYeeXjk4ZFHFJl45IFiRvv2yCOKTDzy8MjDI48oMvHII486Yddff/3qC2H16NEjXIzryy+/DP9fsWKFLVy4MPNHiUbj6u0AAAAAAABAgawJe9BBB9n1119viUTCBg8ebFtuuWVYH/boo4+2O+64w3r16hXPkSKrOrTqlpF9AAAAAJTmUmiZ2AcAgJLthD3ppJNs9uzZ9v7774dO2EsvvdROPvlkO/XUU61t27asCVsEdCGs/r1Oqve+xbBmKwAAAIDMLoVW332ZtQcAKAVpd8KWl5fbhRdeWP3/iooKGzt2bFiSYKONNgodsShsmbhoVps2bWzHHXcMW5BHKmTikYdHHvmTR8f2rTOyT6bRRjzyQDGjfRdeHul0qmaiA7YQMskm8vDIwyOPKDLxyCOPOmGTdJU0LdQ7Y8aMcEEudb7yBCGpffv2oV3gv8gjikw88vDII/d5JJYusaqqhO3df9N67a99s3mlaNqIRx4oZrRvjzyiyMQjD488PPKIIhOPPOLToHnkWnJgt912s9NOO80uu+wymzp1ql111VU2aNAgmzdvXuaPEgVn2bJlNmXKlLAFeaRCJh55eOSR+zyqFs9Pq1M1mx2wQhvxyAPFjPbtkUcUmXjk4ZGHRx5RZOKRRx51wj744IN2yy232PHHH2+PP/54uECXaH1YPUk333xzHMeJAvPDDz/Y6NGjwxbkkQqZeOThkYdHHlFk4pEHihnt2yOPKDLxyMMjD488osjEI4886oR94IEH7JRTTrEzzzzTtthii+rbNTL2rLPOsldeeSXTxwgAAAAAAAAApdMJ+91339n222+f8nu6MNfMmTMzcVwAAAAAAAAAUJqdsN27d7cJEyak/N6HH34Yvg8AAAAAAAAA+K+mlqbDDjssrAnbsmVL23333cNtixYtshdffNHuvPPOsFYsUF5ebq1btw5bkEcqZOKRh0ceHnlEkYlHHihmtG+PPKLIxCMPjzw88ogiE4888qgT9uSTT7ZvvvnGrr/++vAlxxxzTNgedNBBNmTIkMwfJQpO165d7fzzz8/1YeQN8ogiE488PPLwyCOKTDzyQDGjfXvkEUUmHnl45OGRRxSZeOSRR52wZWVldtlll4URr2+++abNnTvX2rVrZ/369bNNNtkknqMEAAAAAKAEdGjVLSP7ANnQpGOXjOwDlIK0O2GTevToEb6AVGbMmGGPPvqoHX744dalC2+45BFFJh55eOThkUcUmXjkgWJG+/bIo3gzqVq6wqoSVda/10n12z9RZeVl5UWbR6aQR3x5JKqqrMOAI+q9b1lM09sbe+KCNuKRR447YS+66KK0RspeeeWVjTkmFIGVK1fa7NmzwxbkkQqZeOThkYdHHlFk4pEHihnt2yOP4s1k5eLlKTtVV2VV+xZLHplCHvHlkU6nahwdsJk6cUEb8cgjx52wTz75ZOhc1boQq1uYV/sBQL7q2L51RvYBAAAAABT+iQsgrzph999/f/vHP/5hy5Yts/32288OPPBA69u3b/xHBwAZkli6xKqqErZ3/03rtb/2LS/npBKKE2t3AQAAAEAedsLeeOONtnjxYvv73/9uL7zwQrgoV+fOne2AAw4IHbKbbbZZ/EcKAI1QtXh+Wp2qdMCiWOXL2l2FitH0AAAAAGK9MFerVq1Cp6u+FixYYC+//HLokL333ntt3XXXtYEDB4YOWS7WBenUqZMdddRRYQvySIVMPPLwyCO+PHK9dlehtpF8H03PawbFjPbtkUcUmXjk4ZGHRx7Fn0ljL1RWbHkUZCdsTW3btrVDDjkkfM2ZMyd0yP71r3+1O+64wzbZZBN74oknMn+kKCgtWrSwXr165fow8gZ5RJGJRx4eeXjkkftM8n00PW0ExYz27ZFHFJl45OGRh0cexZtJpi5UVix55KNGD3FZunRpWKpgyZIl4cpp3377bWaODAVt/vz5YR1hbUEeqZCJRx4eeXjkEUUmHnmgmNG+PfKIIhOPPDzy8MijeDPJ1IXKiiWPoumEnT59ut133312xBFH2B577GGjRo2y9ddfP4yEff311zN/lCg4WrLi1VdfDVuQRypk4pGHRx4eecSbiS5C1rTzOnV+5fuFymgjKGa0b488osjEIw+PPDzyiCITjzzyYDkCdbz+3//9X/h67733whqx6oA96aSTbJdddrHmzZvHeJgAAACZx4XKAAAAAORNJ6xGvL7//vthXYjddtvNbr755rDV/wEAAApVsVyoDAAAAEARdMJOmDDBmjRpEhbmnTVrlj344IPhK5WysrKwVAEAZEt9pgnn+1RiAAAAAABQ4p2w/fr1q/53IpGoc9/VfR+loWXLllZRURG2II84MymWqcS0EY88PPKIIhOPPFDMaN8eeUSRSXHn0aFVt0btU2x5NBZ5RJGJRx457oR94IEHYjwEFKOOHTvaoYcemuvDyBvkEV8mxTKVmDbikYdHHlFk4pEHihnt2yOPKDIpzjyqlq6wqkSV9e91Uv32T1SlvNp7seSRKeQRRSYeecSn3hfmAtKxYsUKmzdvnrVv396aNs3fZtasY+tGfb/Y8sgmMvHIwyMPjzyiyMQjDxQz2rdHHvFmUgzLXBVLG1m5eHnKTtVVWdW+xZJHppBHFJl45BGf/B0WhoL2/fff2y233BK2+SpRlbBuAzaz9Qb1XeWXvq/9SiGPbCMTjzw88vDII4pMPPJAMaN9e+QRXybJZa46DTqzzi/to33zFW3EIw+PPKLIxCOP+NAJi5JVVl6W0f0AAAAAFK5iWeYKAJCf+OQAAAAAAAAAgBjRCQsAAAAAAAAAMWKFXQAAAKR90Zny9p2yciwAAABAMaATFrHo3r27XXrppbk+jLxBHlFk4pGHRx4eeUSRSXx5JC9MA+QLXu8eeUSRiUceHnl45BFFJh55xIdOWAAAAFTjYjMAADRutkh99mmMDq26ZWQfANlFJyxiMXPmTHv66aftZz/7mXXu3NlKHXlEkUm8eayu8Mv3acS0D488osjEIw8UM9q3Rx5RZOKRR3x5pDNbRPtm+sRm1dIVVpWosv69Tqrf/okqKy/zx0D7iCITjzziQycsYrF8+XL75ptvwhbkkQqZxJdHMUwlpn145BFFJh55oJjRvj3yKMxMmnVsnZF9iiWPbMpkHul0qsYxs2Tl4uWRTtW6pNqX9hFFJh55xIdOWAAoMkwlBgCgtHVt2yEj+yAzElUJ6zZgs3rvW1ZeFvsxAQCyj05YAAAAACgSmn581Na71HvfdEbVoWHS6VSlAxYAihedsAByMk0KAAAAmdfYqcoAACAedMIiFmussYYdcsghYYvCyCPb06QKIZNsIg+PPDzyiCITjzxQzGjfHnlEkYlHHh55eOQRRSYeecSHTljEolWrVrbVVlvl+jDyRiHkke1pUoWQSTaRh0ceHnlEkYlHHihmtG+PPKLIxCMPjzw88ogiE4884sP8E8Ri4cKF9vbbb4ctyCMVMvHIwyMPjzyiyMQjDxQz2rdHHlFk4pGHRx4eeUSRiUce8aETFrGYN2+e/fWvfw1bkEcqZOKRh0ceHnlEkYlHHihmtG+PPKLIxCMPjzw88ogiE4884kMnLAAAAAAAAADEiDVhAQBFr0nHLqvdp7x9p6wcCwAAAACg9NAJCwAoaomqKusw4IhcHwYAAAAAoITRCYtYNG/e3Hr27Bm2II9UyMQjj/jyKCsv/JV3aB9RZOKRB4oZ7dsjjygy8cjDIw+PPAozk2YdW2dkn2LJo1DRCYtYrLnmmjZ48OBcH0beII8oMvHIwyMPjzyiyMQjDxQz2rdHHlFk4pGHRx4eeRReJomqhHUbsFm99y0rLyvqPAoZnbCIRVVVlS1fvtyaNWtm5UUwCq2xyCOKTDzy8MjDI48oMvHIA8WM9u2RRxSZeOThkYdHHoWXSTqdqo3tgC2EPHIxOjhT8jdNFLTp06fb1VdfHbYgj1TIxCMPjzw88ogiE488UMxo3x55RJGJRx4eeXjkEUUmhZdH4n+jg9cb1LfOL+2jffMFI2EBAAAAAACQNwpxlCOKd3RwptAJCwAAAAAAgJJcAxXIFpYjAAAAAAAAQF4o1FGOwOrQCQsAAAAAAAAAMWI5AsSiS5cudt5551nLli1zfSh5gTyiyMQjD488PPKIIhOPPFDMaN8eeUSRiUceHnl45BFFJh55xIdOWMSiSZMm1qZNm1wfRt4gjygy8cjDIw+PPKLIxCMPFDPat0ceUWTikYdHHh55RJGJRx7xYTkCxGLWrFn2yCOPhC3IIxUy8cjDIw+PPKLIxCOP0tO1bQdbp32nVX7p+8WC9u2RRxSZeOThkYdHHlFk4pFHfBgJi1gsXbrUPv30U9t9991zfSh5gTyiyMQjD488PPKIIhOPPEpLVaLKjtp6l3rtV15WXhLtuz6dzsXSMc3rPYpMPPLwyMMjj3gzadKxS0b2ySXaSHzohAWAEtaxfeuM7AMAyJ76dqwWQwdsJjulk/uWSi4AgOxKVFVZhwFH1HvfsnI+j0oNnbAAUKKqqhK2d/9N671veXlZ7McEAEC60ulUpQMWABCXdDpV6YAtTQXxrGso9IgRI2ynnXayPn362LnnnrvatSm++eYbGzJkiG277bbWv39/u+mmm2zlypUp933uuedszz33jOnoASA/pdOpSgcsAAAAAABF3gk7fPhw+9e//mW33HKL3Xffffbll1/a0KFDV7n/8uXL7cQTTwz/fvTRR8PPa1HhP/zhD5F9x44da7/97W9jPf5S1K5dO9tnn33CFuSRCpl45OGRh0ceUWTikQeKGe3bI48oMvHIwyMPjzyiyMQjjxJejmD69On21FNP2R133GHbbbdduG3kyJG233772YQJE8LI2NpefPFF++677+zxxx+3Dh062CabbGI//PCDXXvttfarX/3KmjdvbgsWLLArrrgijILt2bOnzZ8/Pwe/XfFq27ZtGLmM/yKPKDLxyMMjD488osjEIw8UM9q3Rx5RZOKRh0ceHnlEkYlHHiU8Enb8+PFhu+OOO1bf1qNHD+vatauNGzcu5c+88847tsUWW4QO2CT9vDpeJ02aVL1cwdSpU23MmDE2YMCA2H+PUrN48WL76KOPwhbkkQqZeOThkYdHHlFk4pEHihnt2yOPKDLxyMMjD488osjEI48SHwnbsWNHa9Gihbu9S5cuNm3atJQ/o9u7desW2V/U8br11ltb7969w9IGySUJMiGRSNiiRYsycl+FTs/bn//8ZzvmmGNCh3mpI48oMvHII/d5lJWVWatWrdL6GRUmeu+PG+0jikw8XjOeHkPHV8ioK3/E690jjygyiSePON7nc/HZke/tI9uZ5HseuUAmhfMekguZrCtz3gmrEal77bXXKr9/5plnhuUDalOnrC7YlcqSJUusffv2kf1lVT+TCVqLNjnSttTNnTs3bCdPnrzai6iVAvKIIhOPPHKfhwqEzTffPK2f0fFl4wwx7SOKTDxeM1Gp6sdCQl35I17vHnlEkUk8ecTxPp+Lz458bx/ZziTf88gFMimc95BcyVRdmfNOWPWqv/DCC6v8/quvvmrLli2L3K7O1FX1qLds2TLyM8nO19atW1tcmjVrZr169Yrt/gvtzMlrr71WvXREqSOPKDLxyCP3eTTk7KaOL1sjYWkfHpl4vGa8zz//3AoddeWPeL175BFFJvHkEcf7fC4+O/K9fWQ7k3zPIxfIpHDeQ3Ihk3Vl03woMHVhrFX55JNPbM6cOaFTtWbP84wZM1bZGLQUwaeffupu0/4S5wtKDSzOTt5Coo7w5JZMyCMVMvHIozDzSHd6TbHnkU1kUph5ZOs1U+hLEQh1ZeG172whjygyyZ884nifb+x9FmP7aEwmxZhHY5FJcb+H5FNdmfNO2NXp27evVVVVhQt0Ja/OpuHJ6pnv169fyp/R7U899VS4EJeu6iZvvvmmtWnTJqwFi/g1bdo0dIZrC/JIhUw88vDIwyOPKDLxyAPFjPbtkUcUmXjk4ZGHRx5RZBJvHk06dsnIPsWgLJFv43xTOPfcc+29996zK6+8MvSKX3rppaFz9YEHHgjf1yhZrVnRoUOHMFpWSw8MHDjQNthgAzvvvPPCurMXX3yxHX300Xb66adH7v+WW26xJ5980l555ZUGH2NlZWXYVlRUNOI3BQDk2uMvTLCZsxbWuU/nTm3sFwf0ydoxAfksH18zhV6XFfrxAygus8bcbCtmflvnPk07r2OdBp1Z7/ucMma8LZ25oM59WnRua+sN6mulgkxQjBJVVVZWXp7xfQu1Lsu/3y6Fyy+/PIyCVQfqiSeeaBtttJGNGjWq+vsTJkyw/v37h23yIlx33313GEH7i1/8wkaMGGFHHnmknXrqqTn8LQAAAAAAAIDSkE6nalkedsBmWkH8hlqD4oorrrBx48aFrxtuuME6duxY/f0ddtghrB2rbZJGwY4ePdo++OCDsKDwmWeeaeWreELPOOOMRo2CRdTUqVPDc6YtyCMVMvHIwyMPjzyiyMQjDxQz2rdHHlFk4pGHRx4eeUSRiUce8WHBC8Rm5cqVuT6EvEIeUWTikUd+5NGxfeuM7JNptI8oMvHIA8WM9u2RRxSZeOThkYdHHlFk4pFHPOiEBQDgf6qqErZ3/03rvW95eeFfgR0AAAAAEL+CWI4AAIBsSKdTlQ5YAAAAAEB90QkLAAAAAAAAADEqSyQSiTgfoFRUVlaGbUVFRa4PJS8sX77cZs+eHS6g1qxZMyt15BFFJh55eOThkUcUmeRPHo+/MMFmzlpY5z6dO7WxXxzQJ2vHVOh1WaEff6bxevfII4pM4s1j1pibbcXMb+vcp2nndazToDPrfZ9Txoy3pTMX1LlPi85tbb1Bfa1U2ke2MimUPLKJTDzyiK8uY01YxEIv1C5duuT6MPIGeUSRiUceHnl45BFFJh55oJjRvj3yiCITjzw88vDII4pMPPKID8sRIBZz5syxZ555JmxBHqmQiUceHnl45BFFJh55oJjRvj3yiCITjzw88vDII4pMPPKID52wiMXixYttwoQJYQvySIVMPPLwyMMjjygy8cgDxYz27ZFHFJl45OGRh0ceUWTikUd86IQFAAAAAAAAgBjRCQsAAAAAAAAAMeLCXAAAAGiwju1bZ2QfAAAAoJjRCYtYtGnTxnbeeeewBXmkQiYeeXjk4ZFHFJnkRx5VVQnbu/+m9d63vLws9mNC8eH17pFHFJnEm0eTjl0ysk+u0D488ogiE4884lOWSCQSMd5/yaisrAzbioqKXB8KAABASSv0uqzQjx9A8UhUVVlZeXnG950yZrwtnbmgzn1adG5r6w3qa6WCTIDir8tYExaxWLp0qX311VdhC/JIhUw88vDIwyOPKDLxyAPFjPbtkUcUmcSXR307VdPdN5toHx55RJGJRx7xyc93SRS8WbNm2X333Re2II9UyMQjD488PPKIIhOPPFDMaN8eeUSRiUceHnl45BFFJh55xIdOWAAAAAAAAACIEZ2wAAAAAAAAABAjOmEBAAAAAAAAIEZ0wiIW5eXl1q5du7AFeaRCJh55eOThkUcUmXjkgWJG+/bII4pMPPLwyMMjjygy8cgjPmWJRCIR4/2XjMrKyrCtqKjI9aEAAACUtEKvywr9+AFgdaaMGW9LZy6oc58WndvaeoP6WqkgE6D46zK6tQEAAAAAAAAgRnTCIhbTp0+3kSNHhi3IIxUy8cjDIw+PPKLIxCMPFDPat0ceUWTikYdHHh55RJGJRx7xoRMWsaiqqrL58+eHLcgjFTLxyMMjD488osjEIw8UM9q3Rx5RZOKRh0ceHnlEkYlHHvGhExYAAAAAAAAAYkQnLAAAAAAAAADEiE5YAAAAAAAAAIhRWSKRSMT5AKWisrIybCsqKnJ9KHlh6dKlNnXqVOvevbu1aNHCSh15RJGJRx4eeXjkEUUmHnkUV11W6MefabRvjzyiyKTw8pgyZrwtnbmgzn1adG5r6w3qWxJ5ZDOTQskjm8jEI4/46rKmjb4HIAW9UDfccMNcH0beII8oMvHIwyMPjzyiyMQjDxQz2rdHHlFk4pGHRx4eeUSRiUce8WE5AsRi3rx5Nnbs2LAFeaRCJh55eOThkUcUmXjkgWJG+/bII4pMPPLwyMMjjygy8cgjPnTCIhYLFy60119/PWxBHqmQiUceHnl45BFFJh55oJjRvj3yiCITjzw88vDII4pMPPKID52wAAAAAAAAABAjOmEBAAAAAAAAIEZ0wgIAAAAAAABAjOiERSxatWplffr0CVuQRypk4pGHRx4eeUSRiUceKGa0b488osjEIw+PPDzyiCITjzziU5ZIJBIx3n/JqKysDNuKiopcHwoAAEBJK/S6rNCPHwBWZ8qY8bZ05oI692nRua2tN6ivlQoyAYq/LmMkLGKxfPlymzFjRtiCPFIhE488PPLwyCOKTDzyQDGjfXvkEUUmHnkUZh7NOrYOnax1fWmfUskjm8jEI4/40AmLWMycOdNuv/32sAV5pEImHnl45OGRRxSZeOSBYkb79sgjikw88ii8PBJVCes2YLMwyrWuL+2jfYs9j2wjE4884kMnLAAAAAAAQI6UlZfFsi+A/EInLAAAAAAAAADEiE5YAAAAAAAAAIgRnbCITZMmTXJ9CHmFPKLIxCMPjzw88ogiE488UMxo3x55RJGJRx4eeXjkEUUmHnnEoyyRSDRuVWcElZWVYVtRUZHrQwEAAChphV6XFfrxA8DqTBkz3pbOXFDnPi06tw0XowKAYqnLGAkLAAAAAAAAADGiExax+P777+3OO+8MW5BHKmTikYdHHh55RJGJRx4oZrRvjzyiyMQjD488PPKIIhOPPOJDJyxisWLFCps2bVrYgjxSIROPPDzy8Mgjikw88kAxo3175BFFJh55eOThkUcUmXjkER86YQEAAAAAAAAgRnTCAgAAAAAAAECM6IQFAAAAAAAAgBjRCYtYrLHGGnbYYYeFLcgjFTLxyMMjD488osjEIw8UM9q3Rx5RZOKRh0ceHnlEkYlHHvEpSyQSiRjvv2RUVlaGbUVFRa4PBQAAoKQVel1W6McPAKszZcx4WzpzQZ37tOjc1tYb1DdrxwQAcddljIRFLBYsWGBvvPFG2II8UiETjzw88vDII4pMPPJAMaN9e+QRRSYeeXjk4ZFHFJl45BEfOmERi/nz59tLL70UtiCPVMjEIw+PPDzyiCITjzxQzGjfHnlEkYlHHh55eOQRRSYeecSHTlgAAAAAAAAAiBGdsAAAAAAAAAAQIzphAQAAAAAAACBGdMIiFi1atLBNNtkkbEEeqZCJRx4eeXjkEUUmHnmgmNG+PfKIIhOPPDzy8Mgjikw88ohPWSKRSMR4/yWjsrIybCsqKnJ9KAAAACWt0OuyQj9+AFidKWPG29KZdV95vUXntrbeoL5ZOyYAiLsuYyQsYrFy5UpbuHBh2II8UiETjzw88vDII4pMPPJAMaN9e+QRRSYeeXjk4ZFHFJl45BEfOmERixkzZtj1118ftiCPVMjEIw+PPDzyiCITjzxQzGjfHnlEkYlHHh55eOQRRSYeecSHTlgAAAAAAAAAiBGdsAAAAAAAAAAQo6Zx3jkAAAAAAEBNzTq2zsg+AFBI6IQFAAAAAABZkahKWLcBm9V737LystiPCQCyoSyRSCSy8khFrrKyMmwrKipyfSh5oaqqypYvX27NmjWz8nJWvSCPKDLxyMMjD488osjEI4/iqssK/fgzjfbtkUcUmXjk4ZGHRx5RZOKRR3x1WUGkuXTpUhsxYoTttNNO1qdPHzv33HNt1qxZdf7MN998Y0OGDLFtt93W+vfvbzfddJOtXLmy+vtLliyxG264wfbcc89wn4ceeqj97W9/y8JvUxr0Qm3RogUv2P8hjygy8cjDIw+PPKLIxCMPFDPat0ceUWTikYdHHh55RJGJRx7xKYhEhw8fbv/617/slltusfvuu8++/PJLGzp06Cr3V4/9iSeeGP796KOPhp9/5JFH7A9/+EP1PldccYU9++yzdumll9pTTz1lAwYMsNNPP93eeuutrPxOxe6HH36wBx98MGxBHqmQiUceHnl45BFFJh55oJjRvj3yiCITjzw88vDII4pMPPIo4TVhp0+fHjpJ77jjDttuu+3CbSNHjrT99tvPJkyYEEax1vbiiy/ad999Z48//rh16NDBNtlkk9B4rr32WvvVr34VRsTqPq+88krbbbfdws+ceuqpoQP2L3/5i+2www5Z/z2LzbJly+yLL74IW5BHKmTikYdHHh55RJGJRx4oZrRvjzyiyMQjD488PPKIIhOPPEp4JOz48ePDdscdd6y+rUePHta1a1cbN25cyp955513bIsttggdsEn6+QULFtikSZOsrKwsdOruuuuu7uc01HrevHmx/S4AAAAAAAAASk9BjITt2LFjWI+ipi5duti0adNS/oxu79atW2R/mTp1qm299dZhndiaPvjgA3vzzTdt2LBhDT5WXeNs0aJFDf75YqI1d5NbMiGPVMjEIw+PPDzyiCITjzyiNZlOuhcy6sof0b498ogiE488PPLwyCOKTDzyiK+uzHknrC6gtddee63y+2eeeaY1b948crs6ZXXBrlTUUNq3bx/ZX1L9jNaYPe2002yrrbayX/ziF9ZQWotWI21hNnfu3LCdPHnyai+iVgrII4pMPPLwyMMjjygy8cgjKlX9WEioK39E+/bII4pMPPLwyMMjjygy8cgjvroy552wWlbghRdeWOX3X3311ZTrUKgztVWrVil/pmXLlpGfSXa+tm7d2t3+7rvvhvVgNXJWSxQ0a9asgb+JhZ/t1atXg3++mOhsiRpp7969I5mXIvKIIhOPPDzy8Mgjikw88vA+//xzK3TUlT+ifXvkEUUmHnl45OGRRxSZeOQRX11ZltC42jymDtrzzjvP3nvvPdfzrPVcjz76aDv55JMjPzN8+HD79NNP7eGHH66+7euvv7Z99tnHxowZE0a8yksvvRTuW8sT3HbbbdauXbsGH2dlZWXYVlRUNPg+AAAA0HiFXpcV+vEDAAAUi8oM1mV5f2Guvn37WlVVVfUFupJDorVWbL9+/VL+jG6fOHFiuBBXktZ7bdOmTejJl1deecXOPvts23333e2ee+5pVAcsohYvXhzW2dUW5JEKmXjk4ZGHRx5RZOKRB4oZ7dsjjygy8cjDIw+PPKLIxCOP+OR9J6yWKzjwwAPDBbPeeuut0BDOOecc23777W2bbbYJ+2jpge+//756CYIBAwbYWmutZWeddZZ9/PHHNnbsWBs5cqSdcMIJYTSt1re48MILbYsttrCLL744/F8/r685c+bk+DcuDsrxySefJM//IY8oMvHIwyMPjzyiyMQjDxQz2rdHHlFk4pGHRx4eeUSRiUceJdwJK5dffrnttNNOdvrpp9uJJ55oG220kY0aNar6+xMmTLD+/fuHbfIiXHfffXcYQasLbY0YMcKOPPLIsPar/POf/7R58+bZ+++/H5Y10M8mv84444yc/Z4AAAAAAAAAik/OL8xVH1oI+Iorrghfqeywww72ySefuNs22GADGz16dMr9DzrooPAFAAAAAAAAAHEriJGwAAAAAAAAAFCo6IRFLJo1a2brrrtu2II8UiETjzw88vDII4pMPPJAMaN9e+QRRSYeeXjk4ZFHFJl45BGfskQikYjx/ktGZWVl2FZUVOT6UAAAAEpaoddlhX78AAAAxaIyg3UZI2EBAAAAAAAAIEZ0wiIWU6dOtREjRoQtyCMVMvHIwyMPjzyiyMQjDxQz2rdHHlFk4pGHRx4eeUSRiUce8aETFgAAAAAAAABiRCcsAAAAAAAAAMSITlgAAAAAAAAAiBGdsAAAAAAAAAAQo7JEIpGI8wFKRWVlZdhWVFTk+lDywooVK2zevHnWvn17a9q0qZU68ogiE488PPLwyCOKTDzyKK66rNCPP9No3x55RJGJRx4eeXjkEUUmHnnEV5eRJmKhF2qnTp1yfRh5gzyiyMQjD488PPKIIhOPPFDMaN8eeUSRiUceHnl45BFFJh55xIflCBCL2bNn2xNPPBG2II9UyMQjD488PPKIIhOPPFDMaN8eeUSRiUceHnl45BFFJh55xIdOWMRiyZIlYci2tiCPVMjEIw+PPDzyiCITjzxQzGjfHnlEkYlHHh55eOQRRSYeecSHTlgAAAAAAAAAiBGdsAAAAAAAAAAQo7JEIpGI8wFKxbvvvmuKsnnz5rk+lLywcuXK6qvpNWnSxEodeUSRiUceHnl45BFFJh55eMuWLbOysjLbdtttrRBRV3q0b488osjEIw+PPDzyiCITjzziqyvphM2QCRMmhGK5WbNmuT4UAACAkrZ8+fJQLPfp08cKEXUlAABA8dWVdMICAAAAAAAAQIxYExYAAAAAAAAAYkQnLAAAAAAAAADEiE5YAAAAAAAAAIgRnbAAAAAAAAAAECM6YQEAAAAAAAAgRnTCAgAAAAAAAECM6IQFAAAAAAAAgBjRCQsAAAAAAAAAMaITFgAAAAAAAABiRCcsAAAAAAAAAMSITlgAAAAAAAAAiBGdsA3wzDPP2C9+8QvbZpttrE+fPvbzn//cHn300ZT7Pvfcc7bnnns26vEycR+1ffPNN7bpppvaW2+9lbVM9Fh6zPvvv79Bv8+SJUvshhtuCD+rxzj00EPtb3/7W0aOv+bxKZtstZEnnngiPGZD8li8eLFdfvnl1r9/f9t6663tqKOOsvfee8/ysY2sLo/kc7vzzjuHxxw4cGCjnts777zTjj76aMukTLaP+mZyyimnhMdsaHufM2eOXXLJJbbrrrvatttua0cccYS98847linJ9psJ9W0j2223nfXu3btBefzwww92/vnn24477hgeQ/l+8cUXVojvIcnXv/LQYzb29Z/vnzP1zWP77bcPj3nYYYelnUchfcbUN5PjjjsuPGZDPyMK6XMmV89DJlBXRlFXetSVHnVlFHWlR13pUVc2LJPTTjstPOZWW23VoEyK6XMmE22kkD5nYn0OEkjLmDFjEttss03Yfvnll4kvvvgicf/99ye22GKLxC233OL2ffnllxMVFRWJPfbYo8GPl4n7SGXFihWJGTNmJJYuXZq1TN58883EJptskthyyy0b9PtcfPHFid122y3xj3/8I/HVV18l/vCHPyR69+4d7jcTlIUyUTbZaiOXXXZZyKQheZxzzjmJffbZJ/HWW2+FPIYPHx4ed9q0aYl8aiP1ySP53N55550hj6uuuqrBz+2DDz4Yfnbw4MGJTMpU+0gnk379+oU8Gtrejz/++MTAgQMT48aNC48zYsSIxFZbbRUeLxMWL14cMmmsdNrIueeem9hll10alMcvf/nLxKBBgxLvv/9+4vPPP0+cccYZif79+ycWLVqUKLT3kOTr/7rrrgttpDGv/3z/nEknj3vvvTfkcd5556WdR6F8xqSTyU477VT9HtKQNlIonzPpSNYiU6ZMSeQD6soo6kqPutKjroyirvSoKz3qyoZnorahPNQuGpJJMX3OZKKNFMrnTNx1JZ2waTrkkEMSl19+eeR2NUZ9sMn8+fMTF154YWi0P/3pTxv0BpSJ+8i3TE444YTQQPfff/+0fx99mCmLp59+2t1+zDHHJM4///xEobaRzTbbrEHFst5gfvOb3yT+/e9/V982b968cF8vvPBCopDyqPnc1nwTS/e51Zv3kCFDwhv5fvvtl/FiOReZDBs2LOSRlE4m+mDTz77zzjvVt1VVVSUGDBiQuOmmmxKF2kZGjRpV/XpJJ485c+aED/5PPvmk+rZJkyaFjFQ8F1IeNV//f/nLX8Lv0JDXf6F8zqSTR/I9JPnc1jePQvqMSSeTa665pvo9JN02UkifM4XcCUtdGUVd6VFXetSVUdSVHnWlR13Z8Ezuueee6veQdDMpps+ZTLSRQvqcibuuZDmCNJWXl9uECRNs7ty57nZNP3jsscfCvzUUeerUqTZmzBgbMGBAgx4nE/fxwQcf2JFHHhmGk/fr18/OOOMM++6771IO1V65cqXdeOONYWi4hqAPHTrUfv/731dPvdF+m2++ub366qthSs+WW25p++23n40dO7Y6kylTptiwYcNsl112sS222CIc+0477RSGnevxZs2aFe5LU4PSVVZWZnfccUeY/lKTHnvevHn1vh8dv6YBaPi7ju03v/lN9XNZeyi5jvvSSy+1HXbYIUy5ufjii+3cc88NP5OcMrP33ntXb5WJ7ls/l2wjyvvss88OjzV69Ghr2rSpXXfddfaf//wnPL+nnnqqNUSTJk3sqquuCvcrCxYssLvuusvatGkTnr98aiM6tmQe+kq2EeUhl112md18882Nfm4/+ugja9asWZhKoee3IbLRPsaPH1/9mvnkk0+q24deM0899ZTts88+OjkW2nvtKVnpZNKxY8fQJioqKtzrSF/p5KpjOvDAA8P96HnTc75s2bLq37HmMeo1rt9H01SUy/XXX2/HHHOM3XLLLeH72mp6tI5Lz7fuc/DgwbZ8+fLqNvLpp5/akCFDQnv805/+ZC1btgxTTRv7+u/QoUOYDrTJJptUH+u9995r3bp1s169ehXUe8jIkSPD85B8/UtDXv+F8jmzuvcQZazpkTXz0PSpdPIopM+Y+ryH6PfRZ0SybTfkM6KQPmdUiyTVbCPKRMev/yvvfERdSV1JXUldKdSV1JXUlfnzOaM2qfdE3SYLFy5MO5Ni+pzJRBsppM+ZsTHXlXTCpumkk06yiRMnhheTCmQ1HDWEdu3aWY8ePcI+Wlfmvvvus80226zBj9PY+1CDS37gqHjQh4Ia529/+9uU++tDTcW+XrR/+ctfbK211rIHHnggcp8q9PRi1jov+tC58MILQyNWJvqQ/+tf/xredFX86LG05onuV79P8sXfEPrA1ItnjTXWqL5Nub/55pvhBVEf+nA8/fTTw/omL7zwgt166602btw4u/baa1Pur9/t9ddfDy9c/UE/f/58e/75590++qDR95TLk08+aa1atQpvqsk2ohez/q0s/u///i+0mbvvvjs8F3p+1157bWssvbn37dvX/vjHP4bnpnv37nnVRqZPn16dx/777x/e5M466yx78cUXwxvYs88+Gz4Aaz63H3/8cVrPrWitHRVj6623njVEttqHXgcnnnhiyORnP/uZvfHGG6Gd3HTTTeF2ffj/+9//Du29devWDW7v7du3t912282aN29efZsy//rrr+t9H3oe9Bzpw00/e+WVV9rTTz8d2nBtVVVVoT3p/vV9fWhrjZ+3337b7ae1w/QHg947H3744bCeln422UaU/4wZM8IfUWpDBx10UPjgX3PNNRv1+q/pd7/7XfgA1fOlD+KaORfKe8grr7wSfv7vf/972Kb7+i+kz5nVvYfoD7pkZ5WOQ5RpOnkU0mdMfd5Dku0jqSGfEYX0OaMs9QeSKB9lo/zVRi666CLXRvINdSV1ZU3UldSV1JX/RV0ZRV2Z3c+Zmn7605+mnUmxfc5koo0UyufMhXHXlWmNtUUwYcKExNlnn53Yfvvtw9BjfWlti5rTM5JqTnFoqIbch6ZIbLrppmEdo5UrV4bb/vOf/4RjFw2XTq5voqHyWs/nkUcecdNLNCw9OfUmOcxaa7zUnnLx7rvvhvvV/n379nWZHHDAAYmLLrrI3ccVV1zR6Ey0TonW3PnFL36RWLZsWb1+ZuLEieHxX3nllerbPv300/B71Dw+ZaOs9O9//vOf1fsuWbIksfPOO4dpFpIciq/7TVI+yccYOnRoyLV2G/nJT36SuPXWW919NCYPTQ/66KOPwnQBrTFT8/fLlzby2GOPhdfM1ltvHclDaynVbiNaxzCd57Y2PUfpThvLZvuYPn16WAvnZz/7WWK77bZzmWjKR+320ZD2Xtv48eMTffr0SZx++un1/hkdr9ba++CDD6pv07+1VlDN45M33nij+liTvv/++7AmlN7DRFu1ObW9JK3hqak6anennXZa5DWTvN8nn3yy+j6URWPy+OyzzxKVlZVhSowe78MPPyzY95Dkenfpvv4L7XOmvu8hmvKl711yySWNyiPfP2PSfQ9pyGdEoX3OqBaRBx54IPHxxx+740j1OZMvyxEIdeV/UVdSV1JXUldSV1JX5uPnjHJobCbF8jmTiTbyVYnXlU0b3n1bujSUWV86y6YzejoD++CDD9rJJ59sL7/8cjizlmuaIqHRFbr63KhRo8JVG3X2UmeMa9NVHHXlvprDwDV8Xmcn9PvVtNFGG1X/u23btmGrKR+6IvWf//znMHRbGVRWVoYzl8ooOU0jU959990w3UrTPXQWRVOF6kNn5XRm51e/+lU4C6Lpa7vvvnsYil+bznaIhrkntWjRIlwZsbaePXtW/1sjV0S/s86mKVdNffnHP/4RpjXpCoCaEqRcMmWDDTYIWw2lnzRpUni8PfbYI6/ayIYbbhiutrhixYpw9umll16yDz/8sDqP5M989tln1VOe0nluMyGb7SP5mnn88cfDWc1//vOfoX1oOqHahqZn1KQpF+m295r0ujzvvPPCtBSdEawvnaXV76grza+77rohk7322itM1UiVidpUzee/c+fO1SO5at6m/WpmojzUtnSGUWdiNdrhX//6V2hbxx57bNgv+ZrR2duZM2eGqSYNzSM5TUyjFd5///3w/q3pMYX4HqI8Rc9vOq//TMjH95CuXbuGrT6PNSWpIXkUwmdMuu8h+nxI9zOi0D5nlEny/VKjNTS646uvvrLPP/88tIWaP5NvqCv/i7ryv6grqSuFupK6snYeQl2Zm8+ZjTfeOOTQ0EyK6XMmE21kgxKvK1mOIA3Tpk2zESNGhG1yPQ81nF//+tdhKLSGLGt4eL7QC0MNRlN09MJRY9VQ9uS6O0la50O0z+rUnIKSlBwGrqHhmlaiP4L1JvOHP/whfF8fbJmiIktr/+iNUEWXiqp0aO0eTTnQi3f27Nl2/vnnh6k6qdYskfoUtTUzSa5PpmkvixYtCi9aTYvSG6bWVlHGNackNJTamqYHzJkzx92enKaVL23k+++/D9vk1CC9VjRNRW9+mopUs1DWc3v11VdXP0/pPreZEHf7SNIUscmTJ9vhhx8epk/pj4kzzzwzTMmQ5Lo2+oNCGtreRYWgstYHmz709WFcX9pX62bpQ+eXv/xl+OBREZBqyocyaUgeyTWN9L6q9nLwwQeHQlnTAC+44AK3r9qIpn+oPaabh16bmo6jP9iS9B6uwlmv10J6D1EBogKgsa//TMiH9xC9fr799tuM5JHvnzH1fQ/RVFx9RqgNNTSTQvmcSUr+gaBa5Iorrgj3d8ABB9idd94ZOgryEXUldWUq1JUedaVHXelRV0ZRVzb+c0a/t94Ta5/AKMbaMlttpFA+Z7JRV9IJmwY9OVpXJ7nmXO11cmqeGci1L7/8Mqx9odETRxxxRDhToLU8dEagds+/zkRozRKts1OTzuTVh86S3HPPPeGsq86e6IWhdVOSZ5BSNeqG0ItNbwQ6+6PHS561qS/9PnqTVXGWXMRd/9e6LCrmatLZUJ0pqZmJXtg6G1SX5FktnVHTB772V7GhRaB1Fku0Nkt93gzqojeEc845J7yR1aR1Zuq7GHw22kjyuddaVDrLVbONaN0qUfbJBcCTZ6qSZ6CyKRvtI0mjFG677TbXPvSm3qVLl/B9rc2j9v7II4+E/zekvYvWxtIHk85gav2rdF+LGo2lUQTqFNB6QMlj1fGnWgdKbVvtJ0mFgs4o1yX5Aan3Va3Dow9m/d4qhPbdd193dldtRH9Y6H023Tz0R7teM1orLUlnOHW/Nc8GF8J7iApCrUnUmNd/JuTLe4jamTqqGptHIXzG1Pc9RBc5UHvXqI6GZlIonzM11W4jqkXWX3/9MBqssZ+7caCuTI268kfUlR51ZWrUlT+irvSoKxv2OaPXjJ7f2msQF2Ntma02UiifM9moK1mOIA2dOnUKZyD0JKgnX1dO04e6zgrog09XodPVG/OBzrDo7JyGYOtDTmfmdNYxOa2j5hkIvclocWo1Yg1z1weHprOogWqY/uroCpf6cNOLXmdH9Zj6AFImNf+QaAyd1dQCyboinRZNrnkVYb1x1GcUgJ4rFQ/aX1OYli5dGj709eFb+4yUFuHXsHYVGlrIXbnorIfOqur3XJXkG6uG1OtFKnoT04tVU2H0fRUUtc/UpEv3o99BbVHTGnT/WmBbz5m2+dJGktODtBC2zn7rDJ1+Tlcq1RlIHYMKKi2or+dWRZ06U3RGTvvX97nNhGy0jySNVEgWwhqloMXgdUXK22+/vfr5VXtfZ511woi2hrR3jYjQh7Smq+gMXs2RQ/pAqk8RoMfSGWFlo+liOg4VLTWnuSTp/U9X7dQoA12gQI+hRc515ci6MlFnkagta1SFzsA+9NBD4fiUjdqe7kMdFWojemx9eCdHw9Q3DxVVWmxeZzL1pbap50zT1FTU1Ec+vYdoepIy0wUmRM91Oq//TMin9xDlozySz6U+f9LJo1A+Y+r7HqL70zEkO/dUtKb7GVEonzM16Q9p/QGuESOq2XT/Gqml94vGfu7GgboyNerKH1FXetSVqVFX/oi60qOubPjnjJ4TvdeIXjfKrRhry2y1kUL5nMlGXUknbJo07FmNXk+g3tDVAHQlUjV4fSDlCzVQfdBo+Loau676prPBenHpxVx7GLimrOjsna5YqQ8mfWjpw1Ev9NXRuj4arq4GqaHr+qNPRZHOYOoxX3vttUb/PjoDoQ81vWj0gVeTXkS1r3KXil54usqpzsDqzUwvWq0jopz079r0BqYP1eT0Jr3h6IO6Pmu46EyJziap4NObn974km88Gm5fe3RSQ2jqjt5wNJVRhZDe4FWAplpXKddtRFMmVBArO629oy/lobP0WotJz6+eW72+ZNCgQWk9t5mQzfZx/PHHW0VFRXg8TaPT86Y3eK3Zo1ELGuGh9q4v0ZU1k+qbic5W6vnSGkf6qumQQw6pnqJXl5/85CdhfSt9AOsqmyqAte7Oqq5Ird9HH/oqPtX2NZ1FnT/1yUSPo/dV7at1tPSaUfvWVENNFdP9qI0kz14mM0mnjWjUhtq7zkirmFDnht7H63s16Xx6D9GUIT0XyaJFZ5HTef1nQr68h6jI0pVsdQx6PYnOhqeTR6F9xqzuPUSfMXpcFd66iq1GiKX7GVFonzOi6YR6b1Muem2r6NboE70nJa/qm2+oK6OoK6OoKz3qSo+6Moq60qOuTP9zRp19OkGq72mNdmVRzLVlNtpIIX3OxFpX1vsSXihqL730UuKHH35wtx1//PHVV30rNbqSoK6SN3/+fHe7rhCYvDJgqaGN/Ij2EaW2oStb1rza59KlSxPbbLNN9RVoSwltJIr3kB/RPlKjjRQPnkuP13wUbeRHtI8o6kqPNhLFe4hHGymcNsJIWARao0RnVzTlQ2cRNKpIa43oTGUp0hpHOkOjs1RaQ0hnxnSWXWtMabpgKaKN/Ij2EaURFxoJoClxWqNHZx3VZpRV7bO/pYA2EsV7yI9oH6nRRooHz6XHaz6KNvIj2kcUdaVHG4niPcSjjRROGylTT2xOj6DEaEqF1q2oi9bK0XSNOO+jtm+++SYMtda6SZoKp8WRdbVKrfsTt0z8PjrWt956q877eOKJJ6xHjx5pLcSstYc01F5D3bWIvKY19evXz+JEG8n8c1tM7SNTv4/W/NH6RnXRY6Rz0QV9qOkKvZ988kmYIqMrR2pqixaKjxNtxOM9xOMzJoo2Ujx4LqN4zXu0EY+aIYq60qONeLyHRPE549FG0kMnbJZpYXitGVMXrd2jNe7ivI98konfR+uU6IVVF63PU5/1UHKNNpL557aY2kemfh+dFdWogrpowfT6XBAi12gjHu8hHp8xUbSR4sFzGcVr3qONeNQMUdSVHm3E4z0kis8ZjzaSHjphAQAAAAAAACBG0UuqAQAAAAAAAAAyhk5YAAAAAAAAAIgRnbAAAAAAAAAAECM6YQGgSGR6iW+WDAcAAChN1JUAkHl0wgJAnvv000/t7LPPtp133tm23HJL69+/v5111ln28ccfV+8zfvx4O+WUUzLyeMuWLbMrr7zSnn322YzcHwAAAPIDdSUA5A6dsACQxz777DP75S9/aXPmzLFhw4bZ6NGj7YILLrDvvvvOfvGLX9h7770X9hszZox98cUXGXnMGTNm2H333WcrVqzIyP0BAAAg96grASC3mub48QEAdfjTn/5kHTt2tD/+8Y/WtOmPb9kDBgyw/fbbz2677Ta76667cnqMAAAAyH/UlQCQW4yEBYA8NnPmzLCGVlVVlbu9devW9tvf/tb2339/+81vfmNPPvmkffvtt7bpppvaE088Yd988034t4ptFdVbb721/eUvfwk/O3bsWDvyyCOtT58+YRqavv/QQw+F7+nn9tprr/Dviy66yPbcc8/qx3znnXds8ODB4b623357u/DCC23WrFnuuCZMmGBHHXWUbbPNNrb77ruHkQ/HHXdcOEb5+c9/bocffnjk99Q+xx9/fAwJAgAAQKgrASC36IQFgDymglNTxFRgqqDV1LDkhQ1U5B5yyCF26qmn2m677WZrrbWWPfbYY+Fnkm655RY7+eST7dprrw1rf/3jH/+w0047zbbYYosw2kHfX2+99eyyyy6z999/37p06WK33npr+Nlf//rX1f8eN25cKGhbtmxpN910UyjU3377bTvmmGNsyZIlYR8dm/aRkSNH2hlnnBFGU2hdsaTDDjssFNRff/119W1Tp061t956yw499NAspQoAAFB6qCsBILdYjgAA8phGFnz//fd2zz33hIJWNI1MF1FQobrVVlvZ+uuvb506dbLmzZuHkQKyaNGisNWIBo0SSHruuedCgX3xxRdX36aRCzvssEMoWDUaYbPNNgu3634333zz8O8bbrjBevToYXfeeac1adIk3KZ9DzzwwDASQqMU9L127drZ3Xffba1atQr7bLTRRm6EwsCBA+3qq6+2p59+2oYOHRpu07/btGlje++9d+x5AgAAlCrqSgDILUbCAkCeO/PMM+21114LBavO+Ldt2zZcYVYXULj//vvr/Nlk4Zt00kknhWJ14cKF9uGHH9oLL7wQitzk1WtTWbx4cRjNoFERGi2hCyvoSyMdevbsaa+//nrY780337Rdd921ulBOFuLrrLNO9f9VTO+zzz72zDPPVN+mKW8HHHBAGA0BAACA+FBXAkDuMBIWAApAhw4dwtl+fcnEiRPt/PPPt+uuu84OOuigVf6c1viqSWttXXrppWH9rrKyMttggw1su+22C99LTkerbd68eWHtMF3EQV+1tWjRovq+11xzzcj3O3fu7P6vgl/FstYC0+iHr776yq655pp65QAAAIDGoa4EgNygExYA8tT06dPDlC+NWBg0aJD7nqZznX322WEdrilTptT7Ps877zz78ssv7d577w2jCTTVTCMSHn/88VX+jKZ0qbDWulyaJlZbcoRCt27dwgUfavvhhx/C9LEkXXxBU9L+7//+z8rLy8P3ktPdAAAAkHnUlQCQeyxHAAB5Smf6mzZtag8//LAtXbo08n0VvRotoFEHKjrrQxcz0LQtrdWlQln++c9/hm3ySrnJtbmSNE1Nxbker6Kiovpr4403Dhdg0Jpf0q9fvzC9reaxamSFroxbkwpvXSxBoyZeeeWVsJYYAAAA4kNdCQC5x0hYAMhTKlqHDx8eRiVo5IIuUqC1sjTCQOtl6aq2Gs2gKWXt27cPowVeffXVyHpdNemCC1r3S1ex1QiDd999N1xpVgWs7je5vpa88cYb4fF0oYRzzjnHTjnlFDv33HPtpz/9qa1cudJGjx4d1vTSVXTlV7/6VVgLTOuDnXDCCWG62c033xwKed1/TSqWVWjLz372sxhTBAAAAHUlAOReWWJVi7UAAPLCRx99FK5iq9EGWh9LIw00guDoo48Oow/k008/DYWzppDp6rC6IMFee+1lV111VShMk7799lu7/PLLw7pZsuGGG4ar4WotrTlz5tif//zncLsusvDYY49Zs2bNQmGurYrnW2+9NVx4Qf9XwX3GGWdUr/0lut9rr73WJk2aFNbxGjJkiN1+++3hOIcNG+Z+Lx2XRmWoWAcAAED8qCsBIHfohAUAZISKaRXRNYtnjVr4yU9+YhdccEEoymuuS7bHHnvYqFGjbMCAATk6YgAAAOQj6koAxYjlCAAAGRtZoeJXU8w0mkEjIP70pz+FaWjJq+9qJMPf/vY3e/HFF8NoiT333DPXhw0AAIA8Q10JoBjRCQsAyAit17Vs2TJ75JFHbOrUqda6detwxVpNXevUqVPYRxdXUAHdtWtXGzlyZL0v/AAAAIDSQV0JoBixHAEAAAAAAAAAxIhTRQAAAAAAAAAQIzphAQAAAAAAACBGdMICAAAAAAAAQIzohAUAAAAAAACAGNEJCwAAAAAAAAAxohMWAAAAAAAAAGJEJywAAAAAAAAAxIhOWAAAAAAAAACIEZ2wAAAAAAAAABAjOmEBAAAAAAAAIEZ0wgIAAAAAAABAjOiEBQAAAAAAAIAY0QkLAAAAAAAAADGiExYAAAAAAAAAYkQnLAAAAAAAAADEiE5YAAAAAAAAAIgRnbAA0ACJRCIv7ytflcLvCAAA0FjUmOkphd8RQPGgExZAxhx99NG26aab2uGHH77Kfc4+++ywz29+8xvLJ7Nnz7arrrrKBgwYYFtuuaVtv/32duyxx9rLL7/s9ps2bZqdcsop9u2332bkcceMGWPXXHON5dtzWPOrd+/etu2229qhhx5qTz/9dNr3OX78+JBZrt177722884721ZbbWW33XZbLI+xfPlye+ihh+yXv/xlaEN9+/YNuY0ePdoWL16c058BAKBQUWOmjxqzuGrMJ554IrR/5bX11lvbgQceaDfffLMtWLDA7Vc7Y33puLT/H//4R6uqqgod18ccc0xoj59++mnKx3v00UfDzz7yyCOx/D5AqWqa6wMAUFzKy8vtvffeC4Vkt27d3PcWLVpkf//73y3fLFmyxI466ihbuXJlKOQ22GADmz9/vv31r3+1008/3X7729+GYln+/e9/26uvvpqxx7799ttDMZ5PNt98c7v00kur/69c9HyqwLzgggtsjTXWsN122y2tPwK++OILyyUVqPpDZPfdd7cTTjjB1l133Yw/xty5c23IkCH28ccf25FHHhnaTllZmb3zzjvheX7yySdD8VvzdZGtnwEAoNBRY6aHGrN4asxbb73V7rjjjnD/v/71r61Zs2b24Ycf2t13322vvfZa6CjVbUmHHXaYDRo0qPr/OkH/0ksv2fXXX2/z5s2zc889137/+9/bT3/6Uxs2bFjocNXrK0nPyXXXXWe77LKLHXHEERn/fYBSRicsgIwXV59//rn93//9nx133HHueyqOW7VqZe3bt7d8omNVAffiiy/ahhtuWH27RiyoeB41apQNHjzYmjRpYqWgbdu2ts0220Ru33XXXW2nnXYKZ+LTKZDzgToudeZfz2m/fv1ieYzhw4eH0QQqhDfbbLPq2/v3728/+9nPQhF73nnn2QMPPBA6TbP5MwAAFDpqzMJHjZm+ZcuWhZPrJ554YhjtnfSTn/zENtpoIzvttNNs7Nixtv/++1d/TycpauesfL/88sswk2ro0KG23nrr2TnnnGNXXHGF3X///e41pY7ypk2bho5aAJnFcgQAMqp169aheFLRWdsLL7xg++67b/hQr0mFy1133WV77713mBajfdSBVJPOlGufgQMHhik1Kiw0JefNN9+s3ueWW24J9/GPf/zDDjrooOr7euqpp+o85pkzZ1YfR20acXjqqaeGAkiF4UUXXRRu32uvvaqnu+2555525ZVXhpEMOraLL7443K6RihrlsOOOO9oWW2wRziar0FHRnfw5TTnTyEVN9/nmm2/C7d99910oijR6QdONdL8TJ050xzVjxoxQiGkfFXyXXHKJ3XjjjeE+RWfkdSwabVGTpkhp6npDpqy3aNHCmjdv7jr2VvfcKSP9fvo99Tsqw7feeiv8W9va09T0lZQq1+TPvvHGG2E0gPLR9C+drVcbSUWPmcxFI0708zXbpKbA9enTJ9yPclQxXbtNaQSCslZHZ83vJ3311VfhvtReanaMJvXo0cPOPPNMGzduXHWbzdbPAABQDKgxqTFLscbUSFs9r6nakF4Peq7UoVofynHhwoXVj6MTANttt11Y1iC5DMZzzz0X2rmOt2vXrvW6XwD1RycsgIw74IADqqeL1Swg/vnPf4YCtzaN7NNIAE2J0VSb/fbbLxRGf/jDH6r30fQZFXdaA1NTby6//HKbM2dO6HCqWex9//33dtlll4V1jlS4aUrQhRdeWOdUJRWuKtpViKkQ0rFrzU1RYaYzzxpdoWlGmgIk2k+Fc5LOKldUVIRj1BQgFbCafqZju/rqq8MZbK3FpOJRZ5uT97HWWmuFAuqxxx6zLl262KxZs0Lh/9FHH9nvfvc7u+GGG0LRpftK/g4q1nWs7777bij4tM6YinGtB5qkY1i6dGnkDxWtt6XnR7/PqmidqBUrVlR/6X505lx/HKhw02jL+j53yki/n35P/Y7KMB21c03SSE8V+npMtSm1CU1JS0WPqaxFz5+OQ3Sf+kNEf2zpd9BIAo1UUZGe/CMm+QeLpgfqDxBl0KFDh8hjvPLKK2GrURCrotz1x8Xf/va3rP4MAADFghqTGrPUasxOnTqFDuF77rkntDeNetVzKVqC4Fe/+lXoXK2PyZMnW5s2bWzNNdcM/1e9qEzVDtSW1LGurUbVqk0ByDyWIwCQcSpIVIDVnC6miw/oA19FTe1i4PHHHw+FSnJhfZ0JVlFw5513hjUvO3bsWH1WvuZZbJ01P+OMM+yTTz6pnnKjglRTZzTlRjT1a4899ggFTs+ePVMer85aq/gZMWJEOCutr5YtW4YzwyrKktN7VAStv/764d8ahVhzzae11147FG1J//rXv8I+OrOsqVfJaUOvv/56ONOu31XT6nTWX/ebPP777rsvFP6aar7OOutUT9FSUav7UiH3zDPPhIL1L3/5S3XRpZEQNTvm9LvqzLsK4uSaUCqoNZJSxVVdNIpSoypq0vOxySabhGNQnvV97pSXfj/9nqmmn61O7VyTIxv0O6mgFT3XKkh11j7VBTv0+MlRozoeHYdGAGittF/84hfhTH+Sfkf9MaJstRX9kaCiV+1hVVRES13rgKmw1lfN0SjZ+BkAAIoFNSY1ZqnVmKLnRmvmauS1vpTDxhtvHEbSqtO8duetOlV138mOb43IfvbZZ8PJ/JNOOsmNONY6xWr/6nDXReSSHeAA4sFIWAAZp+JSU3NqniF//vnnQ6FZe41KTfVScaD9a54Z1/91dlxXPRWdrVeRoTO/ugCRChgVismz9jXVLMSSF27QBRvqss8++4QCS2e7NQVJBaYukHDWWWeFdZN0jHWpPTVcheKDDz4YinitX6ZRiSrIdPy1j7cmTYHSfWn6TzILLZSvIlnHk8xM045qnvVWEZ4sXJN+/vOfh6yS04s0ZUvT1VU410XF8Z///OfwpTP5Khr1h8ZNN90URiGk+9w1Rqop91L7d9DzvLrnuCaNRNHzUHvUjIpg/WHy9ttv1+s40qXnMtV0snz4GQAA8h01JjVmKdaYOgaNclZbV6etRgAre40K1ohVdYDXpGyVtb70XOrkhfbVaG+dXKhNo7v1e6uTXCcadIE0APFgJCyAWKgY1lpVmi6mIlGFn4rN2nRGXlY15WX69OlhW1lZGUYRaKsREL169QpnsKV28VpzGlTySp+rK3CTU3o0bUxfycfW+lqaPqTiuXYBWnudsprUATZy5Mgw1UmFW/fu3cO0M2VRF+Xx9ddfR0YJJGkUhs5SJ6cR1VT7No1s0BQjjVTQdDddiTc5mqAumqak6VlJmgKlqWD6w0FrX+msf/JY6/PcNUbtXGv+EVaTnuf6PMdJybWwOnfuHPmebqu9zpkyqUuyLWr06apGw2i6pDJL7putnwEAoJhQY1JjllKNWZPapr6Ul5a1UGZaIkPtQaNlkzQKV1+ikxN6DI2uVjtMRb+j1q2dMGFCwV0YDSg0dMICiIXOqusDXyMVVOTogz/VekXJq9hqilSqIkRFsDqVNHVGU7p0BlhXAlWxoOlfKl4bS9OLdPZe03Bq0kgBnQ1+6aWXwkiDugrk2rRW2L333huKeo2AaNeuXbi95ppTqWg/Lc6vKUepaMqVjqv2GW/54Ycf3P+Vp0YVqDDWSAMV6jXX2qovFYyaTqW10ZSHRozU97lLJTlSpfZITa0Flk4h2hjJaVuanqX2VJPWfKvvBQ6SNDJDF6pQe6y5jpvWWFMO+qNN0yX1O+u1kc2fAQCgmFBjUmOWUo2pDDTS+e9//7s7CaAOVY1sVVtVG6pJawDX7OwGkD9YjgBALFTIaf0oFbAq0FZ1Jju5BpLOvKtYSH5pSpXWhtKZcK1Npa2myujsb3LkgS7CII2ddq2pQSrkp0yZEvme1qQSFZiSfOzV0TQpHaumayWLY521//TTT93x1r4/Fcd6TBXsNfPQSANN3WrSpEnYRyMhJ02aVP1zWuT/tddeixyHCnI9pgo4rRfW0KucqtDW6A1dMTU5jao+z12q3zG5flnNi2po1EBdF7bINI28UBvV71OTptZp3dVtt902rfvTVDpdLVkXx6h5lWH90aURBfpjSX9YaPRJ8g+tbP0MAADFhBqTGrOUakw918pBF16rbeXKlaFtJdsQgPzHSFgAsdFUpSFDhoQCadiwYSn30cgDTUPSVVq1tpFGMqhA1EUMNLJBnU46u66iSlcp1RVm9aXCWwWj1LxybUNoMXotxq9iMrkmko5Z09J0NViNuEiOKkyemddoQ922qinhmham9Zg0WkHrh2n6ly4koDWiah6v7k+daSo69TO6yISKYW011UgXjHjhhRfCxQl01VTRGlO6X100QCMHdB9/+tOfwiiF2iMDdJEKFdu6f2XaGLpKrp4rTZ/T2l/1ee6Sv6NGA+hMvda90s9p6pzWptLzmrzIQl1X0800rXWlaXM6Bo0kUIel/uhQYa9i95BDDkn7Pi+99NJQ9OtiC7pghP4gOf7448NVl5MjYJRNzTXrsvUzAAAUE2pMasxSqTG1TICeFy05oAvF7bvvvmHZBtWCjz76aNhqTV0AhYFOWACxUeeQiiMVQ6sqJEUdRyqQkoWE1p1Sca31vXRWXmf5VWxee+21oSDUdCIVWroowcknnxzOLGuadkOpmFPBp2PQlUM1ylBrP+lqoVrnSkVzskNrhx12CL+XRhtqDTIVqqnoDwOdtdYi+irClIGmaSWLwXnz5oVsVARrTS09jopcnflXDrp/XZlUFx9QoakpWslpZvoD4Z577gm3aR/9X4Wqir7kqIqatBi/Rg7UvLJtQ2hKla4crD8adGXdwYMHr/a5k0MPPTQUxyrodQEKFaZat0q/t656q6louiCGRqOkOv646MIEemy1o8ceeyzkp9EYOvZVrRNWF7VTjUQdM2ZMuHKt7lMjUjTtTI+lUSWa8qj2dO6552b1ZwAAKCbUmNSYpVRjXnfddWGUsi4Yp5MOOnmgjlh10CqndJc4AJA7ZYl0VpkGAOTcZ5999v/s3Ql4VNX5x/E3CfsqqCyiIkIVwQiooBZwAxUVrfpXWxV3lKoVFbdaqYIrFkVF3AVxr+K+0IrUqmiVTaqpiIqiVWSVfQmQZP7Pe+iEvDlDyCRzM3PvfD/Pk+fC5Gbm5jdnZt6ce+45osWkzgNWdrSjFtC6euqYMWNKb9O3eL1MT1fS1VEGSC+9nE+fO/2DINN+BgAAZDdqTAAIFp2wABAyn332mZuIXy9FP+KII9x8UHo5ma6QqiMkDzzwQLfQhP5bL3f717/+5b7PWXIAAABsDTUmAASLTlgACCFd5EEvF9OFBvRtvFOnTnLRRRe50QiqqKjIXSKml6nrPF+6mBMAAABQEWpMAAgOnbAAAAAAAAAAEKDcIO8cAAAAAAAAALIdnbAAAAAAAAAAECA6YQEAAAAAAAAgQLWCvPNsMmvWLDdxee3atdN9KAAAAFlt06ZNkpOTI926dZMwoq4EAACIXl0ZipGwuvLi6NGjpXfv3tK1a1e54IIL5Mcff9zq/suXL5crr7xSunfvLj169JDhw4fL+vXrS79fXFzs7u+www6TffbZR0466SR57733qnWMWiizxtkWmkVhYSGZ/A95+MjEIg+LPCzy8JGJRR7RqsvCfvypRvu2yMNHJhZ5WORhkYePTCzyCK4uC8VI2AceeECeffZZGTFihLRq1UpGjhwpAwcOlDfeeEPq1Knj7T948GDX6Tp+/HhZtWqVXH/99bJu3Tq544473PfvvfdemTBhgtx+++3Svn17efPNN+Xiiy+WF154Qfbee+8qHWN8pEJ+fn41f9toWLBggTzyyCNy4YUXSuvWrSXbkYePTCzysMjDIg8fmVjkYRUUFEiYUVdatG+LPHxkYpGHRR4WefjIxCKP4OrKjB8Ju3HjRhk3bpzrWD300EOlY8eOcvfdd8vChQtl0qRJCS/fmjZtmutw7dy5sxx00EFy0003yWuvvSaLFi0qHUqsHbN6f7vssotcdNFF0rBhQ/nkk0/S8BsCAAAAAAAAiLKM74SdM2eOrF271nWmxjVp0kQ6deok06dP9/afMWOG7Ljjjm6Ea5xOSaDzN8ycOdP9/9prr5X+/fu7f+sQ66eeesqNnD3ggANq5HcCAAAAAAAAkD0yfjoCHfGqyg+BbtGiRen3ytLRruX31SkLtttuOzekuqzXX39drrnmGje3w6WXXsolXwAAAAAAAACyrxM2vqBW+blf69atKytXrky4f6J5YnX/DRs2mNt04a5XX31VPvroIxk1apQ0b95cTj/99Cofq3bm6tyz2JzFXnvtRSb/Qx4+MrHIwyIPizx8ZGKRh6U56FVQYcZzuQXt2yIPH5lY5GGRh0UePjKxyCO4ujInluHLnb399ttuPtjPPvtM6tWrV3r7ZZdd5uaLffDBB83+N998s3z++edu4a2ydDqDQYMGyTnnnJPwcW644QbXGfuPf/yjyhP16vEAAAAg/fSkfFivcqKuBAAAiF5dmfEjYeNTCyxevFh23XXX0tv1/3vuuae3f6tWrWTy5MnmNi1iV6xY4aYwKCoqkvfee8/NKbvTTjuV7qP39fLLL1d7JdsOHTpUuE9xcbE7hqjT31Pn8tUFz/Ly8iRMatWqlfJj1ud89erV0rhxY3f/IJPyyMMiD4s8fGRikYc1d+5cCTvqyi2oKy1e7z4yscjDIg+LPHxkYpFHcHVlxqfZsWNHadSokUydOrW0E3bVqlUye/ZsGTBggLe/TjFw5513yg8//CBt27Z1t02bNs1t99tvP1cE/fnPf5aTTz5ZrrzyytKf05G22yp0t0WHJzdo0CDh93TAsc5hq53B2UCL5fiLNmzFstI5hLVDP1VDznU+4scee0wuvPBCb87ibEUmFnlY5GGRh49MLPKwwj4VgaKu3IK60uL17iMTizws8rDIw0cmFnkEV1fWCsOQX+1s1Y5VnbO1TZs2MnLkSFfIHHnkka4oW7ZsmSvKdLqCLl26yL777itXXHGFDBs2zM1foVMNnHDCCdKyZUt3n+edd56MGTNG9thjDzeceNKkSfLmm2/KfffdF9jvES+UdTSuFtRR+OOgIvHRx1p0JpqjN1PF5zzRkdaKNxwAAJBpqCvDgboSAACEqhNW6ZywOhx66NChUlhY6Ea7jh071l2m9dNPP0mfPn3k9ttvl5NOOskVodrBOnz4cDn77LPdglz9+vWT6667rvT+zj//fPez2umqPfy77767jB492t1PELSjOF4ob7/99pINcnNz3bB17RgPU7Gs6tev77ZaMOtzFsYRFwAAIJqoK6krAQBAOIWiE1aLlauvvtp9lbfzzjvLV199ZW7TglQ7VSsq5HSBrq0t0pVqmzZtctutXVKGzBN/rvS5o1gGAACZgroyfKgrAQCAyiWGmhP1S8WihOcKAABkMmqV8OC5AgAAKiemkxWh2goKCtxW55gtT6dQmDdvnrRr185dRoXMx3MGAEA067IwoK6MFp4zAADCK5V1ZSimI4i6M888U6ZNm2Zu0zlrd9hhBznssMPk8ssvl6ZNm2bMscVX691tt93cvLu/+c1vUv64Ol+vzu1bfqoJAAAAbB11pY+6EgAAZAI6YTNEp06d5MYbbyz9v84Z9cUXX8ioUaPkyy+/lOeeey5tlzKVPzZdEEJX5R0/frxcc801bqXaQw45xPyMHn98FVst/JN1yimnSO/evSUqli5dKq+99pr7w0L/CAKZlEceFnlY5OEjE4s8UBZ1pUVdGX1kYpGHRR4WefjIxCKP4NAJmyEaNWokXbt2Nbd1795d1q5d6xYZ++yzz7zvp/PY1MEHHywHHXSQvPzyy16xrLNcaMFc1dkuWrVq5b6iQrP46aefShfTAJmURx4WeVjk4SMTizxQFnWlRV0ZfWRikYdFHhZ5+MjEIo/gsDBXhtt7773d9ueffy69jOuqq66SwYMHuwL23HPPdbdv2LBB/vKXv7iiVX/muOOOk4kTJ5bez5///Gfp2bOnG21Q1q233ioHHHBAlV5cdevWlTp16piRFCUlJfLII4/IMcccI0ceeaT0799fnnrqKe9nx44dK3369JF99tlHfve738m7774re+65p0ydOrX0sjH9f5z+3jfccIM88MADbiRDly5d5IILLnBnaF566SU54ogjpFu3bnLOOee4N4uyJk+eLCeddJKbv0MzuOWWW2TdunVJ/74AAABhRl25GXUlAABIB0bCZjidxF/tsssupbf97W9/k+OPP14efPBBV5zqqIBLLrlEPv30U1dEt2/fXt555x254oorZOPGjXLCCSe4YeQvvPCCK0Z//etfu/vRn9X7OvbYYyu8tEvvv6ioqPT/WnDPnz9f7r//fjeiouzcXcOGDXMjGAYOHOgWH/jmm2/ktttuk1WrVrljVDonl/7s+eefLwceeKBMmTLFzU+2LW+++aZ07tzZFfh62dpNN90kAwYMcEX7tddeK+vXr3cFtd6uBbt644033B8X+seDPoYe99133y1z586Vxx9/nNVqAQBA1qCu3IK6EgAA1DQ6YTNE+YJ05cqVbuECLYj1THx85ILSwnb48OFutID66KOPXMGpRaCOFFB6Vl+LxzvvvNONGthvv/2kTZs2ruCMF8taOC9ZsmSbCyBMnz7dFallaZG5xx57yL333usWeYgX9lqQDxkyxI0c0NEERx99tNSqVUsefvhhOf30011h++ijj8oZZ5zhiljVq1cvd6zPP/98hceh+WihHV9MYtKkSe731hEJ8T8m/v3vf7u5S+KZ6u+vWeg2Thd+0ON7//335dBDD63EswMAABAe1JXUlQAAIPMwHUGGiBek8S8taLXo1CL5rrvuMmfWd99999JCWX388cfu+3rJmBaU8a/DDz/cFcM6akC/r6MctLDUUQzqrbfecoWjXoJVET2eF1980X3pZVtaJOvP3XPPPdKvX7/S/T755BNXoOrjxuf8Uvp/vaxt5syZrpgtLCw0P6e0oN8WHYlRdjVfnSC6WbNmZjSHLtiwevVq9+/vvvvOjWzQxy+bi86Jpsemf2TUFD2uE0880W2xGZlY5GGRh0UePjKxyANlUVdSV2YbMrHIwyIPizx8ZGKRR3AYCZshtCDVUQhKC1s9s9+6devSgrOshg0bmv/rarFapO67774J73vx4sWy1157uZEJOgJCz/LrWXw943/22Wdv89j08XTeqzgtrrXwPu+889wlYs2bNy89DqWXoSWyaNGi0mI3/jNx22+//TaPI1EWDRo02Or+8ePRXOPZls+lptSvX9/NU4YtyMQiD4s8LPLwkYlFHiiLupK6MtuQiUUeFnlY5OEjE4s8gkMnbIYoX5Amo3Hjxq5ofPLJJxN+v23btm6rc2npC0nn68rNzXXzaWnRmywdKaBzZF122WVuHi0dUaGaNGnitk888YR70erICB1ZoY+ldtppp9K5yH755Rc38iJu2bJlkmrx47nmmmukR48e3vfLjn4Ims5x9sUXX7g/isr/sZOtyMQiD4s8LPLwkYlFHiiLupK6MtuQiUUeFnlY5OEjE4s8gsN0BBGghaCuyqqjFrTgjn99/fXXbqGCsnOC6agFHbGgl4zpCIeyl1wlQy/70lEPOheYzjGm9t9/f7ddvny5GyGhc4XpVgthneNLRxB07NjRFfe6wENZOnoi1bQY15EQuqpt2VxatmzpCvzZs2dLTdE/TPSPFN1iMzKxyMMiD4s8fGRikQdShboyMerKzEYmFnlY5GGRh49MLPIIDiNhI0Dn7NL5qC6++GL3pXNcff755zJ69GhX0Ja9REsXWBgxYoRMnDhRbrzxxmo97p/+9Cc34uGWW26RV155Rfbcc0/3/z//+c/y3//+V3beeWdXOOtx6L91vq+8vDy3wq3epqMatNDXYvu5555z9xkf3ZAK+li6kq+OrtB/60IP+iai84/pJWzlF4UAAADIdtSViVFXAgCA6qITNgK0wHzkkUfcqABdLVYvydKz8ueee65ccsklZl8tnHXVWF08oPwiBlUZEXDmmWfKuHHjXLE7YMAAuf32290x6Gq2uniBjhjQAv3yyy93BasaNGiQG12hq9aOHTvWzQWmK9rqz1Y0F1dVnHLKKW74/GOPPeYeT+9fR2roqrZVHa0BAAAQVdSVW0ddCQAAqoNO2Azw1FNPVXtfLQKvu+4697UtDz30UMqO7dprr3VfcbVq1XIF+gUXXCBLly5183yVXXFXL2HTS81OOOEEueiii0pvf+aZZ1zRHy9gL730UvdV0XHoyIvyyv+c0mJdvwAAAKKOupK6EgAAZCY6YREILXx1Jd7yl4FpMf3oo4+6RRa0WG7WrJmbY+yee+5xBXR80YOo0T8Y9HK+sn84ZDsyscjDIg+LPHxkYpEHooy60uL17iMTizws8rDIw0cmFnkEJyem1++g2goKCtw20Uq0hYWFbvVWXUW2Xr16ku1+/PFHGTVqlEydOtXNpaWr2+qcX3o5We3atSUT8JwBABDNuiwMqCsrj7oSAACEpa5kJCwCoX37+pWTk+O+ytJLw+6++27JJiUlJbJp0yb3x0AqF4kIMzKxyMMiD4s8fGRikQeijLrS4vXuIxOLPCzysMjDRyYWeQSHNBEIfcHqAgq6hbhVc3WuMd1iMzKxyMMiD4s8fGRikQeijLrS4vXuIxOLPCzysMjDRyYWeQSHTlgAAAAAAAAACBCdsAAAAAAAAAAQIDphAQAAAAAAACBAdMICAAAAAAAAQIByYrrUKKqtoKDAbfPz873vFRYWyrx586Rdu3ZSr149yQbarHRFPV1Jr/wqtmGQ6uesuLjY3afeV15eXkqOMezIxCIPizws8vCRiUUela/LwoC60qKutHi9+8jEIg+LPCzy8JGJRR7B1ZW1qn0PQAJaIPNi3UKzaNiwYboPI6OQiUUeFnlY5OEjE4s8EGXUlRavdx+ZWORhkYdFHj4yscgjOExHEGElsZK0Pvby5culqKio8j9TUiKjR4+W3r17S9euXeWCCy6QH3/8UaJg2bJl8txzz7ktNiMTizws8rDIw0cmFnkgaNSVmYPXu49MLPKwyMMiDx+ZWOQRHEbCRlhuTq4889kUWbRmZY0+bstGTeWMLr1doawFcGU98MAD8uyzz8qIESOkVatWMnLkSBk4cKC88cYbUqdOHQmzDRs2yNdffy2HHnpoug8lY5CJRR4WeVjk4SMTizwQNOrKzMHr3UcmFnlY5GGRh49MLPIIDp2wEaeF8vxVmX/2YuPGjTJu3Di56qqrSl/od999txu9MGnSJOnfv3+6DxEAACCrUVcCAABUHdMRICPMmTNH1q5dKwcddFDpbU2aNJFOnTrJ9OnT03psAAAACA/qSgAAkInohEVGWLhwodu2bt3a3N6iRYvS7wEAAADbQl0JAAAyEZ2wCIyuplfZlWzXr1/vtuXn6Kpbt66bjyTsGjduLEceeaTbYjMyscjDIg+LPHxkYpEHoo66cgte7z4yscjDIg+LPHxkYpFHcJgTFoFp0KBBpfetV69e6Rxe8X8rLZTr168vYdeoUSNzSRzIpDzysMjDIg8fmVjkgaijrtyC17uPTCzysMjDIg8fmVjkERxGwiIwhYWFlV7FNn652OLFi83t+v+WLVtK2OmIjC+++KJ0ZAbIpDzysMjDIg8fmVjkgaijrtyC17uPTCzysMjDIg8fmVjkERw6YRGY1atXS1FRUaX27dixozvbMnXq1NLbVq1aJbNnz5bu3btL2K1YsUJefPFFt8VmZGKRh0UeFnn4yMQiD0QddeUWvN59ZGKRh0UeFnn4yMQij+AwHQEygs7ZNWDAALnzzjulefPm0qZNGxk5cqS0atXKzUUCAAAAVAZ1JQAAyER0wkZcy0ZNQ/OYgwcPdiMchg4d6i4505EKY8eOldq1a6f8GAEAAJAc6koAAICqoxM2wkpiJXJGl95pe+zKztsVpyveXn311e4LAAAAmYO6EgAAoHqYEzbCcnPS9/QWFxVLbm6u5OTkpO0YMkmtWrXcJXC6xWZkYpGHRR4WefjIxCIPBI26MnPweveRiUUeFnlY5OEjE4s8gpMTi8ViAd5/1igoKHDb/Px873t6CdS8efOkXbt2Uq9evTQcHZLFcwYAQDTrsjCgrowWnjMAAMIrlXUlI2EBAAAAAAAAIEB0wiIQGzdulJ9//tltIbJgwQK55ZZb3BabkYlFHhZ5WOThIxOLPBBl1JUWr3cfmVjkYZGHRR4+MrHIIzh0wgI1pLi4ON2HkHHIxCIPizws8vCRiUUeQPbg9e4jE4s8LPKwyMNHJhZ5BINOWAAAAAAAAAAIEJ2wAAAAAAAAABAgOmEBAAAAAAAAIEA5sVgsFuQDZIuCggK3zc/P975XWFgo8+bNk3bt2km9evUkG5SUlLg5RPLy8iQ3N3x9/al+zjZt2iTLly+XZs2aSe3atVNyjGFHJhZ5WORhkYePTCzyqHxdFgbUlRZ1pcXr3UcmFnlY5GGRh49MLPIIrq4MXxWDUNACWV+sVS2UH374YTnzzDMlKjSLFi1a8AZWBplY5GGRh0UePjKxyANRRl1p8Xr3kYlFHhZ5WOThIxOLPIJDJ2yExUpK0vrYK1eulKKioqR/9plnnpF77rlHomTFihXy+uuvuy02IxOLPCzysMjDRyYWeSBo1JWZg9e7j0ws8rDIwyIPH5lY5BGcWgHeN9IsJzdXVk5+ToqXL67Rx81r1kKa9j1NNm7cKPXr16/0zy1atEhuvPFGmTp1quy2224SJevXr5dZs2ZJ9+7dZbvttkv34WQEMrHIwyIPizx8ZGKRB4JGXZk5eL37yMQiD4s8LPLwkYlFHsGhEzbitFAuWjpfwuCLL75ww931jMv9998v8+eH47gBAACyAXUlAABA1dEJi4xx+OGHuy8AAACgOqgrAQBApmFOWAAAAAAAAAAIEJ2wCIzO25WXl5fuw8gIDRs2lJ49e7otNiMTizws8rDIw0cmFnkg6qgrt+D17iMTizws8rDIw0cmFnkEh+kIEJhGjRql+xAyRpMmTaRv377pPoyMQiYWeVjkYZGHj0ws8kDUUVduwevdRyYWeVjkYZGHj0ws8ggOI2ERGF3FtqSkJN2HkRE2bNgg33//vdtiMzKxyMMiD4s8fGRikQeijrpyC17vPjKxyMMiD4s8fGRikUdw6IRFYFauXClFRUXpPoyMsGzZMnniiSfcFpuRiUUeFnlY5OEjE4s8EHXUlVvweveRiUUeFnlY5OEjE4s8gsN0BBGX16xFVjwmAAAAgkVdCQAAUHV0wkZYrKREmvY9LW2PXZ1LxkaMGJHS4wEAAEDVUVcCAABUD9MRRFhObvqe3k1FRVJcXJy2xwcAAEDqUFcCAABUD52wCEROTo7k5ua6LcRl0bhxY7fFZmRikYdFHhZ5+MjEIg9EGXWlxevdRyYWeVjkYZGHj0ws8ghOTiwWiwV4/1mjoKDAbfPz873vFRYWyrx586Rdu3ZSr169NBwdksVzBgBANOuyMKCujBaeMwAAwiuVdSXd2gAAAAAAAAAQIDphEYhNmzbJwoUL3RYiixYtklGjRrktNiMTizws8rDIw0cmFnkgyqgrLV7vPjKxyMMiD4s8fGRikUdw6IRFIHSWC13FltkuNtMsVq9eXa2VfaOGTCzysMjDIg8fmVjkgSijrrR4vfvIxCIPizws8vCRiUUeWd4Jq0/86NGjpXfv3tK1a1e54IIL5Mcff9zq/suXL5crr7xSunfvLj169JDhw4fL+vXrzf099thjctRRR7n7O/bYY2XChAk19NsAAAAAAAAAyCah6IR94IEH5Nlnn5Wbb75Z/vrXv7pO1IEDB8rGjRsT7j948GD54YcfZPz48XLvvffK+++/L8OGDSv9/sMPP+y+LrvsMnn99dflrLPOct9/9dVXa/C3AgAAqBklsZJA9gUAAABQObUkw2lH67hx4+Sqq66SQw891N129913u1GxkyZNkv79+5v9Z82aJdOmTZOJEydK+/bt3W033XST67QdMmSItGzZUp577jk577zz5JhjjnHf33XXXeWzzz5zo2FPOOGENPyWAAAAwcnNyZVnPpsii9asrHC/lo2ayhldetfYcQEAAADZIuM7YefMmSNr166Vgw46qPS2Jk2aSKdOnWT69OleJ+yMGTNkxx13LO2AVTolQU5OjsycOVP69esnd9xxh7Rr1878XG5urqxataoGfqPsUKtWLdl+++3dFiLNmzeXs88+222xGZlY5GGRh0UePjJJPg/tgJ2/almNHheQCtSVFu9/PjKxyMMiD4s8fGRikUdwMr6S0ZVQVevWrc3tLVq0KP1eWbp6W/l969SpI9ttt50sWLDAdbaW7dBVP//8s7z11lvyu9/9TqKkpCQmubk5aXr0HKlbt25SP7FixQq3At97770na9askT333NPN7bv//vtL2GkWu+22W7oPI6OQiUUeFnlY5OEjE4s8EDTqyszB691HJhZ5WORhkYePTCzyyOJO2PiCWtqRWr5RrFy5MuH+5feN779hwwbv9qVLl7qFvvTs+kUXXVStY9UVW9etW+fdro+r89gWFxe7r5qSl5cn73z4lSxf5R9TkJo1aSBH9NrTraZXr1491/FdGVdccYV7PkaOHCk77LCDPP3003L++efLSy+95I1cDpo+T/qcaXtKxYqAmoVOldGtWzdp3LhxSo4x7MjEIg+LPCzy8JFJ5fPQq4Hq16+f1P3p51+YV6LXY9ffO8yoKzejrvTx/ucjE4s8LPKwyMNHJhZ5BFdXZnwnrBZb8blh4/+OF6CJ/qDQfRIt2KX7N2jQwNz23XffyYUXXugKoyeffNJNc1AdmzZtki+//DLh9/TyqUSdwEHRAlXz0UJ56bK1kg6FhYWusWrRvi3//e9/5V//+peb/3fvvfd2t+lohQ8++MAtmFbdDvJk6XNVVFTk2kgq6AmDqVOnuhMETZs2Tcl9hh2ZWORhkYdFHj4yqXweWg/oNE7JmDdvXumJ8LBKdFI+TKgrLerKLXj/85GJRR4WeVjk4SMTizyCqyszvhM2PrXA4sWL3QJacfp/vayovFatWsnkyZPNbdopq5ck6RQGcTo/rBZgulDXY4895rbVVbt2benQoUPCwkunPNDRuGU7krOB/s6Vmb9Ln7cHH3xQ9t13X9O4tejXOYHTkZset7a5ZC9/S0SnyZgyZYobeZGKthYFZGKRh0UeFnn4yKTyeVTlzL3eT5hHws6dO1fCjrrSR125Ge9/PjKxyMMiD4s8fGRikUdwdWXGd8J27NhRGjVq5Hrh452wuoDW7NmzZcCAAd7+3bt3lzvvvFN++OEHadu2rbtt2rRpbrvffvu57eeffy4DBw50o0K0QKvuCNiyf+SUH20bL/j0S8/cV+bsfZRoJpX5nZs1ayaHH364ue3tt992IxkOOeSQGs9NHy8+6iMVhXr8PnSbqI1kIzKxyMMiD4s8fGQSbB7JTl+QacI+FYGirvRRV27G+5+PTCzysMjDIg8fmVjkEVxdmfGdsHr2WjtbtWNVV2Zr06aNm9tJz3AfeeSRbiqBZcuWuXkqtIF06dLFnfXWeaCGDRvm5tK64YYb5IQTTnA9+Hop0FVXXeXmgB0xYoQbTbBkyZLSAonV3zLDp59+Ktddd517jg899NB0Hw4AAABCiroSAABkgozvhFWDBw92nadDhw5180HpaNexY8e6y7R++ukn6dOnj9x+++1y0kknuR7qMWPGyPDhw+Xss892l/z069fPFV7xUbA6Slb17dvXPI528L777rtp+R2jKJnFE8rS6SS0o1w707XzPQp05INOah32kUWpRCYWeVjkYZGHj0ws8kDUUVduwevdRyYWeVjkYZGHj0ws8ghOTizME35lkIKCArfNz8/3vqcdx7rAhc6nUdNzUL0wcVaNL6CwQ/OGcuox3ar0s7py7a233uo6zu+44460LaqRzucMAIAgjProTZm/almF+7Rp0lyG9OwvUa7LwoC6cgvqSgAAEJW6MvnTyUASq/qWlJRUev9nn31Wbr75ZjnjjDNk1KhRoV/VuHwWupicbrEZmVjkYZGHRR4+MrHIA1FHXbkFr3cfmVjkYZGHRR4+MrHIIzh0wiIwK1ascNNIVIaODrjtttvkiCOOkEGDBsnSpUvdXL36tXr1agk7/X10ETjdYjMyscjDIg+LPHxkYpEHoo66cgte7z4yscjDIg+LPHxkYpFHls8Ji6pr1qRBKB5TV6zVsyzvvPOO+yrrxBNPdIuoAQAAIH2oKwEAAKqOTtgIKymJyRG99kzbYydzydjvf/979wUAAIDMQ10JAABQPUxHEGG5uTlpe+yiok1SXFyctscHAABA6lBXAgAAVA+dsEANycvLS/chZBwyscjDIg+LPHxkYpEHkD14vfvIxCIPizws8vCRiUUewciJxWKxgO47qxQUFLhtfn6+973CwkK3QEC7du2kXr16aTg6JIvnDAAQNaM+elPmr1pW4T5tmjSXIT37S5TrsjCgrowWnjMAAMIrlXUlI2EBAAAAAAAAIEB0wiIQuiLtkiVL3Bbisnj44YfdFpuRiUUeFnlY5OEjE4s8EGXUlRavdx+ZWORhkYdFHj4yscgjOHTCIhA6y4UWysx2sVlRUZEsXLjQbbEZmVjkYZGHRR4+MrHIA1FGXWnxeveRiUUeFnlY5OEjE4s8gkMnLAAAAAAAAAAEiE5YAAAAAAAAAAgQnbAAAAAAAAAAECA6YRGIWrVqSbNmzdwWItttt52cfPLJbovNyMQiD4s8LPLwkYlFHogy6kqL17uPTCzysMjDIg8fmVjkERwqmQiLlcQkJzcnLY+dIzlSv379pH7ml19+kREjRsiUKVNkw4YN0r17d7n22mulffv2EnaaRefOndN9GBmFTCzysMjDIg8fmVjkgaBRV2YOXu8+MrHIwyIPizx8ZGKRR3DohI0wLZQXTv5SNi1fV6OPW7tZA2nVdy9Zt26d1K1bV/Ly8ir1c5dccomUlJTII488Ig0bNpR7771XzjnnHJk0aVLShXemWbNmjRQUFEh+fr40atQo3YeTEcjEIg+LPCzy8JGJRR4IGnVl5uD17iMTizws8rDIw0cmFnkEh07YiNNCecPSNWl57LVr17rLxipTLK9cuVLatGkjgwYNkj322MPddvHFF8tvfvMb+eabb2SfffaRMFu9erUr+nfbbTfexP6HTCzysMjDIg8fmVjkgZpAXZkZeL37yMQiD4s8LPLwkYlFHsGhExYZoWnTpnLXXXeV/n/ZsmUyfvx4adWqlXTo0CGtxwYAAIDwoK4EAACZiE5YZJw///nP8sILL0idOnXkwQcflAYNGqT7kAAAABBC1JUAACBT5Kb7AIDyzj77bHnppZekf//+bj6vL774It2HBAAAgBCirgQAAJmCTlgEpnbt2pKbm3wT08vE9t57b7n11lvdfF5PP/20hJ0uJKFzkukWm5GJRR4WeVjk4SMTizwQddSVW/B695GJRR4WeVjk4SMTizyCkxOLxWIB3n/W0JXjlK4eV15hYaHMmzdP2rVrJ/Xq1avR4/pxwswaX0Ch7g6NZJdT9kvqZ3Suro8//liOOuoot+hC3ODBg91CDGPHjpWalM7nDACAIIz66E2Zv2pZhfu0adJchvTsL1Guy8KAunIL6koAABCVupKRsAhMcXGxVLaPf+nSpTJkyBBXMMdt2rRJZs+eLe3bt5coZKFFv26xGZlY5GGRh0UePjKxyANRR125Ba93H5lY5GGRh0UePjKxyCM4dMIiMDoKQQveytCh7gcffLDccsstMn36dPn666/lj3/8o6xatUrOOeccCbvFixfLnXfe6bbYjEws8rDIwyIPH5lY5IGoo67cgte7j0ws8rDIwyIPH5lY5BGcLdfnIJJqN2sQmsccNWqU3HXXXXLFFVfI6tWrZf/995dnnnlGdtppp5QfIwAAAJJDXQkAAFB1dMJGWKwkJq367pW2xy4pKUnqZxo3bizDhg1zXwAAAMgc1JUAAADVw3QEEZaTm5O2x95UtIn5QwAAACKCuhIAAKB66IQFAAAAAAAAgADlxCq7zCgqVFBQ4Lb5+fne9woLC2XevHnSrl07qVevnmQDbVb6lZOT477CJtXPmV5Cp4tJ1K5dW3JzOfehyMQiD4s8LPLwkUnyeYz66E2Zv2pZhffTpklzGdKzv0S5LgsD6kqLutLi/c9HJhZ5WORhkYePTCzyCK6uZE5YBCKsRXJQ9I2rbt266T6MjEImFnlY5GGRh49MLPJAlFFXWrzefWRikYdFHhZ5+MjEIo/g0KWNQBQVFckvv/zithCXxdNPP+222IxMLPKwyMMiDx+ZWOSBKKOutHi9+8jEIg+LPCzy8JGJRR7BoRMWgQ1f37BhQ9Ir2UbVxo0b5dtvv3VbbEYmFnlY5GGRh49MLPJAlFFXWrzefWRikYdFHhZ5+MjEIo/g0AkLAAAAAAAAAAGiExYAAAAAAAAAAkQnLAAAAAAAAAAEiE5YBCIvL0+aNm3qtlUxb9486datm7z88ssSBU2aNJGjjz7abbEZmSSXR0ms8vPgJbNvpqJ9WOThIxOLPBBl1JUWr3cfmVjkYZGHRR4+MrHIIzi1ArxvpJl2xOTmpKefPSc3Rxo2bFiln920aZNcddVVsm7dOokKzaJHjx7pPoyMQibJ5aGv5Wc+myKL1qys8H5aNmoqZ3TpLWFH+7DIw0cmFnkgaNSVmYPXu49MLPKwyMMiDx+ZWOQRHDphI0wL5Q/nPiYr1y+s0cdtWr+V9OowUNavXy9169aV3NzkCvb77rtPGjVqJFGiWXzzzTfyq1/9SurXr5/uw8kIZJJ8HtoBO3/VMskGtA+LPHxkYpEHgkZdmTl4vfvIxCIPizws8vCRiUUewWE6gojTQnnZuv/W6Fe8OF+zZo0UFRUldbzTp0+X559/XkaMGCFRsmLFCnnllVfcFpuRiUUeFnlY5OEjE4s8UBOoKzMDr3cfmVjkYZGHRR4+MrHIIzh0wiJjrFq1Sq655hoZOnSotG7dOt2HAwAAgJCirgQAAJmGTlhkjGHDhrlFE4477rh0HwoAAABCjLoSAABkGuaERUZ49dVXZcaMGfLGG2+k+1AAAAAQYtSVAIJaeDCdixQCCD86YRGYWrVqSU5OTqX2femll+SXX36RQw891Nx+4403ysSJE+Wxxx6TMKtdu7bsvPPObovNyMQiD4s8LPLwkYlFHog66soteL37yMQij+Ty0E7VZz6b4hbBrUjLRk3ljC69JexoHz4yscgjODmxWCwW4P1njYKCArfNz8/3vldYWCjz5s2Tdu3aSb169Wr0uN4quMUtalCTmjfYVY7NH5rUzyxatMjlVNaRRx4pV111lRx//PHSsmVLqUnpfM6ArRn10Zsyf9WyCvdp06S5DOnZv8aOCUB4ZNN7SEV1WRhQV25BXQmgJmTTZyRQXdk2erwghXUlI2GREbZWDG+//fY1XigDAAAgvKgrAQAITraNHk8lOmEjrmn9Vml7zCVLlkjTpk2lTp06ku0WLFggjzzyiFx44YWs0Ps/ZGKRh0UeFnn4yMQiD9QE6srMwOvdRyYWeVjkYZGHj0ySz0M7YLc1ehw+OmEjTId99+owMG2PXVJSUq37+Oqrr1J2PAAAAKg66koAAIDqCffEDKhQOufdKNpUJMXFxWl7fAAAAKQOdSUAAED10AkLAAAAAAAAAAGiExYAAAAAAAAAApQTi8ViQT5AtigoKHDb/Px873uFhYUyb948adeundSrV0+ygTYrvWwsLy9PcnJyJGxS/ZwVFRXJqlWrpEmTJlKrFlMxKzJJPo9RH725zcnP2zRpLkN69pewo31Y5OEjE4v3kMrXZWFAXWlRV1q8//nIxCIPi89Ii/bhIxOL10xwdSWtC4HQApk3ry00i+bNm6f7MDIKmVjkYZGHRR4+MrHIA1FGXWnxeveRiUUeFnlY5OEjE4s8gsN0BDUomwYd65mT5cuXu20Ypfq50ixefvllt8VmZGKRh0UeFnn4yMQij+xDXRke1JXBIxOLPCzysMjDRyYWeWRYJ+zq1avlnXfekddee01effVV7wtW7dq13XbdunWSLUpKSmT9+vVuG0bx5yr+3KXiMjQdwq5bbEYmFnlY5GGRh49MLPLIHtSV4UNdGTwyscjDIg+LPHxkYpFHcJK+rmfKlCkyePBg92QkOqurlwudcMIJqTq+SND5q7bbbjtZvHix+3+DBg1COZ9VMjZu3OhGK2g7CVPBrG1aC2V9rvQ50+cOAAAgU1BXUlcCAIAs6YS96667ZPfdd5frrrtOWrZsKbm5zGhQGa1atXLbeMEcdbp4go6Y1smcw1hwaqEcf84AAAAyCXVluFBXAgCAKnXCfvvtt/LAAw/I/vvvT4JJ0BEKrVu3lhYtWsimTZsk6vSPgr///e9y6qmnut85TPRSsTAW+AAAIDtQV4YHdSUAAKhyJ+xOO+0ka9asSfbH8D9ahGVDIdasWTPXUa/bevXqSbZr1KiRHHLIIW6LzcjEIg+LPCzy8JGJRR7ZiboyO/F695GJRR4WeVjk4SMTizyCkxNLcrlOXSFt3Lhx8tBDD8nOO+8c3JGFjE5arPLz89N9KAAiatRHb8r8Vcsq3KdNk+YypGf/GjsmAOGRTe8hYa/Lwn78ABA22fQZCaRCNr1mClJYlyU9oesbb7whixYtkiOOOEJ69uwpffr0MV99+/at9kEh/DZs2CBz5851W5BHImRikYdFHhZ5+MjEIg9EGe3bIg8fmVjkYZGHRR4+MrHIIzhJd8LqpPLa0XrCCSfIwQcfLD169DBf3bt3D+ZIESrLli2TZ555xm1BHomQiUUeFnlY5OEjE4s8EGW0b4s8fGRikYdFHhZ5+MjEIo8MmhP2+OOPl27dujEfEwAAAAAAAAAEMRL20ksvlUmTJiX7YwAAAAAAAACQlZLuhG3SpAmjYAEAAAAAAAAgqOkIBg0aJLfccovMmzdPOnbsKA0aNPD2YV5Y5OXlSbNmzdwW5JEImVjkYZGHRR4+MrHIA1FG+7bIw0cmFnlY5GGRh49MLPIITk4sFosl8wPa8WruICen9N96V/r/L7/8MnVHKCIlJSUyZswYmTBhgqxevdp18t5www2yyy67JNx/+fLlrqP4gw8+cMdz7LHHyjXXXCP169f39p05c6YMGDCg2sdcUFDgtvn5+dW6HwDYmlEfvSnzV1U8OXqbJs1lSM/+NXZMAMIjm95Dwl6Xhf34ASBssukzEkiFbHrNFKSwLkt6JOyTTz4pNe2BBx6QZ599VkaMGCGtWrWSkSNHysCBA+WNN96QOnXqePsPHjxY1q9fL+PHj5dVq1bJ9ddfL+vWrZM77rjD64C9+OKLXScvAAAAAAAAAGTEnLA9evTY5lcqbdy4UcaNG+c6Vg899FA3Evfuu++WhQsXJlwgbNasWTJt2jTX4dq5c2c56KCD5KabbpLXXntNFi1a5PYpKiqS22+/Xc4++2xp06ZNSo8Xm2nW2lkez7w6Ykl0kiezb1jziAoyscjDIg+LPHxkYpEHooz2bZGHj0ws8rDIwyIPH5lY5BGcpEfCvvrqq9vc54QTTpBUmTNnjqxdu9Z1ppZdHKxTp04yffp06d/fDm2eMWOG7LjjjtK+ffvS27RjWKcl0JGvxxxzjBsVqz/72GOPyc8//yzXXXddyo4Xm+noYs05FaOMc3JzZeXk56R4+eIK98tr1kKa9j1Nop5HVJCJRR4WeVjk4SMTizwQZbRvizx8ZGKRh0UeFnn4yMQijwzqhP3jH/+Y8Hbt5NRJe/UrlZ2wOuJVtW7d2tzeokWL0u+VpT315ffVKQu22247WbBgQWkn7ssvv+z+Hd+mgs6Jqw0VIoWFhaXb6mSi7Urn8tUO2KKl8yv1MzoVRZJTHYcmjyghk8rnEX8dJCMTXwfJoH1Y5OEjE4v3ECu+TkGYUVduwevdIg8fmVjkYfEZadE+fGRi8ZoJrq5MuhP2H//4h3ebPik6AvXRRx+V+++/X1JJnyxVfu7XunXrysqVKxPun2ieWN1/w4YNEqRNmzalfFGysIo/N/PmzZNlyyqerLki+uLWUc/J0MeMt5uo5RElZFL5PKLyOkgG7cMiDx+ZWLyH+BLVg2FCXbkFr3eLPHxkYpGHxWekRfvwkYnFaya4ujLpTtitzaH6q1/9yhWLN998s1tEK1Xq1atXOjds/N9KO1QT9b7rPrpvebp/gwYNJEi1a9eWDh06BPoYYaEjkqdMmSLt2rWTli1bVvl+qnK2QR8z086ypCqPKCGTyucRlddBMmgfFnn4yMTiPcSaO3euhB115Ra83i3y8JGJRR4Wn5EW7cNHJhavmeDqyqQ7YSuy5557yl133ZXKuyydWmDx4sWy6667lt6u/9fHK69Vq1YyefJkc5t2yq5YscJNYRAkbYxBd/SGhXbWn3feee4FW9MjUZIdGh/1PDIVmQSbRya+DpJB+7DIw0cmFu8hVtinIlDUlVvwerfIw0cmFnlYfEZatA8fmVi8ZoKrK3NTdUfa0fniiy/K9ttvL6nUsWNHadSokUydOrX0tlWrVsns2bOle/fu3v56m84V+8MPP5TeNm3aNLfdb7/9Unps2Dp9oe6yyy68gf0PefjIxCIPizws8vCRiUUeiDLat0UePjKxyMMiD4s8fGRikUdwku6EPfzww6VPnz7m67DDDpMePXrIm2++KWeddVZKD1Cf9AEDBsidd97p5qOdM2eOXHHFFW7E65FHHinFxcWyZMmS0omDu3TpIvvuu6/b5/PPP5dPPvlEbrjhBrdYGMPKa452lL/99ttuC/JIhEws8rDIwyIPH5lY5IEoo31b5OEjE4s8LPKwyMNHJhZ5ZFAnrHa2lv868MAD5ZRTTpGxY8fKOeeck/KDHDx4sJx88skydOhQOe200yQvL889ls6VtWDBAunVq5dMnDixdJjwmDFjZOedd5azzz5bLr/8cjn44INl2LBhKT8ubN3atWtdB7huQR6JkIlFHhZ5WOThIxOLPBBltG+LPHxkYpGHRR4WefjIxCKP4CQ9J+yIESMq/L5OBaCjVFNJO12vvvpq91WedrZ+9dVX5jadEmH06NGVuu+TTjrJfQEAAAAAAABARoyE3Wuvvdxl/onMmDFDjj766FQcFwAAAAAAAABkz0jYcePGybp169y/Y7GYTJgwQT744ANvv1mzZjFxLwAAAAAAAAAk2wm7YcMGN89qfM5V7YQtLzc3Vxo3biwXXXRRZe4SEdegQQPZf//93RbkkQiZWORhkYdFHj4yscgDUUb7tsjDRyYWeVjkYZGHj0ws8ghOTkyHtiahY8eO8sILL8g+++wT3FGFUEFBgdvm5+en+1AiadmEe6Vo6fwK96m1QxtpfsplNXZMQE0b9dGbMn/Vsgr3adOkuQzp2b/GjglAeGTTe0jY67KwHz8AhE02fUYCqZBNr5mCFNZlSc8JO2fOHNMBq6Nkk+zHRRbYtGmTLFiwwG1BHomQiUUeFnlY5OEjE4s8EGW0b4s8fGRikYdFHhZ5+MjEIo/gJN0Jq7777ju5/PLLpUePHtKtWzeZPXu2DB8+XJ566qnUHyFCaenSpfLII4+4LcgjETKxyCO5PEpiJZW+r2T2zVS0Dx+ZWOSBKKN9W+ThIxOLPCzysMjDRyYWeaR5TtiyvvzySznjjDNk++23l+OOO06effZZd3teXp7cdttt0qhRIznxxBODOFYAAJzcnFx55rMpsmjNygr3a9moqZzRpXeNHRcAAAAAACnphL3jjjtk7733lnHjxrn/P/PMM247dOhQNzXBk08+SScsACBw2gG7rXmIAAAAAAAI5XQE//73v+Wcc86RWrVqSU5OjvneMcccI99//30qjw8AAAAAAAAAsqsTtm7dulJYWJjweytWrJA6deqk4rgQctpBr22hfEd9tiKP5DLJtvk+FW3EIg+LPHxkYpEHooz2bZGHj0ws8rDIwyIPH5lY5BGcnFgsFkvmB4YMGeIW4ho/frzsuOOO0rlzZ3n55Zelbdu2boTszjvvLHfffbdkm4KCArfNz89P96FE0rIJ90rR0vkV7lNrhzbS/JTLauyYECzm+/SN+ujNbV5+36ZJcxnSs79kA/JARSdndN7gVO8bdtn0mgl7XRb24weAsMmmz0ggFbLpNVOQwros6Tlhr776avntb38r/fr1k44dO7qe8REjRsi8efNE+3NHjRpV7YMCAOb7BFBVLNwGAAAAINMkPfSjdevW8tprr8nZZ5/tOl133XVXWbdunfTv39+NiN1ll12COVKEypIlS+SBBx5wW5BHImRikYdFHhZ5JJ9J/ERORV/b6qQNE9oIooz2bZGHj0ws8rDIwyIPH5lY5BGcpEfC6hNx1FFHyRVXXBHMESESioqK3AtWtyCPRMjEIg+LPCzy8JGJRR6IMtq3RR4+MrHIwyIPizx8ZGKRRwaNhH344Yflp59+CuZoAIRCNi6cBQAAwi9WUhLIvgAAACkfCduhQwc3/+shhxyS7I8CiNB8ix/OfUxWrl9Y4X5N67eSXh0G1thxAQAAVCQnN1dWTn5OipcvrnC/vGYtpGnf0yTqtKNZM0n1vgDCiwVOgQzqhD3ssMPc4ltTpkyRPffcUxo0aGC+rwt1XXLJJak8RgAZSDtgl637b7oPAwAAICnaAVu0dH66DyMj0CmdnehkQ0VY4BTIoE7YMWPGuO1HH33kvsqjExaqWbNm8rvf/c5twy4VRUqU8kgVMrHIwyKP5PLIxj+maCMWeSDKaN/B5hGFTmnaSHJ5ZFsnG+0j+TziC5xmC9qIRR4Z1Ak7Z86cYI4EkVKvXj03UjoKUnHpfZTySBUyscjDIo/k8si2P6YUbcQiD0QZ7dsiDx+ZJJ9HNnWy0T4s8vCRiUUewQlsKExxcbHstdde8sUXXwT1EMhga9ascVNW6DZKl95X9FVRJ23U8kgFMrHIwyKP5POI/zFV0de2OmnDhDZikQeijPZtkYePTCzysMjDIg8fmVjkEZxAr0eMxWJB3j0y2OrVq+Xdd991W5BHImRikYdFHhZ5+MjEIg9EGe3bIg8fmVjkYZGHRR7JZ6LTeVVGZffLdLSRDJqOAAAAAAAAAMgGlZn6K0rTfiE4dMICAAAAAAAAW5FN8ygjOOFfHhkAAAAAAAAAMhidsAhsNb1OnTq5LcgjETKxyMMiD4s8fGRikQeijPZtkUdymSQzR2NU5nOkjVjkYZGHj0ws8ggO0xEgEM2aNZNTTjkl3YeRMcjDRyYWeVjkYZGHj0ws8kCU0b4t8kguk8rM5Ri1+RxpIxZ5WOThIxOLPIJDJywCUVxcLGvXrpWGDRtKXl6eZDvy8JGJRR4WeVjk4SMTizwQZbRvizySzyTb5nKkjVjkYZGHj0ws8ggO0xEgEIsXL5a7777bbUEeiZCJRR4WeVjk4SMTizwQZbRvizx8ZGKRh0UeFnn4yMQijwzqhJ0+fbrrEU9k1apV8tZbb22+49xcOfHEE90wZgAAAAAAAADIVkl3wp511lny7bffJvze7Nmz5brrrnP/zsnJkdtvv1122mmn6h8lAAAAAAAAAER5Tthrr71WFixY4P4di8Vk2LBh0qhRI2+/77//XnbYYYfUH2UWiZWUSE5ubsr3BQAAAAAAAJDBnbBHHXWUPP744+Y27YwtSyfr7dq1q5xxxhmpPcIso52qKyc/J8XLK557I69ZC2na97QaOy4AAAAAAAAAAXbCHn744e5LnXnmmW4kbPv27av4kNgW7YAtWjo/bY9fEiuR3Jzcau3bqlUruf7661lJ73/Iw0cmFnlY5GGRh49MLPJAlNG+LfLwkYlFHhZ5WOThIxOLPNLcCVvWU089VeH3v/vuO9l9992rc0wIQKwkJjm5OZXaVztVP5z7mKxcv7DC/ZrWbyW9OgxM+D2dE7hWraSbV2SRh49MLPKwyMMiDx+ZWOSBKKN9W+ThIxOLPCzysMjDRyYWeQQn6QlFV65c6UbCHnPMMdK3b1/p06eP+9KRsgceeKAce+yxwRwpqkU7YBdO/lJ+nDCzwq+lU+e5/bUDdtm6/1b4VVEn7S+//CLjx493W5BHImRikYdFHhZ5+MjEIg9EGe3bIg8fmVjkYZGHRR4+MrHIIzhJd23fdttt8tZbb0nv3r3dqNf69evLbrvtJjNnzpRVq1bJTTfdFMyRoto2LV8nG5auqXCf2tvVT8ljbdy4UX744Qe3RWrziMribbQRizws8rDIw0cmFnkgymjfFnn4yMQiD4s8LPLwkYlFHhnUCTtlyhS59NJLZdCgQTJu3DiZNm2a3HPPPbJ27VoZMGCAzJ07N5gjBeCweBsAAAAAAEC4JD1ETke7duvWzf1bF+f6z3/+4/7dsGFDOe+88+S9995L/VECSLh4W0Vf2+qkBQAAAAAAQIZ2wjZr1kxWr17t/q3TEOgcEStWrHD/b9mypSxatCj1RwkAAAAAAAAA2dIJe9BBB8lDDz0k8+fPl1133VWaNm0qr7zyivveP//5T9dJC2i7OO6449wW5JEImVjkQR4VIQ8fmVjkgSiLWvsuiZVUa79szSObMqku8rDIwyIPH5lY5JFBc8IOHjxYzjrrLLn22mvl6aefdnPD3nHHHa5jVqcquOSSS4I5UoRKgwYNZN999033YWQM8vCRiUUeFnlY5OEjE4s8EGVRa9+5Obny4dzHZOX6hVvdp2n9VtKrw8CE38vGPLItk+oiD4s8LPLwkYlFHhnUCbvzzjvLxIkT5fvvv3f/P/fcc2WHHXaQTz/9VPbZZx858cQTgzhOhMy6detkzpw50rFjR/cCznbk4SMTizws8rDIw0cmFnkgyqLYvrXDcdm6/1bpZ8kjOzKpDvKwyMMiDx+ZWOSRQdMRnH/++TJr1iz3ZMTpMOUbb7yRDliUWrlypbzxxhtuC/JIhEws8rDIwyIPH5lY5IGaFCuJBbLv1tC+LfLwkYlFHhZ5WOThIxOLPDJoJKyOeM3JyQnmaAAAAABktJzcHFk4+UvZtHxdhfvVbtZAWvXdq8aOCwAAIFKdsL1795bXX39d9ttvP6ldu3YwRwUAAACgWmIlJZKTm5vyfZV2wG5YuqYaRwcAAJBdku6ErVu3ruuE/dvf/ibt27f35ofQUbJPPPFEKo8RAAAAQJK0U3Xl5OekePniCver1Wo3adTzeOFaNwAAgAzqhF24cKF069at9P+xmJ3nqfz/kZ3q1Kkjbdu2dVuQRyJkYpGHRR4WefjIxCIPbI12wBYtnV/hPnnb7Si5uTnyzodfyfJVFU8xsGvrZnJgt92kJtG+LfLwkYlFHhZ5WOThIxOLPDKoE/app54K5kgQKdtvv72cc8456T6MjEEePjKxyMMiD4s8fGRikQdSQTtgly5bW+E+2zWpLzWN9m2Rh49MLPKwyMMiDx+ZWOQRnMpP/PQ/Z511lnz77bcJvzdnzhw57rjjUnFcCDkdEV1UVMTI6P8hDx+ZWORhkYdFHj4yscgDUUb7tsjDRyYWeVjkYZGHj0ws8khzJ+yMGTNk+vTp7mvatGml/y7/pXPF/vjjjwEeLsJCp6249dZb3RbkkQiZWORhkYdFHj4yscgDUUb7tsjDRyYWeVjkYZGHj0ws8kjzdAQTJkyQ1157zS26pV/Dhw/39on3kPfv3z/1RwkAAAAAAAAAUe6EHTp0qPzf//2f62g9++yz5YYbbpAOHTqYfXJzc6VJkybyq1/9KqhjBQAAAAAAAIBodsI2btxYevTo4f795JNPSufOnaVhw4ZBHxsAAACAkMqrX1tKYiWSm1O5ZSiS2RcAACCSnbBlaWeszgtbp04d6dq1q/z8889y0003yfz586Vfv35yySWXBHOkAAAAAEIjt24t16n64dzHZOX6iueVa1q/lfTqMLDGjg0AACDjO2FfffVVue666+S8885znbA6NcHMmTOlZ8+e8tBDD0nt2rXlwgsvDOZoERotWrSQK664ghHT/0MePjKxyMMiD4s8fGRikQcymXbALlv33yr/PO3bIg8fmVjkYZGHRR4+MrHIIzhJX+8zfvx4OfHEE+Xqq6+WJUuWyL/+9S/5wx/+IGPGjHFP0ksvvRTMkSJU8vLy3BzBugV5JEImFnlY5GGRh49MLPJAlNG+LfLwkYlFHhZ5WOThIxOLPDKoE/a7776TE044wf37/fffd4t19enTx/0/Pz9fFixYkPqjROgsX75cJkyY4LZITx659RtLSUms0vsns28q0EYs8rDIwyIPH5lY5IEoo31b5OEjE4s8LPKwyMNHJhZ5ZFAnrPaGr1mzxv17ypQpstNOO8luu+3m/v/f//5XmjVrlvqjROgUFhbK7Nmz3RbpySOnbj3Jzc2Rdz78Sl6YOKvCL91H961JtBGLPCzysMjDRyYWeSDKaN8WefjIxCIPizws8vCRiUUeGTQn7AEHHOCmHpg7d6784x//kHPPPdfd/vbbb8u9994rvXr1CuI4AVTR8lXrZOmytek+DAAAAAAAgKyV9EjY66+/3o121Y7Ygw46SAYNGuRuv/32292o2CuvvDKI4wQAAAAAAACA7BgJ27x5cxk7dqx3+7PPPus6YQEAAAAAAAAA1RgJuzV0wKKsxo0by+GHH+62II9EyMQiD4s8LPLwkYlFHogy2rdFHj4yscjDIg+LPHxkYpFHBo2EBSqjUaNG0rt373QfRsYgDx+ZWORhkYdFHj4yscgDUUb7Tn8eufUbS0lJrNILuSazbyrQRizysMjDIg8fmVjkERw6YREIXUXvhx9+kLZt20q9evUk25GHj0ws8rDIwyIPH5lY5IEoo32nP4+cuvVcp+o7H37lFn2tSLMmDeSIXntKTaKNWOQR7TxKYiWSm5Nb5X2jlkcqkIlFHiGYjiBIJSUlMnr0aNcT37VrV7ngggvkxx9/3Or+y5cvdwuEde/eXXr06CHDhw+X9evXm33+9re/yTHHHCP77LOPnHDCCfLxxx/XwG+SPfQ5+Otf/+q2II9EyMQiD4s8LPIIXyaxklgg+4Y1D6A6aN+Zk4d2wC5dtrbCr2110gZyXLQRgzyinYd2qn449zF5q+CWCr90n0SdtVHLIxXIxCKPLB8J+8ADD7iFv0aMGCGtWrWSkSNHysCBA+WNN96QOnXqePsPHjzYdbqOHz9eVq1aJddff72sW7dO7rjjDvf9Tz75RK6++mq55pprpGfPnvLiiy/KhRdeKK+++qq0b98+Db8hANS8TL6sEAi7nNwcWTj5S9m0vOLOiNrNGkirvnvV2HEBAGqenmzTz4VU74vstXL9Qlm27r/pPgwANdEJO2/ePHn//fddx6aOUi0rJydHLrnkEkmVjRs3yrhx4+Sqq66SQw891N129913u1GxkyZNkv79+5v9Z82aJdOmTZOJEyeWdqjedNNNrtN2yJAh0rJlS3n00Uelb9++ctZZZ7nvX3vtte7nnnjiCbcvwinT56oCMk0mX1YIRIF2wG5YuibdhwEASDNOzAEAqtQJ+9prr8kf//hHicUSXzqX6k7YOXPmyNq1a+Wggw4qva1JkybSqVMnmT59utcJO2PGDNlxxx3NiFadkkCPa+bMmdKvXz/59NNP3e9Q1gEHHOA6dRFemT5XFZCJ4pcVAgAAIDicmAMA1KrK1AC//vWv5ZZbbnFTA2jnZpAWLlzotq1btza3t2jRovR7ZS1atMjbV6cs2G677WTBggVuegIdwavHXpn7S4Z2TOt9l1fZjHQ/nfQ4r1mLbe4b30cnTN5ah3j5+9Uzq9tSq0l9t21a3+aTSHwfnfqh/DFs2rRJtt9+e7etqUxymzSXZG0rv/jjhzkP7XDelvg+ybSnoDLR+69fv760bNR0m/cf36cyxx2/78rsF+S+KtG+FbWRIDKJP4+pbh9hzSPT2wh5VL6NZEIeyXzuxvep7DFkw2smFe1Dbwu6Rg3a1upKVZnfLaiaoUnDzQt0RL2urNVqt6SvsNq4cUPK6qhMy4O6MvGx85kQ/Ps8dWXqXzNRyiPZfYNsI+QRjUxiAdeVObFknh0Ryc/Pl0ceecSMTA2SjrzVuVu//PJLyc3dMqm03rZ48WI372tZOv/r999/L88884y5XacyOPXUU+Wkk06SQw45xP1c2d9B54W94YYbZPbs2VU6zoKCAjd1Qnm1a9eWTp07S628vErdT6ykRHLK/J4VSaYwTGZuoWRWWywuLpIvvpjtXpyVFbZMyKNmMyGPmsuEPKKRCXlY5BH+TFKVh56E17o1jLZWVyb7fKb7uXT3S/uucibk4eMzIRpthDwyNxPy8PG5mz1tpLgG6sqkR8K2a9fOjSitKXqWR2khGv+32rBhg+t9T7R/oqJV92/QoIHUrVu39P7Kfz/R/SVDG2OHDh3Mbdpbro3zmc+myKI1K7d5luCMLr0rfda4Tp3Nv0tl6L1tCGgUW/nfuTL3H0QmVTmDuK25meLzMiVzNjrKedRUJps2bpTKfAzEj3vl5OekePniCvetveue0viAfpWarmLX1s3kwG67VSqP+rs2lx0OaOdWH9UJ8rd1NrpXh4Hyq1/9KqnXWBCZ6KiXpn1PS2qUSpTzCHsbIY/MyiM+5U0yry9eM6ltH3PnzpWwS1RXJlM3BFUzBLmvoo6yyCP8dSWfCZldM2RCG0kmk2x4zYS1jZBHuDNpWkN1ZdKdsFdeeaXcfPPN0qZNG+natWtpp2ZQ4lML6KjXXXfdtfR2/f+ee/pzeuo0A5MnTza3aYfrihUr3JQDOi2Bdsbqz5el/9dFu6pDG5jedyJaBM1ftaxS91O2szlV9GxCEPe7NTq1w+OPPy7nnnuuN/VDpmSSzNxM1X38qOVRU5lUlr6hFy2dX+E+edvtWOk5ULf73+WTlcmj9nb1k16hNNEJn1TmUdlMkn0eo55HJreRdOaRjLC2kVS3j6q8vjIpj3S+ZlLVPsI+FcG26spk6oaarP+CQh1lkYePz4TwfCZUpYZKRtjySDaTmnoPyaY6O9PfQ8KeR9gyqR9wXZl0J+ytt94qv/zyi5xzzjkJv68HV9VL+hPp2LGjNGrUSKZOnVraCavzuupjDBgwwNu/e/fucuedd8oPP/wgbdu2dbdNmzbNbffbbz93fPvuu6+77ZRTTin9Ob3//fffP2XHne30zIF2fid7RiWqyMNHJhZ5WOSR/jxiGwrdJUGZuoghbcQiD0QZ7dsiDx+ZRDOPkg1F7jJiHZ1WnUuOo5JHqpCHj0ws8ghO0p2wxx9/vNQknXdBO1u1Y7V58+ZuBO7IkSNdb/yRRx4pxcXFsmzZMmncuLE7G9SlSxfXyXrFFVfIsGHD3CTCOtfrCSecUDrSVXvzL7zwQunUqZMcfPDB8tJLL7k5Z7WDGQAAiJSsX13pOZkAAABSrXj9pkrPbamS2RcAQtEJ+4c//EFq2uDBg6WoqEiGDh3q5j7R0a5jx451c2X99NNP0qdPH7n99tvdols60nXMmDEyfPhwOfvss910Cf369ZPrrruu9P569eolt912mzzwwANy9913uzlSHnroIWnfvn2N/24AalYyKz8DAAAAAACkpRM2vojVV199ZYYnl5SUyPr162XGjBly1VVXpfQg8/Ly5Oqrr3Zf5e28887uWMrafvvtZfTo0RXep46M1S8A2SHTL60GAAAAAADRlXQnrM6detlll8nKlYlX22zYsGHKO2ERPjvssIOb8kG3II9MyCTTL62mjVjkYZGHj0ws8kCU0b4t8vCRiUUeFnlY5OEjE4s8MqgTVi/fb9asmdx8883y+uuvS25urpsG4IMPPpDnnntOHn300WCOFKGiU0W0bt063YeRMcjDRyYWeVjkYZGHj0ws8kCU0b4t8vCRiUUeFnlY5OEjk8zJo1nEpw9MuhNWL/2/5ZZb5IgjjpDVq1fLX//6VznkkEPc16ZNm+TBBx+URx55JJijRWjoSOkPP/zQzb/btGlTyXbk4SMTizws8ghnHrWbbbtoqtWkflZlUlPIA1FG+7bIw0cmmZPHtjpQ0tF5QvuwyMNHJunPI5Yl0wcm3Qmrc7+2bNnS/btt27byzTfflH7vqKOOkmuvvTa1R4hQWrdunZsfeN999+VNLER5VKYDpTL7RCmTmkIeFnmEL49YSUxa9d2rxh4vDJnUpFTnkdesxTb3yW3SvNqPA1QGr3eLPHxkkv48MrkDhfZhkYePTNKfR0mGTx+Ytk7YXXfd1Y2G3X///aVdu3ZuMa7vvvtOdt99dykqKpK1a9cGc6QAMqYDRffNyYI3SACVx3tCdMRKSqRp39PSfRgAgBDJlg4UIBuuOEMGdcIed9xxcuedd0osFpMBAwbI3nvv7eaHPfPMM+Whhx6SDh06BHOkADKmA4XOFiB5Teu3Ssk+QNBycnPTfQgAAAAQkY0bi2r8ijNkUCfswIEDZfny5fLZZ5+5Ttgbb7xRLrjgArn44oulUaNGbk5YAACwWcmGIimJlUivDgMrt3+sRHJz6ARDeER9AQUAAIB0WVe4iUFQ2dwJm5uba+Z9zc/Pl8mTJ5dOSaAdsUDDhg3lwAMPdFuQR1gzqclLPsKQR02KUh7F6zcl1amaaN8o5ZEqZJIZeSQ7/9+23le5jA6J8Hq3yCP6mVT36pmo5VFd5GGRh49MLPLIoE7Ysqul6US9ixcvdgtyaecrTxDimjRp4toFNiOP8GVS05d8ZHoeNY08LPLInEwqM+qzMvtEJY9k5v/jUjpUFe+BFnlEO5NUXD0TpTxSgTyin0d1T1xEMZPqyMY20rSGpoWrUiesTjnw8MMPS2FhoeTk5Mg+++wj99xzj5umYNy4ce4JQ3bbuHGjLFq0SFq2bCl16tSRbEce4cukpi/5yPQ8ahp5WOSR/kySXfVZ963JBUrC0Ea4lA5Rbt81iTyinUl1r56JWh6pQB7RzSNV035FKZNUyNY2UlID08Ilfe9PP/203HfffXLuuefKCy+84BboUjo/7I8//ij33ntvEMeJkPnll19ch7xuQR6JkIlFHhZ5WOSR/kySXfW5pleIpo0gymjfFnn4yMQiD4s8optHKqb9ilomqZCtbSS3BtblSPoRnnrqKbnwwgvlsssuk86dO5fefsghh8jll18u7777bqqPEQAAAAAQIjoHdN0dGlX4VZn59wEAiIqkpyP4+eefpUePHgm/pwtzLV26NBXHBQAAAAChUZkOxWzpdExmDmjdl+lKAADZIOlO2NatW8usWbPk17/+tfe9//znP+77AAAAAJAt6HS0kvn9op4FAABV7oQ9+eST3Zyw9erVk0MPPdTdtm7dOnn77bfdYl06VyyQm5srDRo0cFuQRyJkYpGHRR4WefjIxCIPRFkY2ndNdjqGIY+aRiYWeVjkYZGHj0ws8sigTtgLLrhAfvrpJ7nzzjvdlzrrrLPc9rjjjpNBgwal/igROrqK3tVXX53uw8gY5OEjE4s8LPKwyMNHJhZ5IMpo3xZ5+MjEIo/MyaNZk21PQdKkYT2pSbSPzMmkMu2jMvuU17R+q2rtQxvJoE7YnJwcuemmm9yI108++URWrlwpjRs3lu7du8see+wRzFECAAAAAJBBgupAQfjFNhRKSUlMjui1Z7oPBRFoH7pvbiWvoiiJlUivDgMrvW9uDqNda1KV027Xrp2cdtpp8vvf/17OOOMMOmBhLF68WEaPHu22YV61NVWLJ4Qlj5pEJhZ5WORhkYePTCzyQJTRvi3ySH8mZTtQTj2mW4Vfuo/uW5NoI+nPo2T96kp3mtU02kf6M0m2fSS1bxKdqlvblzaS5pGw1113XVIjZW+77bbqHBMioLi4WJYvX+62YV9AIRWLJ4Qhj5pGJhZ5WORhkYePTCzyQJTRvi3ySH8mQXagpAJtxCKPzMkjE6dnULSRcOZRuxKD5lI1sK5GO2FfeeUV17mq80Jsa2Je3Q8Ig8p2rLJiKwAAAAAAVcP0DEjXoLpUDayr0U7Yo48+Wt577z3ZuHGj9OvXT4499ljZb7/9gj86AAAAAAAAhFYmT8+AcMpJoj1lSgdspTth7777blm/fr3885//lIkTJ7pFuXbYYQc55phjXIfsXntVrvcZAAAAAAAAALJNpTphVf369V2nq36tWbNG3nnnHdchO378eNl5552lf//+rkNWF+wCmjdv7hZs0y3IIxEyscjDIg+LPHxkYpEHooz2bZGHj0ws8rDIwyIPH5lY5JEBnbBlNWrUSE488UT3tWLFCtch+7e//U0eeugh2WOPPeTll19O/ZEiVOrWrSsdOnRI92FkDPLwkYlFHhZ5WOThIxOLPBBltG+LPHxkYpGHRR4WefjIxCKP4FS8ylYlbNiwwU1VUFhY6FZOmz9/fmqODKG2evVqN4+wbkEeiZCJRR4WeUQ/j6b1W0nzBrtW+KX7ZFMm1UEeiDLat0UePjKxyMMij3Dmoava192hUYVfuk82ZVJTyCPDRsIuWrRI/v73v7uvzz77TBo0aCB9+/aVQYMGSc+ePVN/lAgdnbLi/ffflz333FMaN24s2Y48fGRikYdFHtHOoyRWIr06DKz0vrk5uZHPpLrIA1FG+7bIw0cmFnlY5BG+PGp65fswZFKTyCMDOmHLdrz++9//dnPEHnbYYTJw4EDp3bu31KlTJ8DDRBS1bNQ0JfsAAMIlUadqKvYFAABA+CXTqVrdDlgg4zphTzvtNDfiVeeFOOSQQ+Tee+91W/0/UBU6sumMLr0rvS9/hAMAkD0qmooimX0AAACAUHXCzpo1S/Ly8tzEvMuWLZOnn37afSWSk5MjTzzxRKqPExHDKCgAABDUdBUAUFV5zVqkZB8gW/CaAVLcCdu9e/fSf8disQr33db3kR3q1asn+fn5bgvyyIZMqjtqK2p5VBd5WOThI5Po5sGJWkS5facCeQSXSaykRJr2Pa3S++bkZuZ7EG3EIo/g8uA1E03kkeZO2KeeeirAQ0AUNWvWTE466aR0H0bGII9oZ5KKUVtRyiMVyMMiDx+ZWOSBKKN9W+QRXCbJdBBlameSoo1Y5BFcHrxmook8gpO5rwKEWlFRkZu6Qrcgj6hnkopRW1HKIxXIwyIPH5lY5IEoo31b5OEjE4s8LPKwyMNHJsHmodNR1NqhTYVf2TJlBZ2wNaRlo6bSpknzCr90n6hYsmSJ3HfffW4L8kiETCzysMjDIg8fmVjkgSijfVvk4SMTizws8rDIw0cmweURn7Ki+SmXVfil++i+UVep6QhQPXr58Rldeld6X+Y3AwAAACqvMoMZojTgAQCAMIjKlBWpQidsDWCBCQDZproLlQEAUFkMeAAAAGFAJywAIGVKNhSlZKEyAAAqiwEPAAAgDKhCAAApU7x+E38MAwAAAABQDiNhEYjWrVvLjTfemO7DCFUe2TaXGW3EIg+LPILNozKrj2b6CqW0EYs8EGW0b4s8fGRikUc486jdrEFK9olKHjWJTCzyCA6dsEAGYC4zADUlvkJpZffNhgnyAQAA0ilWEpNWffeq9L45uTmBHxOA1OMvKwRi6dKlMnbsWLfFtvPIxsu3aSMWeYQzDx2NUHeHRhV+pWLEQirziMoKpWFpIzWFPBBltG+LPHxkYpFH+PJIplO1uh2wYcijppGJRR7BYSQsArFp0yb56aef3BbkEXQmUbi0mjYSrjw2biyq0RELmZ5HOkQtk6b1W1Vrn6jlAZRF+04+j2yb5oo2YpGHRR4WefjIxCKP4NAJCyDUuLQa6bCucFONjlhAtOk0M706DKz0vlG5IgJAMJjmCgCAzMQnLoBQi8ql1QCyVzZOSQMgOLynAACQmRgJCwAAAITMti4lj9Kl5gAAAFFAJywCsd1228mJJ57otiCPRMjEIg+LPCzy8JGJRR7ZpbKXm0flUnPat0UePjKxyMMiD4s8fGRikUdw6IRFIOrXry/77LNPug8jY5CHj0ws8rDIwyIPH5lY5JFdKtuxGoUOWEX7tsjDRyYWeVjkYZGHj0ws8ghONCozZJy1a9fKtGnT3BbkkQiZWORhkYdFHj4yscgDUUb7tsjDRyYWeVjkYZGHj0ws8ggOnbAIxKpVq+Rvf/ub24I8EiETizws8rDIw0cmFnkgymjfFnn4yMQiD4s8LPLwkYlFHsFhOgIAAAAAAIBKyGvWIiX7AMg+dMICAAAAAABsQ6ykRJr2Pa3S++bkcvExgC14RwAAAAAAANiGZDpV6YAFUB7vCghEnTp1pH379m4L8kiETCzysMjDIg8fmVjkgSijfVvk4SMTizws8rDIw0cmFnkEJycWi8UCvP+sUVBQ4Lb5+fnpPhQAkGUT7pWipfO3+v1aO7SR5qdcltR9/jhhpmxYuqbCferu0Eh2OWU/CVseqm6HrtL0iNPlhYmzZOmyilcC3aF5Qzn1mG4pPkpkcvuoymsG6RP2uizsxw8gWoL4nAxzXQlUZOXk56R4+eJtzhlc2WktEK26jDlhEYiSkhLZtGmT1K5dW3K5DIM8EiATizws8rDIw0cmFnkgymjfFnn4yMQiD4s8LPIILpOozBlMGwkOaSIQixYtkhEjRrgtyCMRMrHIwyIPizx8ZGKRB6KM9m2Rh49MLPKwyMMij+AyicqcwbSR4DASFgCAMpo1aZCSfQAAAAAAiKMTFgAAvSRoQ6GUlMTkiF57Vmp/3Tc3Nyfw4wIAAAAAhF/mjn8GAKAGlaxfnVSnKh2wAAAAAIDKYiQsAKBSajdrkJJ9gEyjK9SmYh8AAAAA2JqcWCwW2+p3UWkFBQVum5+fn+5DyQjFxcVSWFgo9erVk7y8PMl25OEjk2DzWDbhXilaOn+r36+1Qxtpfspllb6/WElMcio58jOZfTMlj6pkUpN4vQSXSTIr02byKra0kWjVZWE//lSjfVvk4SOTYPNYOfk5KV6+eJsnKyu7Krz6ccJM2bB0TYX71N2hkexyyn5SXbQPizx8ZGKRR3B1GSNhEQh9oTZs2DDdh5ExyMNHJuHKI5lO1ep2wIYhj5pGHsFlEpVVbGkjiDLat0UePjIJLg89AVnZztVMPVlJ+7DIw0cmFnkEJ/PeIREJy5Ytk+eee85tQR6JkIlFHhZ5WOThIxOLPBBltG+LPHxkElweUThZSfuwyMNHJhZ5BCcz3yURehs2bJCvv/7abUEeiZCJRR4WeVjk4SMTizwQZbRvizx8ZGKRh0UeFnn4yMQij+DQCQsAAAAAAAAA2d4Jq73vw4cPl4MOOki6desmV1555TaHRf/0008yaNAg2XfffaVXr15yzz33uMmFE3nzzTfl8MMPD+joAQAAAAAAAGSzUHTCDhs2TD788EO577775IknnpDvvvtOBg8evNX9N23aJOeff77791//+lf38zqfxf333+/tO3nyZPnTn/4U6PEDAAAAAAAAyF61JMMtWrRIXn31VXnooYdk//33d7eNGjVK+vXrJ7NmzXIjY8t7++235eeff5YXXnhBmjZtKnvssYf88ssv8pe//EV+//vfS506dWTNmjVyyy23uFGw7du3l9WrV6fht4uuxo0by5FHHum2II9EyMQiD4s8LPLwkYlFHogy2rdFHj4yscjDIg+LPHxkYpFHFnfCzpw5020PPPDA0tvatWsnLVu2lOnTpyfshJ0xY4Z07tzZdcDG6c9rx+uXX34pXbp0cdMVLFiwQCZMmOBGw77yyis19Btlh0aNGrnpI7AZefjIxCIPizws8vCRiUUeiDLat0UePjKxyMMiD4s8fGRikUcWT0egI2GbNWsmdevWNbe3aNFCFi5cmPBn9PZWrVp5+yvteFUdO3Z0UxvstddegR17Nlu/fr188cUXbgvySIRMLPKwyMMiDx+ZWOSBKKN9W+ThIxOLPCzysMjDRyYWeUR4JKyOSO3Tp89Wv3/ZZZe56QPK005ZXbArkcLCQmnSpIm3v9raz6RCLBaTdevWBXb/YaKd5y+++KKcddZZbtRytiMPH5kEk0dOTo7Ur1+/0vvrB6u+d2WadOWRqZnwevGRiUUelr6G9fUfZtSVW9C+LfLwkUl48khHbZbJeaQDefjIxCKP4OrKtHfC6hM6ceLErX7//fffl40bN3q3a2fq1t6869Wr5/1MvPO1QYMGEhRdEEynO4DIypUr3XbevHmybNkyyXbk4SOTYPLQ98VOnTpVen99vEw8w5muPDI1E14vPjKxyMOX6CR+mFBXbkH7tsjDRybhySMdtVkm55EO5OEjE4s8gqsr094JW7t2bbcw1tZ89dVXsmLFCtepWvaXXrx48VZ75HUqgq+//trcpvurIHvx9Xfp0KFDYPcftjMnU6ZMKZ2/N9uRh49Mgskj2TN0+niZNuoznXlkaia8XnxkYpGHNXfuXAk76sotaN8WefjIJDx5pKM2y+Q80oE8fGRikUdwdWXaO2G3Zb/99pOSkhK3QFd8YmDtjddG0b1794Q/o7e/+uqrbiEunVBYffLJJ9KwYUM3F2yQHyhBjrQNEx2NHN+SCXkkQiaZkUeyl4NlQ/vIxEx4vfjIxCIPK+xTESjqyi1o3xZ5+Mgk2nlUtzaLWh7VRR4+MrHII7i6MuMX5tJe92OPPVaGDh0qU6dOlc8//1yGDBkiPXr0kK5du7p9dJTskiVLSqcg6Nu3r+y4445y+eWXy5w5c2Ty5MkyatQoOe+880J/aVpY1KpVy41I1i3IIxEyscjDIg+LPHxkYpEHooz2bZGHj0ws8rDIwyIPH5lY5BGcnFimXXOZgC5KcNttt8nbb7/t/n/wwQe7TtlmzZq5/2vnrE4Y/OSTT8oBBxzgbvvhhx9k+PDhMmPGDGnatKmcfPLJcumll0purt/vfN9998krr7wi7777bpWPsaCgwG3z8/OrfB8AkCorJz8nxcs3T8OSSF6zFtK072mSLZZNuFeKls6vcJ9aO7SR5qdcVmPHBCA4Ya/Lwn78ALAtP06YKRuWrqlwn7o7NJJdTtmvxo4JAIKuy0LRCRsGFMsAMkWspERyEpxwqup+UUAnLJBdwl6Xhf34AWBb6IQFkI11WXb89Y0at2DBArnlllvcFuSRCJkEl0dlO1YzuQOW9mGRh49MLPJAlNG+LfLwkYlFHhZ5WOThIxOLPIKTuX+BI/SKi4vTfQgZhTx8ZGKRh0UeFnn4yMQiD0QZ7dsiDx+ZWORhkYdFHj4yscgjGHTCAgAAAAAAAECAWOoMABB5uhBZKvYBAAAAAKAq6IQFAESaLkDWtO9pld43k+fKBQAAAACEU04sFoul+yCigFVsrU2bNsny5culWbNmUrt2bcl25OEjE4s8LPKwyMNHJhZ5RKsuC/vxpxrt2yIPH5mEL48fJ8yUDUvXVLhP3R0ayS6n7JcVedQk8vCRiUUewdVljIRFIPSF2qIFl/bGkYePTCzysMjDIg8fmVjkgSijfVvk4SMTizws8rDIw0cmFnkEh2suEYgVK1bI66+/7rYgj0TIxCIPizws8vCRiUUeiDLat0UePjKxyMMiD4s8fGRikUdw6IRFINavXy+zZs1yW5BHImRikYdFHhZ5+MjEIg9EGe3bIg8fmVjkYZGHRR4+MrHIIzh0wgIAAAAAAABAgOiEBQAAAAAAAIAAsTAXAAAAAACoMbWbNUjJPgAQJnTCIhANGzaUnj17ui3IIxEyscjDIg+LPHxkYpEHooz2bZGHj0zClUesJCat+u5V6X1zcnMinUdNIw8fmVjkEZycWCwWC/D+s0ZBQYHb5ufnp/tQAAAAslrY67KwHz8AAEBUFKSwLmNOWARiw4YN8v3337styCMRMrHIwyIPizx8ZGKRB6KM9m2Rh49MLPKwyMMiDx+ZWOQRHDphEYhly5bJE0884bYgj0TIxCIPizws8vCRiUUeiDLat0UePjKxyMMiD4s8fGRikUdw6IQFAAAAAAAAgADRCQsAAAAAAAAAAaITFgAAAAAAAAACRCcsApGbmyuNGzd2W5BHImRikYdFHhZ5+MjEIg9EGe3bIg8fmVjkYZGHRR4+MrHIIzg5sVgsFuD9Z42CggK3zc/PT/ehAAAAZLWw12VhP34AAICoKEhhXUa3NgAAAAAAAAAEiE5YBGLRokUyatQotwV5JEImFnlY5GGRh49MLPJAlNG+LfLwkYlFHhZ5WOThIxOLPIJDJywCUVJSIqtXr3ZbkEciZGKRh0UeFnn4yMQiD0QZ7dsiDx+ZWORhkYdFHj4yscgjOHTCAgAAAAAAAECA6IQFAAAAAAAAgADRCQsAAAAAAAAAAcqJxWKxIB8gWxQUFLhtfn5+ug8lI2zYsEEWLFggrVu3lrp160q2Iw8fmVjkYZGHRR4+MrHII1p1WdiPP9Vo3xZ5+MjEIg+LPCzy8JGJRR7B1WV0wqYIxTIAAEBmCHtdFvbjBwAAiIqCFNZlTEeAQKxatUomT57stiCPRMjEIg+LPCzy8JGJRR6IMtq3RR4+MrHIwyIPizx8ZGKRR3DohEUg1q5dKx999JHbgjwSIROLPCzysMjDRyYWeSDKaN8WefjIxCIPizws8vCRiUUewaETFgAAAAAAAAACRCcsAAAAAAAAAASITlgAAAAAAAAACBCdsAhE/fr1pVu3bm4L8kiETCzysMjDIg8fmVjkgSijfVvk4SMTizws8rDIw0cmFnkEJycWi8UCvP+sUVBQ4Lb5+fnpPhQAAICsFva6LOzHDwAAEBWprMsYCYtAbNq0SRYvXuy2II9EyMQiD4s8LPLwkYlFHogy2rdFHj4yscjDIg+LPHxkYpFHcOiERSCWLl0qDz74oNuCPBIhE4s8LPKwyMNHJhZ5IMpo3xZ5+MjEIg+LPCzy8JGJRR7BoRMWAAAAAAAAAAJEJywAAAAAAAAABIhOWAAAAAAAAAAIEJ2wCExeXl66DyGjkIePTCzysMjDIg8fmVjkgSijfVvk4SMTizws8rDIw0cmFnkEIycWi8UCuu+sUlBQ4Lb5+fnpPhQAAICsFva6LOzHDwAAEBUFKazLGAkLAAAAAAAAAAGiExaBWLJkiTz88MNuC/JIhEws8rDIwyIPH5lY5IEoo31b5OEjE4s8LPKwyMNHJhZ5BIdOWASiqKhIFi5c6LYgj0TIxCIPizws8vCRiUUeiDLat0UePjKxyMMiD4s8fGRikUdw6IQFAAAAAAAAgADRCQsAAAAAAAAAAaITFgAAAAAAAAAClBOLxWJBPkC2KCgocNv8/Px0H0pGWL9+vXz33Xey++67S/369SXbkYePTCzysMjDIg8fmVjkEa26LOzHn2q0b4s8fGRikYdFHhZ5+MjEIo/g6jI6YVOEYhkAACAzhL0uC/vxAwAAREVBCusypiNAINasWSMff/yx24I8EiETizws8rDIw0cmFnkgymjfFnn4yMQiD4s8LPLwkYlFHsGhExaBWL16tUyaNMltQR6JkIlFHhZ5WOThIxOLPBBltG+LPHxkYpGHRR4WefjIxCKP4NAJCwAAAAAAAAABohMWAAAAAAAAAAJEJywAAAAAAAAABIhOWASibt26sscee7gtyCMRMrHIwyIPizx8ZGKRB6KM9m2Rh49MLPKwyMMiDx+ZWOQRnJxYLBYL8P6zRkFBgdvm5+en+1AAAACyWtjrsrAfPwAAQFQUpLAuYyQsAlFcXCxr1651W5BHImRikYdFHhZ5+MjEIg9EGe3bIg8fmVjkYZGHRR4+MrHIIzh0wiIQixcvljvvvNNtQR6JkIlFHhZ5WOThIxOLPBBltG+LPHxkYpGHRR4WefjIxCKP4NAJCwAAAAAAAAABohMWAAAAAAAAAAJEJywAAAAAAAAABIhOWAAAAAAAAAAIUE4sFotJhtuwYYOMGDFC/v73v0thYaEcfvjhcv3110vz5s23+jM//fST3HzzzTJ9+nRp0KCBnHzyyXLppZdKXl6e+77ez/333y9vvfWWLF++XNq1ayeXXHKJ9OnTp0rHWFBQ4Lb5+flV/C2jpaSkRDZt2iS1a9eW3Fz6+snDRyYWeVjkYZGHj0ws8ohWXRb240812rdFHj4yscjDIg+LPHxkYpFHcHVZKNIcNmyYfPjhh3LffffJE088Id99950MHjx4q/trYzn//PPdv//617+6n3/uuedcp2vcLbfcIm+88YbceOON8uqrr0rfvn3lD3/4g0ydOrVGfqeo0xdq3bp1ecH+D3n4yMQiD4s8LPLwkYlFHogy2rdFHj4yscjDIg+LPHxkYpFHcDI+0UWLFrlO0qFDh8r+++8v++yzj4waNcqNcJ01a1bCn3n77bfl559/lr/85S+yxx57uA7WIUOGuA7cjRs3yvr169196m2HHHKItG3bVi6++GLp0aOHvPTSSzX+O0bRL7/8Ik8//bTbgjwSIROLPCzysMjDRyYWeSDKaN8WefjIxCIPizws8vCRiUUeWdwJO3PmTLc98MADS2/TqQNatmzpOmITmTFjhnTu3FmaNm1aepv+/Jo1a+TLL7+UnJwceeihh+Tggw82P6e9/KtWrQrsd8km2tn97bffui3IIxEyscjDIg+LPHxkYpEHooz2bZGHj0ws8rDIwyIPH5lY5JHlI2GbNWvmhkKX1aJFC1m4cGHCn9HbW7Vq5e2vFixYIPXq1ZNevXrJdtttV/r9zz//XD755BPp3bt3IL8HAAAAAAAAgOxUK90HoAtoVbQY1mWXXSZ16tTxbtdOWV2wKxFddKtJkybe/irRz+gcs7ool051cOqpp0pV6Rpn69atq/LPR4k+B/EtmZBHImRikYdFHhZ5+MjEIg+/JtMrn8KMunIL2rdFHj4yscjDIg+LPHxkYpFHcHVl2jthdVqBiRMnbvX777//fsIh0NqZWr9+/YQ/oyNdy/9MvPO1QYMG5vZPP/3UzQerI2d1igJd/a2qdEEwne4AIitXrnTbefPmybJlyyTbkYePTCzysMjDIg8fmVjk4Ut0Ej9MqCu3oH1b5OEjE4s8LPKwyMNHJhZ5BFdXpr0TVjs927dvv9Xvf/XVV7JixQrXqVr2l168eLHrwE1EO1S//vprc5vur8r+zKRJk+Sqq66SLl26yAMPPCCNGzeu9u/SoUOHat1HVOjZEn2+Onbs6HV8ZyPy8JGJRR4WeVjk4SMTizysuXPnSthRV25B+7bIw0cmFnlY5GGRh49MLPIIrq7Miem42gyfE/aQQw6Rxx9/XA466KDS3vh+/frJ888/L127dvV+5q233pLrr79ePvzwQ2nUqJG7Tfe944473Lyv2pjeffddufTSS91UCHfeeWe1e7ULCgrcNj8/v1r3AwAAAMnquizsxw8AABAVBSmsyzJ+YS4duXrsscfK0KFDZerUqW4BrSFDhkiPHj1KO2B1lOySJUtKpyDo27ev7LjjjnL55ZfLnDlzZPLkyTJq1Cg577zzXGerDq2+9tprpXPnzq6zVv+vP69fOuoW1bd+/Xr3XOkW5JEImVjkYZGHRR4+MrHIA1FG+7bIw0cmFnlY5GGRh49MLPIITsZ3wqqbb77ZjYL9wx/+IOeff77svvvuMnr06NLvz5o1S3r16uW28UW4HnvsMSkpKXELbQ0fPlxOP/10N/er+uCDD2TVqlXy2WefycEHH+x+Nv6lo2NRfdqZ/corr9Cp/T/k4SMTizws8rDIw0cmFnkgymjfFnn4yMQiD4s8LPLwkYlFHsFJ+5ywlaFzUNxyyy3uK5EDDjjAzR1bVtu2bWXcuHEJ9z/uuOPcFwAAAAAAAAAELRQjYQEAAAAAAAAgrOiEBQAAAAAAAIAA0QmLQNSuXVt23nlntwV5JEImFnlY5GGRh49MLPJAlNG+LfLwkYlFHhZ5WOThIxOLPIKTE4vFYgHef9YoKChw2/z8/HQfCgAAQFYLe10W9uMHAACIioIU1mWMhAUAAAAAAACAANEJi0AsWLBAhg8f7rYgj0TIxCIPizws8vCRiUUeiDLat0UePjKxyMMiD4s8fGRikUdw6IQFAAAAAAAAgADRCQsAAAAAAAAAAaITFgAAAAAAAAACRCcsAAAAAAAAAAQoJxaLxYJ8gGxRUFDgtvn5+ek+lIxQVFQkq1atkiZNmkitWrUk25GHj0ws8rDIwyIPH5lY5BGtuizsx59qtG+LPHxkYpGHRR4WefjIxCKP4Ooy0kQg9IXavHnzdB9GxiAPH5lY5GGRh0UePjKxyANRRvu2yMNHJhZ5WORhkYePTCzyCA7TESAQy5cvl5dfftltQR6JkIlFHhZ5WOThIxOLPBBltG+LPHxkYpGHRR4WefjIxCKP4NAJi0AUFha6Idu6BXkkQiYWeVjkYZGHj0ws8kCU0b4t8vCRiUUeFnlY5OEjE4s8gkMnLAAAAAAAAAAEiE5YAAAAAAAAAAhQTiwWiwX5ANni008/FY2yTp066T6UjFBcXFy6ml5eXp5kO/LwkYlFHhZ5WOThIxOLPKyNGzdKTk6O7LvvvhJG1JUW7dsiDx+ZWORhkYdFHj4yscgjuLqSTtgUmTVrliuWa9eune5DAQAAyGqbNm1yxXK3bt0kjKgrAQAAoldX0gkLAAAAAAAAAAFiTlgAAAAAAAAACBCdsAAAAAAAAAAQIDphAQAAAAAAACBAdMICAAAAAAAAQIDohAUAAAAAAACAANEJCwAAAAAAAAABohMWAAAAAAAAAAJEJywAAAAAAAAABIhOWAAAAAAAAAAIEJ2wAAAAAAAAABAgOmEBAAAAAAAAIEB0wlbB66+/Lqeeeqp07dpVunXrJv/3f/8nf/3rXxPu++abb8rhhx9ercdLxX2U99NPP8mee+4pU6dOrbFM9LH0MZ988skq/T6FhYVy1113uZ/VxzjppJPkH//4R0qOv+zxaTY11UZefvll95hVyWP9+vVy8803S69evaRLly5yxhlnyL///W/JxDayrTziz23Pnj3dY/bv379az+3DDz8sZ555pqRSKttHZTO58MIL3WNWtb2vWLFCbrjhBjn44INl3333ldNOO01mzJghqRJvv6lQ2Tay//77S8eOHauUxy+//CJXX321HHjgge4xNN9vv/1WwvgeEn/9ax76mNV9/Wf650xl8+jRo4d7zJNPPjnpPML0GVPZTM455xz3mFX9jAjT50y6nodUoK70UVda1JUWdaWPutKirrSoK6uWySWXXOIec5999qlSJlH6nElFGwnT50ygz0EMSZkwYUKsa9eubvvdd9/Fvv3229iTTz4Z69y5c+y+++4z+77zzjux/Pz82GGHHVblx0vFfSRSVFQUW7x4cWzDhg01lsknn3wS22OPPWJ77713lX6f66+/PnbIIYfE3nvvvdj3338fu//++2MdO3Z095sKmoVmotnUVBu56aabXCZVyWPIkCGxI488MjZ16lSXx7Bhw9zjLly4MJZJbaQyecSf24cfftjlcfvtt1f5uX366afdzw4YMCCWSqlqH8lk0r17d5dHVdv7ueeeG+vfv39s+vTp7nGGDx8e22effdzjpcL69etdJtWVTBu58sorY717965SHr/97W9jp5xySuyzzz6LzZ07N3bppZfGevXqFVu3bl21f4eafg+Jv/5Hjhzp2kh1Xv+Z/jmTTB7jx493eVx11VVJ5xGWz5hkMjnooINK30Oq0kbC8jmTjHgt8uOPP8YyAXWlj7rSoq60qCt91JUWdaVFXVn1TLRtaB7aLqqSSZQ+Z1LRRsLyORN0XUknbJJOPPHE2M033+zdro1RP9jU6tWrY9dee61rtMcff3yV3oBScR+Zlsl5553nGujRRx+d9O+jH2aaxWuvvWZuP+uss2JXX311LKxtZK+99qpSsaxvMH/84x9j//rXv0pvW7VqlbuviRMnxsKUR9nntuybWLLPrb55Dxo0yL2R9+vXL+XFcjoyGTp0qMsjLplM9INNf3bGjBmlt5WUlMT69u0bu+eee2JhbSOjR48ufb0kk8eKFSvcB/9XX31VetuXX37pMtLiOUx5lH39v/TSS+53qMrrPyyfM8nkEX8PiT+3lc0jTJ8xyWRyxx13lL6HJNtGwvQ5E+ZOWOpKH3WlRV1pUVf6qCst6kqLurLqmYwdO7b0PSTZTKL0OZOKNhKmz5mg60qmI0hSbm6uzJo1S1auXGlu18sPnn/+efdvHYq8YMECmTBhgvTt27dKj5OK+/j888/l9NNPd8PJu3fvLpdeeqn8/PPPCYdqFxcXy9133+2GhusQ9MGDB8utt95aeumN7tepUyd5//333SU9e++9t/Tr108mT55cmsmPP/4oQ4cOld69e0vnzp3dsR900EFu2Lk+3rJly9x96aVBycrJyZGHHnrIXf5Slj72qlWrKn0/evx6GYAOf9dj++Mf/1j6XJYfSq7HfeONN8oBBxzgLrm5/vrr5corr3Q/E79k5ogjjijdaiZ63/pz8TaieV9xxRXuscaNGye1atWSkSNHyn//+1/3/F588cVSFXl5eXL77be7+1Vr1qyRRx55RBo2bOiev0xqI3ps8Tz0K95GNA910003yb333lvt5/aLL76Q2rVru0sp9PmtippoHzNnzix9zXz11Vel7UNfM6+++qoceeSRenLMtffyl2Qlk0mzZs1cm8jPzzevI/1KJlc9pmOPPdbdjz5v+pxv3Lix9Hcse4z6GtffRy9T0VzuvPNOOeuss+S+++5z39etXh6tx6XPt97ngAEDZNOmTaVt5Ouvv5ZBgwa59vj4449LvXr13KWm1X39N23a1F0OtMcee5Qe6/jx46VVq1bSoUOHUL2HjBo1yj0P8de/qsrrPyyfM9t6D9GM9fLIsnno5VPJ5BGmz5jKvIfo76OfEfG2XZXPiDB9zmgtEle2jWgmevz6f807E1FXUldSV1JXKupK6krqysz5nNE2qe+Jeptau3Zt0plE6XMmFW0kTJ8zkwOuK+mETdLAgQNl9uzZ7sWkBbI2HG0IjRs3lnbt2rl9dF6ZJ554Qvbaa68qP05170MbXPwDR4sH/VDQxvmnP/0p4f76oabFvr5oX3rpJdlxxx3lqaee8u5TCz19Mes8L/qhc+2117pGrJnoh/zf/vY396arxY8+ls55overv0/8xV8V+oGpL57tttuu9DbN/ZNPPnEviMrQD8c//OEPbn6TiRMnypgxY2T69Onyl7/8JeH++rt99NFH7oWrf9CvXr1a3nrrLbOPftDo9zSXV155RerXr+/eVONtRF/M+m/N4u9//7trM4899ph7LvT53WmnnaS69M19v/32k0cffdQ9N61bt86oNrJo0aLSPI4++mj3Jnf55ZfL22+/7d7A3njjDfcBWPa5nTNnTlLPrdK5drQY22WXXaQqaqp96Ovg/PPPd5n85je/kY8//ti1k3vuucfdrh/+//rXv1x7b9CgQZXbe5MmTeSQQw6ROnXqlN6mmf/www+Vvg99HvQ50g83/dnbbrtNXnvtNdeGyyspKXHtSe9fv68f2jrHz7Rp08x+OneY/sGg753PPvusm09LfzbeRjT/xYsXuz+itA0dd9xx7oN/++23r9brv6w///nP7gNUny/9IC6bc1jeQ95991338//85z/dNtnXf5g+Z7b1HqJ/0MU7q/Q4lGaaTB5h+oypzHtIvH3EVeUzIkyfM5ql/oGkNB/NRvPXNnLdddeZNpJpqCupK8uirqSupK7cjLrSR11Zs58zZR1//PFJZxK1z5lUtJGwfM5cG3RdmdRYWzizZs2KXXHFFbEePXq4ocf6pXNblL08I67sJQ5VVZX70Esk9txzTzePUXFxsbvtv//9rzt2pcOl4/Ob6FB5nc/nueeeM5eX6LD0+KU38WHWOsdL+UsuPv30U3e/uv9+++1nMjnmmGNi1113nbmPW265pdqZ6DwlOufOqaeeGtu4cWOlfmb27Nnu8d99993S277++mv3e5Q9Ps1Gs9J/f/DBB6X7FhYWxnr27Okus1Dxofh6v3GaT/wxBg8e7HIt30Z+/etfx8aMGWPuozp56OVBX3zxhbtcQOeYKfv7ZUobef75591rpkuXLl4eOpdS+Tai8xgm89yWp89RspeN1WT7WLRokZsL5ze/+U1s//33N5noJR/l20dV2nt5M2fOjHXr1i32hz/8odI/o8erc+19/vnnpbfpv3WuoLLHpz7++OPSY41bsmSJmxNK38OUbrXNaduL0zk89VIdbXeXXHKJ95qJ3+8rr7xSeh+aRXXy+Oabb2IFBQXukhh9vP/85z+hfQ+Jz3eX7Os/bJ8zlX0P0Uu+9Hs33HBDtfLI9M+YZN9DqvIZEbbPGa1F1FNPPRWbM2eOOY5EnzOZMh2Boq7cjLqSupK6krqSupK6MhM/ZzSH6mYSlc+ZVLSR77O8rqxV9e7b7KVDmfVLz7LpGT09A/v000/LBRdcIO+88447s5ZueomEjq7Q1edGjx7tVm3Us5d6xrg8XcVRV+4rOwxch8/r2Qn9/crafffdS//dqFEjt9VLPnRF6hdffNEN3dYMCgoK3JlLzSh+mUaqfPrpp+5yK73cQ8+i6KVClaFn5fTMzu9//3t3FkQvXzv00EPdUPzy9GyH0mHucXXr1nUrI5bXvn370n/ryBWlv7OeTdNc9dKX9957z13WpCsA6iVBmkuqtG3b1m11KP2XX37pHu+www7LqDay2267udUWi4qK3NmnSZMmyX/+85/SPOI/880335Re8pTMc5sKNdk+4q+ZF154wZ3V/OCDD1z70MsJtW3o5Rll6SUXybb3svR1edVVV7nLUvSMYGXpWVr9HXWl+Z133tll0qdPH3epRqJMtE2Vff532GGH0pFcZW/T/cpmonlo29IzjHomVkc7fPjhh65tnX322W6/+GtGz94uXbrUXWpS1Tzil4npaIXPPvvMvX/r5TFhfA/RPJU+v8m8/lMhE99DWrZs6bb6eayXJFUljzB8xiT7HqKfD8l+RoTtc0Yzib9f6mgNHd3x/fffy9y5c11bKPszmYa6cjPqys2oK6krFXUldWX5PBR1ZXo+Z371q1+5HKqaSZQ+Z1LRRtpmeV3JdARJWLhwoQwfPtxt4/N5aMO56KKL3FBoHbKsw8Mzhb4wtMHoJTr6wtHGqkPZ4/PuxOk8H0r32Zayl6DExYeB69BwvaxE/wjWN5n777/ffV8/2FJFiyyd+0ffCLXo0qIqGTp3j15yoC/e5cuXy9VXX+0u1Uk0Z4mqTFFbNpP4/GR62cu6devci1Yvi9I3TJ1bRTMue0lCVWlb08sDVqxYYW6PX6aVKW1kyZIlbhu/NEhfK3qZir756aVIZQtlfW5HjBhR+jwl+9ymQtDtI04vEZs3b5787ne/c5dP6R8Tl112mbskQ8XntdE/KFRV27vSQlCz1g82/dDXD+PK0n113iz90Pntb3/rPni0CEh0yYdmUpU84nMa6fuqtpcTTjjBFcp6GeA111xj9tU2opd/aHtMNg99berlOPoHW5y+h2vhrK/XML2HaAGiBUB1X/+pkAnvIfr6mT9/fkryyPTPmMq+h+iluPoZoW2oqpmE5XMmLv4HgtYit9xyi7u/Y445Rh5++GHXUZCJqCupKxOhrrSoKy3qSou60kddWf3PGf299T2x/AmMKNaWNdVGwvI5UxN1JZ2wSdAnR+fVic85V36enLJnBtLtu+++c3Nf6OiJ0047zZ0p0Lk89IxA+Z5/PROhc5boPDtl6Zm8ytCzJGPHjnVnXfXsib4wdN6U+BmkRI26KvTFpm8EevZHHy9+1qay9PfRN1ktzuKTuOv/dV4WLebK0rOheqakbCb6wtazQRWJn9XSM2r6ga/7a7Ghk0DrWSylc7NU5s2gIvqGMGTIEPdGVpbOM1PZyeBroo3En3udi0rPcpVtIzpvldLs4xOAx89Uxc9A1aSaaB9xOkrhgQceMO1D39RbtGjhvq9z82h7f+6559z/q9Lelc6NpR9MegZT579K9rWoo7F0FIF2Cuh8QPFj1eNPNA+Utm1tP3FaKOgZ5YrEPyD1fVXn4dEPZv29tRA66qijzNldbSP6h4W+zyabh/7Rrq8ZnSstTs9w6v2WPRschvcQLQh1TqLqvP5TIVPeQ7SdaUdVdfMIw2dMZd9DdJEDbe86qqOqmYTlc6as8m1Ea5Fdd93VjQar7uduEKgrE6Ou3IK60qKuTIy6cgvqSou6smqfM/qa0ee3/BzEUawta6qNhOVzpibqSqYjSELz5s3dGQh9ErQnX1dO0w91PSugH3y6Cp2u3pgJ9AyLnp3TIdj6Iadn5vSsY/yyjrJnIPRNRien1kasw9z1g0MvZ9EGqsP0t0VXuNQPN33R69lRfUz9ANJMyv4hUR16VlMnSNYV6XTS5LKrCOsbR2VGAehzpcWD7q+XMG3YsMF96OuHb/kzUjoJvw5r10JDJ3LXXPSsh55V1d9za+JvrDqkXl+kSt/E9MWql8Lo97WgKH+mJll6P/o7aFvUyxr0/nWCbX3OdJspbSR+eZBOhK1nv/UMnf6crlSqZyD1GLSg0gn19bnVok47U/SMnO5f2ec2FWqifcTpSIV4IayjFHQyeF2R8sEHHyx9frW9t2nTxo1oq0p71xER+iGtl6voGbyyI4f0A6kyRYA+lp4R1mz0cjE9Di1ayl7mEqfvf7pqp44y0AUK9DF0knNdObKiTLSzSGlb1lEVegb2mWeeccen2Wjb0/vQjgptI/rY+uEdHw1T2Ty0qNLJ5vVMpn5p29TnTC9T06KmMjLpPUQvT9LMdIEJpc91Mq//VMik9xDNR/OIP5f6+ZNMHmH5jKnse4jenx5DvHNPi9ZkPyPC8jlTlv4hrX+A64gRrdn0/nWklr5fVPdzNwjUlYlRV25BXWlRVyZGXbkFdaVFXVn1zxl9TvS9RunrRnOLYm1ZU20kLJ8zNVFX0gmbJB32rI1en0B9Q9cGoCuRaoPXD6RMoQ1UP2h0+Lo2dl31Tc8G64tLX8zlh4HrJSt69k5XrNQPJv3Q0g9HfaFvi87ro8PVtUHq0HX9o0+LIj2DqY85ZcqUav8+egZCP9T0RaMfeGXpi6j8KneJ6AtPVznVM7D6ZqYvWp1HRHPSf5enb2D6oRq/vEnfcPSDujJzuOiZEj2bpAWfvvnpG1/8jUeH25cfnVQVeumOvuHopYxaCOkbvBagieZVSncb0UsmtCDW7HTuHf3SPPQsvc7FpM+vPrf6+lKnnHJKUs9tKtRk+zj33HMlPz/fPZ5eRqfPm77B65w9OmpBR3hoe9cvpStrxlU2Ez1bqc+XznGkX2WdeOKJpZfoVeTXv/61m99KP4B1lU0tgHXena2tSK2/j37oa/GpbV8vZ9HOn8pkoo+j76u6r86jpa8Zbd96qaFeKqb3o20kfvYynkkybURHbWh71zPSWkxo54a+j1d2NelMeg/RS4b0uYgXLXoWOZnXfypkynuIFlm6kq0eg76elJ4NTyaPsH3GbOs9RD9j9HG18NZVbHWEWLKfEWH7nFF6OaG+t2ku+trWoltHn+h7UnxV30xDXemjrvRRV1rUlRZ1pY+60qKuTP5zRjv79ASpfk/naNcsolxb1kQbCdPnTKB1ZaWX8EKkTZo0KfbLL7+Y284999zSVd+yja4kqKvkrV692tyuKwTGVwbMNrSRLWgfPm0burJl2dU+N2zYEOvatWvpCrTZhDbi4z1kC9pHYrSR6OC5tHjN+2gjW9A+fNSVFm3Ex3uIRRsJTxthJCwcnaNEz67oJR96FkFHFelcI3qmMhvpHEd6hkbPUukcQnpmTM+y6xxTerlgNqKNbEH78OmICx0JoJfE6Rw9etZR24xmVf7sbzagjfh4D9mC9pEYbSQ6eC4tXvM+2sgWtA8fdaVFG/HxHmLRRsLTRnK0JzatR5Bl9JIKnbeiIjpXjl6uEeR9lPfTTz+5odY6b5JeCqeTI+tqlTrvT9BS8fvosU6dOrXC+3j55ZelXbt2SU3ErHMP6VB7Hequk8jrZU3du3eXINFGUv/cRql9pOr30Tl/dH6jiuhjJLPogn6o6Qq9X331lbtERleO1EtbdKL4INFGLN5DLD5jfLSR6OC59PGat2gjFjWDj7rSoo1YvIf4+JyxaCPJoRO2hunE8DpnTEV07h6d4y7I+8gkqfh9dJ4SfWFVROfnqcx8KOlGG0n9cxul9pGq30fPiuqogorohOmVWRAi3WgjFu8hFp8xPtpIdPBc+njNW7QRi5rBR11p0UYs3kN8fM5YtJHk0AkLAAAAAAAAAAHyl1QDAAAAAAAAAKQMnbAAAAAAAAAAECA6YQEAAAAAAAAgQHTCAkBEpHqKb6YMBwAAyE7UlQCQenTCAkCG+/rrr+WKK66Qnj17yt577y29evWSyy+/XObMmVO6z8yZM+XCCy9MyeNt3LhRbrvtNnnjjTdScn8AAADIDNSVAJA+dMICQAb75ptv5Le//a2sWLFChg4dKuPGjZNrrrlGfv75Zzn11FPl3//+t9tvwoQJ8u2336bkMRcvXixPPPGEFBUVpeT+AAAAkH7UlQCQXrXS/PgAgAo8/vjj0qxZM3n00UelVq0tb9l9+/aVfv36yQMPPCCPPPJIWo8RAAAAmY+6EgDSi5GwAJDBli5d6ubQKikpMbc3aNBA/vSnP8nRRx8tf/zjH+WVV16R+fPny5577ikvv/yy/PTTT+7fWmxrUd2lSxd56aWX3M9OnjxZTj/9dOnWrZu7DE2//8wzz7jv6c/16dPH/fu6666Tww8/vPQxZ8yYIQMGDHD31aNHD7n22mtl2bJl5rhmzZolZ5xxhnTt2lUOPfRQN/LhnHPOcceo/u///k9+97vfeb+n7nPuuecGkCAAAAAUdSUApBedsACQwbTg1EvEtMDUglYvDYsvbKBF7oknnigXX3yxHHLIIbLjjjvK888/734m7r777pMLLrhA/vKXv7i5v9577z255JJLpHPnzm60g35/l112kZtuukk+++wzadGihYwZM8b97EUXXVT67+nTp7uCtl69enLPPfe4Qn3atGly1llnSWFhodtHj033UaNGjZJLL73UjabQecXiTj75ZFdQ//DDD6W3LViwQKZOnSonnXRSDaUKAACQfagrASC9mI4AADKYjixYsmSJjB071hW0Si8j00UUtFDdZ599ZNddd5XmzZtLnTp13EgBtW7dOrfVEQ06SiDuzTffdAX29ddfX3qbjlw44IADXMGqoxH22msvd7veb6dOndy/77rrLmnXrp08/PDDkpeX527TfY899lg3EkJHKej3GjduLI899pjUr1/f7bP77rubEQr9+/eXESNGyGuvvSaDBw92t+m/GzZsKEcccUTgeQIAAGQr6koASC9GwgJAhrvssstkypQprmDVM/6NGjVyK8zqAgpPPvlkhT8bL3zjBg4c6IrVtWvXyn/+8x+ZOHGiK3Ljq9cmsn79ejeaQUdF6GgJXVhBv3SkQ/v27eWjjz5y+33yySdy8MEHlxbK8UK8TZs2pf/XYvrII4+U119/vfQ2veTtmGOOcaMhAAAAEBzqSgBIH0bCAkAING3a1J3t1y81e/Zsufrqq2XkyJFy3HHHbfXndI6vsnSurRtvvNHN35WTkyNt27aV/fff330vfjlaeatWrXJzh+kiDvpVXt26dUvve/vtt/e+v8MOO5j/a8GvxbLOBaajH77//nu54447KpUDAAAAqoe6EgDSg05YAMhQixYtcpd86YiFU045xXxPL+e64oor3DxcP/74Y6Xv86qrrpLvvvtOxo8f70YT6KVmOiLhhRde2OrP6CVdWljrvFx6mVh58REKrVq1cgs+lPfLL7+4y8fidPEFvSTt73//u+Tm5rrvxS93AwAAQOpRVwJA+jEdAQBkKD3TX6tWLXn22Wdlw4YN3ve16NXRAjrqQIvOytDFDPSyLZ2rSwtl9cEHH7htfKXc+NxccXqZmhbn+nj5+fmlX7/61a/cAgw655fq3r27u7yt7LHqyApdGbcsLbx1sQQdNfHuu++6ucQAAAAQHOpKAEg/RsICQIbSonXYsGFuVIKOXNBFCnSuLB1hoPNl6aq2OppBLylr0qSJGy3w/vvve/N1laULLui8X7qKrY4w+PTTT91Ks1rA6v3G59dSH3/8sXs8XShhyJAhcuGFF8qVV14pxx9/vBQXF8u4cePcnF66iq76/e9/7+YC0/nBzjvvPHe52b333usKeb3/srRY1kJb/eY3vwkwRQAAAFBXAkD65cS2NlkLACAjfPHFF24VWx1toPNj6UgDHUFw5plnutEH6uuvv3aFs15CpqvD6oIEffr0kdtvv90VpnHz58+Xm2++2c2bpXbbbTe3Gq7OpbVixQp58cUX3e26yMLzzz8vtWvXdoW5brV4HjNmjFt4Qf+vBfell15aOveX0vv9y1/+Il9++aWbx2vQoEHy4IMPuuMcOnSo+b30uHRUhhbrAAAACB51JQCkD52wAICU0GJai+iyxbOOWvj1r38t11xzjSvKy85Ldthhh8no0aOlb9++aTpiAAAAZCLqSgBRxHQEAICUjazQ4lcvMdPRDDoC4vHHH3eXocVX39WRDP/4xz/k7bffdqMlDj/88HQfNgAAADIMdSWAKKITFgCQEjpf18aNG+W5556TBQsWSIMGDdyKtXrpWvPmzd0+uriCFtAtW7aUUaNGVXrhBwAAAGQP6koAUcR0BAAAAAAAAAAQIE4VAQAAAAAAAECA6IQFAAAAAAAAgADRCQsAAAAAAAAAAaITFgAAAAAAAAACRCcsAAAAAAAAAASITlgAAAAAAAAACBCdsAAAAAAAAAAQIDphAQAAAAAAACBAdMICAAAAAAAAQIDohAUAAAAAAACAANEJCwAAAAAAAAABohMWAAAAAAAAAAJEJywAAAAAAAAABIhOWAAAAAAAAAAIEJ2wAAAAAAAAABAgOmEBAAAAAAAAIEB0wgJAisRisYy8r0yVDb8jAABAZVBHJicbfkcA0UMnLIBAnXnmmbLnnnvK7373u63uc8UVV7h9/vjHP0omWb58udx+++3St29f2XvvvaVHjx5y9tlnyzvvvGP2W7hwoVx44YUyf/78lDzuhAkT5I477pBMew7LfnXs2FH23XdfOemkk+S1115L+j5nzpzpMku38ePHS8+ePWWfffaRBx54IGX3O3XqVC+zRF8//fRT6b66LU+/X5n7SfSzAACEHXVk8qgjw19Hlq0BX3755YTf31r9qPvr60Xz7dKlixx77LFy7733ypo1a7z7KCkpkVdffdU9R/vvv7907dpV+vfvL/fdd59rvwBSr1YA9wkARm5urvz73/92RWarVq3M99atWyf//Oc/JdMUFhbKGWecIcXFxa7Ia9u2raxevVr+9re/yR/+8Af505/+5App9a9//Uvef//9lD32gw8+6Ar1TNKpUye58cYbS/+vuejzqcXnNddcI9ttt50ccsghSf2B8O2330o6aTGqf6Qceuihct5558nOO++csvvu3LmzPP/886X//+KLL+Smm26SG264wX0vrkWLFhX+0aXfL3s/S5Ysce3voosucscd16FDh5QdOwAAmYQ6MjnUkeGvI6tqzJgx8tBDD7nj0Vqxdu3a8p///Ecee+wxmTJlijz33HPuNrVp0ya57LLLXNv7v//7P/cz9erVk4KCAnnyySddZ67el3b0AkgdOmEB1EjhNXfuXPn73/8u55xzjvmeFs7169eXJk2aSCbRY9Xi7u2335bddtut9HYdzaCF9ejRo2XAgAGSl5cn2aBRo0bu7Hh5Bx98sBx00EGuUEumeM4EK1eudCMA9Dnt3r17oHlt2LChtLM0UY5bU6dOHbO/jopQu+66a1L3AwBAWFFHhh91ZPA2btwojz76qJx//vludHjcr3/9a9l9993lkksukcmTJ8vRRx/tbh81apR88MEH7md0nzh9Pk488UTXPgcPHuxGKmvnLIDUYDoCAIFr0KCBK6y0IC1v4sSJctRRR0mtWvackBY1jzzyiBxxxBHuEi7d56mnnjL76Fl03Ucvm9HLgLS408tvPvnkk9J99HIavY/33ntPjjvuuNL70ktvKrJ06dLS4yhv0KBBcvHFF7tiR4vG6667zt3ep0+f0kvhDj/8cLntttvcKAc9tuuvv97dPmfOHDcC4sADD3QjInv37i233HKLK8jjP6cjI1955ZXSy9XVzz//LEOGDHEjG/TSIr3f2bNnm+NavHixK7p0Hy0GddTl3Xff7e5T6dl6PRYdiVGWXj613377yfr16yVZdevWdR2FOTk5lX7uNCP9/fT3jF9mtbVLqvTyKP2KS5Rr/Gc//vhjdxZf89FLw0aOHOnaSCL6mPFcdDRK2bP82ib18rhu3bq5+9EctdAu36Z0tIFm3atXL/N9AACQOtSR1JHUkZUbmavtIFGb09ePPre77LKL+79ONfDMM8+44yzbARu34447umy+//57efPNN6t9bAC2oBMWQI045phjSi8lK1ss6BlYLX7LGzZsmBslcPzxx7tLYfr16+eKpvvvv790nzvvvNMVfr/97W/dZTY333yzrFixwl1aU7YQ1Eu49VLws846yxV1ernQtddeW+FlTFrUakGvRZoWSXrsetmO0qJNzzLryAu9BEkv91G6nxbVcVrc5Ofnu2M8+eSTXXGrl6bpsY0YMcKdedZ5mrSw1Mt+4vehhY8WS3oZul6OvmzZMvdHgV7S/uc//1nuuusuV2DpfcV/By3k9Vg//fRTVwzqHGRaqI8bN670ePQYdERm+T9i9Ay3Pj/6+1S0+EFRUVHpl97Pd9995/5wWLt2rfzmN7+p9HOnGenvp7+n/o5lL6uvjPK5xl111VXujwB9TG1T2ib0crVE9DE1a6XPX/ySf71P/SNF/xDT30FHDegoFi3g43/gxP+Y0cu39I8TzaBp06ZJ/Q4AAKDyqCOpI6kjK9a8eXPXgTx27FjXPnXUqz73Sqcg+P3vf+86tdW0adPcc6Ad/1ujncM6TcQ//vGPah8bgC2YjgBAjdBiRYuzspeS6cIE22+/vSt4ypo3b5688MILroiJT7qvhYCeJX/44Yfl9NNPl2bNmpWesS97hlvPqF966aXy1VdflV72pMXqrbfe6i6vUXpZ2GGHHeaKn/bt2yc8Xj2jrYXR8OHD3Rlr/dJLcXTSei3Y4pfyaMGjl4arvfbay8wHtdNOO7mCLu7DDz90++jk+HpZltKzzx999JE7C6+/q15ypyMC9H7jx//EE0+4Pwp0Hqc2bdqUXr6lBa/elxZ5r7/+uitmX3rppdICS0dJ6CVScfq76ll5LZZPOeUUd5sW23qWW4v5ikyfPt3MZar0+dhjjz3cMWielX3uNC/9/cpfal9Z5XONj3rQ30mLXaXPtRafOnIl0WIe+vj6XJS9tF9HIeg8aqeeeqobtRCnv6P+oaLZ6lbpHxBa4Gp7AAAAwaKOpI6kjtw2fS51jl0dqa1fmtuvfvUrN/JWO9njnb3xEdLx9rC1uZj1+6laMA7AZoyEBVAjtPDUy3bKnj1/6623XBFa9hIkpZeB6Rlz3b/sWXP9v5611RVRlZ7J14JCz/LOmDHDFTdaRMbP6JdVtkiLL+qgizlU5Mgjj3TFl54J18uTtPjUxRMuv/xyN0eSHmNF4sVZnBaRTz/9tCvwdW4zPbOsxZoef/njLUsvj9L7atmyZWkWWhhpAa3HE89MLzGKF85KC/R4URunE+9rVvGCSi/nateunSuqK6KF84svvui+9Cy/FpT6R8g999zjRigk+9xVR/lc48r/Dvo8b+s5LktHqejzUH5EjRbIWoTqqIHKHAcAAEgt6kjqyGyrI8u368rsp8eso6L1taGdvDpiWJ8rHUWso6a1w1zF2175aTzK0+9vq50CSA4jYQHUGC2UdR4rvZRMC0gtCrUQLU/P1istFhJZtGiR2+rqnTrCQLc6OkIXPdKz26p8wVD2EiktPBPtk4hevqOXlOlX/LF17i29tEgL6/LFafk5zMrSS790Eny9DEqLutatW7tL0jSLimgeP/zwgzeCIE5HaOjcTjoapLzyt+moB72kS0cx6KVwukpvfKRBRRo2bOgu3YrTy530MjH9o0LnxdIRAfFjrcxzVx3lc40rv2iAPs/JFI7x+bh22GEH73t6W/k50DQTAABQM6gjqSOzqY6Mt7mtdbDHb080DYS2Zf3SfHUaDM1Yp9TQ9qOjZeMjYLWDtuzCceX9+OOP7rkCkDp0wgKoMXrGXQsOHcWgBZBeclX2jHtcfIVbvXwqUYGiBbLOAzZw4EB3uZee7dVVP7VY0kvDtLCtLr30SM/s65xYZekoAr0kbdKkSW4UQkXFc3k6j9j48eNdwa+jIxo3buxuLzsfVSK6n07cr5cXJaKXY+lxxc9ul/XLL7+Y/2ueOuJAi2YdhaBFfNl5uCpLi0m91ErnTdM8dDRJZZ+7is7il19MQOcJq6nOzvglWrqYhransnQ+uPhiBgAAoOZRR1JHZlMdqfenz41Om5FIfH5knRs3npmOjP7nP/9pOmb1RIDOe6xtW9tcfFS13re+lnTxsER05K6Osq5o3lgAyWM6AgA1Rj/sdW4pLW61eNvaWe74/Eh6Vl7Pmse/tBDQeaP0LLnOW6VbXSRBz/TGRyXoAg0q0cqgydAzxFqY6Bng8nS+KqXFp4o/9rboJVR6rHopV7xw1jP6X3/9tTne8venhbM+phbzZfPQUQh6WVdeXp7bR+d3+vLLL0t/ThcAmDJlinccWqzrY2qxpnOJaeFdFVqE68gOXTU1folVZZ67RL9jfG6zsgtu6IiCiha9SDU9069ttPwqsHrZnS6gsO+++9bYsQAAAIs6kjoym+pIfV50vmOd+1inZChPXwc6ijU+PYa2Dc1NF2orr7i42LXFeJvT9nPuuee6519HZJen96Od/Trf7dZeZwCqhpGwAGqUXsY0aNAgVzwNHTo04T46KkEvUdIVXPUyGR3loMWjLnCgox604NAz71pw6QqmOl+RfmkxosWEKruqbVXoQg06Ub8Wmlqg6zxResx6yZquFKujMfSr7Fl7LZL0tq0t0qCXjOk8WDqSQecW00vDdJEBvZyo7PHq/c2ePdsVpPozugCFFsq61cuKdDGJiRMnuoULdEVVpfNP6f3qggI6qkDv4/HHH3cjGMqPGtCCTgtxvX/NtDp0BV19rvTSOp0XrDLPXfx31JECelZe58TSn9PL6nTOKn1e4wswVLTSbqrpCrB6SZ0eg44a0NEp+geJFv1a2J544omBPr6237J//MTpQhFMfQAAAHUkdWR21ZH6XGj70S9d1Es7vLWD9I033nDz544ZM6Z0Xx3Rqs+jTjmgC8sdddRRbpoH7Zj+61//6rY6B2+cLkCnbUifc+3Y1xGvmpe2HR1xrVMx6Otja9M3AKgaOmEB1Cg9Y66FkxZKWysylV6+pcVTvGjQOam08Na5v/TMsJ7B1UL0L3/5iytQtJNKizBdsOCCCy5wZ511Ev+q0kJPi0E9Bi10Hn30UVeMtG3b1s2BpcVQ/NKnAw44wP1eeimVzk+mRWwi+keDFk46Yb4WaJqBXsIVLxRXrVrlstECWefb0sfRAlhHBWgOev/Dhg1zCxNoEaqXb8UvQdM/HsaOHetu0330/1rEakEYH3FRfpVhHVVQdtXbqtDLrXRVYf2DQlfdHTBgwDafO3XSSSe5wlkLP12cQotWnaNKf29dEVcvU9PFMnSkSqLjD4oWpPrY2o6ef/55l5+O1NBjD7oI1TneEtHHpxMWAADqSOrI7KojtfNec9A2obnoSGCdpkA717UdlB9dO3LkSDeqWReY05MUerJBO2K1g1Z/vuyUCNpRrB3E2iGvx6oLeenoZ227mq8+L9phDyC1cmIsdwcAoffNN9+4QlPnCCu7SqoW13qZUtkz5fq2r5cW6XxQOgIBAAAA2Ys6EgBqBiNhASAC9Ey3juQ4/fTT5YgjjnBzP+mZ7f/85z9y1VVXuX10EQq9vEgvhdN5ofQMNwAAALIbdSQA1AxGwgJAROgCEHopmS5CoG/tnTp1kosuusiNVFA6qb9ePqaLN+gcYMcdd1y6DxkAAAAZgDoSAIJHJywAAAAAAAAABCg3yDsHAAAAAAAAgGxHJywAAAAAAAAABIhOWAAAAAAAAAAIUK0g7zybzJo1y01gXrt27XQfCgAAQFbbtGmT5OTkSLdu3SSMqCsBAACiV1eGYiSsrsA4evRo6d27t3Tt2lUuuOAC+fHHH7e6//Lly+XKK6+U7t27S48ePWT48OGyfv360u8XFxe7+zvssMNkn332kZNOOknee++9ah2jFsqscbaFZlFYWEgm/0MePjKxyMMiD4s8fGRikUe06rKwH3+q0b4t8vCRiUUeFnlY5OEjE4s8gqvLQjES9oEHHpBnn31WRowYIa1atZKRI0fKwIED5Y033pA6dep4+w8ePNh1uo4fP15WrVol119/vaxbt07uuOMO9/17771XJkyYILfffru0b99e3nzzTbn44ovlhRdekL333rtKxxgfqZCfn1/N3zYaFixYII888ohceOGF0rp1a8l25OEjE4s8LPKwyMNHJhZ5WAUFBRJm1JUW7dsiDx+ZWORhkYdFHj4yscgjuLoy40fCbty4UcaNG+c6Vg899FDp2LGj3H333bJw4UKZNGlSwsu3pk2b5jpcO3fuLAcddJDcdNNN8tprr8miRYtKhxJrx6ze3y677CIXXXSRNGzYUD755JM0/IYAAAAAAAAAoizjO2HnzJkja9eudZ2pcU2aNJFOnTrJ9OnTvf1nzJghO+64oxvhGqdTEuj8DTNnznT/v/baa6V///7u3zrE+qmnnnIjZw844IAa+Z0AAAAAAAAAZI+Mn45AR7yq8kOgW7RoUfq9snS0a/l9dcqC7bbbzg2pLuv111+Xa665xs3tcOmll1b7ki+9H532AJuz2Guvvcjkf8jDRyYWeVjkYZGHj0ws8rA0Bz0BH2Y8l1vQvi3y8JGJRR4WeVjk4SMTizyCqytzYhk+065OI6AdpV9++aXk5m4ZuKu3LV682M37WpZOM/D999/LM888Y27XqQdOPfVUN/drnHbKrly5Uj766CMZNWqU+9nTTz+9ynNE6NQJAAAASD89CR/WOVWpKwEAAKJXV2b8SNh69eq5rRai8X+rDRs2SP369RPun6ho1f0bNGhgbtMRs/ql88z+8MMPMnbs2Cp3wsYXUejQoUOVfz5KioqKZPXq1dK4cWOpVSvjm1ngyMNHJhZ5WORhkYePTCzysObOnSthR125Be3bIg8fmVjkYZGHRR4+MrHII7i6MuPTjE8toKNed91119Lb9f977rmnt3+rVq1k8uTJ5jbtlF2xYoWbwkAb03vvvefmlN1pp51K99H7evnll6t1rDo8uXxHb7bSUcaPPfYYq+n9D3n4yMQiD4s8LPKo2UyKi4vdIp5honXOCy+84K760Xon6rSDMi8vb6vfD/tUBIq6cgveAy3y8JGJRR4WeVjk4aOutKgrg6srM74TVkepNmrUSKZOnVraCbtq1SqZPXu2DBgwwNu/e/fucuedd7qRrW3btnW3TZs2zW33228/F+yf//xnOfnkk+XKK68s/bnPPvuM0QYAAGQxnaFJ55vXwjNstMDv2bOnq5F0QdNsoPP968n3KHS4AgCAaKGuDJftaqiurBWGeRe0s1U7Vps3by5t2rSRkSNHunCOPPJI1ziWLVvmhknrVARdunSRfffdV6644goZNmyYm0T4hhtukBNOOEFatmzp7vO8886TMWPGyB577OHmdJg0aZK8+eabct9996X71wUAAGkSL5T1jL+OQAxT5178qh8tILV2irL4IhF6VZRiFA8AAMg01JXhEKvhujLjO2HV4MGD3TQCQ4cOlcLCQjfaVedv1SHDP/30k/Tp00duv/12Oemkk1zD1g7W4cOHy9lnny1169aVfv36yXXXXVd6f+eff777We101WHnu+++u4wePdrdDwAAyD56UjdeKG+//fYSNrp4qc7ZpSeko14sq/i6AFow63NW0SVkAAAANYm6Mlzq12BdGYpOWA3g6quvdl/l7bzzzvLV/7d3J1BSVOffx58ZtgEGcBBZ3BEUFEdEBEXBFTdEoyYajXtEMS64ocZoFNS4REXF3Shx14i7hkQl/qNoFBFRJywqikaR1QGGdVim3/Nc3x7n4TbD9ExXd1X193NOn4Ke6u47v75VdefWrVuff26e00qunaq1VajTTjvNPQAAAJJzdTEHZ3Qkvyv97uiEBQAAYUG7MnpaZKldWZDQsbdosLKyMrfU6Q0AAEC06JU2s2bNks6dO7uz/oj2dxb1dlnUyw8AQD6jXRk9q7LUrixs8DsAAAAAAAAAADaITlgEYuHChW7eXl2CPFIhE4s8LPKwyCP3mZx88snSrVs389h5551lv/32c/PQL1myJCvlqGvZunfv7m5UqvPlv/zyy4F8rs6tr58FBI19oEUePjKxyMMiD4s8fLQray8b7co8mxMW0aPzaOhN05JzoeQ78vCRiUUeFnlY5BGOTHbaaSe55pprTBmmTp0qo0aNkunTp8vTTz+dszvf7rjjjnLeeedJmzZt3M1H9YYQelfeRx55RC677DJ3d9t99903o5957LHHyoABAzL6nkAq7AMt8vCRiUUeFnlY5OGjXWnRrgwOnbAAAAB1UFxcLLvuuqt5rk+fPrJ8+XJ3Q9BPP/3U+3m2tGzZ0jXm27VrZ+5iu88++0i/fv3khRdeyHhjuWPHju4BAACA9NCuzM92JdMRAAAANIBePqZ++OGH6su4hg8fLsOGDXON59NPP909X1lZKX/+859do1Vfc8QRR8i4ceOq3+ePf/yj7L333m60QU1/+tOfZI899qjX6IxmzZq5xnPNkRRVVVXy4IMPykEHHeTKccghh8jjjz/uvVYvyzvwwANll112keOPP17eeustd5nYxIkTU142pr/31VdfLffee68bydCzZ08588wz3aV9zz//vPu8Xr16yWmnneZGm9Q0fvx4d4mb3vBAM7j++utlxYoVaf++AAAAUUa7Mt7tSkbCAgAANIDeSVVttdVW1c/94x//kCOPPFLuu+8+1zhNJBJy7rnnyscff+wa0V26dJE333xTLrroIlm9erUcddRR8otf/EKeffZZ1xjda6+93Pvoa/W9Dj/8cHc52Ibo+2sje+3atVJYWOj+PXv2bLnnnnvciAp976QRI0a4EQxDhw51jddJkybJDTfcIBUVFa6M6u6773avPeOMM2TPPfeUCRMmyIUXXrjRLF577TXp0aOHa+DrZWvXXnutnHTSSa7Rfvnll8vKlStdg1qf1wa7evXVV90fF/rHg36Glvv222+XmTNnyl//+tecXYoHAACQbbQr492upBMWgdA5Qo4++mi3BHmkQiYWeVjkYZFHODLRBqk2RpP0pgkffvihaxBrozM5ckFpw1ZvrJC8hOu9995zDU5tBA4aNMg9p2f1tfF46623yuDBg6V3796yxRZbuAZnsrGsDecFCxaYxm4qkydPloEDB5rntJG5ww47yJ133in7779/dcNeG+QXX3yxnHXWWe65/v37u3UfeOAB+c1vfuMatn/5y1/kxBNPdI3Y5Dpa1r/97W+1lkPz0Ya2ziGm3njjDfd764iE5B8Tn3zySfVNHTRT/f01C10mbbvttm5kw9tvv+1uUoH8xj7QIg8fmVjkEY48qqoSUlhYkPF1G4r64aNdadGuDA6dsAhE8+bN3TBz/IQ8fGRikYdFHhZ5hCMTPbOvZ+Nr0tEB2rDVM/A1z6xvt912Zg6t999/3/1cLxmr2eA+4IAD5JVXXpEvv/zS3QRBRzk89dRTblSBvv7vf/+7azjqJVi10XJp41zNnz9f7rjjDneZmS61LEkffPCBa6Dq565fDm30a6O7RYsWsmrVKjn00EPNZ2iDfmONZR2JkWwoK51LrKSkxIzm0D9wli5d6v799ddfu5ENOnqiZnl0TjSdK03/yMh1Yxm5xz7QIg8fmVjkEY48tFP1zXc/l0UVtV8GXdK6hRzUP3t3had++GhXWrQrg0MnLAKhQ9T1zn668eqkzvmOPHxkYpGHRR4WeYQjk5oNUm346pn9Tp06uUbd+tanibJ+AACH4ElEQVQv0+LFi10jdbfddkv53trA1cayjkzQRque5dez+HrG/9RTT91o2bSBq43ioqIiN/+VNq614f3b3/7WXSLWtm3b6nIovQwtlXnz5lU3dpOvSdp00003Wo5UWWjZNiRZHs01me36uQDsAy3y8JGJRR7hyUM7YBeWL5cwoX74aFdatCuDQycsAqHzf+hcI3qGgh07eaRCJhZ5WORhkUc4MtHP0YZofbRq1co1Gh977LGUP99mm23csnPnzm4khv5uOhpCf09t9G6MNsT1Mja9XK1Ro0ZupIDOkXXBBRe4ebRuu+02t17r1q3d8tFHH02Z2+abb149F9mPP/5oRjuUl5dLpiXLc9lll0nfvn29n9cc/YD8xT7QIg8fmVjkYZGHRR4+2pUW7crgFAb43gAAABBxDUG9K6s2arXBnXx88cUX7kYFNS+Z0lELOmJBLxnTEQ41L7lKh172paMedC4wnWNM7b777m65aNEiUw5tCOscXzqCoHv37q5xrzd4qElHT2SaNsZ1JITe1bZmeTp06OAa+NOmTcv4ZwIAAEQZ7crotisZCQsAABAwnbNL56M655xz3EPnuPrss89k9OjRrkFb8xItvcHCTTfdJOPGjZNrrrmmQZ/7hz/8wY14uP766+XFF1+Ubt26uf//8Y9/dHeL1Zs+6AgFvbHDlltu6eYJ0xEPQ4YMcWXTOdK0oa+N7aefftq9p46kyBT9LL2Tr46u0H/rjR50lMa9997rLmFbf640AACAfEe7MrrtSjphAQAAAqYNzAcffNCNCtC7xeolWXpW/vTTT5dzzz3XrKsNZ71rrN48YP2bGNRnRMDJJ58sY8aMcY3dk046SW688UZXhmeeecbdvEBHDGgD/cILL3QNVqU3NNDRFXrDhIcfftjNBaZ3tNXX1jYXV30ce+yx7hK2hx56yH2evr+O1NC72tZ3tAYAAEBc0a6MbruyIKFJoMHKysrcsr5zesSN7gR03pHDDjusThMuxx15+MjEIg+LPCzyCD4TvWurnrnXubP0JgRRo5ed6dxdOtdV48aNG/xeeqnZHnvs4W4QkfTkk0+6kQ8TJ06snnMrl2r7zqLeLot6+TONfaBFHj4yscgjPHk8O27KRm/M1a5tSzluUK+slYn64aNdadGuLAqsXUYnbIbQWAYAILqi3ljONL3LbdOmTeV3v/udlJSUuDnG7rjjDhk4cKAbtRAGdMICAMIujJ2wCB7tSot25c+YjgCBqKqqkjVr1ri76WVyjo+oIg8fmVjkYZGHRR4+MrH0nLo+CgoK3KOh7r//fhk1apSMGDHCzaWld7c99dRT3eVkQLaxvVvk4SMTizws8rDIw0cmFu3K4FC7EAid9Fgnf9YlyCMVMrHIwyIPizx8ZGLpHw46D5cuM0HnzNKbKvznP/+R//73v+4Otuedd5774wTINrZ3izx8ZGKRh0UeFnn4yMSiXRkcOmEBAAAAAAAAIEB0wgIAAAAAAABAgOiEBQAAAAAAAIAA0QkLAAAAAAAAAAEqSOgtz9BgZWVlbllaWprrooTCunXrZNWqVVJUVCSNGjWSfEcePjKxyMMiD4s8gs9E32vWrFnSuXNn955Ro805vbOv3tE3E3exjYLavrOot8uiXv5MYx9okYePTCzyCE8ez46bIgvLl9e6Tru2LeW4Qb2yVibqh492pUW7siiwdlnjBr8DkILuuFq2bJnrYoQGefjIxCIPizws8vCRiaUNZP6QQlyxvVvk4SMTizws8rDIw0cmFu3K4DAdAQJRXl4uTz/9tFuCPFIhE4s8LPKwyMNHJtbatWtl8eLFbhkkHRUxevRoGTBggOy6665y5plnynfffRfoZwJs7xZ5+MjEIg+LPCzy8JGJRbsyOHTCIhCVlZXyxRdfuCXIIxUyscjDIg+LPOKbSVWiKiPv07hxY9lkk03cMsjPvffee+Wpp56S6667Tp555hnXeB4yZIisXr26Xu8H5NP2nink4SMTizws8rDII76Z0K4MP6YjAAAAyJHCgkJ58tMJMm/Zkqx9ZofiNnJizwFpv04bxGPGjJHhw4fLfvvt5567/fbb3eiFN954QwYPHhxAaQEAAFAXtCvDj05YAACAHNKG8uyK8F/+NmPGDFm+fLn069ev+rnWrVvLTjvtJJMmTYptYxkAACAqaFeGG9MRAAAAYKPmzp3rlp06dTLPt2/fvvpnAAAAwMbMzdN2JZ2wCESrVq3k4IMPdkuQRypkYpGHRR4WefjIJPtWrlzplk2bNjXPN2vWLPJzqCHc2N4t8vCRiUUeFnlY5OEjk+xbmaftSqYjQCCKi4vNsPJ8Rx4+MrHIwyIPizx8ZJJ9RUVF1XN4Jf+ttKHcvHnzHJYMccf2bpGHj0ws8rDIwyIPH5lkX1GetisZCYvAzmpMnTq1+uxGviMPH5lY5GGRh0UePjLJvuTlYvPnzzfP6/87dOiQo1IhH7C9W+ThIxOLPCzysMjDRybZ1ylP25V0wiIQixcvlueee84tQR6pkIlFHhZ5WOThI5Ps6969uxspMnHixOrnKioqZNq0adKnT5+clg3xxvZukYePTCzysMjDIg8fmWRf9zxtVzIdAQAAADZK5+w66aST5NZbb5W2bdvKFltsIbfccot07NjRzaMGAAAA1EXTPG1X0gkLAACQQx2K20Tm84YNGyZr166Vq666SlatWuVGKjz88MPSpEmTjJYRAAAA6aNdGW50wgIAAORIVaJKTuw5ICefW1iQ/qxUjRo1kksvvdQ9AAAAEB60K8OPOWERiMaNG7th5LoEeaRCJhZ5WORhkUd8M6lPgzWVNWvWyKJFi9wym58LZENctvdMIQ8fmVjkYZGHRR7xzYR2ZfgVJBKJRK4LEQdlZWVuWVpamuuiAACANOklULNmzZLOnTtLUVFRrouDBn5nUW+XRb38AICfPDtuiiwsX17rOu3atpTjBvXKWpkQPNqV0bMqS+1KuqsBAAAAAAAAIEB0wiIQc+bMkeuvv94tQR6pkIlFHhZ5WOThIxNr9erV8sMPP7glEDds7xZ5+MjEIg+LPCzy8JGJRbsyOHTCIjDr1q3LdRFChTx8ZGKRh0UeFnn4yATIH2zvFnn4yMQiD4s8LPLwkQmygU5YAAAAAAAAAAgQnbAAAAAAAAAAECA6YQEAAAAAAAAgQAWJRCIR5Afki7KyMrcsLS3NdVFCYc2aNbJo0SIpKSmRJk2aSL4jDx+ZWORhkYdFHsFnsmrVKpk1a5Z07txZioqKJGqqqqrcXGaNGjWSwsL8OMde23cW9XZZ1MufaewDLfLwkYlFHuHJ49lxU2Rh+fJa12nXtqUcN6hX1spE/fDRrrRoVxYF1i5r3OB3AFLQHVf79u1zXYzQIA8fmVjkYZGHRR4+MrG0gZwvjWTkH7Z3izx8ZGKRh0UeFnn4yMSiXRkcUkUgFi9eLK+88opbgjxSIROLPCzysMgjvpkkqqoi+7kPPPCAnHzyyRkpD5AP23umkIePTCzysMjDIo/4ZkK7MvwYCYtArFy5UqZMmSJ9+vSRTTbZRPIdefjIxCIPizws8ohvJgWFhbJk/NOybtH8rH1mo5L20mbgCQ16jyeffFLuuOMO2X333TNWLiDu23umkIePTCzysMjDIo/4ZkK7MvzohAUAAMghbSivXThbomDevHlyzTXXyMSJE2XbbbfNdXEAAABQA+3KcGM6AgAAANTJ1KlT3bxpeslez549c10cAAAARNTUPGxXMhIWAAAAdXLAAQe4BwAAANAQB+Rhu5KRsAhEy5YtZe+993ZLkEcqZGKRh0UeFnn4yATIH2zvFnn4yMQiD4s8LPLwkQmyhZGwCETr1q1l4MCBuS5GaJCHj0ws8rDIwyIPH5kA+YPt3SIPH5lY5GGRh0UePjJBtjASFoGorKyUb775xi1BHqmQiUUeFnlY5OEjEyB/sL1b5OEjE4s8LPKwyMNHJsgWOmERiPLycnn00UfdEuSRCplY5GGRh0UePjIB8gfbu0UePjKxyMMiD4s8fGSCbKETFgAAAAAAAAACxJywAAAAOdSopH2sPw8AAADZQbsy3OiEBQAAyJFEVZW0GXhCTj63oLBhF0TddNNNGSsPAAAAGoZ2ZfgxHQECUVhYKK1atXJLkEcqZGKRh0UeFnnEN5OGNliT1qxZIwsXLnTLbH4ukA1x2d4zhTx8ZGKRh0UeFnnENxPaleFXkEgkErkuRByUlZW5ZWlpaa6LAgAA0rRq1SqZNWuWdO7cWYqKinJdHDTwO4t6uyzq5QcA/OTZcVNkYfnyWtdp17alHDeoV9bKhODRroyeVVlqV9JdDQAAAAAAAAABohMWgZg3b56MGjXKLUEeqZCJRR4WeVjk4SMTSy8Xmzt3bp0vGwOihO3dIg8fmVjkYZGHRR4+MrFoVwaHTlgEoqqqSpYuXeqWII9UyMQiD4s8LPLwkYmls0tpFswyhThie7fIw0cmFnlY5GGRh49MLNqVwaETFgAAAAAAAADyvRNWe+BHjx4tAwYMkF133VXOPPNM+e677za4/qJFi+SSSy6RPn36SN++fWXkyJGycuVK834PPfSQHHLIIe79Dj/8cBk7dmyWfhsAAAAAAAAA+SQSnbD33nuvPPXUU3LdddfJM8884zpRhwwZIqtXr065/rBhw+Tbb7+VRx55RO688055++23ZcSIEdU/f+CBB9zjggsukFdeeUVOOeUU9/OXXnopi78VAAAAAAAAgHxQkAj5JA/a0brnnnvK8OHD5Te/+Y17rqKiwo2K/dOf/iSDBw8260+ZMkWOP/54GTdunHTp0sU99+6777pOW+2M7dChg+yzzz5ywgknyO9+97vq1/3hD39wHbdPPvlkvcpZVlbmlqWlpQ34beOjsrJS5syZI506dZJmzZpJviMPH5lY5GGRh0UewWeyatUqmTVrlnTu3FmKiookavQEtd48oUmTJlJYGIlz7IF+Z1Fvl0W9/JnGPtAiDx+ZWOQRnjyeHTdFFpYvr3Wddm1bynGDemWtTNQPH+1Ki3ZlUWDtssYScjNmzJDly5dLv379qp9r3bq17LTTTjJp0iSvE/ajjz6SzTbbrLoDVumUBAUFBTJ58mQ59NBD5eabb3bB1qQVSzt3kRm649p2221zXYzQIA8fmVjkYZGHRR4+MhGvHcMfUogrtneLPHxkYpGHRR4WefjIxKJdGZzQd8LOnTvXLfWMRE3t27ev/llN8+bN89Zt2rSpbLLJJu7Mhlammh266ocffpC///3vbgRtQ+ig4hUrVjToPeJC7yyoo5J79eolrVq1knxHHj4yscjDIg+LPILPREdA6Fn/devWuUe2FBQUSmFhgWRbVVVCEon07wC8ePFiueOOO9zVRcuWLZNu3brJRRddJL1795Zs0+9JvzOd93/9uxlrm0xPwEcZ7cqfsQ+0yMNHJhZ55D4PPQY1b948rdfo8SwbFypTP3y0KxuGdmWMOmGTN9TSjtSatFd+yZIlKddff93k+rohrG/hwoXuRl+bbrqpmZ6gPnS49vTp0xv0HnGh383EiRPdd9GmTRvJd+ThIxOLPCzysMgjO5k0btw4ZVshKHpiWP9Ae/Pdz2VRRfY620pat5CD+neTlStXe43Mjbn44otd20mnhNK209NPP+3aUTp3f7ZHkOh3tXbtWvn6669T/jxVezBKaFf+jH2gRR4+MrHII/d56PFdr95Nh14KXfOG4kGhfvhoV9Yf7cqYdcIm52LQuWFrzsugAaU6s6TrpLphl67fokUL85yGe9ZZZ7ke78cee8xNc9AQOl9G165dG/QecaEjkidMmOCmfdB5ePMdefjIxCIPizws8gg+E20n6JUxetI223N3aUN5Y/PFBSHdxqTOnf/BBx/IE088Ibvttpt77pprrpH3339f3nzzTTn//PMl2/QPnK233tq7ZG7mzJkSdbQrf8Y+0CIPH5lY5JH7POozak7Ll42RsNQPH+3KhqNdWcfPkJBLTi0wf/58F0aS/l+HKq+vY8eOMn78ePOcdsrqMGedwiBJ54fVka+6gT300EMZ2dB0R7t+R2++Su5odEkm5JEKmVjkYZGHRR7BZ6KjB/TRqFEj98gH6f6e7dq1kwcffFB69uxpXqu56WV82c5NPy856mP9P3CiPhWBol35M/aBFnn4yMQij2jmke70BXHPI5toVzYc7cq6Cf1tzrp37y7FxcVuaHiS3kBr2rRp0qdPH299fU7nitVe9aQPP/zQLZPzSnz22WcyZMgQ2X777eXJJ5/k7A8AAMBG6BVD++67rxnp8Prrr7s214ABA3JaNgAAAERH6zxtV4Z+JKx+ISeddJLceuut0rZtW9liiy3klltucSNeDz74YDeVQHl5uZs8WXurtRddhzLrZL4jRoxwNzS4+uqr5aijjnKdrTrHw/Dhw918EzfddJMbJr5gwYLqnm/9DDScnj3QSa2zdTYv7MjDRyYWeVjkYZGHj0xy7+OPP5YrrrjCtcf222+/XBcHMcb2bpGHj0ws8rDIwyIPH5nk3sd50q4sSGRj0pEG0o7WUaNGyQsvvCCrVq1yo121Y3XLLbeU77//Xg488EC58cYb5ZhjjnHr//jjjzJy5Eg3p4fO5XDooYe6L1P/rV/sCSeckPJztIP3rbfeqlcZy8rK3LK0tLQBvykAAMgFbV/oDTF0LrBsz9317LgpWZ27q13blnLcoF4Neg+d+klPauuJ7/vuu8+bOyvX31nU22VRLz+A/KR3SK/Lndnrul4c1OUYn4njMsKFdmV6xudRuzL0I2GTI1QvvfRS91ifdsR+/vnn5jkd5Tp69OiU76Vf6vrrI5g7+i5atEhKSkrcjSXyHXn4yMQiD4s8LPLwkUnu6A0U9C62epL75ptvztjdYoENYXu3yMNHJuHIQztWN3Zn9uSd1LOJ+mGRh49McueJPGtXhn5OWETTwoUL3RkMXYI8UiETizws8rDIw0cmufHUU0/JddddJyeeeKK7SinuDWWEA9u7RR4+MglPHsk7s2/oUVsHbVCoHxZ5+MgkN/KxXRmJkbAAAADILb1E64YbbpCDDjpIhg4dav5Q0cu2dH5+AAAAYGNm5Wm7kk5YAACAHNJLM6PweXrHWr1c780333SPmo4++mh3w1MAAADkDu3KcKMTFgAAIEf05iTZnhuvvjdFOfvss90DAAAA4UO7MvyYExaB3lANPyMPH5lY5GGRh0Ue8cwkU3eH1pEECxYscMtsfi6QLXHY3rOVR1Wiqs7vk866YUcdscjDIg+LPOKZCe3K8CtIJBKJXBciDsrKytyytLQ010UBAABpWrVqlZubqnPnzm4eKkT7O4t6uyzq5UfuPfnpBJm3bEmt63QobiMn9hyQtTIhPzw7boq7AdeGtGvbUo4b1EvyxcbyyMdM8gHtyuhZlaV2JdMRAAAAAECMaAfs7IryXBcDAADUwHQECIQOXX/ggQfcEuSRCplY5GGRh0UePjJp2GVjQJSwvVvk4SMTizws8rDIw0cmFu3K4NAJi0CsXbtW5s6d65Ygj1TIxCIPizws8vCRiaWzS2lDmVmmEEds7xZ5+MjEIg+LPCzy8JGJRbsyOHTCAgAAAAAAAECA6IQFAAAAAAAAgADRCQsAAAAAAAAAAaITFoHYZJNN5Fe/+pVbgjxSIROLPCzysMjDRyZW48aNpaSkxC2BuGF7t8jDRyYWeVjkYZGHj0ws2pXBIVEEonnz5tKjR49cFyM0yMNHJhZ5WORhkYePTKzCwkKXSdB+/PFHuemmm2TChAlSWVkpffr0kcsvv1y6dOkS+Gcjf7G9W+ThIxOLPCzysMjDRyYW7crgMBIWgVi2bJm8//77bgnySIVMLPKwyMMij/hmkqhKROpzzz33XPn222/lwQcflOeee06KiorktNNOk5UrV2a8jEDctvdMIQ8fmVjkYZGHRR7xzYR2ZfgxEhaBWLp0qbzxxhuy7bbbSnFxseQ78vCRiUUeFnlY5BHfTAoKC2Tu+OmyZtGKrH1mk5IW0nHgjmm/bsmSJbLFFlvI0KFDZYcddnDPnXPOOfKLX/xCvvzyS9lll10CKC0Qn+09U8jDRyYWeVjkYZFHfDOhXRl+dMICAADkkDaUKxeGf+RFmzZt5Lbbbqv+f3l5uTzyyCPSsWNH6dq1a07LBgAAANqVYUcnLAAAANLyxz/+UZ599llp2rSp3HfffdKiRYtcFwkAAAAR9Mc8alcyJywAAADScuqpp8rzzz8vgwcPdvN5TZ06NddFAgAAQASdmkftSjphEYhmzZq5eT10CfJIhUws8rDIwyIPH5nkll4mtvPOO8uf/vQnN5/XE088kesiIcbY3i3y8JGJRR4WeVjk4SOT3OqaR+1KpiNAINq2bSsnnHBCrosRGuThIxOLPCzysMjDRybZp3N16Z2DDznkEGnc+KcmZGFhoWs4z58/P9fFQ4yxvVvk4SMTizws8rDIw0cm2Veep+1KRsIiEOvWrZPly5e7JcgjFTKxyMMiD4s8fGSSfQsXLpSLL77YNZiT1qxZI9OmTZMuXbrktGyIN7Z3izx8ZGKRh0UeFnn4yCT7FuZpu5JOWARCz1zceuutsT6DkQ7y8JGJRR4WeVjk4SOT7NPL9PbZZx+5/vrrZdKkSfLFF1/I73//e6moqJDTTjst18VDjLG9W+ThIxOLPCzysMjDRybZt0OetiuZjgAAACCHmpS0iMznjRo1Sm677Ta56KKLZOnSpbL77rvLk08+KZtvvnlGywgAAID00a4MNzphAQAAciRRlZCOA3fMyecWFBak/bpWrVrJiBEj3AMAAADhQbsy/JiOAAAAIEfq02BNRefQWrBggVtm83MBAAAQDrQrw49OWAAAgIhLJBKuoaxLAAAAoL5oVwanIEGqGVFWVuaWpaWluS5KKFRVVbmNtkmTJlJYSF8/efjIxCIPizws8gg+k1WrVsmsWbOkc+fOUlRUJFGjzTl9FBQUuEc+qO07i3q7LOrlzzT2gennMeq912R2RXmt77NF67Zy8d6DJQ6oI+HJ49lxU2Rh+fIN/rxd25Zy3KBeWS1TmPPIRSZsLz7alRbtyqLA2mXMCYtA6I6rWbNmuS5GaJCHj0ws8rDIwyIPH5lY+dRIRv5he7fIw0cmFnlY5GGRh49MLNqVweG0BwLx448/yhNPPOGWII9UyMQiD4s8LPLwkYm1du1al4Uugbhhe7fIw0cmFnlY5GGRh49MwtGuTKRxoX5UL+pnJCwCsXr1avnqq6/cEuSRCplY5GGRh0UePjLxL6OrrKx0SyBu2N4t8vCRiUUeFnlY5OEjk3C0KwsKCqRi6SpZu5HPbVxYKK1bRW+aB0UnLAAAAAAAAICcWltVJWvXrottTybTEQAAAAAAAABAgOiEBQAAAAAAAIAA0QmLQLRu3VoOO+wwtwR5pEImFnlY5GGRh49MrEaNGklJSYlbAnHD9m6Rh49MLPKwyMMiDx+ZWLQrg0MnLALRsmVL6du3r1uCPFIhE4s8LPKwyCO+mVQlMnPDA20kN2/evM6N5Ux87qxZs6RXr17ywgsvNPi9gHzY3jOFPHxkYpGHRR4WecQ3kzi0K//+2isSZxGezhZhtnLlSvnyyy9l++23dxtvviMPH5lY5GGRh0Ue8c2ksKBQ3p35kCxZOTdrn9mmeUfp33VIg95jzZo1Mnz4cFmxYkXGygXEfXvPFPLwkYlFHhZ5WOQR30xoV4YfI2ERiMWLF8uLL77oliCPVMjEIg+LPCzyiHcm2lAuX/G/rD0y0TC/6667pLi4OCO/P5BP23smkIePTCzysMjDIo94Z0K7MtzohAUAAECdTZo0Sf72t7/JTTfdlOuiAAAAIMIm5Vm7kk5YAAAA1ElFRYVcdtllctVVV0mnTp1yXRwAAABEVEUetivphAUAAECdjBgxwt004Ygjjsh1UQAAABBhI/KwXcmNuRCIJk2ayJZbbumWII9UyMQiD4s8LPLwkUn2vfTSS/LRRx/Jq6++muuiIM+wvVvk4SMTizws8rDIw0cm2fdSnrYrCxKJRCLXhYiDsrIytywtLc11UQAAQJpWrVols2bNks6dO0tRUVFWP/vvZde7GxtkS9sWW8vhpVel/bqTTz5ZPv74Y2natGn1c3oXW/3/HnvsIQ899JCE5TuLerss6uVH7o167zWZXVFe6zpbtG4rF+89OGtlQn54dtwUWVi+fIM/b9e2pRw3qJfki43lkY+Z5APalQ1rV/babXe5ddToDb62ceNG0rZNC4liu5KRsAAAANioW2+91TVQazr44INl2LBhcuSRR+asXAAAAIhHu/LMs34nBx50iMQVc8IiEHPmzJGRI0e6JcgjFTKxyMMiD4s8fGSSfR06dJBtttnGPNSmm27qfgYEhe3dIg8fmVjkYZGHRR4+MglPu7KkbVvZbLP2EleMhAUAAMihNs07xvrzAAAAkB20K8ONTlgAAIAcqUpUSf+uQ3LyuYUFDb8g6vPPP89IeQAAANAwcWhXli9ZIWvXrpO4YjoCAACAHMlEg1WtWbNGFixY4JbZ/FwAAACEA+3K8CMpAACAiEskEq6hrEsg3+gInCDWBQAgH9GuDE5BglQzoqyszC1LS0tzXZRQWLt2rVRUVEjr1q2lcWNmvSAPH5lY5BGOPKqqElJYWJDxdRuK+hF8Jnp31lmzZknnzp2lqKhIokabc+vWrZNGjRpJQUF26mWu1fadRb1dFvXy52J7f/LTCTJv2ZJa36dDcRs5secAyYc8Rr33msyuKK/1fbZo3VYu3nuwxAHHyfDk8ey4KbKwfPkGf96ubUs5blCvrJYpzHnkIhO2Fx/tyvC0K8vrMB1B48aNpG2bFpFsV7LFIRC642rbtm2uixEa5OEjE4s8wpGHdqq++e7nsqhiRa3rlbRuIQf175a1clE/fGRiaQOZP6SQz9u7dsBurNMxSImqhBTU8cRcOuumwv7PRyYWeVjkYZGHj0ws2pXBYToCBGLRokXywgsvuCXIIxUyscgjPHloB6yOWKjtsbFO2oyXifrhIRN/BIdmoUsgbqKwvWun6tzx0+W7sZNrfeg6DemAjUoe2UYmFnlY5GGRh49MLNqVIeuEXbp0qbz55pvy8ssvy0svveQ9AB3KrUO2dQnySIVMLPKwyMMij+xlEtVZmqqqqmTlypVumS+i+l0hvvvANYtWSOXCZbU+dJ18ySObyMQiD4s8LPLw0a60aFcGJ+3xxRMmTJBhw4a5ypmqkDps+aijjspU+QAAAALXpEkTt1yxYoU0b94818VBHeh3VfO7AwAACAPaldGzIkvtyrQ7YW+77TbZbrvt5IorrpAOHTpIYSEzGgAAgGjTGw9ssskmMn/+fPf/Fi1aROoGV6tXr3aXjOlJ8riPWtBBANpQ1u9KvzP97gAAAMKCdmVDPrtS1q2t/TOrqgpl1arCSLYr0+6E/eqrr+Tee++V3XffPZgSAQAA5EDHjh3dMtlgjhK9g61OF6V39s2XTkltKCe/MwAAgDChXVk/y1eulqp1tXfCFjYqlEXNm0ayXZl2J+zmm28uy5YtC6Y0iI3i4mLZd9993RLkkQqZWORhkYdFHtnJREcodOrUSdq3by9r1qyRKFm+fLmUl5e78rds2VLiTi8Vy5fOZrAPXB95+MjEIg+LPCzy8NGuDE+78h9vT5NFS1bWuk5Jm+Zy2L6dI9muTLsTdujQoXLPPfdIaWmpbLnllsGUCpHXqlUr2W+//XJdjNAgDx+ZWORhkYdFHtnNRBthUevgKyoqkn322SfXxQACwT7QIg8fmVjkYZGHRR4+2pXhaVeuWVcgq1YnNrqOljGK0p5E4dVXX5V58+bJQQcdJHvvvbcceOCB5jFw4MBgSopIqayslJkzZ7olyCMVMrHIwyIPizx8ZGKRB+KM+m2Rh49MLPKwyMMiDx+ZWOQRok5YnSNBO1qPOuoo1zPet29f8+jTp08wJUWk6ND1J5980i1BHqmQiUUeFnlY5OEjE4s8EGfUb4s8fGRikYdFHhZ5+MjEIo8QTUdw5JFHSq9evSI79BcAAAAAAAAAQj0S9vzzz5c33ngjmNIAAAAAAAAAQL53wrZu3ZpRsAAAAAAAAAAQ1HQEQ4cOleuvv15mzZol3bt3lxYtWnjrMC8s9O5/JSUlkbsLYFDIw0cmFnlY5GGRh49MLPJAnFG/LfLwkYlFHhZ5WOThIxOLPIJTkEgkEum8QDtezRsUFFT/W99K/z99+vTMlVBEqqqq5O6775axY8fK0qVLXSfv1VdfLVtttVXK9RctWuQ6it955x1XnsMPP1wuu+wyad68ubfu5MmT5aSTTmpwmcvKytyytLS0Qe8DAMitZ8dNkYXly2tdp13blnLcoF5ZKxOA/GqXRb38uTDqvddkdkXtNxDZonVbuXjvwYGV4buxk6Vy4bJa12nWrli2Ora35EMeyE8ba0flWxuKdiUQ/W2mLIPtsrRHwj722GOSbffee6889dRTctNNN0nHjh3llltukSFDhsirr74qTZs29dYfNmyYrFy5Uh555BGpqKiQK6+8UlasWCE333yz1wF7zjnnuE5eAAAAAAAAAPFRlaiSwoLCjK3XEGm/e9++fTf6yKTVq1fLmDFjXMfqfvvt50bi3n777TJ37tyUNwibMmWKfPjhh67DtUePHtKvXz+59tpr5eWXX5Z58+a5ddauXSs33nijnHrqqbLFFltktLz4iWatneXJzPMdefjIxCIPizws8vCRiUUeiDPqt0UePjKxyMMiD4s8fGQS7zwKCwrl3ZkPyd/Lrt/gQ38edAdsvUbCvvTSSxtd56ijjpJMmTFjhixfvtx1pta8OdhOO+0kkyZNksGD7SU0H330kWy22WbSpUuX6ue0Y1inJdCRr4MGDXKjYvW1Dz30kPzwww9yxRVXZKy8+ImOLtacGWX8E/LwkYlFHhZ5WOThIxOLPBBn1G+LPHxkYpGHRR4WefjIJP55LFk5V8pX/C/XxUi/E/b3v/99yue1k1Mn7dVHJjthdcSr6tSpk3m+ffv21T+rSXvq119XpyzYZJNNZM6cOdWduC+88IL7d3IJAAAAAAAAAKHohP3Xv/7lPac95DoC9S9/+Yvcc889kkk6t6taf+7XZs2ayZIlS1Kun2qeWF2/srJSgqQ3JtMsILJq1arqJZmQRypkYpFH7vPQk4mpbuBYGz3mpHl/y3qhfvjIxCIPK3mz2CijXVm3+h2GfXe2yxD2PJLlSEdDP599YPTaUdlqQ0UlD0W7MnfIJL7bTEEG9k2ZbFem3Qm7oTlUt99+e1mzZo1cd9117iZamVJUVFQ9N2zy30o7VFMFqevouuvT9Vu0aCFB0t9/+vTpgX5GVCQ7yGfNmiXl5bXfmTUfkIePTCzyyH0eekzRqW7SoeVLniwMEvXDRyYWefhSnZSPEtqVdavfYdh3Z7sMYc+jSZMm7t4ceoVkXaxbt06mTp3q6nx9sQ+MXjsqW22oqOShaFfmDpnEd5tpnqF9U6balWl3wtamW7ductttt2XyLaunFpg/f75svfXW1c/r//Xz1texY0cZP368eU47ZRcvXuymMAiSNji6du0a6GdEhWa+1VZbufl5o/5HUCaQh49MLPLIfR71ObvZuXPnrIxYoH74yMQiD2vmzJkSdbQr61a/w7DvznYZopCHdsDOHT9d1iyqfQRVk5IW0nHgjm5AT0PKwD4weu2obLWhopKHol2ZO2QS322mIAP7pky2Kxtn8kt67rnnZNNNN5VM6t69uxQXF8vEiROrO2ErKipk2rRpctJJJ3nr9+nTR2699Vb59ttvZZtttnHPffjhh27Zu3dvCZJ+uUGPto0KzUHn4cVPyMNHJhZ5RDOPdC+ZiXse2UQmFnlYUZ+KQNGuDK5+Z2vfHVQZopKHdsBWLlyWlTKwD4xeHtncDqOQh6JdmTtkEs08mgewzaR6z0y2KwvTfcEBBxwgBx54oHnsv//+0rdvX3nttdfklFNOkUzSXnftbNWOVZ2PdsaMGXLRRRe5Ea8HH3ywu3xlwYIF1XNW9OzZU3bbbTe3zmeffSYffPCBXH311e5mYR06dMho2bBh2lH++uuvuyXIIxUyscjDIg+LPHxkYpEH4oz6bZGHj0ws8rDIwyIPH5lY5BGctDthtbN1/ceee+4pxx57rDz88MNy2mmnZbyQw4YNk1/96ldy1VVXyQknnOAub9HP0su05syZI/3795dx48ZV91DffffdsuWWW8qpp54qF154oeyzzz4yYsSIjJcLG7Z8+XLXAa5LkEcqZGKRh0UeFnn4yMQiD8QZ9dsiDx+ZWORhkYdFHj4yscgjOGlPR3DTTTfV+vO5c+e6UaqZpJ2ul156qXusTztbP//8c/OcTokwevToOr33Mccc4x4AAAAAAAAAEIqRsDvuuKO7zD+Vjz76SA477LBMlAsAAAAAAAAA8mck7JgxY2TFip/ubKl3CRs7dqy888473npTpkzhTnIAAAAAAAAAkG4nbGVlpZtnNTnnqnbCrq+wsFBatWolv/vd7+rylsiDu+ntvvvu3NX3/yMPH5lY5GGRh0UePjKxyANxRv22yMNHJvHNoypRJYUFhQ1aN055ZAJ5+MjEIo8cd8Jqx2qyc7V79+7y7LPPyi677BJgsRB1bdq0kcMPPzzXxQgN8vCRiUUeFnlY5OEjE4s8EGfUb4s8fGQS3zy0U/XdmQ/JkpVza12vTfOO0r/rkNjnkQnk4SMTizxCNCfsjBkzTAesjpLVKQqAmtasWSNz5sxxS5BHKmRikYdFHhZ5+MjEIg/EGfXbIg8fmcQ7D+2ALV/xv1oftXXSxi2PhiIPH5lY5BGiTlj19ddfy4UXXih9+/aVXr16ybRp02TkyJHy+OOPZ76EiKSFCxfKgw8+6JYgj1TIxCIPizws8vCRiUUeiDPqt0UePjKxyCO4PBJVVRJ11A8fmVjkkePpCGqaPn26nHjiibLpppvKEUccIU899ZR7vlGjRnLDDTdIcXGxHH300UGUFQAAAAAAICcKCgtlyfinZd2i+bWu12TrbtJqj0NDO08ugIh0wt58882y8847y5gxY9z/n3zySbe86qqr3NQEjz32GJ2wAAAAQI7piC3tMMj0ugCQz7QDdu3C2bWu02iTzUI9Ty6AiHTCfvLJJzJq1Chp3LixrFu3zvxs0KBB8tprr2WyfAAAAAACHLHVqKS9tBl4QtbKBQDIzDy5AGLeCdusWTNZtWpVyp8tXrxYmjZtmolyIeIKCgpcXdAlyCMVMrHIwyIPizx8ZGKRBxoyYivsqN8WefjIxCIPizws8vCRiUUeIeqE3XvvvWX06NGy2267yWab/TTEXr+Y5cuXuykK9tprryDKiYjp2LGjXHHFFbkuRmiQh49MLPKwyMMiDx+ZWOSBOKN+W+ThIxOLPCzysMjDRyYWeYSoE/bSSy+VX//613LooYdK9+7dXQfsTTfdJLNmzZJEIuGmKgAAAAAAAAAA/CTt2fc7deokL7/8spx66qmu03XrrbeWFStWyODBg+WFF16QrbbaKt23RAwtWLBA7r33XrcEeaRCJhZ5WORhkYePTCzyQJxRvy3y8JGJRR4WeaSXR1Wiqs7vlc66QclEeakjFnmEaCSsfhGHHHKIXHTRRcGUCLGwdu1at8HqEuSRCplY5GGRh0UePjKxyANxRv22yMNHJhZ5WOSRXh6FBYXy5KcTZN6yJbW+T4fiNnJizwF1/tyqqoQUFhZkfF0t77szH3I3K6tNm+YdpX/XISl/Rh2xyCNEnbAPPPCA9OjRQ7p06RJMiQAAAAAAAJAT2gE7u6I8o++pnapvvvu5LKpYUet6Ja1byEH9u6X13toBW77ifw0sIRDCTtiuXbu6+V/33XffYEoEAAAAAACAWNEO2IXly3NdDCA6nbD777+/u/nWhAkTpFu3btKiRQvzc71R17nnnpvJMgIAAAAAAABA/nTC3n333W753nvvucf66ISFKikpkeOPP94tQR6pkIlFHhZ5WOThIxOLPBBn1G+LPHxkYpGHRR4WefjIxCKPEHXCzpgxI5iSIFaKiorcSGn8hDx8ZGKRh0UeFnn4yMQiD8QZ9dsiDx+ZWORhkYdFHj4yscgjOIVBvfG6detkxx13lKlTpwb1EQixZcuWuSkrdAnySIVMLPKwyMMiDx+ZWOSBOKN+B5NHq6ZFkqiqqvP66aybbdQRizws8rDIw0cmFnlEsBNWJRKJIN8eIbZ06VJ566233BLkkQqZWORhkYdFHj4yscgDcUb9DiaP5k2aSkFhoSwZ/7SUj72z1oeuo+uGFXXEIg+LPCzy8JGJRR4hmo4AAAAACEpVokoKCwozvi6A1NYtmi9rF87OdTEAAIg9OmEBAAAQGtqp+u7Mh2TJyrm1rtemeUfp33VI1soFAAAANASdsAAAAAgV7YAtX/G/XBcDAAAAyBiu30Jgd9Pbaaed3BLkEfdM9HLYhq4bpzwygTws8vCRiUUeiDPqt0UePjKxyMMiD4s8fGRikUdwGAmLQJSUlMixxx6b62KEBnnEO5NMXDobpzwygTws8vCRiUUeiDPqt0UePjKxyMMiD4s8fGRikUdw6IRFINatWyfLly+Xli1bSqNGjSTfkUf8M2nopbNxy6OhyMMiDx+ZWOSBbEpUJaSgsCDj624I9dsiDx+ZWORhkYdFHuHIpKoqIYV1PD6ms24mUEeCw3QEIZOoqgpk3WybP3++3H777W4J8kiFTCzysMjDIg8fmVjkgWzSTtW546fLd2Mn1/rQdRraAauo3xZ5+MjEIg+LPCzyCEcm2qn65rufy7PjptT60HWy2QGrqCMhGgk7adIkNzeE9oivr6KiQiZMmCCHH364FBYWytFHH+2GMaPuCgoLZcn4p2Xdotore6OS9tJm4AlZKxcAAACQtGbRCqlcuCzXxQAAILIWVayQheXLc10MhHkk7CmnnCJfffVVyp9NmzZNrrjiCvfvgoICufHGG2XzzTdveCnzjHbArl04u9bHxjppAQAAAAAAAERoJOzll18uc+bMcf9OJBIyYsQIKS4u9tb75ptvpF27dpkvJQAAAAAAAADEeSTsIYcc4jpf9ZGU/H/yodMP7Lrrrm70KwAAAAAAAAAgjZGwBxxwgHuok08+2Y2E7dKlS11eijzVsWNHufLKK7mT3v9HHj4yscjDIg+LPHxkEo48wnxnX8QH27tFHj4yscjDIg+LPHxkYpFHiG7M9fjjj9f686+//lq22267hpQJMaBzAjdunHb1yts8qhJVUlhQtyma01k3zKgjFnlY5GGRh49MwpFH8s6+emOJ2pS0biEH9e+WtXIhXtjeLfLwkYlFHhZ5WOThIxOLPIKTdqpLliyR22+/XT788ENZvXp19RQFulyxYoX7+fTp04MoKyLkxx9/lFdffVWOOOII2XTTTSXfbSwP7VR98tMJMm/Zklrfp0NxGzmx5wCJA+qIRR4WeVjk4SOT8OTBnX0RNLZ3izx8ZGKRh0UeFnn4yMQijxB1wt5www3y97//XQYMGOBGvTZv3ly23XZbmTx5slRUVMi1114bTEkRKdpB/+2337ol6paHdsDOriiXfEEdscjDIg+LPHxkYpEH4oz6bZGHj0ws8rDIwyIPH5lY5BGctK9pnjBhgpx//vly3333ya9//Ws3V8Qdd9wh//znP6Vbt24yc+bMYEoKAAAQQzrNTBDrAgAAAIjwSFgd7dqrVy/3b70515gxY9y/W7ZsKb/97W/l7rvvliuuuCLzJQUAAIghnZLm3ZkPyZKVc2tdr03zjtK/65CslQsAAABADjthS0pKZOnSpe7fOg2BzhWxePFi2WSTTaRDhw4yb968IMoJAAAQW9oBW77if7kuBgAAAICwTEfQr18/uf/++2X27Nmy9dZbS5s2beTFF190P/u///s/10kLaL3QSZx1CfJIhUws8rDII955ZOLy+7hl0lDkgTijflvk4SMTizws8rDIw0cmFnmEaCTssGHD5JRTTpHLL79cnnjiCRk6dKjcfPPNrmNWpyo499xzgykpIqVFixay22675boYoUEePjKJbx7aaaaXVzdk3TjlkQlxyyMTl9/HLZOGIg/EGfXbIg8fmVjkYZGHRR4+MrHII0SdsFtuuaWMGzdOvvnmG/f/008/Xdq1aycff/yx7LLLLnL00UcHUU5EzIoVK2TGjBnSvXt3twEH0UkTpzzyEZnEN49MdLDFKY9MiGMeDb38Po6ZNAR5IM6o3xZ5xDuTTPydFKc8MoE8LPLwkYlFHiHqhD3jjDNkyJAhblqCJB2mrA8gacmSJfLqq69Kp06dUm602lh48tMJMm/Zklrfp0NxGzmx5wCJex75iEzinUdDO9jilkdDkYePTCzyQJxlqn63alokiaoqKSisWwdXOutmE9t7vDPJxMnsOOWRCeRhkYePTCzyCFEnrI54LSgoCKY0yCvaATu7ojzXxQAAAEAeaN6kqetUXTL+aVm3aH6t6zYqaS9tBp6QtbIBNXGzRgCIp7Q7YQcMGCCvvPKK9O7dW5o0aRJMqYCYjVgAgCiqqkpIYWFBxtcFgFzSDti1C2fnuhgAACDPpN0J26xZM9cJ+49//EO6dOniDU3WUbKPPvpoJsuIPMaIBYtOaQDZpJ2qb777uSyqWFHreiWtW8hB/btlrVwAAAAAEPtO2Llz50qvXr2q/59IJMzP1/8/8lPTpk1lm222cctMiPqIhUzlEadO6UzXkagjD4s8wpOHdsAuLF9e6zotippIoiohBVkcCUsdscgDcUb9tsjDRyYWeVjkYZGHj0ws8ghRJ+zjjz8eTEkQK5tuuqmcdtppuS5GbPOIeqd0FOpItjuUwp5HtpFHtPJo2rSx217mjp8uaxbVPmq2+dZtpd0enSOZSZinZwh7HQEagvptkYePTCzysMjDIg8fmVjkEaJO2FNOOUWuueYaNxXB+mbMmCGXXnqpu4sa8puOiF63bp00atSIG7mRRyQzyXaHUi7yCHOHUtjrR7ZFJQ/dXioXLqt1nSabNI9sJmGeniEqdQSoD+q3RR4+MrHIwyIPizx8ZGKRR3DqNFnkRx99JJMmTXKPDz/8sPrf6z90rtjvvvsuwOIiKnTaij/96U9uCfKIaibJDqXaHmsrVkY2j2SH0rPjptT60HWyfcOlKNSPbCKP8GSSnJ6htsfGOmmDQB1BnFG/LfLwkYlFHhZ5WOThIxOLPHI8Enbs2LHy8ssvux5wfYwcOdJbJzkX7ODBgzNfSgDIAO7eXr/5PgEAAKKqKlElhQWFGV8XAIBAOmGvuuoq+eUvf+k6Wk899VS5+uqrpWvXrmadwsJCad26tWy//fZpFwIAwnQp8dadSmTPXttmrVwAAAAIhnaqPvnpBJm3bEmt63UobiMn9hyQtXIBAPJPnTphW7VqJX379nX/fuyxx6RHjx7SsmXLoMsGADkZ+blJ68zMWQkAAIDc0w7Y2RXluS4GACDPpX2thXbGTp06VT755BP3/x9++EHOPvtsOeKII+See+4JoowAAAAAAAAAEO+RsDW99NJLcsUVV8hvf/tb2XXXXd3UBJMnT5a9995b7r//fmnSpImcddZZwZQWkdG+fXu56KKLGDH9/5GHj0ws8rDIwyIPH5lY5IE4o35b5OEjE4s8LPKwyMNHJhZ5hGgk7COPPCJHH320XHrppbJgwQL5z3/+I+edd57cfffd7kt6/vnngylphOkE7/mmUaNGbo5gXYI8UiETizws8rDIw0cmFnkgzqjfFnn4yMQiD4s8LPKIdybp9D9taN045RH5kbBff/21/OEPf3D/fvvtt93Nug488ED3/9LSUrnjjjsyX8o8mQy++2aby6AddpM4WLRokYwfP14GDhwoJSUlku/Iw0cmFnlY5GGRh49MLPJAnFG/LfLwkYlFHhZ5WOQR70y0/+ndmQ/JkpVza12vTfOO0r/rkHrloZ23+jl1kc66+SDtTljtDV+2bJn794QJE2TzzTeXbbf96S7i//vf/yJfYXM5GXz7lq0lLlatWiXTpk2T/v3757oooUAePjKxyMMiD4s8fGRikQfijPptkYePTCzysMjDIo/4Z6IdsOUr/hdYHnUdaNihuI2c2HNAvcsRR2l3wu6xxx5u6oGZM2fKv/71Lzn99NPd86+//rrceeedsam0iL9EVUIKCgsyth4AAAAAAEDc1WWgITLQCXvllVe6+WC1I7Zfv34ydOhQ9/yNN97oRsVecskl6b4lkBPasTp3/HRZs2jFBtdpUtJCOg7cMavlAgAAAAAAQJ53wrZt21Yefvhh7/mnnnrKdcICUaIdsJULf5peAwAAAAAAAAhCxmbHpQMWNbVq1UoOOOAAtwR5pEImFnlY5GGRh49MLPJAnFG/LfLwkYlFHhZ5WOThIxOLPEI0Ehaoi+LiYhkwgAmYk8jDRyYWeVjkYZGHj0ws8kCcUb8t8ghHJlVVCSms430j0lk3E6gjFnlY5OEjE4s8gkMnLAKhd9P79ttvZZtttpGioiLJd+ThIxOLPCzysMjDRyYWeSDOqN8WeYQjE+1UffPdz2VRxYbvL6FKWreQg/p3k2yijljkYZGHj0ws8ojAdARBqqqqktGjR7ue+F133VXOPPNM+e677za4/qJFi9wNwvr06SN9+/aVkSNHysqVK806//jHP2TQoEGyyy67yFFHHSXvv/9+Fn6T/KHfwTPPPOOWII9UyMQiD4s8LPKIViYtippIoiqR1c8Mcx5AQ1G/LfIITybaAbuwfHmtj4110gZSLuqIQR4WefjIxCKPPB8Je++997obf910003SsWNHueWWW2TIkCHy6quvStOmTb31hw0b5jpdH3nkEamoqJArr7xSVqxYITfffLP7+QcffCCXXnqpXHbZZbL33nvLc889J2eddZa89NJL0qVLlxz8hgAAIC6aNm0sBYUFMnf8dHcDyNo037qttNujc9bKBgAAACBCnbCzZs2St99+23Vs6ijVmgoKCuTcc8/NVPlk9erVMmbMGBk+fLjst99+7rnbb7/djYp94403ZPDgwWb9KVOmyIcffijjxo2r7lC99tprXaftxRdfLB06dJC//OUvMnDgQDnllFPczy+//HL3ukcffdStCwAA0FDaAVu5cFmt6zTZpHnWygMAAAAgQp2wL7/8svz+97+XRCL1ZXaZ7oSdMWOGLF++XPr161f9XOvWrWWnnXaSSZMmeZ2wH330kWy22WZmRKtOSaDlmjx5shx66KHy8ccfu9+hpj322MN16gIAAAAAAABATjthdWqAvfbaS66//no3NYB2bgZp7ty5btmpUyfzfPv27at/VtO8efO8dXXKgk022UTmzJnjpifQEbxa9rq8H+qncePGrjNcl4hGHjp/oV4+m+l1o5xJNpGHRR4WefjIxCIPxBn12yIPH5lY5GGRh0UePjKxyCM4aSf6ww8/yIgRI7yOzqAkb6i1/tyvzZo1kyVLlqRcP9U8sbp+ZWWlu8vbht5Pf94QOjpYO3hr0k7q5s2bS4fiNht9fdsWxW7ZqKT9RtdNrqO/z4ZGJa9fjrqsl+66KtW6LVu2lNNOO839O4yZaBn0Ln9NSlrUul7y53XNOep5lH/0raxd9tM2siGNi4uk7e7bBJ5JXdW1viZ/R71D7ca0bvnTHSA3Vj9U49Y/XUrcprk9sZNKch3dT61f5trySJY/k5mkk0dynXTqUtTyCDKTdMqQFLU8wrbNkEf46kinzVqndQKvoXno/4MeKBC0VO3KpLr8bsnvJ1dtqHxsRwWRCXk0LJN08kiuk87vSDsq/UyinEc6+9XC1m3dMox1JFP7ELaZ8P3dkY084lpH2mSpXVmQSOevQhE58sgj3ZdxzDHHSDa8/vrr7kZbn376qQsu6YILLnDzxd53331m/euuu04+++wzGTt2rHlepzMYOnSo/OIXv5A999xTHnzwQdl3332rf/7kk0/KqFGj3JQF9VFWVubKs74mTZrITj16SONGjer0PomqKikoLKzTulVVCSkMYORiVaJKCgvqVoZ169bK1KnTZM2aNVJXUcuEPLKbCXlkLxPyiEcm5GGRR/QzyVQeesK9tLRUomhD7cp0v89cf5fufanf9c6EPHwcE+JRR8gjvJmQh4/jbv7UkXVZaFemPRL2kksucR2dW2yxhey6665uBGmQkiNu58+fL1tvvXX18/r/bt26eevrNAPjx483z2kjdvHixW7KAZ2WoEWLFu71Nen/9aZdDaGVsWvXrt7za1avlrpW6XTPnLz57ueyqKL2Oy9v3alE9uy1bVp3aX535kOyZOXcjZ4p6N91iGy//fZemXVaiGeeeUaOP/74lLnmOhM9c3JQ/24bPXOSfE/yyF4m+v66Q3/y0wkyb5k/2r2m7pttLoN22E2WjH9a1i2y2/T69Ix1m4EnhGL0eKr9RG11JIhM0skj+Z3XZR+iI1o6DtwxrREtYcgjyEwysV8Nex5h2mbII/p1JBN5zJw5U6JuQ+3Kun6fOvrkxJ4D0tqnRa3NEOd2FHlkLpO65pEsSy7bDPnQjopyHunsV+uzfWUrk0ztQ9hmwvd3RzbyiHsd6RpwuzLtTtg//elP8uOPP1YPTU4VxrRp0yRTunfvLsXFxTJx4sTqTlid11U/46STTvLW79Onj9x6663y7bffyjbbbOOe+/DDD92yd+/erny77babe+7YY4+tfp2+/+67796gsup7awdvNmkjaGH58lrX2eT/X+qYzl2atRFUvuJ/dSqDDkVfn24Q2vmtyzBmklRzdHVtyCP7megBbnZFea3v275la7fUHfrahbMz/jtmU13qSBCZBJVHQ983V3kkP7uusrVfjUoe2cQ+xKKOWFGfiqAu7cq6fJ/pfj9RbTMEKdeZkEf2M8llm6E+7xvVY0IU88hUeXKdSab3IWwz4fm7oz7vu6HXU0eCaVem3Qmr0xFkkw751c5W7Vht27atG4F7yy23uBGvBx98sKxbt07Ky8ulVatWLtSePXu6TtaLLrrIzV2r81dcffXVctRRR1X34J9++uly1llnyU477ST77LOPPP/88zJ9+nTXwYzoS2cOEQBS58s99Axitm7cBgAAAABAnKTdCXveeedJtumcsGvXrpWrrrrKDSHW0a4PP/ywu0zr+++/lwMPPFBuvPFGN0+t9lDffffdMnLkSDn11FPddAmHHnqoXHHFFdXv179/f7nhhhvk3nvvldtvv90NN77//vulS5cuWf/dwiqdiZzDROcQ0cufMj3fCJDv0ulUpQMWAAAAAIAGdsKqyspK+fzzz93w5OScClVVVe4uYh999JEMHz5cMqlRo0Zy6aWXusf6ttxyS1eWmjbddFMZPXp0re+pI2P1Aauqcq2btFjnW8r0pM/ZkE6nKh2wAAAAAAAAwdH5XjOxTl52wurcqRdccIEsWZJ6QuKWLVtmvBMW2bNu5Zq0OlU3tG67du3clA+6BHmkQiYWeVjkYZGHj0ws8kCcUb8t8vCRiUUeFnlY5OEjk+DySFRVuRtu1XXdgsLwDPILRSesXr5fUlIi1113nbzyyitSWFjopgF455135Omnn5a//OUvwZQUkaJTRXTq1CnXxQiNXOYR1jlyqSMWeVjkYZGHj0ws8kCcUb8t8vCRiUUeFnlY5OEjk+DySKdTtSDmHbAq7d9QL/3XeWEPOugg2X///WXOnDmy7777yh//+Ef51a9+Jffdd18wJUWk6Ejpv//97xscMZ1vcpVHco7c4wb1qvWh6+i62UQdscjDIg+LPHxkYpEH4oz6bZGHj0ws8rDIwyIPH5lY5BGiTlid+7VDhw7u39tss418+eWX1T875JBDZNq0aZktISJpxYoVbn5gXSJ3eYR5jlzqiEUeFnlY5OEjE4s8EGfUb4s8fGRikYdFHhZ5+MjEIo8QTUew9dZbu9Gwu+++u3Tu3NndjOvrr7+W7bbbTtauXSvLly8PpqSo92XkrVsWZaUsAAAAAAAAADLQCXvEEUfIrbfeKolEQk466STZeeed3fywJ598stx///3StWvXdN8SDbzUHAAAAAAAAECMpiMYMmSIHH/88fLpp5+6/19zzTUyffp0Oeecc9yI2MsuuyyIciIEl48DAAAAAAAAyMJI2MLCQrn88sur/19aWirjx4+vnpKguLi4HsVA3LRs2VL23HNPtwR5pEImFnlY5GGRh49MLPJAnFG/LfLwkYlFHhZ5WOThIxOLPELUCZukd0nTiXrnz5/vbsilna98QeHWpKRFRtapi9atW7t6gZ+Qh49MLPKwyMMiDx+ZWOSBOItj/W7TvGO9fx7HPBqKTCzysMjDIg8fmVjkEbJO2Pvuu08eeOABWbVqlRQUFMguu+wid9xxhyxatEjGjBnjvjCES6IqIR0H7ljndQsaONXB6tWrZd68edKhQwdp2rSp5Dvy8JGJRR4WeVjkkX4mHYrbbPQ92raIz9U71BHEWS7rd11ugluXdWqqSlRJ/65D6rReYYE/exzbu49MLPKwyMMiDx+ZWOQRojlhn3jiCbnrrrvk9NNPl2effdbdoEvpTbq+++47ufPOO4MoJxoonU7VhnbAqh9//NF1yOsS5JEKmVjkYZGHRR7pZaIdFyf2HCAX7z241segHXaTuKCOIM5yVb+TN8E9blCvWh+6jq5bV6k6VtNZj+3dRyYWeVjkYZGHj0ws8ghRJ+zjjz8uZ511llxwwQXSo0eP6uf33XdfufDCC+Wtt97KdBkBAAAy3sEBAJm6CS43zAUAABmfjuCHH36Qvn37pvyZ3phr4cKF6b4lEPl5u+q6TpyQCQAAAAAAQECdsJ06dZIpU6bIXnvt5f3sv//9r/s5ECd1nbcruW4+jMAiEyB9nLgAAAAAgPyVdifsr371KzcnbFFRkey3337uuRUrVsjrr7/ubtalc8UChYWF0qJFC7eMunQ6EDe0bpzyUGSSeeQR3zyqKtc2+MRFXfLItxtRxamOZAJ5IM6o3xZ5+MjEIg+LPCzy8JGJRR4h6oQ988wz5fvvv5dbb73VPdQpp5zilkcccYQMHTo086VE5Ohd9C699NJcFyM0yMNHJhZ5xDePdSvXNPjExcbySN6IKp/EqY5kAnkgzqjfFnn4yCTYPBqVtM/IOrlC/bDIw0cmFnmEqBO2oKBArr32Wjfi9YMPPpAlS5ZIq1atpE+fPrLDDjsEU0oAAEKoSUmLjKzTUEz5AQAAMm3lmtWSqKqSNgNPqNP6um4BI+cAYIPqvYfs3LmznHDCCXL22WfLiSeeSAcsjPnz58vo0aPdEuSRCplY5BG9PBJVCek4cEfZ6tjetT50HV037nlkG5lY5IE4o35b5OEjk2DyWLp6VVqdqmHtgKV+WOThIxOLPHI8EvaKK65Ia6TsDTfc0JAyIQbWrVsnixYtckuQR30yybf5Lakj0cujoLAgkHWjmke2kYlFHogz6rdFHj4yscjDIg+LPHxkYpFHjjthX3zxRde5qvNCbGxiXl0PABoiH+e3BAAAAAAAed4Je9hhh8m///1vWb16tRx66KFy+OGHS+/evYMvHYC8xPyWAAAAAJC/wnLvBSDrnbC33367rFy5Uv7v//5Pxo0b527K1a5dOxk0aJDrkN1xxx0zWigAAAAAAADkn+S9F+q6bkOn/gJC1Qmrmjdv7jpd9bFs2TJ58803XYfsI488IltuuaUMHjzYdcjqDbuAtm3buhu26RLkkQqZWORhkYdFHj4yscgDYdameccGrUP9tsjDRybp51GX+y/UZZ0ooH5EL49s3nshKplkE3mEoBO2puLiYjn66KPdY/Hixa5D9h//+Ifcf//9ssMOO8gLL7yQ+ZIiUpo1ayZdu3bNdTFCgzx8ZGKRh0UeFnn4yMQij/yzsc6RsHSe6Dzv/bsOqfO6qaYkon5b5OEjk/TySOf+CxvaLqOE+mGRh49MLPIIWSdsTZWVlW6qglWrVrk7p82ePTszJUOkLV26VCZPnuzmDm7VqpXkO/LwkYlFHhZ5WOThIxOLPPJLXTtQwtB5ks7nb2hd6rdFHj4ySS+PTGyXUUL9sMjDRyYWeQSnXnvUefPmyaOPPionnHCC7L///jJ69GjZeuut3UjY9957L/OlROTolBVvv/22W4I8UiGT9PPQUU1btG5b66Nti2KJA+qHRR4+MrHII7/UtVMkDp0nivptkYePTCzysMjDIg8fmVjkEYKRsNrx+s9//tM9PvnkEzdHrHbADhkyRAYMGCBNmzYNsJgAkN/SuWwMAAAAAABEsBNWR7x++umnbl6IfffdV+6880631P8DAIIXl9FMAAAAAADkozp1wk6ZMkUaNWrkJuYtLy+XJ554wj1SKSgocFMVAAAQpLrcdCYu0zMAAAAAAPKgE7ZPnz7V/04kErWuu7GfIz8UFRVJaWmpW4I8UiETizzSyyPfpmegfvjIxCIPxBn12yIPH5lY5GGRh0UePjKxyCPHnbCPP/54gEVAHJWUlMgxxxyT62KEBnn4yMQij/TyyLfpGagfPjKxyANxRv22yMNHJhZ5WORhkYePTCzyCE5+/RWLrFm7dq2bukKXII9UyMQiD4s8LPLwkYlFHogz6rdFHj4yscjDIg+LPHxkYpFHcOiERSAWLFggd911l1uCPFIhE4s8LPKwyMNHJhZ5IM6o3xZ5+MjEIg+LPCzy8JGJRR7BoRMWAAAAAAAAAAJEJywAAAAAAAAABIhOWAAAAAAAAAAIEJ2wAAAAAAAAABCgxkG+OfJXp06d5Jprrsl1MUKDPHxkYpGHRR4WefjIxCIPxBn12yIPH5lY5GGRh0UePjKxyCM4jIQFAAAAAAAAgADRCYtALFy4UB5++GG3BHmkQiYWeVjkYZGHj0ws8kCcUb8t8vCRiUUeFnlY5OEjE4s8gkMnLAKxZs0a+f77790S5JEKmVjkYZGHRR4+MrHIA3FG/bbIw0cmFnlY5GGRh49MLPIIDnPCAgAAAJCS1i0ysg6QrjbNO2ZkHQAAwoxOWAAAACDPVVUl5KD+3eq8bmFhQeBlQn6oSlRJ/65D6rxuYQEXcwIAookjGAAAAJDn0ulUpQMWmZROpyodsACAKGMkLAKxySabyNFHH+2WII9UyMQiD4s8gs2jUUn7jKyTS9QRizwQZ9Rvizx8ZGKRh0UeFnn4yMQij+DQCYtANG/eXHbZZZdcFyM0yMNHJhZ5WOQRXB6JqippM/CEOq9bUBjOUUfUEYs8EGfU7/DkEdZ5g6kjFnlY5GGRh49MLPIIDp2wCMTy5ctl6tSp0qNHD2nZsqXkO/IINpM4jOqjjljkEVwe6XSqhrUDVlFHLPJAnFG/w5FHmOcNpo5Y5GGRh0UePjKxyCM4dMIiEBUVFfKPf/xDttpqKzZa8gg0k7iM6qOOWORhkUewmcThRA51BHFG/Q5HHmGeN5g6YpGHRR4WefjIxCKP4NAJCyDS4jKqD0BuxOVEDgAAAIBwoxMWAADkrXw6kdOhuM1G12nbojgrZQEAAADyDZ2wAAAAMVeVqJITew7IdTEAAACAvBXtIR0IraZNm0qXLl3cEuSRCplY5GGRh0UePjJJL4/CApp8iC62d4s8fGRikYdFHhZ5+MjEIo/gMBIWgdh0003lpJNOynUxQoM8fGRikYdFHhZ5+MjEIg/EGfXbIg8fmVjkYZGHRR4+MrHIIzgMi0AgqqqqpLKy0i1BHqmQiUUeFnlY5OEjE4s8EGfUb4s8fGRikYdFHhZ5+MjEIo/g0AmLQMybN09uuukmtwR5pEImFnlY5GGRh49MLPJAnFG/LfLwkYlFHhZ5WOThIxOLPIJDJywAAAAAAAAABIhOWAAAAAAAAAAIEJ2wAAAAAAAAABCgxkG+OQAAAAAAABBlHYrb1Przti2Ks1YWRBedsAhE+/btZfjw4VJUVJTrooQCefjIxCIPizws8vCRiUUeiDPqt0UePjKxyMMiD4s80s+kKlElJ/YcIPmCOhIcOmERiEaNGknLli1zXYzQIA8fmVjkYZGHRR4+MrHIA3FG/bbIw0cmFnmkn8fGRjnWdZ0ooH6kn0lhQX7N5EkdCU5+1SRkTXl5uTz99NNuCfJIhUws8rDIwyIPH5lY5IE4o35b5OEjE4s80ssjOcrx4r0H1/rQdXTdqKN++MjEIo/g0AmLQFRWVsoXX3zhliCPVMjEIo9g82hU0l4at9ui1oeuE1bUDx+ZWOSBOKN+W+ThIxOLPNLLI51RjnEYEUn98JGJRR7BYToCAECsJaqqpM3AE+q8bkFh9BvXAAAAAIBw4S9NAECspdOpSgcsAAAAACAIkfhrU4dAjxw5Uvr16ye9evWSSy65ZKNzU3z//fcydOhQ2W233aR///5yxx13yLp161Ku+9prr8kBBxwQUOkBAAAAAAAA5LNIdMKOGDFC3n33Xbnrrrvk0Ucfla+//lqGDRu2wfXXrFkjZ5xxhvv3M888416vkwrfc8893rrjx4+XP/zhD4GWPx+1atVKDj74YLcEeaRCJhZ5WORhkYePTCzyQJxRvy3y8JGJRR4WeVjk4SMTizzyeE7YefPmyUsvvST333+/7L777u65UaNGyaGHHipTpkxxI2PX9/rrr8sPP/wgzz77rLRp00Z22GEH+fHHH+XPf/6znH322dK0aVNZtmyZXH/99W4UbJcuXWTp0qU5+O3iq7i42I1cxk/Iw0cmFnlY5GGRh49MLPJAnFG/LfLwkYlFHhZ5WOThIxOLPPJ4JOzkyZPdcs8996x+rnPnztKhQweZNGlSytd89NFH0qNHD9cBm6Sv147X6dOnV09XMGfOHBk7dqwMHDgw8N8j36xcuVKmTp3qliCPVMjEIg+LPCzy8JGJRR6IM+q3RR4+MrHIwyIPizx8ZGKRR56PhC0pKZFmzZqZ59u3by9z585N+Rp9vmPHjt76Sjtee/bsKd27d3dTGySnJMiERCIhK1asyMh7RZ1+b88995yccsoprsM835GHj0yCyaOgoECaN29e5/X1wKr7rrChfljk4SOTcOxDwrof0fLo7xJltCt/xvZukUcwmQS1/8vFfjXMdYQ8cp8JbQYf+xCLbSa4dmXOO2F1ROqBBx64wZ9fcMEFbvqA9WmnrN6wK5VVq1ZJ69atvfXVhl6TCToXbXKkbb5bsmSJW86aNWujN1HLB+ThI5Ng8tCD0U477SSNSn468bQhyZ/r54XxDCf1wyIPH5kEuw9JR1j3I6naj1FCu/JnbO8WeQSTSVD7v1zsV8NcR8gj95nQZojmPqRJSYuNvl9yHbYZX0MzyVS7MuedsNqrPm7cuA3+/O2335bVq1d7z2tn6oZ6vouKirzXJDtfW7TYeMWtryZNmkjXrl0De/8o0TMnEyZMqJ46It+Rh49MgslDz9AlqqqkzcATNrqurqefF9az0dSPn5GHj0yC24ekK4z7kZkzZ0rU0a78Gdu7RR7BZBLU/i8X+9Uw1xHyyH0mtBmitw/Rv9s6DtyxTu+Zib/x2GaCa1c2DkMDU2+MtSGff/65LF682HWq1ux5nj9//gYrg05F8MUXX5jndH0VZAXSihBkJ2+UaEd4ckkm5JEKmeQ+j4LCwrQv48gW6odFHj4yCU8eYdyPRH0qAkW78mds7xZ5hCeToPZ/DX3fuNUR8shsJrQZ4r0PycTfeGwzwbUrQ39jrt69e0tVVVX1DbqSw4i1Z75Pnz4pX6PPT5s2zd2IK+mDDz6Qli1burlgEbzGjRu7znBdgjxSIROLPCzysMjDRyYWeSDOqN8WefjIxCIPizws8vCRiUUewSlIhHEs+HouueQS+eSTT+SGG25wvdfXXHONFBcXy+OPP+5+rqNkdc6KNm3auNGyOvXA4MGDZZtttpHhw4e7eWevvPJKOfnkk+W8887z3v+uu+6SF198Ud566616l7GsrMwtS0tLG/CbAgAA5F752Dtl7cLZta7TuN0W0vbYCySMot4ui3r5gSgLav/33djJUrnw50FCqTRrVyxbHdtb8gF5xCeTqLcZMo08sidb20wm22WhHwmrrrvuOunXr5/rQD3jjDNku+22k9GjR1f/fMqUKdK/f3+3TN6E66GHHnIjaI877jgZOXKk/OY3v5Fzzjknh78FAAAAAAAAgHwUiU5YnYPi+uuvl0mTJrnHbbfdJiUlJdU/32OPPdzcsbpM0lGwY8aMkc8++8xNKHzBBRdIYWHqX/f8889v0ChY+ObMmeO+M12CPFIhE4s8LPKwyMNHJhZ5IM6o3xZ5+MjEIg+LPCzy8JGJRR553gmLaFq3bl2uixAq5OEjE4s8LPKwyMNHJhZ5IM6o3xZ5+MjEIg+LPCzy8JGJRR7BoBMWAAAAAAAAAAJEJywAAAAAAAAABIhOWAAAAAAAAAAIUOMg3xz5q127dvK73/3O3EAtn5GHj0ws8rDIwyIPH5lY5IE4o35b5OEjE4s8LPKwyMNHJhZ5BIdOWASiSZMm0r59+1wXIzTIw0cmFnlY5GGRh49MLPJAnFG/LfKIZiZNSlpkZJ245JFN5GGRh49MLPIIDtMRIBCLFy+WV155xS1BHqmQiUUeFnlY5OEjE4s8EGfUb4s8opdJoiohHQfuKFsd27vWh66j68Y9j2wjD4s8fGRikUdw6IRFIFauXClTpkxxS5BHKmRikYdFHhZ5+Mgk2DwalbSXxu22qPWh6wDZwPZukUf0MikoLAhk3ajmkW3kYZGHj0ws8ggO0xEAAACgWqKqStoMPKHO6xYUck4fAAAA2BhazQAAAKiWTqcqHbAAAABA3TASFgAAAAAAAGmry/RETGEE/IROWASiZcuWsvfee7slyCMVMrHIwyIPizx8ZGKRB+KM+m2Rh49MLPKwyCO4POIyhRF1xCKP4BQkEomG334RUlZW5palpaW5LgoAAEBei3q7LOrlB6KsfOydsnbh7FrX0ZsTtj32gqyVKY6+GztZKhcuq3WdZu2KZatje0u+IJN4YB8Sv22mLIPtsnCehkDkVVZWyjfffOOWII9UyMQiD4s8LPLwkYlFHogz6rdFHj4yscjDIg+LPILNRKde0E7W2h5hn56BOhIcOmERiPLycnn00UfdEuSRCplY5GGRh0UePjKxyANxRv22yMNHJhZ5WORhkUdwmSSnZ9BRrrU9dB1dN6yoI8GhExYAAAAAAABogHTmvA3r/LgIFt86AAAAAAAAAASITlgAAAAAAAAACBCdsAhEYWGhtGrVyi1BHqmQiUUeFnlY5OEjE4s8EGfUb4s8fGRikYdFHhZ5+MjEIo/gFCQSiUSA7583ysrK3LK0tDTXRQEAAMhrUW+XRb38QJSVj71T1i6cXes6endzvbkO6u+7sZOlcuGyWtdp1q5Ytjq2t+QLMgHCuc1ksl3WuMHvAAAAAAAAUEdNSlpkZB0AiBLGFiMQ8+bNk1GjRrklyCMVMrHIwyIPizx8ZGKRB+KM+m2Rh49MopVHoiohHQfu6Ean1fbQdXTduOeRbeThIxOLPIJDJywCUVVVJUuXLnVLkEcqZGKRh0UeFnn4yMQiD8QZ9dsiDx+ZRCuPgsKCQNaNah7ZRh4+MrHIIzh0wgIAAAAAAABAgOiEBQAAAAAAAIAA0QkLAAAAAAAAAAEqSCQSDZ/pGlJWVuaWpaWluS5KKFRWVsqcOXOkU6dO0qxZM8l35OEjE4s8LPKwyMNHJhZ5xKtdFvXyZxr12yKPYDMpH3unrF04u9Z1GrfbQtoee4GEFXUkmnl8N3ayVC5cVus6zdoVu5uW5UMe2UQm0czjuyxtM5lslzVu8DsAKeiGuu222+a6GKFBHj4yscjDIg+LPHxkYpEH4oz6bZGHj0ws8rDIwyIPH5lY5BEcpiNAICoqKmT8+PFuCfJIhUws8rDIwyIPH5lY5IE4o35b5OEjE4s8LPKwyMNHJhZ5BIdOWARi+fLl8t5777klyCMVMrHIwyIPizx8ZGKRB+KM+m2Rh49MLPKwyMMiDx+ZWOQRHDphAQAAAAAAACBAdMICAAAAAAAAQIDohAUAAAAAAACAANEJi0A0b95cevXq5ZYgj1TIxCIPizws8vCRiUUeiDPqt0UePjKxyMMiD4s8fGRikUdwChKJRCLA988bZWVlbllaWprrogAAAOS1qLfLol5+IMrKx94paxfOrnWdxu22kLbHXpC1MiE/fDd2slQuXFbrOs3aFctWx/bOWpmAMPsuS9tMJttljIRFINasWSPz5893S5BHKmRikYdFHhZ5+MjEIg/EGfXbIg8fmVjkYZGHRR4+MrHIIzh0wiIQCxculPvuu88tQR6pkIlFHhZ5WOThIxOLPBBn1G+LPHxkYpGHRR4WefjIxCKP4DQO8L0BAAAAAIiMRiXtM7IOAADroxMWAAAAAJD3ElVV0mbgCXVet6CQC0sBAHXHUQMAAAAAkPfS6VSlAxYAkC6OHAhMo0aNcl2EUCEPH5lY5GGRh0UePjKxyANxRv22yMNHJhZ5WORhkYePTCzyCEZBIpFIBPTeeaWsrMwtS0tLc10UAACAvBb1dlnUyw8ASN93YydL5cJlta7TrF2xbHVs76yVCQiz77K0zWSyXcZIWAAAAAAAAAAIEJ2wCMSCBQvkgQcecEuQRypkYpGHRR4WefjIxCIPxBn12yIPH5lY5GGRh0UePjKxyCM4dMIiEGvXrpW5c+e6JcgjFTKxyMMiD4s8fGRikQfijPptkYePTCzysMjDIg8fmVjkERw6YQEAAAAAAAAgQHTCAgAAAAAAAECAGgf55gAAAAAAAACQSU1KWmRknWwqSCQSiVwXIg7KysrcsrS0NNdFCYWVK1fK119/Ldttt500b95c8h15+MjEIg+LPCzy8JGJRR7xapdFvfyZRv22yMNHJhZ5RDOP78ZOlsqFy2pdp1m7Ytnq2N55kUc2kUn08khUJaSgsCDj6wbdLqMTNkNoLAMAAIRD1NtlUS8/ACC8nbAActcuY05YBGLZsmXy/vvvuyXIIxUyscjDIg+LPHxkYpEH4oz6bZGHj0ws8rDIwyIPH5lY5BEcOmERiKVLl8obb7zhliCPVMjEIg+LPCzy8JGJRR6IM+q3RR4+MrHIwyIPizx8ZGKRR3DohAUAAAAAAACAANEJCwAAAAAAAAABohMWAAAAAAAAAAJEJywC0axZM9lhhx3cEuSRCplY5GGRh0UePjKxyANxRv22yMNHJhZ5WORhkYePTCzyCE5BIpFIBPj+eaOsrMwtS0tLc10UAACAvBb1dlnUyw8ASN93YydL5cLa70bfrF2xbHVs76yVCYBktF3GSFgEYt26dbJ8+XK3BHmkQiYWeVjkYZGHj0ws8kCcUb8t8vCRiUUeFnlY5OEjE4s8gkMnLAIxf/58ufXWW90S5JEKmVjkYZGHRR4+MrHIA3FG/bbIw0cmFnlY5GGRh49MLPIIDp2wAAAAAAAAABCgxkG+OQAAAAAAAGrXpKRFRtYBEF50wgIAAAAAAORIoiohHQfuWOd1CwoLAi8TgMxjOgIAAAAAAIAcSadTlQ5YILoKEolEIteFiIOysjK3LC0tzXVRQqGqqkrWrFkjTZo0kcJC+vrJw0cmFnlY5GGRh49MLPKIV7ss6uXPNOq3RR4+MrHIwyIPizx8ZGKRR3DtskikWVlZKSNHjpR+/fpJr1695JJLLpHy8vJaX/P999/L0KFDZbfddpP+/fvLHXfcIevWrav++apVq+S2226TAw44wL3nMcccI//617+y8NvkB91QmzVrxgb7/5GHj0ws8rDIwyIPH5lY5IE4o35b5OEjE4s8LPKwyMNHJhZ5BCcSiY4YMULeffddueuuu+TRRx+Vr7/+WoYNG7bB9bXH/owzznD/fuaZZ9zrn376abnnnnuq17n++uvl1VdflWuuuUZeeuklGThwoJx33nkyceLErPxOcffjjz/KE0884ZYgj1TIxCIPizws8vCRiUUeiDPqt0UePjKxyMMiD4s8fGRikUce35hr3rx5rpP0/vvvl9133909N2rUKDn00ENlypQpbhTr+l5//XX54Ycf5Nlnn5U2bdrIDjvs4CrPn//8Zzn77LPdiFh9zxtuuEH23Xdf95pzzjnHdcA+//zzsscee2T994yb1atXy1dffeWWII9UyMQiD4s8LPLwkYlFHogz6rdFHj4yscjDIg+LPHxkYpFHHo+EnTx5slvuueee1c917txZOnToIJMmTUr5mo8++kh69OjhOmCT9PXLli2T6dOnS0FBgevU3WeffczrdKh1RUVFYL8LAAAAAAAAgPwTiZGwJSUlbj6Kmtq3by9z585N+Rp9vmPHjt76as6cOdKzZ083T2xNn332mXzwwQdy1VVX1buseo+zFStW1Pv1caJz7iaXZEIeqZCJRR4WeVjk4SMTizz8NpmedI8y2pU/o35b5OEjE4s8LPKwyMNHJhZ5BNeuzHknrN5A68ADD9zgzy+44AJp2rSp97x2yuoNu1LRitK6dWtvfZXqNTrH7Lnnniu77LKLHHfccVJfOhetjrSFyJIlS9xy1qxZG72JWj4gDx+ZWORhkYdFHj4yscjDl6r9GCW0K39G/bbIw0cmFnlY5GGRh49MLPIIrl2Z805YnVZg3LhxG/z522+/nXIeCu1Mbd68ecrXFBUVea9Jdr62aNHCPP/xxx+7+WB15KxOUdCkSZN6/ibiXtu1a9d6vz5O9GyJVtLu3bt7mecj8vCRiUUeFnlY5OEjE4s8rJkzZ0rU0a78GfXbIg8fmVjkYZGHRR4+MrHII7h2ZUFCx9WGmHbQDh8+XD755BPT86zzuZ588sly5plneq8ZMWKEfPHFF/LUU09VP/ftt9/KwQcfLGPHjnUjXtUbb7zh3lunJ7j33nulVatW9S5nWVmZW5aWltb7PQAAANBwUW+XRb38AAAAcVGWwXZZ6G/M1bt3b6mqqqq+QVdySLTOFdunT5+Ur9Hnp02b5m7ElaTzvbZs2dL15Ku33npLLrroItlvv/3k4YcfblAHLHwrV6508+zqEuSRCplY5GGRh0UePjKxyANxRv22yMNHJhZ5WORhkYePTCzyCE7oO2F1uoLDDz/c3TBr4sSJriJcfPHF0rdvX9l1113dOjr1wIIFC6qnIBg4cKBsttlmcuGFF8qMGTNk/PjxMmrUKPntb3/rRtPq/BaXX3659OjRQ6688kr3f329PhYvXpzj3zgeNMcXX3yRPP8/8vCRiUUeFnlY5OEjE4s8EGfUb4s8fGRikYdFHhZ5+MjEIo887oRV1113nfTr10/OO+88OeOMM2S77baT0aNHV/98ypQp0r9/f7dM3oTroYceciNo9UZbI0eOlN/85jdu7lf1zjvvSEVFhXz66aduWgN9bfJx/vnn5+z3BAAAAAAAABA/Ob8xV13oRMDXX3+9e6Syxx57yOeff26e22abbWTMmDEp1z/iiCPcAwAAAAAAAACCFomRsAAAAAAAAAAQVXTCIhBNmjSRLbfc0i1BHqmQiUUeFnlY5OEjE4s8EGfUb4s8fGRikYdFHhZ5+MjEIo/gFCQSiUSA7583ysrK3LK0tDTXRQEAAMhrUW+XRb38AAAAcVGWwXYZI2EBAAAAAAAAIEB0wiIQc+bMkZEjR7olyCMVMrHIwyIPizx8ZGKRB+KM+m2Rh49MLPKwyMMiDx+ZWOQRHDphAQAAAAAAACBAdMICAAAAAAAAQIDohAUAAAAAAACAANEJCwAAAAAAAAABKkgkEokgPyBflJWVuWVpaWmuixIKa9eulYqKCmndurU0btxY8h15+MjEIg+LPCzy8JGJRR7xapdFvfyZRv22yMNHJhZ5WORhkYePTCzyCK5dRpoIhG6obdu2zXUxQoM8fGRikYdFHhZ5+MjEIg/EGfXbIg8fmVjkYZGHRR4+MrHIIzhMR4BALFq0SF544QW3BHmkQiYWeVjkYZGHj0ws8kCcUb8t8vCRiUUeFnlY5OEjE4s8gkMnLAKxatUqN2RblyCPVMjEIg+LPCzy8JGJRR6IM+q3RR4+MrHIwyIPizx8ZGKRR3DohAUAAAAAAACAANEJCwAAAAAAAAABKkgkEokgPyBffPzxx6JRNm3aNNdFCYV169ZV302vUaNGku/Iw0cmFnlY5GGRh49MLPKwVq9eLQUFBbLbbrtJFNGutKjfFnn4yMQiD4s8LPLwkYlFHsG1K+mEzZApU6a4xnKTJk1yXRQAAIC8tmbNGtdY7tWrl0QR7UoAAID4tSvphAUAAAAAAACAADEnLAAAAAAAAAAEiE5YAAAAAAAAAAgQnbAAAAAAAAAAECA6YQEAAAAAAAAgQHTCAgAAAAAAAECA6IQFAAAAAAAAgADRCQsAAAAAAAAAAaITFgAAAAAAAAACRCcsAAAAAAAAAASITlgAAAAAAAAACBCdsAAAAAAAAAAQIDph6+GVV16R4447TnbddVfp1auX/PKXv5Rnnnkm5bqvvfaaHHDAAQ36vEy8x/q+//576datm0ycODFrmehn6Wc+9thj9fp9Vq1aJbfddpt7rX7GMcccI//6178yUv6a5dNsslVHXnjhBfeZ9clj5cqVct1110n//v2lZ8+ecuKJJ8onn3wiYawjG8sj+d3uvffe7jMHDx7coO/2gQcekJNPPlkyKZP1o66ZnHXWWe4z61vfFy9eLFdffbXss88+sttuu8kJJ5wgH330kWRKsv5mQl3ryO677y7du3evVx4//vijXHrppbLnnnu6z9B8v/rqK4niPiS5/Wse+pkN3f7Dfpypax59+/Z1n/mrX/0q7TyidIypayannXaa+8z6HiOidJzJ1feQCbQrfbQrLdqVFu1KH+1Ki3alRbuyfpmce+657jN32WWXemUSp+NMJupIlI4zgX4HCaRl7NixiV133dUtv/7668RXX32VeOyxxxI9evRI3HXXXWbdN998M1FaWprYf//96/15mXiPVNauXZuYP39+orKyMmuZfPDBB4kddtghsfPOO9fr97nyyisT++67b+Lf//534ptvvkncc889ie7du7v3zQTNQjPRbLJVR6699lqXSX3yuPjiixMHH3xwYuLEiS6PESNGuM+dO3duIkx1pC55JL/bBx54wOVx44031vu7feKJJ9xrTzrppEQmZap+pJNJnz59XB71re+nn356YvDgwYlJkya5zxk5cmRil112cZ+XCStXrnSZNFQ6deSSSy5JDBgwoF55/PrXv04ce+yxiU8//TQxc+bMxPnnn5/o379/YsWKFYmo7UOS2/8tt9zi6khDtv+wH2fSyeORRx5xeQwfPjztPKJyjEknk379+lXvQ+pTR6JynElHsi3y3XffJcKAdqWPdqVFu9KiXemjXWnRrrRoV9Y/E60bmofWi/pkEqfjTCbqSFSOM0G3K+mETdPRRx+duO6667zntTLqgU0tXbo0cfnll7tKe+SRR9ZrB5SJ9whbJr/97W9dBT3ssMPS/n30YKZZvPzyy+b5U045JXHppZcmolpHdtxxx3o1lnUH8/vf/z7xn//8p/q5iooK917jxo1LRCmPmt9tzZ1Yut+t7ryHDh3qduSHHnpoxhvLucjkqquucnkkpZOJHtj0tR999FH1c1VVVYmBAwcm7rjjjkRU68jo0aOrt5d08li8eLE78H/++efVz02fPt1lpI3nKOVRc/t//vnn3e9Qn+0/KseZdPJI7kOS321d84jSMSadTG6++ebqfUi6dSRKx5kod8LSrvTRrrRoV1q0K320Ky3alRbtyvpn8vDDD1fvQ9LNJE7HmUzUkSgdZ4JuVzIdQZoKCwtlypQpsmTJEvO8Xn7wt7/9zf1bhyLPmTNHxo4dKwMHDqzX52TiPT777DP5zW9+44aT9+nTR84//3z54YcfUg7VXrdundx+++1uaLgOQR82bJj86U9/qr70Rtfbaaed5O2333aX9Oy8885y6KGHyvjx46sz+e677+Sqq66SAQMGSI8ePVzZ+/Xr54ad6+eVl5e799JLg9JVUFAg999/v7v8pSb97IqKijq/j5ZfLwPQ4e9att///vfV3+X6Q8m13Ndcc43sscce7pKbK6+8Ui655BL3muQlMwcddFD1UjPR99bXJeuI5n3RRRe5zxozZow0btxYbrnlFvnf//7nvt9zzjlH6qNRo0Zy4403uvdVy5YtkwcffFBatmzpvr8w1REtWzIPfSTriOahrr32Wrnzzjsb/N1OnTpVmjRp4i6l0O+3PrJRPyZPnly9zXz++efV9UO3mZdeekkOPvhgPTnm6vv6l2Slk0lJSYmrE6WlpWY70kc6uWqZDj/8cPc++r3pd7569erq37FmGXUb199HL1PRXG699VY55ZRT5K677nI/16VeHq3l0u9b3/Okk06SNWvWVNeRL774QoYOHerq41//+lcpKipyl5o2dPtv06aNuxxohx12qC7rI488Ih07dpSuXbtGah8yatQo9z0kt39Vn+0/KseZje1DNGO9PLJmHnr5VDp5ROkYU5d9iP4+eoxI1u36HCOidJzRtkhSzTqimWj59f+adxjRrqRdSbuSdqWiXUm7knZleI4zWid1n6jPqeXLl6edSZyOM5moI1E6zowPuF1JJ2yahgwZItOmTXMbkzaQteJoRWjVqpV07tzZraPzyjz66KOy44471vtzGvoeWuGSBxxtPOhBQSvnH/7wh5Tr60FNG/u60T7//POy2WabyeOPP+69pzb0dGPWeV70oHP55Ze7SqyZ6EH+H//4h9vpauNHP0vnPNH31d8nufHXhx4wdePZZJNNqp/T3D/44AO3QdSFHhzPO+88N7/JuHHj5O6775ZJkybJn//855Tr6+/23nvvuQ1X/6BfunSp/P3vfzfr6IFGf6a5vPjii9K8eXO3U03WEd2Y9d+axT//+U9XZx566CH3Xej3u/nmm0tD6c69d+/e8pe//MV9N506dQpVHZk3b151HocddpjbyV144YXy+uuvux3Yq6++6g6ANb/bGTNmpPXdKp1rRxtjW221ldRHtuqHbgdnnHGGy+QXv/iFvP/++66e3HHHHe55Pfj/5z//cfW9RYsW9a7vrVu3ln333VeaNm1a/Zxm/u2339b5PfR70O9ID2762htuuEFefvllV4fXV1VV5eqTvr/+XA/aOsfPhx9+aNbTucP0Dwbddz711FNuPi19bbKOaP7z5893f0RpHTriiCPcgX/TTTdt0PZf0x//+Ed3ANXvSw/ENXOOyj7krbfecq//v//7P7dMd/uP0nFmY/sQ/YMu2Vml5VCaaTp5ROkYU5d9SLJ+JNXnGBGl44xmqX8gKc1Hs9H8tY5cccUVpo6EDe1K2pU10a6kXUm78ie0K320K7N7nKnpyCOPTDuTuB1nMlFHonKcuTzodmVaY23hTJkyJXHRRRcl+vbt64Ye60Pntqh5eUZSzUsc6qs+76GXSHTr1s3NY7Ru3Tr33P/+9z9XdqXDpZPzm+hQeZ3P5+mnnzaXl+iw9OSlN8lh1jrHy/qXXHz88cfufXX93r17m0wGDRqUuOKKK8x7XH/99Q3OROcp0Tl3jjvuuMTq1avr9Jpp06a5z3/rrbeqn/viiy/c71GzfJqNZqX/fuedd6rXXbVqVWLvvfd2l1mo5FB8fd8kzSf5GcOGDXO5rl9H9tprr8Tdd99t3qMheejlQVOnTnWXC+gcMzV/v7DUkb/97W9um+nZs6eXh86ltH4d0XkM0/lu16ffUbqXjWWzfsybN8/NhfOLX/wisfvuu5tM9JKP9etHfer7+iZPnpzo1atX4rzzzqvza7S8OtfeZ599Vv2c/lvnCqpZPvX+++9XlzVpwYIFbk4o3YcpXWqd07qXpHN46qU6Wu/OPfdcb5tJvu+LL75Y/R6aRUPy+PLLLxNlZWXukhj9vP/+97+R3Yck57tLd/uP2nGmrvsQveRLf3b11Vc3KI+wH2PS3YfU5xgRteOMtkXU448/npgxY4YpR6rjTFimI1C0K39Cu5J2Je1K2pW0K2lXhvE4ozk0NJO4HGcyUUe+icBxJsh2ZeP6d9/mLx3KrA89y6Zn9PQM7BNPPCFnnnmmvPnmm+7MWq7pJRI6ukLvPjd69Gh310Y9e6lnjNend3HUO/fVHAauw+f17IT+fjVtt9121f8uLi52S73kQ+9I/dxzz7mh25pBWVmZO3OpGSUv08iUjz/+2F1upZd76FkUvVSoLvSsnJ7ZOfvss91ZEL18bb/99nND8denZzuUDnNPatasmbsz4vq6dOlS/W8duaL0d9azaZqrXvry73//213WpHcA1EuCNJdM2WabbdxSh9JPnz7dfd7+++8fqjqy7bbburstrl271p19euONN+S///1vdR7J13z55ZfVlzyl891mQjbrR3KbefbZZ91ZzXfeecfVD72cUOuGXp5Rk15ykW59r0m3y+HDh7vLUvSMYF3pWVr9HfVO81tuuaXL5MADD3SXaqTKROtUze+/Xbt21SO5aj6n69XMRPPQuqVnGPVMrI52ePfdd13dOvXUU916yW1Gz94uXLjQXWpS3zySl4npaIVPP/3U7b/18pgo7kM0T6XfbzrbfyaEcR/SoUMHt9TjsV6SVJ88onCMSXcfoseHdI8RUTvOaCbJ/aWO1tDRHd98843MnDnT1YWarwkb2pU/oV35E9qVtCsV7UralevnoWhX5uY4s/3227sc6ptJnI4zmagj2+R5u5LpCNIwd+5cGTlypFsm5/PQivO73/3ODYXWIcs6PDwsdMPQCqOX6OiGo5VVh7In591J0nk+lK6zMTUvQUlKDgPXoeF6WYn+Eaw7mXvuucf9XA9smaKNLJ37R3eE2ujSRlU6dO4eveRAN95FixbJpZde6i7VSTVniapLo7ZmJsn5yfSylxUrVriNVi+L0h2mzq2iGde8JKG+tK7p5QGLFy82zycv0wpLHVmwYIFbJi8N0m1FL1PRnZ9eilSzoazf7U033VT9PaX73WZC0PUjSS8RmzVrlhx//PHu8in9Y+KCCy5wl2So5Lw2+geFqm99V9oQ1Kz1wKYHfT0Y15Wuq/Nm6UHn17/+tTvwaCMg1SUfmkl98kjOaaT7Va0vRx11lGso62WAl112mVlX64he/qH1Md08dNvUy3H0D7Yk3Ydrw1m31yjtQ7QBog2Ahm7/mRCGfYhuP7Nnz85IHmE/xtR1H6KX4uoxQutQfTOJynEmKfkHgrZFrr/+evd+gwYNkgceeMB1FIQR7UralanQrrRoV1q0Ky3alT7alQ0/zujvrfvE9U9gxLFtma06EpXjTDbalXTCpkG/HJ1XJznn3Prz5NQ8M5BrX3/9tZv7QkdPnHDCCe5Mgc7loWcE1u/51zMROmeJzrNTk57Jqws9S/Lwww+7s6569kQ3DJ03JXkGKVWlrg/d2HRHoGd/9POSZ23qSn8f3clq4yw5ibv+X+dl0cZcTXo2VM+U1MxEN2w9G1Sb5FktPaOmB3xdXxsbOgm0nsVSOjdLXXYGtdEdwsUXX+x2ZDXpPDN1nQw+G3Uk+d3rXFR6lqtmHdF5q5Rmn5wAPHmmKnkGKpuyUT+SdJTCvffea+qH7tTbt2/vfq5z82h9f/rpp93/61Pflc6NpQcmPYOp81+luy3qaCwdRaCdAjofULKsWv5U80Bp3db6k6QNBT2jXJvkAVL3qzoPjx6Y9ffWhtAhhxxizu5qHdE/LHQ/m24e+ke7bjM6V1qSnuHU9615NjgK+xBtEOqcRA3Z/jMhLPsQrWfaUdXQPKJwjKnrPkRvcqD1XUd11DeTqBxnalq/jmhbZOutt3ajwRp63A0C7crUaFf+jHalRbsyNdqVP6NdadGurN9xRrcZ/X7Xn4M4jm3LbNWRqBxnstGuZDqCNLRt29adgdAvQXvy9c5pelDXswJ64NO70OndG8NAz7Do2Tkdgq0HOT0zp2cdk5d11DwDoTsZnZxaK7EOc9cDh17OohVUh+lvjN7hUg9uutHr2VH9TD0AaSY1/5BoCD2rqRMk6x3pdNLkmncR1h1HXUYB6HeljQddXy9hqqysdAd9Pfiuf0ZKJ+HXYe3a0NCJ3DUXPeuhZ1X199yQ5I5Vh9TrRqp0J6Ybq14Koz/XBsX6Z2rSpe+jv4PWRb2sQd9fJ9jW70yXYakjycuDdCJsPfutZ+j0dXqnUj0DqWXQBpVOqK/frTbqtDNFz8jp+nX9bjMhG/UjSUcqJBvCOkpBJ4PXO1Led9991d+v1vctttjCjWirT33XERF6kNbLVfQMXs2RQ3pAqksjQD9LzwhrNnq5mJZDGy01L3NJ0v2f3rVTRxnoDQr0M3SSc71zZG2ZaGeR0rqsoyr0DOyTTz7pyqfZaN3T99COCq0j+tl68E6OhqlrHtqo0snm9UymPrRu6neml6lpo6YuwrQP0cuTNDO9wYTS7zqd7T8TwrQP0Xw0j+R3qcefdPKIyjGmrvsQfT8tQ7JzTxut6R4jonKcqUn/kNY/wHXEiLbZ9P11pJbuLxp63A0C7crUaFf+jHalRbsyNdqVP6NdadGurP9xRr8T3dco3W40tzi2LbNVR6JynMlGu5JO2DTpsGet9PoF6g5dK4DeiVQrvB6QwkIrqB5odPi6Vna965ueDdaNSzfm9YeB6yUrevZO71ipByY9aOnBUTf0jdF5fXS4ulZIHbquf/Rpo0jPYOpnTpgwocG/j56B0IOabjR6wKtJN6L173KXim54epdTPQOrOzPdaHUeEc1J/70+3YHpQTV5eZPucPRAXZc5XPRMiZ5N0gaf7vx0x5fc8ehw+/VHJ9WHXrqjOxy9lFEbQrqD1wZoqnmVcl1H9JIJbRBrdjr3jj40Dz1Lr3Mx6fer361uX+rYY49N67vNhGzWj9NPP11KS0vd5+lldPq96Q5e5+zRUQs6wkPruz6U3lkzqa6Z6NlK/b50jiN91HT00UdXX6JXm7322svNb6UHYL3LpjaAdd6dDd2RWn8fPehr41Prvl7Oop0/dclEP0f3q7quzqOl24zWb73UUC8V0/fROpI8e5nMJJ06oqM2tL7rGWltTGjnhu7H63o36TDtQ/SSIf0uko0WPYuczvafCWHZh2gjS+9kq2XQ7Unp2fB08ojaMWZj+xA9xujnasNb72KrI8TSPUZE7Tij9HJC3bdpLrpta6NbR5/oPil5V9+woV3po13po11p0a60aFf6aFdatCvTP85oZ5+eINWf6RztmkWc25bZqCNROs4E2q6s8y28EGtvvPFG4scffzTPnX766dV3fcs3eidBvUve0qVLzfN6h8DknQHzDXXkZ9QPn9YNvbNlzbt9VlZWJnbdddfqO9DmE+qIj33Iz6gfqVFH4oPv0mKb91FHfkb98NGutKgjPvYhFnUkOnWEkbBwdI4SPbuil3zoWQQdVaRzjeiZynykcxzpGRo9S6VzCOmZMT3LrnNM6eWC+Yg68jPqh09HXOhIAL0kTufo0bOOWmc0q/XP/uYD6oiPfcjPqB+pUUfig+/SYpv3UUd+Rv3w0a60qCM+9iEWdSQ6daRAe2JzWoI8o5dU6LwVtdG5cvRyjSDfY33ff/+9G2qt8ybppXA6ObLerVLn/QlaJn4fLevEiRNrfY8XXnhBOnfunNZEzDr3kA6116HuOom8XtbUp08fCRJ1JPPfbZzqR6Z+H53zR+c3qo1+Rjo3XdCDmt6h9/PPP3eXyOidI/XSFp0oPkjUEYt9iMUxxkcdiQ++Sx/bvEUdsWgz+GhXWtQRi32Ij+OMRR1JD52wWaYTw+ucMbXRuXt0jrsg3yNMMvH76DwlumHVRufnqct8KLlGHcn8dxun+pGp30fPiuqogtrohOl1uSFErlFHLPYhFscYH3UkPvgufWzzFnXEos3go11pUUcs9iE+jjMWdSQ9dMICAAAAAAAAQID8W6oBAAAAAAAAADKGTlgAAAAAAAAACBCdsAAAAAAAAAAQIDphASAmMj3FN1OGAwAA5CfalQCQeXTCAkDIffHFF3LRRRfJ3nvvLTvvvLP0799fLrzwQpkxY0b1OpMnT5azzjorI5+3evVqueGGG+TVV1/NyPsBAAAgHGhXAkDu0AkLACH25Zdfyq9//WtZvHixXHXVVTJmzBi57LLL5IcffpDjjjtOPvnkE7fe2LFj5auvvsrIZ86fP18effRRWbt2bUbeDwAAALlHuxIAcqtxjj8fAFCLv/71r1JSUiJ/+ctfpHHjn3fZAwcOlEMPPVTuvfdeefDBB3NaRgAAAIQf7UoAyC1GwgJAiC1cuNDNoVVVVWWeb9GihfzhD3+Qww47TH7/+9/Liy++KLNnz5Zu3brJCy+8IN9//737tza2tVHds2dPef75591rx48fL7/5zW+kV69e7jI0/fmTTz7pfqavO/DAA92/r7jiCjnggAOqP/Ojjz6Sk046yb1X37595fLLL5fy8nJTrilTpsiJJ54ou+66q+y3335u5MNpp53myqh++ctfyvHHH+/9nrrO6aefHkCCAAAAULQrASC36IQFgBDTBqdeIqYNTG3Q6qVhyRsbaCP36KOPlnPOOUf23Xdf2WyzzeRvf/ube03SXXfdJWeeeab8+c9/dnN//fvf/5Zzzz1XevTo4UY76M+32morufbaa+XTTz+V9u3by9133+1e+7vf/a7635MmTXIN2qKiIrnjjjtcQ/3DDz+UU045RVatWuXW0bLpOmrUqFFy/vnnu9EUOq9Y0q9+9SvXoP7222+rn5szZ45MnDhRjjnmmCylCgAAkH9oVwJAbjEdAQCEmI4sWLBggTz88MOuQav0MjK9iYI2VHfZZRfZeuutpW3bttK0aVM3UkCtWLHCLXVEg44SSHrttddcA/vKK6+sfk5HLuyxxx6uwaqjEXbccUf3vL7vTjvt5P592223SefOneWBBx6QRo0aued03cMPP9yNhNBRCvqzVq1ayUMPPSTNmzd362y33XZmhMLgwYPlpptukpdfflmGDRvmntN/t2zZUg466KDA8wQAAMhXtCsBILcYCQsAIXfBBRfIhAkTXINVz/gXFxe7O8zqDRQee+yxWl+bbPgmDRkyxDVWly9fLv/9739l3LhxrpGbvHttKitXrnSjGXRUhI6W0Bsr6ENHOnTp0kXee+89t94HH3wg++yzT3VDOdkQ32KLLar/r43pgw8+WF555ZXq5/SSt0GDBrnREAAAAAgO7UoAyB1GwgJABLRp08ad7deHmjZtmlx66aVyyy23yBFHHLHB1+kcXzXpXFvXXHONm7+roKBAttlmG9l9993dz5KXo62voqLCzR2mN3HQx/qaNWtW/d6bbrqp9/N27dqZ/2uDXxvLOheYjn745ptv5Oabb65TDgAAAGgY2pUAkBt0wgJASM2bN89d8qUjFo499ljzM72c66KLLnLzcH333Xd1fs/hw4fL119/LY888ogbTaCXmumIhGeffXaDr9FLurRhrfNy6WVi60uOUOjYsaO74cP6fvzxR3f5WJLefEEvSfvnP/8phYWF7mfJy90AAACQebQrASD3mI4AAEJKz/Q3btxYnnrqKamsrPR+ro1eHS2gow600VkXejMDvWxL5+rShrJ655133DJ5p9zk3FxJepmaNs7180pLS6sf22+/vbsBg875pfr06eMub6tZVh1ZoXfGrUkb3nqzBB018dZbb7m5xAAAABAc2pUAkHuMhAWAkNJG64gRI9yoBB25oDcp0LmydISBzpeld7XV0Qx6SVnr1q3daIG3337bm6+rJr3hgs77pXex1REGH3/8sbvTrDZg9X2T82up999/332e3ijh4osvlrPOOksuueQSOfLII2XdunUyZswYN6eX3kVXnX322W4uMJ0f7Le//a273OzOO+90DXl9/5q0sawNbfWLX/wiwBQBAABAuxIAcq8gsaHJWgAAoTB16lR3F1sdbaDzY+lIAx1BcPLJJ7vRB+qLL75wDWe9hEzvDqs3JDjwwAPlxhtvdA3TpNmzZ8t1113n5s1S2267rbsbrs6ltXjxYnnuuefc83qThb/97W/SpEkT1zDXpTae7777bnfjBf2/NrjPP//86rm/lL7vn//8Z5k+fbqbx2vo0KFy3333uXJeddVV5vfScumoDG2sAwAAIHi0KwEgd+iEBQBkhDamtRFds/Gsoxb22msvueyyy1yjvOa8ZPvvv7+MHj1aBg4cmKMSAwAAIIxoVwKII6YjAABkbGSFNn71EjMdzaAjIP7617+6y9CSd9/VkQz/+te/5PXXX3ejJQ444IBcFxsAAAAhQ7sSQBzRCQsAyAidr2v16tXy9NNPy5w5c6RFixbujrV66Vrbtm3dOnpzBW1Ad+jQQUaNGlXnGz8AAAAgf9CuBBBHTEcAAAAAAAAAAAHiVBEAAAAAAAAABIhOWAAAAAAAAAAIEJ2wAAAAAAAAABAgOmEBAAAAAAAAIEB0wgIAAAAAAABAgOiEBQAAAAAAAIAA0QkLAAAAAAAAAAGiExYAAAAAAAAAAkQnLAAAAAAAAABIcP4fjQXdbSUPEZYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1400x2000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_mean_strat_return(df):\n",
    "    \"\"\"\n",
    "    Plot mean strat_return grouped by symbol, strategy, and prev_regime.\n",
    "    \"\"\"\n",
    "    # Compute mean strat_return\n",
    "    grouped = df.groupby(['symbol', 'strategy', 'prev_regime'])['strat_return'].mean().reset_index()\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    symbols = grouped['symbol'].unique()\n",
    "    n_symbols = len(symbols)\n",
    "\n",
    "    # Create subplots, one per symbol (adjust cols and rows as needed)\n",
    "    cols = 2\n",
    "    rows = (n_symbols + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(14, 5 * rows), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, sym in enumerate(symbols):\n",
    "        ax = axes[i]\n",
    "        data = grouped[grouped['symbol'] == sym]\n",
    "\n",
    "        # Draw barplot with strategy on x-axis, hue=prev_regime\n",
    "        sns.barplot(\n",
    "            data=data,\n",
    "            x='strategy',\n",
    "            y='strat_return',\n",
    "            hue='prev_regime',\n",
    "            ax=ax,\n",
    "            palette='Set2'\n",
    "        )\n",
    "\n",
    "        ax.set_title(f'Mean Strategy Return for {sym}')\n",
    "        ax.set_xlabel('Strategy')\n",
    "        ax.set_ylabel('Mean strat_return')\n",
    "        ax.legend(title='Prev Regime')\n",
    "\n",
    "        # Add vertical delimiters between strategies\n",
    "        # Strategies are categorical on x-axis, positions 0,1,2,...,n-1\n",
    "        n_strategies = data['strategy'].nunique()\n",
    "        for pos in range(0, n_strategies - 1):\n",
    "            ax.axvline(pos + 0.5, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_mean_strat_return(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de8948df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\AppData\\Local\\Temp\\ipykernel_8024\\1789363223.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_features = df_trade_raw.groupby('symbol', group_keys=False).apply(add_features)\n"
     ]
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Returns\n",
    "    # df['return_1d'] = df['close'].pct_change(1)\n",
    "    # df['return_3d'] = df['close'].pct_change(3)\n",
    "    # df['return_5d'] = df['close'].pct_change(5)\n",
    "\n",
    "    # # 2. Volatility (rolling std of returns)\n",
    "    # df['log_return_1d'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    # df['vol_5d'] = df['log_return_1d'].rolling(window=5).std()\n",
    "    # df['vol_10d'] = df['log_return_1d'].rolling(window=10).std()\n",
    "    # df.drop(columns=\"log_return_1d\",  inplace=True)\n",
    "\n",
    "    # # 3. Momentum (price relative to N-day ago)\n",
    "    # # df['mom_5d'] = df['close'] / df['close'].shift(5) - 1\n",
    "    # # df['mom_10d'] = df['close'] / df['close'].shift(10) - 1\n",
    "    # # df['mom_20d'] = df['close'] / df['close'].shift(20) - 1\n",
    "\n",
    "    # # 4. Moving averages\n",
    "    # # df['sma_5d'] = df['close'].rolling(window=5).mean()\n",
    "    # # df['sma_10d'] = df['close'].rolling(window=10).mean()\n",
    "    # # df['sma_20d'] = df['close'].rolling(window=20).mean()\n",
    "\n",
    "    # # 5. Price relative to moving averages\n",
    "    # df['price_div_sma5'] = df['close'] / df['close'].rolling(window=5).mean() - 1\n",
    "    # df['price_div_sma10'] = df['close'] / df['close'].rolling(window=10).mean() - 1\n",
    "    # df['price_div_sma20'] = df['close'] / df['close'].rolling(window=20).mean() - 1\n",
    "\n",
    "    # # 6. Volume features\n",
    "    # # df['vol_rolling_5d'] = df['volume'].rolling(window=5).mean()\n",
    "    # # df['vol_rolling_10d'] = df['volume'].rolling(window=10).mean()\n",
    "    # # df['vol_rolling_20d'] = df['volume'].rolling(window=20).mean()\n",
    "\n",
    "    # # 7. Volatility normalized by volume (volume volatility ratio)\n",
    "    # #df['vol_vol_ratio_5d'] = df['vol_5d'] / (df['vol_rolling_5d'] + 1e-9)\n",
    "\n",
    "    # # 8. Price range (High-Low) relative to close\n",
    "    # df['range_pct'] = (df['high'] - df['low']) / df['close']\n",
    "\n",
    "    # # 9. ATR (Average True Range)\n",
    "    # high_low = df['high'] - df['low']\n",
    "    # high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    # low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    # tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    # df['atr_7'] = tr.rolling(window=7).mean()\n",
    "    # df['atr_14'] = tr.rolling(window=14).mean()\n",
    "\n",
    "    # # 10. Log volume change\n",
    "    # #df['log_vol_change_1d'] = np.log(df['volume'] + 1) - np.log(df['volume'].shift(1) + 1)\n",
    "\n",
    "    # Drop rows with NaNs due to rolling calculations\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df.drop(columns=[\"open\", \"high\", \"low\", \"close\", \"volume\", \"trade_count\", \"vwap\"])\n",
    "\n",
    "# Example usage:\n",
    "df_features = df_trade_raw.groupby('symbol', group_keys=False).apply(add_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215a4fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>strategy</th>\n",
       "      <th>signal</th>\n",
       "      <th>strat_return</th>\n",
       "      <th>prev_regime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_2_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S2_2_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S3_1_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S1_3_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-03 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-03 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S1_2_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-03 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S1_3_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-03 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S2_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91467 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          symbol     strategy  signal  strat_return  \\\n",
       "timestamp                                                             \n",
       "2016-11-14 05:00:00+00:00    EEM  S1_1_signal      -1             0   \n",
       "2016-11-14 05:00:00+00:00    EEM  S1_2_signal      -1             0   \n",
       "2016-11-14 05:00:00+00:00    EEM  S1_3_signal      -1             0   \n",
       "2016-11-14 05:00:00+00:00    EEM  S2_2_signal       1             1   \n",
       "2016-11-14 05:00:00+00:00    EEM  S3_1_signal       1             1   \n",
       "...                          ...          ...     ...           ...   \n",
       "2025-07-02 04:00:00+00:00    USO  S1_3_signal       1             0   \n",
       "2025-07-03 04:00:00+00:00    USO  S1_1_signal      -1             0   \n",
       "2025-07-03 04:00:00+00:00    USO  S1_2_signal      -1             0   \n",
       "2025-07-03 04:00:00+00:00    USO  S1_3_signal       1             0   \n",
       "2025-07-03 04:00:00+00:00    USO  S2_1_signal      -1             0   \n",
       "\n",
       "                           prev_regime  \n",
       "timestamp                               \n",
       "2016-11-14 05:00:00+00:00            3  \n",
       "2016-11-14 05:00:00+00:00            3  \n",
       "2016-11-14 05:00:00+00:00            3  \n",
       "2016-11-14 05:00:00+00:00            3  \n",
       "2016-11-14 05:00:00+00:00            3  \n",
       "...                                ...  \n",
       "2025-07-02 04:00:00+00:00            4  \n",
       "2025-07-03 04:00:00+00:00            4  \n",
       "2025-07-03 04:00:00+00:00            4  \n",
       "2025-07-03 04:00:00+00:00            4  \n",
       "2025-07-03 04:00:00+00:00            4  \n",
       "\n",
       "[91467 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join with previous dataset\n",
    "# Set 'symbol' as part of the index\n",
    "# Join on both index levels (timestamp and symbol)\n",
    "final_df = df_features.set_index('symbol', append=True).join(df_joined.set_index('symbol', append=True), how='inner')\n",
    "\n",
    "# back to column\n",
    "final_df = final_df.reset_index(level='symbol')\n",
    "\n",
    "# discretize the target, 1 if returns > 0.005 (+0.5%)\n",
    "final_df[\"strat_return\"] = np.where(final_df[\"strat_return\"] > 0.01, 1, 0)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90306d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strat_return\n",
       "0    0.627953\n",
       "1    0.372047\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"strat_return\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3d2389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symbol', 'strategy', 'signal', 'strat_return', 'prev_regime'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a96bd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_splits(df, n_splits=5, min_train_size=0.5):\n",
    "    \"\"\"\n",
    "    Time-aware walk-forward splits.\n",
    "    - df: DataFrame with timestamp as index, symbol as a column.\n",
    "    - n_splits: number of folds.\n",
    "    - min_train_size: fraction of timestamps in the first training set.\n",
    "    \"\"\"\n",
    "    df_reset = df.reset_index()  # bring timestamp into a column\n",
    "    df_sorted = df_reset.sort_values('timestamp')\n",
    "    \n",
    "    timestamps = df_sorted['timestamp'].unique()\n",
    "    n_timestamps = len(timestamps)\n",
    "    \n",
    "    initial_train_end = int(n_timestamps * min_train_size)\n",
    "    step_size = (n_timestamps - initial_train_end) // n_splits\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end = initial_train_end + i * step_size\n",
    "        val_end = train_end + step_size\n",
    "        \n",
    "        train_mask = df_sorted['timestamp'] <= timestamps[train_end - 1]\n",
    "        val_mask = (df_sorted['timestamp'] > timestamps[train_end - 1]) & \\\n",
    "                   (df_sorted['timestamp'] <= timestamps[min(val_end - 1, n_timestamps - 1)])\n",
    "        \n",
    "        train_idx = df_sorted[train_mask].index\n",
    "        val_idx = df_sorted[val_mask].index\n",
    "        \n",
    "        yield train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10ee017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_recall_curve\n",
    "from itertools import product\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_search_lightgbm(df, features, target, categorical_features, n_splits=5, n_iter=500):\n",
    "    param_space = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "        'num_leaves': [15, 31, 63],\n",
    "        'max_depth': [-1, 5, 10, 20],\n",
    "        'min_data_in_leaf': [10, 20, 50],\n",
    "        'feature_fraction': [0.6, 0.8, 1.0],\n",
    "        'bagging_fraction': [0.6, 0.8, 1.0],\n",
    "        'bagging_freq': [0, 1, 5],\n",
    "        'lambda_l1': [0.0, 0.1, 1.0],\n",
    "        'lambda_l2': [0.0, 0.1, 1.0],\n",
    "        'scale_pos_weight': [1.0, 5.0, 8.0]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*param_space.items())\n",
    "    all_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    sampled_params = random.sample(all_combinations, min(n_iter, len(all_combinations)))\n",
    "\n",
    "    best_pr_auc = -np.inf\n",
    "    best_config = None\n",
    "    best_oof_preds = None\n",
    "    all_results = []\n",
    "\n",
    "    for i, params in enumerate(sampled_params):\n",
    "        print(f\"\\nTrial {i+1}/{len(sampled_params)}: {params}\")\n",
    "        params.update({\n",
    "            'objective': 'binary',\n",
    "            'metric': 'average_precision',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'seed': 42\n",
    "        })\n",
    "\n",
    "        fold_pr_aucs = []\n",
    "        fold_accs = []\n",
    "        oof_preds = np.zeros(len(df))\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(walk_forward_splits(df, n_splits=n_splits)):\n",
    "            train_data = df.iloc[train_idx]\n",
    "            val_data = df.iloc[val_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_data[features], label=train_data[target], categorical_feature=categorical_features)\n",
    "            lgb_val = lgb.Dataset(val_data[features], label=val_data[target], categorical_feature=categorical_features)\n",
    "\n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_train, lgb_val],\n",
    "                num_boost_round=500,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=25)],\n",
    "            )\n",
    "\n",
    "            preds_proba = model.predict(val_data[features])\n",
    "            preds_binary = (preds_proba > 0.5).astype(int)\n",
    "\n",
    "            oof_preds[val_idx] = preds_proba\n",
    "            pr_auc_score_val = average_precision_score(val_data[target], preds_proba)\n",
    "            acc_score = accuracy_score(val_data[target], preds_binary)\n",
    "\n",
    "            fold_pr_aucs.append(pr_auc_score_val)\n",
    "            fold_accs.append(acc_score)\n",
    "\n",
    "        avg_pr_auc = np.mean(fold_pr_aucs)\n",
    "        avg_acc = np.mean(fold_accs)\n",
    "        all_results.append({'trial': i+1, 'params': params.copy(), 'avg_pr_auc': avg_pr_auc, 'avg_acc': avg_acc})\n",
    "        print(f\"Avg PR-AUC: {avg_pr_auc:.4f} | Avg Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        if avg_pr_auc > best_pr_auc:\n",
    "            best_pr_auc = avg_pr_auc\n",
    "            best_config = params.copy()\n",
    "            best_acc = avg_acc\n",
    "            best_oof_preds = oof_preds.copy()\n",
    "\n",
    "    # Retrain best model on full dataset\n",
    "    lgb_train_full = lgb.Dataset(df[features], label=df[target], categorical_feature=categorical_features)\n",
    "    best_model = lgb.train(\n",
    "        best_config,\n",
    "        lgb_train_full,\n",
    "        num_boost_round=500\n",
    "    )\n",
    "\n",
    "    print(f\"\\nBest Config: PR-AUC: {best_pr_auc:.4f} | Accuracy: {best_acc:.4f} | params_config {best_config} \")\n",
    "    return pd.DataFrame(all_results), best_config, best_model, best_oof_preds\n",
    "\n",
    "def plot_pr_curve_from_oof(oof_preds, y_true):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, oof_preds)\n",
    "    pr_auc = average_precision_score(y_true, oof_preds)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR-AUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Cross-Validation Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3592c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll count forward, resetting when the regime changes\n",
    "consecutive_days = []\n",
    "count = 0\n",
    "prev = None\n",
    "for val in final_df['prev_regime']:\n",
    "    if val == prev:\n",
    "        count += 1\n",
    "    else:\n",
    "        count = 1  # start counting again\n",
    "    consecutive_days.append(count)\n",
    "    prev = val\n",
    "\n",
    "final_df['consec_days_current_regime'] = consecutive_days\n",
    "\n",
    "# Last previous regime different from current\n",
    "last_diff_regime = []\n",
    "for i, curr_regime in enumerate(final_df['prev_regime']):\n",
    "    found = np.nan # if no prev regime\n",
    "    for j in range(i-1, -1, -1):\n",
    "        if final_df['prev_regime'].iloc[j] != curr_regime:\n",
    "            found = final_df['prev_regime'].iloc[j]\n",
    "            break\n",
    "    last_diff_regime.append(found)\n",
    "\n",
    "final_df['last_prev_regime_different'] = last_diff_regime\n",
    "\n",
    "# Days since last occurrence for each regime\n",
    "for regime_type in range(5):\n",
    "    col_name = f\"days_since_regime_{regime_type}\"\n",
    "    mask = final_df['prev_regime'] == regime_type\n",
    "    \n",
    "    last_seen_idx = None\n",
    "    days_since = []\n",
    "    \n",
    "    for i, val in enumerate(final_df['prev_regime']):\n",
    "        if val == regime_type:\n",
    "            last_seen_idx = i\n",
    "            days_since.append(0)\n",
    "        else:\n",
    "            if last_seen_idx is None:\n",
    "                days_since.append(np.nan)  # NaN for never seen\n",
    "            else:\n",
    "                days_since.append(i - last_seen_idx)\n",
    "    \n",
    "    final_df[col_name] = days_since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25a28dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(inplace=True) # drop nan rows that generated with these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d282c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ternatively, label encode if your model can handle categories natively (e.g., LightGBM, CatBoost).\n",
    "#  XGBoost can handle label-encoded categorical features, but only if you use its newer categorical feature support (introduced around v1.5+).\n",
    "# final_df['strategy'] = final_df['strategy'].astype('category')\n",
    "# final_df['regime'] = final_df['regime'].astype('category')\n",
    "\n",
    "# only for Lightgbm or catboost (maybe xgboost also)\n",
    "# Categorical columns\n",
    "categ_feats = ['symbol', 'strategy', 'prev_regime', 'last_prev_regime_different']\n",
    "\n",
    "for feat in categ_feats:\n",
    "    final_df[feat] = final_df[feat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c26f5be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symbol', 'strategy', 'signal', 'strat_return', 'prev_regime',\n",
       "       'consec_days_current_regime', 'last_prev_regime_different',\n",
       "       'days_since_regime_0', 'days_since_regime_1', 'days_since_regime_2',\n",
       "       'days_since_regime_3', 'days_since_regime_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aeb760b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 1/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.645826\tvalid_1's average_precision: 0.45118\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.624854\tvalid_1's average_precision: 0.413273\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.625793\tvalid_1's average_precision: 0.462951\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.571738\tvalid_1's average_precision: 0.464721\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.497452\tvalid_1's average_precision: 0.462903\n",
      "Avg PR-AUC: 0.4510 | Avg Accuracy: 0.6120\n",
      "\n",
      "Trial 2/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.78168\tvalid_1's average_precision: 0.435819\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.724239\tvalid_1's average_precision: 0.440363\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.796857\tvalid_1's average_precision: 0.445664\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.516434\tvalid_1's average_precision: 0.427305\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.624806\tvalid_1's average_precision: 0.475598\n",
      "Avg PR-AUC: 0.4449 | Avg Accuracy: 0.6136\n",
      "\n",
      "Trial 3/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.606922\tvalid_1's average_precision: 0.468915\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.404435\tvalid_1's average_precision: 0.431474\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.522548\tvalid_1's average_precision: 0.437543\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.512167\tvalid_1's average_precision: 0.504168\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.536676\tvalid_1's average_precision: 0.474695\n",
      "Avg PR-AUC: 0.4634 | Avg Accuracy: 0.5259\n",
      "\n",
      "Trial 4/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's average_precision: 0.676224\tvalid_1's average_precision: 0.459191\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.402586\tvalid_1's average_precision: 0.431215\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.547082\tvalid_1's average_precision: 0.447885\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.559756\tvalid_1's average_precision: 0.493196\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.520635\tvalid_1's average_precision: 0.472574\n",
      "Avg PR-AUC: 0.4608 | Avg Accuracy: 0.4462\n",
      "\n",
      "Trial 5/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.68763\tvalid_1's average_precision: 0.460846\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.42543\tvalid_1's average_precision: 0.435528\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.636045\tvalid_1's average_precision: 0.458039\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.624969\tvalid_1's average_precision: 0.485089\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.601471\tvalid_1's average_precision: 0.477813\n",
      "Avg PR-AUC: 0.4635 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 6/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.620368\tvalid_1's average_precision: 0.460266\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.410835\tvalid_1's average_precision: 0.434212\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.563616\tvalid_1's average_precision: 0.451874\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.556388\tvalid_1's average_precision: 0.506018\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.539094\tvalid_1's average_precision: 0.46797\n",
      "Avg PR-AUC: 0.4641 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 7/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.65264\tvalid_1's average_precision: 0.467423\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.641865\tvalid_1's average_precision: 0.4148\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.556688\tvalid_1's average_precision: 0.462794\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.48483\tvalid_1's average_precision: 0.496738\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.594278\tvalid_1's average_precision: 0.475366\n",
      "Avg PR-AUC: 0.4634 | Avg Accuracy: 0.4933\n",
      "\n",
      "Trial 8/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.661152\tvalid_1's average_precision: 0.443386\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.724908\tvalid_1's average_precision: 0.428336\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.630724\tvalid_1's average_precision: 0.476502\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.535551\tvalid_1's average_precision: 0.486373\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.59442\tvalid_1's average_precision: 0.472965\n",
      "Avg PR-AUC: 0.4615 | Avg Accuracy: 0.4150\n",
      "\n",
      "Trial 9/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.686167\tvalid_1's average_precision: 0.460171\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.42543\tvalid_1's average_precision: 0.435528\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.621486\tvalid_1's average_precision: 0.459764\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.641609\tvalid_1's average_precision: 0.448596\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.611829\tvalid_1's average_precision: 0.475723\n",
      "Avg PR-AUC: 0.4560 | Avg Accuracy: 0.6168\n",
      "\n",
      "Trial 10/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.692663\tvalid_1's average_precision: 0.434603\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.626014\tvalid_1's average_precision: 0.441132\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's average_precision: 0.74936\tvalid_1's average_precision: 0.471245\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.641364\tvalid_1's average_precision: 0.447245\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's average_precision: 0.667318\tvalid_1's average_precision: 0.467217\n",
      "Avg PR-AUC: 0.4523 | Avg Accuracy: 0.6177\n",
      "\n",
      "Trial 11/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.595958\tvalid_1's average_precision: 0.479185\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.477557\tvalid_1's average_precision: 0.416251\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.57996\tvalid_1's average_precision: 0.465752\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.567636\tvalid_1's average_precision: 0.506119\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.524673\tvalid_1's average_precision: 0.479469\n",
      "Avg PR-AUC: 0.4694 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 12/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's average_precision: 0.692466\tvalid_1's average_precision: 0.481567\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.594276\tvalid_1's average_precision: 0.433644\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.532827\tvalid_1's average_precision: 0.455186\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.563536\tvalid_1's average_precision: 0.493118\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.536247\tvalid_1's average_precision: 0.480257\n",
      "Avg PR-AUC: 0.4688 | Avg Accuracy: 0.4129\n",
      "\n",
      "Trial 13/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's average_precision: 0.609428\tvalid_1's average_precision: 0.453097\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.556001\tvalid_1's average_precision: 0.408041\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.540778\tvalid_1's average_precision: 0.442951\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.525278\tvalid_1's average_precision: 0.47697\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.495703\tvalid_1's average_precision: 0.442015\n",
      "Avg PR-AUC: 0.4446 | Avg Accuracy: 0.6164\n",
      "\n",
      "Trial 14/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.796665\tvalid_1's average_precision: 0.460394\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.592763\tvalid_1's average_precision: 0.44334\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.754745\tvalid_1's average_precision: 0.473724\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.577935\tvalid_1's average_precision: 0.438589\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.547824\tvalid_1's average_precision: 0.463459\n",
      "Avg PR-AUC: 0.4559 | Avg Accuracy: 0.5442\n",
      "\n",
      "Trial 15/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.76737\tvalid_1's average_precision: 0.469142\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.656797\tvalid_1's average_precision: 0.428503\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.712048\tvalid_1's average_precision: 0.464879\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.692551\tvalid_1's average_precision: 0.422869\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.636833\tvalid_1's average_precision: 0.472133\n",
      "Avg PR-AUC: 0.4515 | Avg Accuracy: 0.6186\n",
      "\n",
      "Trial 16/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's average_precision: 0.71123\tvalid_1's average_precision: 0.452167\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.576976\tvalid_1's average_precision: 0.418566\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.613457\tvalid_1's average_precision: 0.451478\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.602219\tvalid_1's average_precision: 0.470688\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.503394\tvalid_1's average_precision: 0.456839\n",
      "Avg PR-AUC: 0.4499 | Avg Accuracy: 0.5179\n",
      "\n",
      "Trial 17/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000536 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.636792\tvalid_1's average_precision: 0.453273\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.602295\tvalid_1's average_precision: 0.417876\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.601871\tvalid_1's average_precision: 0.458067\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.526975\tvalid_1's average_precision: 0.478402\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.56253\tvalid_1's average_precision: 0.460783\n",
      "Avg PR-AUC: 0.4537 | Avg Accuracy: 0.6151\n",
      "\n",
      "Trial 18/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.62921\tvalid_1's average_precision: 0.451361\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.558884\tvalid_1's average_precision: 0.435269\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.618444\tvalid_1's average_precision: 0.455505\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.559629\tvalid_1's average_precision: 0.490562\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.52579\tvalid_1's average_precision: 0.469457\n",
      "Avg PR-AUC: 0.4604 | Avg Accuracy: 0.4104\n",
      "\n",
      "Trial 19/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.654139\tvalid_1's average_precision: 0.457013\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.617771\tvalid_1's average_precision: 0.417067\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.756137\tvalid_1's average_precision: 0.464456\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.638602\tvalid_1's average_precision: 0.420142\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.583458\tvalid_1's average_precision: 0.461711\n",
      "Avg PR-AUC: 0.4441 | Avg Accuracy: 0.4322\n",
      "\n",
      "Trial 20/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.74983\tvalid_1's average_precision: 0.461976\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.499276\tvalid_1's average_precision: 0.433229\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.605719\tvalid_1's average_precision: 0.466299\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.621792\tvalid_1's average_precision: 0.494324\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.588057\tvalid_1's average_precision: 0.4716\n",
      "Avg PR-AUC: 0.4655 | Avg Accuracy: 0.4554\n",
      "\n",
      "Trial 21/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.636315\tvalid_1's average_precision: 0.459303\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.422261\tvalid_1's average_precision: 0.428754\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.668919\tvalid_1's average_precision: 0.473247\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.465643\tvalid_1's average_precision: 0.455441\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.551908\tvalid_1's average_precision: 0.483806\n",
      "Avg PR-AUC: 0.4601 | Avg Accuracy: 0.6230\n",
      "\n",
      "Trial 22/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.752865\tvalid_1's average_precision: 0.449009\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.645421\tvalid_1's average_precision: 0.44283\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.692322\tvalid_1's average_precision: 0.470924\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.679361\tvalid_1's average_precision: 0.442323\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.631168\tvalid_1's average_precision: 0.469179\n",
      "Avg PR-AUC: 0.4549 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 23/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.599826\tvalid_1's average_precision: 0.440304\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.467256\tvalid_1's average_precision: 0.424524\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.572447\tvalid_1's average_precision: 0.455206\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.56065\tvalid_1's average_precision: 0.480163\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.497116\tvalid_1's average_precision: 0.469714\n",
      "Avg PR-AUC: 0.4540 | Avg Accuracy: 0.6120\n",
      "\n",
      "Trial 24/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.60362\tvalid_1's average_precision: 0.467571\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.472162\tvalid_1's average_precision: 0.436965\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.555029\tvalid_1's average_precision: 0.437143\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.545442\tvalid_1's average_precision: 0.526772\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.541176\tvalid_1's average_precision: 0.475021\n",
      "Avg PR-AUC: 0.4687 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 25/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.730434\tvalid_1's average_precision: 0.463353\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.452873\tvalid_1's average_precision: 0.423579\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.613278\tvalid_1's average_precision: 0.469166\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.586002\tvalid_1's average_precision: 0.465927\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.54979\tvalid_1's average_precision: 0.472725\n",
      "Avg PR-AUC: 0.4590 | Avg Accuracy: 0.4375\n",
      "\n",
      "Trial 26/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.703022\tvalid_1's average_precision: 0.458753\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.628319\tvalid_1's average_precision: 0.421683\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.704595\tvalid_1's average_precision: 0.461462\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.572869\tvalid_1's average_precision: 0.465269\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.563612\tvalid_1's average_precision: 0.452143\n",
      "Avg PR-AUC: 0.4519 | Avg Accuracy: 0.6205\n",
      "\n",
      "Trial 27/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.67252\tvalid_1's average_precision: 0.463574\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.623171\tvalid_1's average_precision: 0.422933\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.656612\tvalid_1's average_precision: 0.469903\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.604856\tvalid_1's average_precision: 0.442016\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.48201\tvalid_1's average_precision: 0.458803\n",
      "Avg PR-AUC: 0.4514 | Avg Accuracy: 0.4858\n",
      "\n",
      "Trial 28/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.657595\tvalid_1's average_precision: 0.46247\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.509739\tvalid_1's average_precision: 0.432485\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.656529\tvalid_1's average_precision: 0.450722\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.584695\tvalid_1's average_precision: 0.469315\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.57423\tvalid_1's average_precision: 0.475966\n",
      "Avg PR-AUC: 0.4582 | Avg Accuracy: 0.4390\n",
      "\n",
      "Trial 29/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.649118\tvalid_1's average_precision: 0.456165\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.657463\tvalid_1's average_precision: 0.423391\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.712575\tvalid_1's average_precision: 0.473016\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.534938\tvalid_1's average_precision: 0.452156\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.571924\tvalid_1's average_precision: 0.471975\n",
      "Avg PR-AUC: 0.4553 | Avg Accuracy: 0.6138\n",
      "\n",
      "Trial 30/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.673409\tvalid_1's average_precision: 0.470382\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.468533\tvalid_1's average_precision: 0.432013\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.568124\tvalid_1's average_precision: 0.450242\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.565373\tvalid_1's average_precision: 0.433455\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.580555\tvalid_1's average_precision: 0.4631\n",
      "Avg PR-AUC: 0.4498 | Avg Accuracy: 0.4228\n",
      "\n",
      "Trial 31/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.689359\tvalid_1's average_precision: 0.465768\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.42243\tvalid_1's average_precision: 0.43548\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.607658\tvalid_1's average_precision: 0.451754\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.620014\tvalid_1's average_precision: 0.452481\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.565437\tvalid_1's average_precision: 0.482865\n",
      "Avg PR-AUC: 0.4577 | Avg Accuracy: 0.6161\n",
      "\n",
      "Trial 32/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.595071\tvalid_1's average_precision: 0.465754\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.437757\tvalid_1's average_precision: 0.422071\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.559306\tvalid_1's average_precision: 0.444122\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.530522\tvalid_1's average_precision: 0.49639\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.483882\tvalid_1's average_precision: 0.484009\n",
      "Avg PR-AUC: 0.4625 | Avg Accuracy: 0.4685\n",
      "\n",
      "Trial 33/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.704673\tvalid_1's average_precision: 0.462411\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.692393\tvalid_1's average_precision: 0.43593\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.607471\tvalid_1's average_precision: 0.460602\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.524346\tvalid_1's average_precision: 0.483177\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.562099\tvalid_1's average_precision: 0.457098\n",
      "Avg PR-AUC: 0.4598 | Avg Accuracy: 0.6112\n",
      "\n",
      "Trial 34/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.738967\tvalid_1's average_precision: 0.461801\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.606996\tvalid_1's average_precision: 0.437844\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.749834\tvalid_1's average_precision: 0.474796\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.55857\tvalid_1's average_precision: 0.475896\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.507038\tvalid_1's average_precision: 0.472921\n",
      "Avg PR-AUC: 0.4647 | Avg Accuracy: 0.4178\n",
      "\n",
      "Trial 35/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.625124\tvalid_1's average_precision: 0.466921\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.493475\tvalid_1's average_precision: 0.435519\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.581286\tvalid_1's average_precision: 0.450318\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.575457\tvalid_1's average_precision: 0.465535\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.560314\tvalid_1's average_precision: 0.478391\n",
      "Avg PR-AUC: 0.4593 | Avg Accuracy: 0.4273\n",
      "\n",
      "Trial 36/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.674784\tvalid_1's average_precision: 0.458333\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.661632\tvalid_1's average_precision: 0.431055\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.633506\tvalid_1's average_precision: 0.452586\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.556827\tvalid_1's average_precision: 0.480548\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.580035\tvalid_1's average_precision: 0.467886\n",
      "Avg PR-AUC: 0.4581 | Avg Accuracy: 0.4295\n",
      "\n",
      "Trial 37/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.810554\tvalid_1's average_precision: 0.465714\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.555007\tvalid_1's average_precision: 0.43682\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.697247\tvalid_1's average_precision: 0.473649\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.503637\tvalid_1's average_precision: 0.451516\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.614718\tvalid_1's average_precision: 0.479401\n",
      "Avg PR-AUC: 0.4614 | Avg Accuracy: 0.6137\n",
      "\n",
      "Trial 38/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's average_precision: 0.670741\tvalid_1's average_precision: 0.468863\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.576276\tvalid_1's average_precision: 0.421576\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.602721\tvalid_1's average_precision: 0.464031\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.500127\tvalid_1's average_precision: 0.484303\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.523287\tvalid_1's average_precision: 0.477367\n",
      "Avg PR-AUC: 0.4632 | Avg Accuracy: 0.4579\n",
      "\n",
      "Trial 39/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.587862\tvalid_1's average_precision: 0.471926\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000706 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.434517\tvalid_1's average_precision: 0.422907\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.540337\tvalid_1's average_precision: 0.439514\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.532226\tvalid_1's average_precision: 0.489276\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.521455\tvalid_1's average_precision: 0.479953\n",
      "Avg PR-AUC: 0.4607 | Avg Accuracy: 0.4276\n",
      "\n",
      "Trial 40/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.550759\tvalid_1's average_precision: 0.433407\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.447083\tvalid_1's average_precision: 0.423755\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.535062\tvalid_1's average_precision: 0.441577\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's average_precision: 0.538336\tvalid_1's average_precision: 0.498185\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.502694\tvalid_1's average_precision: 0.478408\n",
      "Avg PR-AUC: 0.4551 | Avg Accuracy: 0.5661\n",
      "\n",
      "Trial 41/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.543439\tvalid_1's average_precision: 0.441265\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.398215\tvalid_1's average_precision: 0.431078\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.544542\tvalid_1's average_precision: 0.448479\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.523323\tvalid_1's average_precision: 0.488456\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.504522\tvalid_1's average_precision: 0.479992\n",
      "Avg PR-AUC: 0.4579 | Avg Accuracy: 0.5894\n",
      "\n",
      "Trial 42/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.679288\tvalid_1's average_precision: 0.447402\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.668834\tvalid_1's average_precision: 0.419449\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.678652\tvalid_1's average_precision: 0.468491\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.56064\tvalid_1's average_precision: 0.442036\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.655363\tvalid_1's average_precision: 0.453434\n",
      "Avg PR-AUC: 0.4462 | Avg Accuracy: 0.6129\n",
      "\n",
      "Trial 43/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.663084\tvalid_1's average_precision: 0.449867\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.555272\tvalid_1's average_precision: 0.408574\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.667951\tvalid_1's average_precision: 0.459769\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000930 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.570524\tvalid_1's average_precision: 0.462186\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.5718\tvalid_1's average_precision: 0.471929\n",
      "Avg PR-AUC: 0.4505 | Avg Accuracy: 0.6151\n",
      "\n",
      "Trial 44/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.559142\tvalid_1's average_precision: 0.464912\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.448765\tvalid_1's average_precision: 0.435111\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.527647\tvalid_1's average_precision: 0.450602\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.520094\tvalid_1's average_precision: 0.488582\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.527902\tvalid_1's average_precision: 0.486233\n",
      "Avg PR-AUC: 0.4651 | Avg Accuracy: 0.5007\n",
      "\n",
      "Trial 45/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.735338\tvalid_1's average_precision: 0.447686\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.693367\tvalid_1's average_precision: 0.415614\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.664068\tvalid_1's average_precision: 0.477083\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.538799\tvalid_1's average_precision: 0.405718\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.672116\tvalid_1's average_precision: 0.475123\n",
      "Avg PR-AUC: 0.4442 | Avg Accuracy: 0.6094\n",
      "\n",
      "Trial 46/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.827002\tvalid_1's average_precision: 0.437893\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.448535\tvalid_1's average_precision: 0.435054\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.737938\tvalid_1's average_precision: 0.459141\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.527974\tvalid_1's average_precision: 0.460864\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.608892\tvalid_1's average_precision: 0.462113\n",
      "Avg PR-AUC: 0.4510 | Avg Accuracy: 0.6132\n",
      "\n",
      "Trial 47/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's average_precision: 0.74304\tvalid_1's average_precision: 0.461162\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.600152\tvalid_1's average_precision: 0.427185\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.639164\tvalid_1's average_precision: 0.470863\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.585673\tvalid_1's average_precision: 0.503923\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.531578\tvalid_1's average_precision: 0.468565\n",
      "Avg PR-AUC: 0.4663 | Avg Accuracy: 0.4216\n",
      "\n",
      "Trial 48/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.667542\tvalid_1's average_precision: 0.469132\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.40934\tvalid_1's average_precision: 0.431863\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.596354\tvalid_1's average_precision: 0.45471\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.588271\tvalid_1's average_precision: 0.490809\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.595482\tvalid_1's average_precision: 0.472039\n",
      "Avg PR-AUC: 0.4637 | Avg Accuracy: 0.4390\n",
      "\n",
      "Trial 49/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.608192\tvalid_1's average_precision: 0.441307\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.462055\tvalid_1's average_precision: 0.417768\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.578613\tvalid_1's average_precision: 0.438977\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.588388\tvalid_1's average_precision: 0.469011\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.509571\tvalid_1's average_precision: 0.475272\n",
      "Avg PR-AUC: 0.4485 | Avg Accuracy: 0.6162\n",
      "\n",
      "Trial 50/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.575464\tvalid_1's average_precision: 0.468814\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.398563\tvalid_1's average_precision: 0.430239\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.524275\tvalid_1's average_precision: 0.4501\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.530347\tvalid_1's average_precision: 0.484044\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.525803\tvalid_1's average_precision: 0.473336\n",
      "Avg PR-AUC: 0.4613 | Avg Accuracy: 0.4161\n",
      "\n",
      "Trial 51/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.770975\tvalid_1's average_precision: 0.461663\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.821413\tvalid_1's average_precision: 0.446749\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.751342\tvalid_1's average_precision: 0.47369\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.78774\tvalid_1's average_precision: 0.403242\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.840658\tvalid_1's average_precision: 0.467433\n",
      "Avg PR-AUC: 0.4506 | Avg Accuracy: 0.4630\n",
      "\n",
      "Trial 52/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.740179\tvalid_1's average_precision: 0.458204\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.471633\tvalid_1's average_precision: 0.427804\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.619719\tvalid_1's average_precision: 0.449609\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.576071\tvalid_1's average_precision: 0.503596\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.548816\tvalid_1's average_precision: 0.471299\n",
      "Avg PR-AUC: 0.4621 | Avg Accuracy: 0.4146\n",
      "\n",
      "Trial 53/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.651658\tvalid_1's average_precision: 0.469703\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.502572\tvalid_1's average_precision: 0.422369\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.687262\tvalid_1's average_precision: 0.467114\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.60294\tvalid_1's average_precision: 0.474622\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.532232\tvalid_1's average_precision: 0.482684\n",
      "Avg PR-AUC: 0.4633 | Avg Accuracy: 0.4353\n",
      "\n",
      "Trial 54/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's average_precision: 0.662416\tvalid_1's average_precision: 0.459813\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.498901\tvalid_1's average_precision: 0.423658\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.608552\tvalid_1's average_precision: 0.456292\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.475161\tvalid_1's average_precision: 0.479452\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.521746\tvalid_1's average_precision: 0.476784\n",
      "Avg PR-AUC: 0.4592 | Avg Accuracy: 0.4872\n",
      "\n",
      "Trial 55/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.677724\tvalid_1's average_precision: 0.463564\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.521553\tvalid_1's average_precision: 0.472993\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.655807\tvalid_1's average_precision: 0.456869\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.557074\tvalid_1's average_precision: 0.473378\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.535668\tvalid_1's average_precision: 0.473125\n",
      "Avg PR-AUC: 0.4680 | Avg Accuracy: 0.3952\n",
      "\n",
      "Trial 56/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.59459\tvalid_1's average_precision: 0.471757\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.471761\tvalid_1's average_precision: 0.436851\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's average_precision: 0.590942\tvalid_1's average_precision: 0.449655\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.560325\tvalid_1's average_precision: 0.511741\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.544196\tvalid_1's average_precision: 0.473581\n",
      "Avg PR-AUC: 0.4687 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 57/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.563173\tvalid_1's average_precision: 0.445402\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.413019\tvalid_1's average_precision: 0.434076\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.537566\tvalid_1's average_precision: 0.437931\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.537503\tvalid_1's average_precision: 0.501001\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.512168\tvalid_1's average_precision: 0.478826\n",
      "Avg PR-AUC: 0.4594 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 58/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.695744\tvalid_1's average_precision: 0.465828\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.496526\tvalid_1's average_precision: 0.435245\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.753502\tvalid_1's average_precision: 0.459994\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.652171\tvalid_1's average_precision: 0.479348\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.608429\tvalid_1's average_precision: 0.470543\n",
      "Avg PR-AUC: 0.4622 | Avg Accuracy: 0.4394\n",
      "\n",
      "Trial 59/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.662847\tvalid_1's average_precision: 0.473512\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.445615\tvalid_1's average_precision: 0.440031\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.514772\tvalid_1's average_precision: 0.4463\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.508824\tvalid_1's average_precision: 0.490361\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.507015\tvalid_1's average_precision: 0.496453\n",
      "Avg PR-AUC: 0.4693 | Avg Accuracy: 0.4430\n",
      "\n",
      "Trial 60/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.608996\tvalid_1's average_precision: 0.461146\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.398859\tvalid_1's average_precision: 0.430774\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.521979\tvalid_1's average_precision: 0.449485\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.540924\tvalid_1's average_precision: 0.509711\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.506408\tvalid_1's average_precision: 0.485259\n",
      "Avg PR-AUC: 0.4673 | Avg Accuracy: 0.4241\n",
      "\n",
      "Trial 61/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.652161\tvalid_1's average_precision: 0.455984\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.612\tvalid_1's average_precision: 0.410397\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's average_precision: 0.646829\tvalid_1's average_precision: 0.455207\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.549802\tvalid_1's average_precision: 0.48985\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's average_precision: 0.603494\tvalid_1's average_precision: 0.471666\n",
      "Avg PR-AUC: 0.4566 | Avg Accuracy: 0.4474\n",
      "\n",
      "Trial 62/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.45588\tvalid_1's average_precision: 0.42763\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.446761\tvalid_1's average_precision: 0.394208\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's average_precision: 0.561274\tvalid_1's average_precision: 0.446453\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.503101\tvalid_1's average_precision: 0.475359\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.492715\tvalid_1's average_precision: 0.472145\n",
      "Avg PR-AUC: 0.4432 | Avg Accuracy: 0.5394\n",
      "\n",
      "Trial 63/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.637313\tvalid_1's average_precision: 0.473129\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.428757\tvalid_1's average_precision: 0.425713\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.603291\tvalid_1's average_precision: 0.466763\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.588724\tvalid_1's average_precision: 0.459071\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.554676\tvalid_1's average_precision: 0.479978\n",
      "Avg PR-AUC: 0.4609 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 64/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.761409\tvalid_1's average_precision: 0.470364\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.621679\tvalid_1's average_precision: 0.417287\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.654631\tvalid_1's average_precision: 0.463517\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001061 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.544634\tvalid_1's average_precision: 0.412026\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's average_precision: 0.80533\tvalid_1's average_precision: 0.480546\n",
      "Avg PR-AUC: 0.4487 | Avg Accuracy: 0.4726\n",
      "\n",
      "Trial 65/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's average_precision: 0.80103\tvalid_1's average_precision: 0.459664\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.41409\tvalid_1's average_precision: 0.425019\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.664326\tvalid_1's average_precision: 0.461707\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.650453\tvalid_1's average_precision: 0.48827\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.647288\tvalid_1's average_precision: 0.473402\n",
      "Avg PR-AUC: 0.4616 | Avg Accuracy: 0.4644\n",
      "\n",
      "Trial 66/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.678987\tvalid_1's average_precision: 0.452118\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.660596\tvalid_1's average_precision: 0.416486\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.680876\tvalid_1's average_precision: 0.466778\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.596681\tvalid_1's average_precision: 0.469119\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.652896\tvalid_1's average_precision: 0.452288\n",
      "Avg PR-AUC: 0.4514 | Avg Accuracy: 0.6124\n",
      "\n",
      "Trial 67/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.592498\tvalid_1's average_precision: 0.467327\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.41315\tvalid_1's average_precision: 0.431464\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.530574\tvalid_1's average_precision: 0.449505\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.556176\tvalid_1's average_precision: 0.503329\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.527265\tvalid_1's average_precision: 0.476239\n",
      "Avg PR-AUC: 0.4656 | Avg Accuracy: 0.4338\n",
      "\n",
      "Trial 68/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.655612\tvalid_1's average_precision: 0.45475\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.500265\tvalid_1's average_precision: 0.448122\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.666284\tvalid_1's average_precision: 0.464021\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.618843\tvalid_1's average_precision: 0.41904\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.66804\tvalid_1's average_precision: 0.484394\n",
      "Avg PR-AUC: 0.4541 | Avg Accuracy: 0.6153\n",
      "\n",
      "Trial 69/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's average_precision: 0.845457\tvalid_1's average_precision: 0.456628\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.530498\tvalid_1's average_precision: 0.439167\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.636063\tvalid_1's average_precision: 0.457987\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.49853\tvalid_1's average_precision: 0.466051\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.591328\tvalid_1's average_precision: 0.475738\n",
      "Avg PR-AUC: 0.4591 | Avg Accuracy: 0.6140\n",
      "\n",
      "Trial 70/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.628317\tvalid_1's average_precision: 0.467535\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.57093\tvalid_1's average_precision: 0.424898\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.6696\tvalid_1's average_precision: 0.473971\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.492955\tvalid_1's average_precision: 0.48137\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.505843\tvalid_1's average_precision: 0.476824\n",
      "Avg PR-AUC: 0.4649 | Avg Accuracy: 0.4321\n",
      "\n",
      "Trial 71/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.515267\tvalid_1's average_precision: 0.439737\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.431756\tvalid_1's average_precision: 0.425838\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.529571\tvalid_1's average_precision: 0.443878\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.497755\tvalid_1's average_precision: 0.498667\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.477838\tvalid_1's average_precision: 0.472235\n",
      "Avg PR-AUC: 0.4561 | Avg Accuracy: 0.5713\n",
      "\n",
      "Trial 72/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's average_precision: 0.741767\tvalid_1's average_precision: 0.467732\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.598668\tvalid_1's average_precision: 0.4467\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.614826\tvalid_1's average_precision: 0.470675\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.577441\tvalid_1's average_precision: 0.414226\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.535965\tvalid_1's average_precision: 0.457375\n",
      "Avg PR-AUC: 0.4513 | Avg Accuracy: 0.5846\n",
      "\n",
      "Trial 73/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's average_precision: 0.715677\tvalid_1's average_precision: 0.454637\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.631217\tvalid_1's average_precision: 0.40758\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's average_precision: 0.733034\tvalid_1's average_precision: 0.476272\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.541254\tvalid_1's average_precision: 0.41145\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.583175\tvalid_1's average_precision: 0.447942\n",
      "Avg PR-AUC: 0.4396 | Avg Accuracy: 0.5346\n",
      "\n",
      "Trial 74/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.763624\tvalid_1's average_precision: 0.465626\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.451215\tvalid_1's average_precision: 0.427634\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.711974\tvalid_1's average_precision: 0.456717\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.53745\tvalid_1's average_precision: 0.472477\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.66601\tvalid_1's average_precision: 0.474816\n",
      "Avg PR-AUC: 0.4595 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 75/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.860432\tvalid_1's average_precision: 0.4338\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.825336\tvalid_1's average_precision: 0.427823\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.783589\tvalid_1's average_precision: 0.481533\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.678131\tvalid_1's average_precision: 0.416809\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.746202\tvalid_1's average_precision: 0.444548\n",
      "Avg PR-AUC: 0.4409 | Avg Accuracy: 0.5987\n",
      "\n",
      "Trial 76/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.676576\tvalid_1's average_precision: 0.457767\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.401135\tvalid_1's average_precision: 0.433129\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.708792\tvalid_1's average_precision: 0.464359\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.557068\tvalid_1's average_precision: 0.484241\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.554171\tvalid_1's average_precision: 0.484771\n",
      "Avg PR-AUC: 0.4649 | Avg Accuracy: 0.4446\n",
      "\n",
      "Trial 77/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.598093\tvalid_1's average_precision: 0.459377\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.449261\tvalid_1's average_precision: 0.422739\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's average_precision: 0.608141\tvalid_1's average_precision: 0.448513\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.551598\tvalid_1's average_precision: 0.472424\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001175 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.549998\tvalid_1's average_precision: 0.472191\n",
      "Avg PR-AUC: 0.4550 | Avg Accuracy: 0.4312\n",
      "\n",
      "Trial 78/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.747713\tvalid_1's average_precision: 0.440319\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.628053\tvalid_1's average_precision: 0.443267\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.712124\tvalid_1's average_precision: 0.460797\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.639935\tvalid_1's average_precision: 0.450606\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.662672\tvalid_1's average_precision: 0.468094\n",
      "Avg PR-AUC: 0.4526 | Avg Accuracy: 0.6184\n",
      "\n",
      "Trial 79/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.622822\tvalid_1's average_precision: 0.470644\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.466755\tvalid_1's average_precision: 0.423749\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.571518\tvalid_1's average_precision: 0.442696\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.576795\tvalid_1's average_precision: 0.485196\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.530907\tvalid_1's average_precision: 0.476048\n",
      "Avg PR-AUC: 0.4597 | Avg Accuracy: 0.5270\n",
      "\n",
      "Trial 80/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.833337\tvalid_1's average_precision: 0.453714\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.593699\tvalid_1's average_precision: 0.44637\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.734735\tvalid_1's average_precision: 0.468995\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.505177\tvalid_1's average_precision: 0.449201\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.749682\tvalid_1's average_precision: 0.476026\n",
      "Avg PR-AUC: 0.4589 | Avg Accuracy: 0.6159\n",
      "\n",
      "Trial 81/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's average_precision: 0.702788\tvalid_1's average_precision: 0.47239\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.415243\tvalid_1's average_precision: 0.430726\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.533135\tvalid_1's average_precision: 0.451337\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.521843\tvalid_1's average_precision: 0.497962\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.527958\tvalid_1's average_precision: 0.487242\n",
      "Avg PR-AUC: 0.4679 | Avg Accuracy: 0.4586\n",
      "\n",
      "Trial 82/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.719188\tvalid_1's average_precision: 0.468552\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.593001\tvalid_1's average_precision: 0.435246\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.755753\tvalid_1's average_precision: 0.473716\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.58353\tvalid_1's average_precision: 0.441933\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.555086\tvalid_1's average_precision: 0.468167\n",
      "Avg PR-AUC: 0.4575 | Avg Accuracy: 0.5445\n",
      "\n",
      "Trial 83/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.624912\tvalid_1's average_precision: 0.457202\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.653035\tvalid_1's average_precision: 0.431733\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.634144\tvalid_1's average_precision: 0.467178\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.559597\tvalid_1's average_precision: 0.464658\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's average_precision: 0.732353\tvalid_1's average_precision: 0.474432\n",
      "Avg PR-AUC: 0.4590 | Avg Accuracy: 0.4309\n",
      "\n",
      "Trial 84/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.643684\tvalid_1's average_precision: 0.454919\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's average_precision: 0.668281\tvalid_1's average_precision: 0.41661\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.635648\tvalid_1's average_precision: 0.490681\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.571546\tvalid_1's average_precision: 0.47605\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001831 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.517712\tvalid_1's average_precision: 0.462831\n",
      "Avg PR-AUC: 0.4602 | Avg Accuracy: 0.6095\n",
      "\n",
      "Trial 85/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.525963\tvalid_1's average_precision: 0.445104\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.445406\tvalid_1's average_precision: 0.425687\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.531833\tvalid_1's average_precision: 0.443322\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.527573\tvalid_1's average_precision: 0.49377\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.472315\tvalid_1's average_precision: 0.472973\n",
      "Avg PR-AUC: 0.4562 | Avg Accuracy: 0.6210\n",
      "\n",
      "Trial 86/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.650535\tvalid_1's average_precision: 0.477152\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.511471\tvalid_1's average_precision: 0.425623\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.600553\tvalid_1's average_precision: 0.460789\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.608027\tvalid_1's average_precision: 0.445153\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.558479\tvalid_1's average_precision: 0.480156\n",
      "Avg PR-AUC: 0.4578 | Avg Accuracy: 0.6152\n",
      "\n",
      "Trial 87/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.667048\tvalid_1's average_precision: 0.475703\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.533783\tvalid_1's average_precision: 0.425999\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.685942\tvalid_1's average_precision: 0.461107\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.553741\tvalid_1's average_precision: 0.448947\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.636197\tvalid_1's average_precision: 0.475194\n",
      "Avg PR-AUC: 0.4574 | Avg Accuracy: 0.6210\n",
      "\n",
      "Trial 88/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.647492\tvalid_1's average_precision: 0.474396\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.428747\tvalid_1's average_precision: 0.425713\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.599494\tvalid_1's average_precision: 0.461073\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.607729\tvalid_1's average_precision: 0.448948\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.55857\tvalid_1's average_precision: 0.48341\n",
      "Avg PR-AUC: 0.4587 | Avg Accuracy: 0.6160\n",
      "\n",
      "Trial 89/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's average_precision: 0.642328\tvalid_1's average_precision: 0.468478\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.460354\tvalid_1's average_precision: 0.423532\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.591843\tvalid_1's average_precision: 0.457456\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.540271\tvalid_1's average_precision: 0.499625\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.500815\tvalid_1's average_precision: 0.480878\n",
      "Avg PR-AUC: 0.4660 | Avg Accuracy: 0.4645\n",
      "\n",
      "Trial 90/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.746492\tvalid_1's average_precision: 0.438099\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.658056\tvalid_1's average_precision: 0.409818\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.718168\tvalid_1's average_precision: 0.476557\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.599733\tvalid_1's average_precision: 0.434194\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's average_precision: 0.797864\tvalid_1's average_precision: 0.472647\n",
      "Avg PR-AUC: 0.4463 | Avg Accuracy: 0.6059\n",
      "\n",
      "Trial 91/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.543716\tvalid_1's average_precision: 0.424923\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.500379\tvalid_1's average_precision: 0.402284\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.569054\tvalid_1's average_precision: 0.44707\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.524113\tvalid_1's average_precision: 0.501596\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.547064\tvalid_1's average_precision: 0.466356\n",
      "Avg PR-AUC: 0.4484 | Avg Accuracy: 0.5518\n",
      "\n",
      "Trial 92/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.762702\tvalid_1's average_precision: 0.4639\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.65491\tvalid_1's average_precision: 0.437144\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.663543\tvalid_1's average_precision: 0.453315\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.674369\tvalid_1's average_precision: 0.455805\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.579548\tvalid_1's average_precision: 0.469404\n",
      "Avg PR-AUC: 0.4559 | Avg Accuracy: 0.4454\n",
      "\n",
      "Trial 93/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.665939\tvalid_1's average_precision: 0.445795\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.660919\tvalid_1's average_precision: 0.415853\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.751646\tvalid_1's average_precision: 0.474045\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.595963\tvalid_1's average_precision: 0.436722\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.765495\tvalid_1's average_precision: 0.456613\n",
      "Avg PR-AUC: 0.4458 | Avg Accuracy: 0.6140\n",
      "\n",
      "Trial 94/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.65411\tvalid_1's average_precision: 0.454321\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.41758\tvalid_1's average_precision: 0.431811\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.580327\tvalid_1's average_precision: 0.446143\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.612905\tvalid_1's average_precision: 0.505876\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.576117\tvalid_1's average_precision: 0.470978\n",
      "Avg PR-AUC: 0.4618 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 95/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.733384\tvalid_1's average_precision: 0.446981\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.628053\tvalid_1's average_precision: 0.443267\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.804894\tvalid_1's average_precision: 0.479196\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.658092\tvalid_1's average_precision: 0.430355\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.762918\tvalid_1's average_precision: 0.46844\n",
      "Avg PR-AUC: 0.4536 | Avg Accuracy: 0.6163\n",
      "\n",
      "Trial 96/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.602707\tvalid_1's average_precision: 0.45641\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.556797\tvalid_1's average_precision: 0.418287\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\ttraining's average_precision: 0.668691\tvalid_1's average_precision: 0.480509\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.561247\tvalid_1's average_precision: 0.501416\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.516823\tvalid_1's average_precision: 0.467703\n",
      "Avg PR-AUC: 0.4649 | Avg Accuracy: 0.4740\n",
      "\n",
      "Trial 97/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.705604\tvalid_1's average_precision: 0.472602\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.451035\tvalid_1's average_precision: 0.416794\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.571157\tvalid_1's average_precision: 0.434502\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.601328\tvalid_1's average_precision: 0.476584\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.532799\tvalid_1's average_precision: 0.48006\n",
      "Avg PR-AUC: 0.4561 | Avg Accuracy: 0.5317\n",
      "\n",
      "Trial 98/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.619227\tvalid_1's average_precision: 0.459362\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.627762\tvalid_1's average_precision: 0.434754\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.601892\tvalid_1's average_precision: 0.445131\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.53142\tvalid_1's average_precision: 0.50523\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.534992\tvalid_1's average_precision: 0.484396\n",
      "Avg PR-AUC: 0.4658 | Avg Accuracy: 0.3962\n",
      "\n",
      "Trial 99/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.669799\tvalid_1's average_precision: 0.466252\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.416667\tvalid_1's average_precision: 0.428782\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.600083\tvalid_1's average_precision: 0.443756\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.610025\tvalid_1's average_precision: 0.514334\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.605665\tvalid_1's average_precision: 0.469017\n",
      "Avg PR-AUC: 0.4644 | Avg Accuracy: 0.6176\n",
      "\n",
      "Trial 100/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.68244\tvalid_1's average_precision: 0.463465\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.48251\tvalid_1's average_precision: 0.429068\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.65753\tvalid_1's average_precision: 0.461347\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.529283\tvalid_1's average_precision: 0.453324\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.542076\tvalid_1's average_precision: 0.487914\n",
      "Avg PR-AUC: 0.4590 | Avg Accuracy: 0.6178\n",
      "\n",
      "Trial 101/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.609718\tvalid_1's average_precision: 0.442024\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.572462\tvalid_1's average_precision: 0.399902\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.540229\tvalid_1's average_precision: 0.441957\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.563329\tvalid_1's average_precision: 0.466197\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.537679\tvalid_1's average_precision: 0.458355\n",
      "Avg PR-AUC: 0.4417 | Avg Accuracy: 0.5798\n",
      "\n",
      "Trial 102/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.817969\tvalid_1's average_precision: 0.453108\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.41877\tvalid_1's average_precision: 0.430119\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.687399\tvalid_1's average_precision: 0.463857\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.610943\tvalid_1's average_precision: 0.491147\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.71668\tvalid_1's average_precision: 0.454906\n",
      "Avg PR-AUC: 0.4586 | Avg Accuracy: 0.4685\n",
      "\n",
      "Trial 103/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.648565\tvalid_1's average_precision: 0.44462\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.557067\tvalid_1's average_precision: 0.444047\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.627119\tvalid_1's average_precision: 0.450987\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.607707\tvalid_1's average_precision: 0.4811\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.580955\tvalid_1's average_precision: 0.47844\n",
      "Avg PR-AUC: 0.4598 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 104/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.665605\tvalid_1's average_precision: 0.445786\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.720513\tvalid_1's average_precision: 0.428549\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.808483\tvalid_1's average_precision: 0.456192\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.594996\tvalid_1's average_precision: 0.448704\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.616764\tvalid_1's average_precision: 0.439019\n",
      "Avg PR-AUC: 0.4437 | Avg Accuracy: 0.6072\n",
      "\n",
      "Trial 105/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.825317\tvalid_1's average_precision: 0.461985\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.601389\tvalid_1's average_precision: 0.429879\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.718743\tvalid_1's average_precision: 0.464827\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.625752\tvalid_1's average_precision: 0.421883\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.670412\tvalid_1's average_precision: 0.474958\n",
      "Avg PR-AUC: 0.4507 | Avg Accuracy: 0.6150\n",
      "\n",
      "Trial 106/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.64713\tvalid_1's average_precision: 0.455715\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.571386\tvalid_1's average_precision: 0.424091\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's average_precision: 0.609054\tvalid_1's average_precision: 0.475553\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.541794\tvalid_1's average_precision: 0.521191\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.550557\tvalid_1's average_precision: 0.474831\n",
      "Avg PR-AUC: 0.4703 | Avg Accuracy: 0.4042\n",
      "\n",
      "Trial 107/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000688 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.717403\tvalid_1's average_precision: 0.465558\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.568865\tvalid_1's average_precision: 0.42166\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.685682\tvalid_1's average_precision: 0.466603\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.577447\tvalid_1's average_precision: 0.465544\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.563801\tvalid_1's average_precision: 0.46917\n",
      "Avg PR-AUC: 0.4577 | Avg Accuracy: 0.4679\n",
      "\n",
      "Trial 108/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.674375\tvalid_1's average_precision: 0.470885\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.629146\tvalid_1's average_precision: 0.432505\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.634649\tvalid_1's average_precision: 0.473068\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.564072\tvalid_1's average_precision: 0.443645\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.580061\tvalid_1's average_precision: 0.488368\n",
      "Avg PR-AUC: 0.4617 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 109/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.640202\tvalid_1's average_precision: 0.463092\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.614532\tvalid_1's average_precision: 0.419625\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.686969\tvalid_1's average_precision: 0.457904\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.602248\tvalid_1's average_precision: 0.42517\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's average_precision: 0.678901\tvalid_1's average_precision: 0.497814\n",
      "Avg PR-AUC: 0.4527 | Avg Accuracy: 0.3968\n",
      "\n",
      "Trial 110/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.759494\tvalid_1's average_precision: 0.446286\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.526083\tvalid_1's average_precision: 0.432678\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.731378\tvalid_1's average_precision: 0.461925\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.492652\tvalid_1's average_precision: 0.451547\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.583418\tvalid_1's average_precision: 0.479896\n",
      "Avg PR-AUC: 0.4545 | Avg Accuracy: 0.6203\n",
      "\n",
      "Trial 111/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's average_precision: 0.724597\tvalid_1's average_precision: 0.482015\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.589762\tvalid_1's average_precision: 0.438869\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.566229\tvalid_1's average_precision: 0.447344\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.520412\tvalid_1's average_precision: 0.506835\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.522463\tvalid_1's average_precision: 0.470971\n",
      "Avg PR-AUC: 0.4692 | Avg Accuracy: 0.4070\n",
      "\n",
      "Trial 112/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.608216\tvalid_1's average_precision: 0.471281\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.438562\tvalid_1's average_precision: 0.422331\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's average_precision: 0.633255\tvalid_1's average_precision: 0.453313\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.55114\tvalid_1's average_precision: 0.508895\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.520635\tvalid_1's average_precision: 0.47366\n",
      "Avg PR-AUC: 0.4659 | Avg Accuracy: 0.4699\n",
      "\n",
      "Trial 113/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.681402\tvalid_1's average_precision: 0.461754\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.582252\tvalid_1's average_precision: 0.433544\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's average_precision: 0.694102\tvalid_1's average_precision: 0.49061\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.567629\tvalid_1's average_precision: 0.501271\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.579623\tvalid_1's average_precision: 0.47469\n",
      "Avg PR-AUC: 0.4724 | Avg Accuracy: 0.4173\n",
      "\n",
      "Trial 114/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.623173\tvalid_1's average_precision: 0.451727\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.406109\tvalid_1's average_precision: 0.427783\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.560529\tvalid_1's average_precision: 0.468103\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.57749\tvalid_1's average_precision: 0.476118\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.547149\tvalid_1's average_precision: 0.476387\n",
      "Avg PR-AUC: 0.4600 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 115/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.79754\tvalid_1's average_precision: 0.458711\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.533933\tvalid_1's average_precision: 0.425716\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's average_precision: 0.793175\tvalid_1's average_precision: 0.465412\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.636585\tvalid_1's average_precision: 0.470938\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.623816\tvalid_1's average_precision: 0.477164\n",
      "Avg PR-AUC: 0.4596 | Avg Accuracy: 0.5001\n",
      "\n",
      "Trial 116/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.735222\tvalid_1's average_precision: 0.465344\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.482854\tvalid_1's average_precision: 0.424528\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.618549\tvalid_1's average_precision: 0.454225\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.582155\tvalid_1's average_precision: 0.475454\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.539473\tvalid_1's average_precision: 0.479448\n",
      "Avg PR-AUC: 0.4598 | Avg Accuracy: 0.4107\n",
      "\n",
      "Trial 117/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's average_precision: 0.670829\tvalid_1's average_precision: 0.46461\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.597626\tvalid_1's average_precision: 0.423748\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.582716\tvalid_1's average_precision: 0.455633\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.543326\tvalid_1's average_precision: 0.499665\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.503437\tvalid_1's average_precision: 0.471541\n",
      "Avg PR-AUC: 0.4630 | Avg Accuracy: 0.4576\n",
      "\n",
      "Trial 118/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.677664\tvalid_1's average_precision: 0.459029\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.518003\tvalid_1's average_precision: 0.448779\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.629153\tvalid_1's average_precision: 0.462733\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.629834\tvalid_1's average_precision: 0.429725\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.546531\tvalid_1's average_precision: 0.48244\n",
      "Avg PR-AUC: 0.4565 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 119/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.583965\tvalid_1's average_precision: 0.466434\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.446831\tvalid_1's average_precision: 0.437855\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.514107\tvalid_1's average_precision: 0.44598\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.561729\tvalid_1's average_precision: 0.506904\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.507549\tvalid_1's average_precision: 0.495643\n",
      "Avg PR-AUC: 0.4706 | Avg Accuracy: 0.5112\n",
      "\n",
      "Trial 120/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.594619\tvalid_1's average_precision: 0.47176\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.471761\tvalid_1's average_precision: 0.436851\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's average_precision: 0.590995\tvalid_1's average_precision: 0.449662\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.560369\tvalid_1's average_precision: 0.51107\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.544211\tvalid_1's average_precision: 0.473581\n",
      "Avg PR-AUC: 0.4686 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 121/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.648082\tvalid_1's average_precision: 0.459854\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.617353\tvalid_1's average_precision: 0.414407\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.631181\tvalid_1's average_precision: 0.45683\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.514766\tvalid_1's average_precision: 0.485765\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.516333\tvalid_1's average_precision: 0.461525\n",
      "Avg PR-AUC: 0.4557 | Avg Accuracy: 0.4840\n",
      "\n",
      "Trial 122/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.8929\tvalid_1's average_precision: 0.440513\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.732969\tvalid_1's average_precision: 0.443375\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.809638\tvalid_1's average_precision: 0.473903\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.651561\tvalid_1's average_precision: 0.419835\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.819464\tvalid_1's average_precision: 0.472439\n",
      "Avg PR-AUC: 0.4500 | Avg Accuracy: 0.6059\n",
      "\n",
      "Trial 123/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.666684\tvalid_1's average_precision: 0.456589\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.818487\tvalid_1's average_precision: 0.440768\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.659852\tvalid_1's average_precision: 0.47051\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.600745\tvalid_1's average_precision: 0.4395\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.583351\tvalid_1's average_precision: 0.457397\n",
      "Avg PR-AUC: 0.4530 | Avg Accuracy: 0.4481\n",
      "\n",
      "Trial 124/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.725004\tvalid_1's average_precision: 0.457328\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.653651\tvalid_1's average_precision: 0.413577\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.643054\tvalid_1's average_precision: 0.458616\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.561562\tvalid_1's average_precision: 0.460398\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.598813\tvalid_1's average_precision: 0.465838\n",
      "Avg PR-AUC: 0.4512 | Avg Accuracy: 0.6067\n",
      "\n",
      "Trial 125/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.747568\tvalid_1's average_precision: 0.443757\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.651829\tvalid_1's average_precision: 0.441549\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.714625\tvalid_1's average_precision: 0.466213\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.695948\tvalid_1's average_precision: 0.434175\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.766629\tvalid_1's average_precision: 0.474716\n",
      "Avg PR-AUC: 0.4521 | Avg Accuracy: 0.6132\n",
      "\n",
      "Trial 126/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's average_precision: 0.740505\tvalid_1's average_precision: 0.483401\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.442183\tvalid_1's average_precision: 0.442958\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.513996\tvalid_1's average_precision: 0.4424\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.508806\tvalid_1's average_precision: 0.493835\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.506075\tvalid_1's average_precision: 0.497661\n",
      "Avg PR-AUC: 0.4721 | Avg Accuracy: 0.4438\n",
      "\n",
      "Trial 127/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.667676\tvalid_1's average_precision: 0.478952\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.457773\tvalid_1's average_precision: 0.429242\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.573992\tvalid_1's average_precision: 0.447046\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.509458\tvalid_1's average_precision: 0.472055\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.542511\tvalid_1's average_precision: 0.475956\n",
      "Avg PR-AUC: 0.4607 | Avg Accuracy: 0.4249\n",
      "\n",
      "Trial 128/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.624853\tvalid_1's average_precision: 0.465198\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.434858\tvalid_1's average_precision: 0.425868\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.550336\tvalid_1's average_precision: 0.453693\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.573091\tvalid_1's average_precision: 0.47637\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.536567\tvalid_1's average_precision: 0.480609\n",
      "Avg PR-AUC: 0.4603 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 129/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.679232\tvalid_1's average_precision: 0.446822\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.698381\tvalid_1's average_precision: 0.418502\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.570259\tvalid_1's average_precision: 0.461231\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.560717\tvalid_1's average_precision: 0.441794\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.644902\tvalid_1's average_precision: 0.459898\n",
      "Avg PR-AUC: 0.4456 | Avg Accuracy: 0.6087\n",
      "\n",
      "Trial 130/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.804611\tvalid_1's average_precision: 0.4496\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.489309\tvalid_1's average_precision: 0.440271\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.678819\tvalid_1's average_precision: 0.428086\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.588193\tvalid_1's average_precision: 0.470182\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.565369\tvalid_1's average_precision: 0.459738\n",
      "Avg PR-AUC: 0.4496 | Avg Accuracy: 0.4237\n",
      "\n",
      "Trial 131/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.624511\tvalid_1's average_precision: 0.478096\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.539479\tvalid_1's average_precision: 0.417843\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000853 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.577715\tvalid_1's average_precision: 0.450917\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.521386\tvalid_1's average_precision: 0.492882\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.506698\tvalid_1's average_precision: 0.472372\n",
      "Avg PR-AUC: 0.4624 | Avg Accuracy: 0.4055\n",
      "\n",
      "Trial 132/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.799609\tvalid_1's average_precision: 0.435543\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.545959\tvalid_1's average_precision: 0.433117\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.712\tvalid_1's average_precision: 0.448941\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.517487\tvalid_1's average_precision: 0.435692\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.630549\tvalid_1's average_precision: 0.486959\n",
      "Avg PR-AUC: 0.4481 | Avg Accuracy: 0.6167\n",
      "\n",
      "Trial 133/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.659485\tvalid_1's average_precision: 0.455373\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.708346\tvalid_1's average_precision: 0.431082\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.669352\tvalid_1's average_precision: 0.459819\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.553821\tvalid_1's average_precision: 0.431155\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.522985\tvalid_1's average_precision: 0.466658\n",
      "Avg PR-AUC: 0.4488 | Avg Accuracy: 0.4538\n",
      "\n",
      "Trial 134/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.786585\tvalid_1's average_precision: 0.453687\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.519755\tvalid_1's average_precision: 0.433977\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.629376\tvalid_1's average_precision: 0.454727\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.653765\tvalid_1's average_precision: 0.456431\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.605384\tvalid_1's average_precision: 0.468449\n",
      "Avg PR-AUC: 0.4535 | Avg Accuracy: 0.4728\n",
      "\n",
      "Trial 135/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.660562\tvalid_1's average_precision: 0.459601\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.550122\tvalid_1's average_precision: 0.423829\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.615542\tvalid_1's average_precision: 0.457239\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.565097\tvalid_1's average_precision: 0.502953\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.536362\tvalid_1's average_precision: 0.47355\n",
      "Avg PR-AUC: 0.4634 | Avg Accuracy: 0.4160\n",
      "\n",
      "Trial 136/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.651217\tvalid_1's average_precision: 0.436855\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.43852\tvalid_1's average_precision: 0.429789\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.600424\tvalid_1's average_precision: 0.438551\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.611666\tvalid_1's average_precision: 0.493129\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.574891\tvalid_1's average_precision: 0.469019\n",
      "Avg PR-AUC: 0.4535 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 137/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.810496\tvalid_1's average_precision: 0.447652\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.571799\tvalid_1's average_precision: 0.426909\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.801782\tvalid_1's average_precision: 0.465164\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.544824\tvalid_1's average_precision: 0.453842\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.696993\tvalid_1's average_precision: 0.472536\n",
      "Avg PR-AUC: 0.4532 | Avg Accuracy: 0.6172\n",
      "\n",
      "Trial 138/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.681103\tvalid_1's average_precision: 0.447971\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.717305\tvalid_1's average_precision: 0.430811\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.745438\tvalid_1's average_precision: 0.479369\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.532841\tvalid_1's average_precision: 0.433454\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.66926\tvalid_1's average_precision: 0.465393\n",
      "Avg PR-AUC: 0.4514 | Avg Accuracy: 0.6115\n",
      "\n",
      "Trial 139/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.606514\tvalid_1's average_precision: 0.466136\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.577675\tvalid_1's average_precision: 0.427241\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.602474\tvalid_1's average_precision: 0.455678\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.539938\tvalid_1's average_precision: 0.525119\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.546999\tvalid_1's average_precision: 0.471103\n",
      "Avg PR-AUC: 0.4691 | Avg Accuracy: 0.3958\n",
      "\n",
      "Trial 140/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.59761\tvalid_1's average_precision: 0.460729\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.58809\tvalid_1's average_precision: 0.420237\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.583284\tvalid_1's average_precision: 0.459714\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.531736\tvalid_1's average_precision: 0.51323\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.529229\tvalid_1's average_precision: 0.478253\n",
      "Avg PR-AUC: 0.4664 | Avg Accuracy: 0.4172\n",
      "\n",
      "Trial 141/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.795188\tvalid_1's average_precision: 0.447677\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.417129\tvalid_1's average_precision: 0.430368\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.738187\tvalid_1's average_precision: 0.461728\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.66195\tvalid_1's average_precision: 0.47581\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.566971\tvalid_1's average_precision: 0.470454\n",
      "Avg PR-AUC: 0.4572 | Avg Accuracy: 0.4361\n",
      "\n",
      "Trial 142/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.61786\tvalid_1's average_precision: 0.468069\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.564659\tvalid_1's average_precision: 0.437827\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.550667\tvalid_1's average_precision: 0.448423\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.523127\tvalid_1's average_precision: 0.498221\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's average_precision: 0.622828\tvalid_1's average_precision: 0.484952\n",
      "Avg PR-AUC: 0.4675 | Avg Accuracy: 0.4033\n",
      "\n",
      "Trial 143/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.677552\tvalid_1's average_precision: 0.470583\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.611248\tvalid_1's average_precision: 0.428037\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.666433\tvalid_1's average_precision: 0.47656\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.612203\tvalid_1's average_precision: 0.482668\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.587692\tvalid_1's average_precision: 0.488311\n",
      "Avg PR-AUC: 0.4692 | Avg Accuracy: 0.4198\n",
      "\n",
      "Trial 144/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.652404\tvalid_1's average_precision: 0.470414\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.593881\tvalid_1's average_precision: 0.436633\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.587492\tvalid_1's average_precision: 0.456249\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.553174\tvalid_1's average_precision: 0.508787\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.483635\tvalid_1's average_precision: 0.472508\n",
      "Avg PR-AUC: 0.4689 | Avg Accuracy: 0.4047\n",
      "\n",
      "Trial 145/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.59822\tvalid_1's average_precision: 0.480435\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.469768\tvalid_1's average_precision: 0.429886\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.553247\tvalid_1's average_precision: 0.475212\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.566433\tvalid_1's average_precision: 0.449981\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.535736\tvalid_1's average_precision: 0.48274\n",
      "Avg PR-AUC: 0.4637 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 146/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.611157\tvalid_1's average_precision: 0.4705\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.472399\tvalid_1's average_precision: 0.436049\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's average_precision: 0.658707\tvalid_1's average_precision: 0.463236\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.546546\tvalid_1's average_precision: 0.492596\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.604879\tvalid_1's average_precision: 0.465073\n",
      "Avg PR-AUC: 0.4655 | Avg Accuracy: 0.6166\n",
      "\n",
      "Trial 147/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.599216\tvalid_1's average_precision: 0.446294\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.467859\tvalid_1's average_precision: 0.428041\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.560781\tvalid_1's average_precision: 0.442866\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.565638\tvalid_1's average_precision: 0.496047\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.532079\tvalid_1's average_precision: 0.489774\n",
      "Avg PR-AUC: 0.4606 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 148/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.59858\tvalid_1's average_precision: 0.444868\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.504706\tvalid_1's average_precision: 0.400464\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.557665\tvalid_1's average_precision: 0.460709\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.503703\tvalid_1's average_precision: 0.464388\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.504706\tvalid_1's average_precision: 0.460301\n",
      "Avg PR-AUC: 0.4461 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 149/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.638755\tvalid_1's average_precision: 0.462669\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.417257\tvalid_1's average_precision: 0.426159\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.565334\tvalid_1's average_precision: 0.431452\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.578706\tvalid_1's average_precision: 0.470868\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.545749\tvalid_1's average_precision: 0.48374\n",
      "Avg PR-AUC: 0.4550 | Avg Accuracy: 0.5105\n",
      "\n",
      "Trial 150/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.776748\tvalid_1's average_precision: 0.457951\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.453762\tvalid_1's average_precision: 0.439243\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's average_precision: 0.763985\tvalid_1's average_precision: 0.464424\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.613479\tvalid_1's average_precision: 0.46521\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.542474\tvalid_1's average_precision: 0.475802\n",
      "Avg PR-AUC: 0.4605 | Avg Accuracy: 0.5297\n",
      "\n",
      "Trial 151/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.610711\tvalid_1's average_precision: 0.464104\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.40991\tvalid_1's average_precision: 0.436553\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.535517\tvalid_1's average_precision: 0.439401\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.532391\tvalid_1's average_precision: 0.47906\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.552852\tvalid_1's average_precision: 0.478713\n",
      "Avg PR-AUC: 0.4596 | Avg Accuracy: 0.4225\n",
      "\n",
      "Trial 152/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's average_precision: 0.763512\tvalid_1's average_precision: 0.439664\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.687311\tvalid_1's average_precision: 0.419347\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.693504\tvalid_1's average_precision: 0.461488\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.667189\tvalid_1's average_precision: 0.405117\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.655033\tvalid_1's average_precision: 0.465291\n",
      "Avg PR-AUC: 0.4382 | Avg Accuracy: 0.6157\n",
      "\n",
      "Trial 153/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.81368\tvalid_1's average_precision: 0.457916\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.512732\tvalid_1's average_precision: 0.430974\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.686379\tvalid_1's average_precision: 0.483454\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.680757\tvalid_1's average_precision: 0.473315\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.563255\tvalid_1's average_precision: 0.473334\n",
      "Avg PR-AUC: 0.4638 | Avg Accuracy: 0.4874\n",
      "\n",
      "Trial 154/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's average_precision: 0.644835\tvalid_1's average_precision: 0.450842\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.54728\tvalid_1's average_precision: 0.405564\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.564754\tvalid_1's average_precision: 0.448949\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.540553\tvalid_1's average_precision: 0.438898\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's average_precision: 0.603153\tvalid_1's average_precision: 0.471165\n",
      "Avg PR-AUC: 0.4431 | Avg Accuracy: 0.6172\n",
      "\n",
      "Trial 155/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.651871\tvalid_1's average_precision: 0.463162\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.416405\tvalid_1's average_precision: 0.425882\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.681885\tvalid_1's average_precision: 0.459725\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.598819\tvalid_1's average_precision: 0.492915\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.564401\tvalid_1's average_precision: 0.479165\n",
      "Avg PR-AUC: 0.4642 | Avg Accuracy: 0.4411\n",
      "\n",
      "Trial 156/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.7764\tvalid_1's average_precision: 0.437387\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.628053\tvalid_1's average_precision: 0.443267\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.78066\tvalid_1's average_precision: 0.463122\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.651462\tvalid_1's average_precision: 0.419746\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.805431\tvalid_1's average_precision: 0.47622\n",
      "Avg PR-AUC: 0.4479 | Avg Accuracy: 0.6176\n",
      "\n",
      "Trial 157/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.703267\tvalid_1's average_precision: 0.464715\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.657606\tvalid_1's average_precision: 0.432667\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.680195\tvalid_1's average_precision: 0.488296\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.545645\tvalid_1's average_precision: 0.509263\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.592448\tvalid_1's average_precision: 0.485639\n",
      "Avg PR-AUC: 0.4761 | Avg Accuracy: 0.4164\n",
      "\n",
      "Trial 158/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.670449\tvalid_1's average_precision: 0.46683\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's average_precision: 0.740638\tvalid_1's average_precision: 0.445328\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.539054\tvalid_1's average_precision: 0.456704\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.551871\tvalid_1's average_precision: 0.486865\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.514062\tvalid_1's average_precision: 0.481279\n",
      "Avg PR-AUC: 0.4674 | Avg Accuracy: 0.4135\n",
      "\n",
      "Trial 159/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.649457\tvalid_1's average_precision: 0.471459\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.512108\tvalid_1's average_precision: 0.434939\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.645223\tvalid_1's average_precision: 0.460885\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.556186\tvalid_1's average_precision: 0.447032\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.575038\tvalid_1's average_precision: 0.482379\n",
      "Avg PR-AUC: 0.4593 | Avg Accuracy: 0.6197\n",
      "\n",
      "Trial 160/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.638992\tvalid_1's average_precision: 0.446625\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.650436\tvalid_1's average_precision: 0.416907\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.65334\tvalid_1's average_precision: 0.462856\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.541556\tvalid_1's average_precision: 0.419919\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.599307\tvalid_1's average_precision: 0.474582\n",
      "Avg PR-AUC: 0.4442 | Avg Accuracy: 0.6146\n",
      "\n",
      "Trial 161/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.627144\tvalid_1's average_precision: 0.458971\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.473327\tvalid_1's average_precision: 0.436873\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.589521\tvalid_1's average_precision: 0.443917\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.484652\tvalid_1's average_precision: 0.45324\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.541536\tvalid_1's average_precision: 0.478035\n",
      "Avg PR-AUC: 0.4542 | Avg Accuracy: 0.4245\n",
      "\n",
      "Trial 162/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.64345\tvalid_1's average_precision: 0.471662\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.41658\tvalid_1's average_precision: 0.424407\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.555917\tvalid_1's average_precision: 0.451809\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.609974\tvalid_1's average_precision: 0.463501\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.563879\tvalid_1's average_precision: 0.476618\n",
      "Avg PR-AUC: 0.4576 | Avg Accuracy: 0.4374\n",
      "\n",
      "Trial 163/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.724823\tvalid_1's average_precision: 0.448641\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.672638\tvalid_1's average_precision: 0.411894\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.570259\tvalid_1's average_precision: 0.461231\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.560717\tvalid_1's average_precision: 0.441794\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.62901\tvalid_1's average_precision: 0.44744\n",
      "Avg PR-AUC: 0.4422 | Avg Accuracy: 0.6062\n",
      "\n",
      "Trial 164/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.632515\tvalid_1's average_precision: 0.460699\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.463981\tvalid_1's average_precision: 0.42979\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.590732\tvalid_1's average_precision: 0.453954\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.559052\tvalid_1's average_precision: 0.490659\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.600255\tvalid_1's average_precision: 0.475736\n",
      "Avg PR-AUC: 0.4622 | Avg Accuracy: 0.4355\n",
      "\n",
      "Trial 165/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.5961\tvalid_1's average_precision: 0.466732\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.454775\tvalid_1's average_precision: 0.424901\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.673004\tvalid_1's average_precision: 0.479532\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.561238\tvalid_1's average_precision: 0.465973\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.550139\tvalid_1's average_precision: 0.485968\n",
      "Avg PR-AUC: 0.4646 | Avg Accuracy: 0.4237\n",
      "\n",
      "Trial 166/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.604755\tvalid_1's average_precision: 0.449244\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.406205\tvalid_1's average_precision: 0.427522\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.559478\tvalid_1's average_precision: 0.472965\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.575645\tvalid_1's average_precision: 0.477447\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.548406\tvalid_1's average_precision: 0.470944\n",
      "Avg PR-AUC: 0.4596 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 167/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.747774\tvalid_1's average_precision: 0.461582\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.448288\tvalid_1's average_precision: 0.430154\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.719779\tvalid_1's average_precision: 0.456976\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.685506\tvalid_1's average_precision: 0.469457\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.682827\tvalid_1's average_precision: 0.473718\n",
      "Avg PR-AUC: 0.4584 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 168/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's average_precision: 0.79209\tvalid_1's average_precision: 0.45955\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.486208\tvalid_1's average_precision: 0.440334\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.622912\tvalid_1's average_precision: 0.465992\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.621066\tvalid_1's average_precision: 0.474108\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.591971\tvalid_1's average_precision: 0.467795\n",
      "Avg PR-AUC: 0.4616 | Avg Accuracy: 0.4470\n",
      "\n",
      "Trial 169/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.680214\tvalid_1's average_precision: 0.4494\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.684913\tvalid_1's average_precision: 0.419827\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.714852\tvalid_1's average_precision: 0.467578\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.600195\tvalid_1's average_precision: 0.439602\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.657859\tvalid_1's average_precision: 0.453915\n",
      "Avg PR-AUC: 0.4461 | Avg Accuracy: 0.6127\n",
      "\n",
      "Trial 170/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.775385\tvalid_1's average_precision: 0.47383\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.5401\tvalid_1's average_precision: 0.46218\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.706685\tvalid_1's average_precision: 0.484024\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.483279\tvalid_1's average_precision: 0.424494\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.583501\tvalid_1's average_precision: 0.477708\n",
      "Avg PR-AUC: 0.4644 | Avg Accuracy: 0.6194\n",
      "\n",
      "Trial 171/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.66614\tvalid_1's average_precision: 0.458712\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.445672\tvalid_1's average_precision: 0.431273\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.618154\tvalid_1's average_precision: 0.459126\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.487615\tvalid_1's average_precision: 0.468876\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.593121\tvalid_1's average_precision: 0.491316\n",
      "Avg PR-AUC: 0.4619 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 172/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.698109\tvalid_1's average_precision: 0.444848\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.60666\tvalid_1's average_precision: 0.425839\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.627087\tvalid_1's average_precision: 0.475521\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.491508\tvalid_1's average_precision: 0.469682\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.582351\tvalid_1's average_precision: 0.459664\n",
      "Avg PR-AUC: 0.4551 | Avg Accuracy: 0.6141\n",
      "\n",
      "Trial 173/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.82704\tvalid_1's average_precision: 0.452411\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.758198\tvalid_1's average_precision: 0.42358\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.686529\tvalid_1's average_precision: 0.463946\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.541274\tvalid_1's average_precision: 0.407277\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.640583\tvalid_1's average_precision: 0.465968\n",
      "Avg PR-AUC: 0.4426 | Avg Accuracy: 0.6034\n",
      "\n",
      "Trial 174/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.658665\tvalid_1's average_precision: 0.472744\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.40287\tvalid_1's average_precision: 0.431053\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.609947\tvalid_1's average_precision: 0.455405\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.554524\tvalid_1's average_precision: 0.502107\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.577558\tvalid_1's average_precision: 0.473149\n",
      "Avg PR-AUC: 0.4669 | Avg Accuracy: 0.4405\n",
      "\n",
      "Trial 175/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.591224\tvalid_1's average_precision: 0.460538\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.590033\tvalid_1's average_precision: 0.437891\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.533263\tvalid_1's average_precision: 0.453175\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.565947\tvalid_1's average_precision: 0.485801\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.53193\tvalid_1's average_precision: 0.476609\n",
      "Avg PR-AUC: 0.4628 | Avg Accuracy: 0.3998\n",
      "\n",
      "Trial 176/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.482042\tvalid_1's average_precision: 0.430112\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.443593\tvalid_1's average_precision: 0.394122\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.518137\tvalid_1's average_precision: 0.436568\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.502982\tvalid_1's average_precision: 0.495849\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.485267\tvalid_1's average_precision: 0.472113\n",
      "Avg PR-AUC: 0.4458 | Avg Accuracy: 0.5085\n",
      "\n",
      "Trial 177/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.636269\tvalid_1's average_precision: 0.459223\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.422288\tvalid_1's average_precision: 0.428754\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.653606\tvalid_1's average_precision: 0.467224\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.465696\tvalid_1's average_precision: 0.457283\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.551951\tvalid_1's average_precision: 0.483818\n",
      "Avg PR-AUC: 0.4593 | Avg Accuracy: 0.6218\n",
      "\n",
      "Trial 178/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's average_precision: 0.645623\tvalid_1's average_precision: 0.464981\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.45577\tvalid_1's average_precision: 0.42473\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.531027\tvalid_1's average_precision: 0.447574\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.567123\tvalid_1's average_precision: 0.505042\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.480293\tvalid_1's average_precision: 0.474354\n",
      "Avg PR-AUC: 0.4633 | Avg Accuracy: 0.5267\n",
      "\n",
      "Trial 179/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.715986\tvalid_1's average_precision: 0.46232\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.632809\tvalid_1's average_precision: 0.437659\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.670684\tvalid_1's average_precision: 0.466363\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.609331\tvalid_1's average_precision: 0.454104\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.81386\tvalid_1's average_precision: 0.464158\n",
      "Avg PR-AUC: 0.4569 | Avg Accuracy: 0.4692\n",
      "\n",
      "Trial 180/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's average_precision: 0.599975\tvalid_1's average_precision: 0.457863\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.578525\tvalid_1's average_precision: 0.40315\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.559294\tvalid_1's average_precision: 0.447264\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.523482\tvalid_1's average_precision: 0.489454\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.54734\tvalid_1's average_precision: 0.465845\n",
      "Avg PR-AUC: 0.4527 | Avg Accuracy: 0.5500\n",
      "\n",
      "Trial 181/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.85227\tvalid_1's average_precision: 0.4434\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.868456\tvalid_1's average_precision: 0.43196\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.770452\tvalid_1's average_precision: 0.46181\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.629084\tvalid_1's average_precision: 0.422822\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.765516\tvalid_1's average_precision: 0.472715\n",
      "Avg PR-AUC: 0.4465 | Avg Accuracy: 0.5994\n",
      "\n",
      "Trial 182/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.763354\tvalid_1's average_precision: 0.463048\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.57566\tvalid_1's average_precision: 0.431486\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.699905\tvalid_1's average_precision: 0.465413\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.665442\tvalid_1's average_precision: 0.431452\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.689828\tvalid_1's average_precision: 0.479422\n",
      "Avg PR-AUC: 0.4542 | Avg Accuracy: 0.6158\n",
      "\n",
      "Trial 183/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.700417\tvalid_1's average_precision: 0.457562\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.646524\tvalid_1's average_precision: 0.43392\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.733254\tvalid_1's average_precision: 0.468051\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.582776\tvalid_1's average_precision: 0.44143\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's average_precision: 0.817805\tvalid_1's average_precision: 0.470243\n",
      "Avg PR-AUC: 0.4542 | Avg Accuracy: 0.4720\n",
      "\n",
      "Trial 184/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.690808\tvalid_1's average_precision: 0.436428\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.635086\tvalid_1's average_precision: 0.441237\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's average_precision: 0.743889\tvalid_1's average_precision: 0.467181\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.64172\tvalid_1's average_precision: 0.447726\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.660453\tvalid_1's average_precision: 0.467314\n",
      "Avg PR-AUC: 0.4520 | Avg Accuracy: 0.6187\n",
      "\n",
      "Trial 185/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.561364\tvalid_1's average_precision: 0.433228\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.561554\tvalid_1's average_precision: 0.405826\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.572863\tvalid_1's average_precision: 0.448928\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.570637\tvalid_1's average_precision: 0.463968\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.499442\tvalid_1's average_precision: 0.460507\n",
      "Avg PR-AUC: 0.4425 | Avg Accuracy: 0.6144\n",
      "\n",
      "Trial 186/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.636567\tvalid_1's average_precision: 0.468104\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.460357\tvalid_1's average_precision: 0.428105\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's average_precision: 0.736733\tvalid_1's average_precision: 0.464357\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.514875\tvalid_1's average_precision: 0.481162\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.49211\tvalid_1's average_precision: 0.477692\n",
      "Avg PR-AUC: 0.4639 | Avg Accuracy: 0.3988\n",
      "\n",
      "Trial 187/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.649824\tvalid_1's average_precision: 0.465483\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.471571\tvalid_1's average_precision: 0.427675\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.717743\tvalid_1's average_precision: 0.454354\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.571808\tvalid_1's average_precision: 0.46974\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.564773\tvalid_1's average_precision: 0.477656\n",
      "Avg PR-AUC: 0.4590 | Avg Accuracy: 0.4334\n",
      "\n",
      "Trial 188/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.655913\tvalid_1's average_precision: 0.466236\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.644832\tvalid_1's average_precision: 0.424913\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.590753\tvalid_1's average_precision: 0.466091\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.563642\tvalid_1's average_precision: 0.455025\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.529529\tvalid_1's average_precision: 0.463123\n",
      "Avg PR-AUC: 0.4551 | Avg Accuracy: 0.6108\n",
      "\n",
      "Trial 189/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.770458\tvalid_1's average_precision: 0.470217\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.596882\tvalid_1's average_precision: 0.425917\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.711916\tvalid_1's average_precision: 0.457669\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.698151\tvalid_1's average_precision: 0.429512\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.744148\tvalid_1's average_precision: 0.466585\n",
      "Avg PR-AUC: 0.4500 | Avg Accuracy: 0.6138\n",
      "\n",
      "Trial 190/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.649114\tvalid_1's average_precision: 0.460853\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.633406\tvalid_1's average_precision: 0.423919\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's average_precision: 0.79372\tvalid_1's average_precision: 0.466079\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.618657\tvalid_1's average_precision: 0.475219\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.562006\tvalid_1's average_precision: 0.464517\n",
      "Avg PR-AUC: 0.4581 | Avg Accuracy: 0.4975\n",
      "\n",
      "Trial 191/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.646711\tvalid_1's average_precision: 0.469688\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.417661\tvalid_1's average_precision: 0.42627\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.66903\tvalid_1's average_precision: 0.459459\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.582233\tvalid_1's average_precision: 0.483955\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.566422\tvalid_1's average_precision: 0.476634\n",
      "Avg PR-AUC: 0.4632 | Avg Accuracy: 0.4387\n",
      "\n",
      "Trial 192/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.640205\tvalid_1's average_precision: 0.478419\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.416405\tvalid_1's average_precision: 0.425882\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.647148\tvalid_1's average_precision: 0.462738\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.598853\tvalid_1's average_precision: 0.492831\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.564389\tvalid_1's average_precision: 0.479214\n",
      "Avg PR-AUC: 0.4678 | Avg Accuracy: 0.4388\n",
      "\n",
      "Trial 193/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.733899\tvalid_1's average_precision: 0.460956\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.451227\tvalid_1's average_precision: 0.427667\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.711768\tvalid_1's average_precision: 0.457856\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.533216\tvalid_1's average_precision: 0.467307\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.694572\tvalid_1's average_precision: 0.473767\n",
      "Avg PR-AUC: 0.4575 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 194/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.674344\tvalid_1's average_precision: 0.456637\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's average_precision: 0.743195\tvalid_1's average_precision: 0.428322\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.621671\tvalid_1's average_precision: 0.467723\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.565417\tvalid_1's average_precision: 0.461857\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's average_precision: 0.685066\tvalid_1's average_precision: 0.475821\n",
      "Avg PR-AUC: 0.4581 | Avg Accuracy: 0.3990\n",
      "\n",
      "Trial 195/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.640504\tvalid_1's average_precision: 0.464865\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.443904\tvalid_1's average_precision: 0.437616\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.618136\tvalid_1's average_precision: 0.45755\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.488423\tvalid_1's average_precision: 0.44432\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.578777\tvalid_1's average_precision: 0.480334\n",
      "Avg PR-AUC: 0.4569 | Avg Accuracy: 0.6195\n",
      "\n",
      "Trial 196/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.770874\tvalid_1's average_precision: 0.47357\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.519063\tvalid_1's average_precision: 0.416801\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.779518\tvalid_1's average_precision: 0.494105\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.640769\tvalid_1's average_precision: 0.405575\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.846077\tvalid_1's average_precision: 0.47705\n",
      "Avg PR-AUC: 0.4534 | Avg Accuracy: 0.4907\n",
      "\n",
      "Trial 197/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.687511\tvalid_1's average_precision: 0.470659\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.462425\tvalid_1's average_precision: 0.43275\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.541085\tvalid_1's average_precision: 0.446716\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.592188\tvalid_1's average_precision: 0.478397\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.598576\tvalid_1's average_precision: 0.48375\n",
      "Avg PR-AUC: 0.4625 | Avg Accuracy: 0.4323\n",
      "\n",
      "Trial 198/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.592622\tvalid_1's average_precision: 0.442457\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.461073\tvalid_1's average_precision: 0.43989\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.576027\tvalid_1's average_precision: 0.451985\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.574182\tvalid_1's average_precision: 0.484564\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.54398\tvalid_1's average_precision: 0.47901\n",
      "Avg PR-AUC: 0.4596 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 199/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.526619\tvalid_1's average_precision: 0.439556\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.433952\tvalid_1's average_precision: 0.429367\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.538391\tvalid_1's average_precision: 0.442178\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.521941\tvalid_1's average_precision: 0.502131\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.49408\tvalid_1's average_precision: 0.486442\n",
      "Avg PR-AUC: 0.4599 | Avg Accuracy: 0.5230\n",
      "\n",
      "Trial 200/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's average_precision: 0.638957\tvalid_1's average_precision: 0.442869\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.466968\tvalid_1's average_precision: 0.421274\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's average_precision: 0.666806\tvalid_1's average_precision: 0.467982\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.544809\tvalid_1's average_precision: 0.479948\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.51707\tvalid_1's average_precision: 0.469436\n",
      "Avg PR-AUC: 0.4563 | Avg Accuracy: 0.4977\n",
      "\n",
      "Trial 201/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's average_precision: 0.710923\tvalid_1's average_precision: 0.448654\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.550478\tvalid_1's average_precision: 0.396614\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's average_precision: 0.652024\tvalid_1's average_precision: 0.463536\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.562934\tvalid_1's average_precision: 0.406066\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's average_precision: 0.63667\tvalid_1's average_precision: 0.45346\n",
      "Avg PR-AUC: 0.4337 | Avg Accuracy: 0.6121\n",
      "\n",
      "Trial 202/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.711933\tvalid_1's average_precision: 0.466464\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.464317\tvalid_1's average_precision: 0.430046\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.554843\tvalid_1's average_precision: 0.469438\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.589586\tvalid_1's average_precision: 0.468785\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.56231\tvalid_1's average_precision: 0.477375\n",
      "Avg PR-AUC: 0.4624 | Avg Accuracy: 0.5062\n",
      "\n",
      "Trial 203/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.654897\tvalid_1's average_precision: 0.464222\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.478677\tvalid_1's average_precision: 0.441044\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.560587\tvalid_1's average_precision: 0.460677\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.582018\tvalid_1's average_precision: 0.462683\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.537772\tvalid_1's average_precision: 0.470781\n",
      "Avg PR-AUC: 0.4599 | Avg Accuracy: 0.6129\n",
      "\n",
      "Trial 204/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.61677\tvalid_1's average_precision: 0.45855\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.422783\tvalid_1's average_precision: 0.439635\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.566754\tvalid_1's average_precision: 0.444782\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.564899\tvalid_1's average_precision: 0.504022\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.541613\tvalid_1's average_precision: 0.482054\n",
      "Avg PR-AUC: 0.4658 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 205/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.617383\tvalid_1's average_precision: 0.469465\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.456785\tvalid_1's average_precision: 0.429722\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.575986\tvalid_1's average_precision: 0.444348\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.509275\tvalid_1's average_precision: 0.493347\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.480177\tvalid_1's average_precision: 0.484261\n",
      "Avg PR-AUC: 0.4642 | Avg Accuracy: 0.4771\n",
      "\n",
      "Trial 206/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.77271\tvalid_1's average_precision: 0.474538\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.472614\tvalid_1's average_precision: 0.429394\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.753132\tvalid_1's average_precision: 0.466972\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.583941\tvalid_1's average_precision: 0.498092\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.540457\tvalid_1's average_precision: 0.472273\n",
      "Avg PR-AUC: 0.4683 | Avg Accuracy: 0.4278\n",
      "\n",
      "Trial 207/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.632593\tvalid_1's average_precision: 0.463078\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.478315\tvalid_1's average_precision: 0.441357\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.601293\tvalid_1's average_precision: 0.473906\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.549947\tvalid_1's average_precision: 0.454411\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.536691\tvalid_1's average_precision: 0.466356\n",
      "Avg PR-AUC: 0.4598 | Avg Accuracy: 0.6189\n",
      "\n",
      "Trial 208/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.575579\tvalid_1's average_precision: 0.449408\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.456062\tvalid_1's average_precision: 0.422878\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.549189\tvalid_1's average_precision: 0.432285\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.545604\tvalid_1's average_precision: 0.490882\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.499004\tvalid_1's average_precision: 0.477582\n",
      "Avg PR-AUC: 0.4546 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 209/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.623158\tvalid_1's average_precision: 0.451259\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.590264\tvalid_1's average_precision: 0.413183\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.592011\tvalid_1's average_precision: 0.463473\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.520615\tvalid_1's average_precision: 0.479395\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.573892\tvalid_1's average_precision: 0.468659\n",
      "Avg PR-AUC: 0.4552 | Avg Accuracy: 0.6143\n",
      "\n",
      "Trial 210/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.643991\tvalid_1's average_precision: 0.463539\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.453182\tvalid_1's average_precision: 0.41898\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's average_precision: 0.711862\tvalid_1's average_precision: 0.464385\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.571221\tvalid_1's average_precision: 0.491884\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.515608\tvalid_1's average_precision: 0.46376\n",
      "Avg PR-AUC: 0.4605 | Avg Accuracy: 0.5092\n",
      "\n",
      "Trial 211/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.652941\tvalid_1's average_precision: 0.487006\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.426187\tvalid_1's average_precision: 0.436722\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.591166\tvalid_1's average_precision: 0.464863\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.490458\tvalid_1's average_precision: 0.445055\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.575534\tvalid_1's average_precision: 0.477804\n",
      "Avg PR-AUC: 0.4623 | Avg Accuracy: 0.6182\n",
      "\n",
      "Trial 212/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.780779\tvalid_1's average_precision: 0.473059\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.555746\tvalid_1's average_precision: 0.44204\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.766915\tvalid_1's average_precision: 0.486735\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.527711\tvalid_1's average_precision: 0.419727\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.492026\tvalid_1's average_precision: 0.449312\n",
      "Avg PR-AUC: 0.4542 | Avg Accuracy: 0.5223\n",
      "\n",
      "Trial 213/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.660317\tvalid_1's average_precision: 0.473423\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.447233\tvalid_1's average_precision: 0.43801\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.529681\tvalid_1's average_precision: 0.444611\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.507145\tvalid_1's average_precision: 0.466402\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.504883\tvalid_1's average_precision: 0.496847\n",
      "Avg PR-AUC: 0.4639 | Avg Accuracy: 0.4296\n",
      "\n",
      "Trial 214/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.616812\tvalid_1's average_precision: 0.438575\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.544642\tvalid_1's average_precision: 0.441728\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.570356\tvalid_1's average_precision: 0.446729\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.582594\tvalid_1's average_precision: 0.48561\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.556196\tvalid_1's average_precision: 0.465775\n",
      "Avg PR-AUC: 0.4557 | Avg Accuracy: 0.5432\n",
      "\n",
      "Trial 215/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.638276\tvalid_1's average_precision: 0.477004\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.453009\tvalid_1's average_precision: 0.428776\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.621612\tvalid_1's average_precision: 0.458659\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.556381\tvalid_1's average_precision: 0.485825\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.546632\tvalid_1's average_precision: 0.477524\n",
      "Avg PR-AUC: 0.4656 | Avg Accuracy: 0.4234\n",
      "\n",
      "Trial 216/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.722573\tvalid_1's average_precision: 0.453152\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.53367\tvalid_1's average_precision: 0.434355\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.802602\tvalid_1's average_precision: 0.469962\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.507527\tvalid_1's average_precision: 0.441662\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.74697\tvalid_1's average_precision: 0.479662\n",
      "Avg PR-AUC: 0.4558 | Avg Accuracy: 0.6221\n",
      "\n",
      "Trial 217/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.698382\tvalid_1's average_precision: 0.475054\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.774538\tvalid_1's average_precision: 0.448937\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.683331\tvalid_1's average_precision: 0.451311\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.567311\tvalid_1's average_precision: 0.497065\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.549132\tvalid_1's average_precision: 0.471212\n",
      "Avg PR-AUC: 0.4687 | Avg Accuracy: 0.4182\n",
      "\n",
      "Trial 218/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.655347\tvalid_1's average_precision: 0.466187\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.849257\tvalid_1's average_precision: 0.455499\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.785905\tvalid_1's average_precision: 0.482407\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.610063\tvalid_1's average_precision: 0.442551\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.78436\tvalid_1's average_precision: 0.453336\n",
      "Avg PR-AUC: 0.4600 | Avg Accuracy: 0.4494\n",
      "\n",
      "Trial 219/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.61196\tvalid_1's average_precision: 0.455749\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.406993\tvalid_1's average_precision: 0.43009\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.590611\tvalid_1's average_precision: 0.442546\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.583328\tvalid_1's average_precision: 0.502234\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.55328\tvalid_1's average_precision: 0.477424\n",
      "Avg PR-AUC: 0.4616 | Avg Accuracy: 0.5797\n",
      "\n",
      "Trial 220/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's average_precision: 0.569249\tvalid_1's average_precision: 0.459042\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.536269\tvalid_1's average_precision: 0.417122\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.52542\tvalid_1's average_precision: 0.440561\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.492132\tvalid_1's average_precision: 0.490387\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's average_precision: 0.518612\tvalid_1's average_precision: 0.475755\n",
      "Avg PR-AUC: 0.4566 | Avg Accuracy: 0.5218\n",
      "\n",
      "Trial 221/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.601561\tvalid_1's average_precision: 0.465502\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.480664\tvalid_1's average_precision: 0.428841\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.558625\tvalid_1's average_precision: 0.459853\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.567789\tvalid_1's average_precision: 0.489735\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.534873\tvalid_1's average_precision: 0.474205\n",
      "Avg PR-AUC: 0.4636 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 222/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.635289\tvalid_1's average_precision: 0.458379\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000771 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.565829\tvalid_1's average_precision: 0.427522\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.591753\tvalid_1's average_precision: 0.452957\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.559086\tvalid_1's average_precision: 0.498076\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.52571\tvalid_1's average_precision: 0.4811\n",
      "Avg PR-AUC: 0.4636 | Avg Accuracy: 0.3962\n",
      "\n",
      "Trial 223/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000692 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.738743\tvalid_1's average_precision: 0.442176\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.771996\tvalid_1's average_precision: 0.438763\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.752976\tvalid_1's average_precision: 0.47054\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.598823\tvalid_1's average_precision: 0.399865\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.639178\tvalid_1's average_precision: 0.463674\n",
      "Avg PR-AUC: 0.4430 | Avg Accuracy: 0.6157\n",
      "\n",
      "Trial 224/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.596185\tvalid_1's average_precision: 0.469887\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.411364\tvalid_1's average_precision: 0.426732\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.564864\tvalid_1's average_precision: 0.458554\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.565889\tvalid_1's average_precision: 0.489918\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.536429\tvalid_1's average_precision: 0.482842\n",
      "Avg PR-AUC: 0.4656 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 225/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.682322\tvalid_1's average_precision: 0.460092\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.419744\tvalid_1's average_precision: 0.43218\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.63429\tvalid_1's average_precision: 0.464801\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.618138\tvalid_1's average_precision: 0.469868\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.619758\tvalid_1's average_precision: 0.473545\n",
      "Avg PR-AUC: 0.4601 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 226/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.676391\tvalid_1's average_precision: 0.443387\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.630697\tvalid_1's average_precision: 0.413895\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.626469\tvalid_1's average_precision: 0.473354\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.513584\tvalid_1's average_precision: 0.474146\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's average_precision: 0.718911\tvalid_1's average_precision: 0.480365\n",
      "Avg PR-AUC: 0.4570 | Avg Accuracy: 0.6112\n",
      "\n",
      "Trial 227/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's average_precision: 0.738019\tvalid_1's average_precision: 0.452714\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.544867\tvalid_1's average_precision: 0.441487\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.572137\tvalid_1's average_precision: 0.447255\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.583071\tvalid_1's average_precision: 0.469963\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's average_precision: 0.566211\tvalid_1's average_precision: 0.466196\n",
      "Avg PR-AUC: 0.4555 | Avg Accuracy: 0.5168\n",
      "\n",
      "Trial 228/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.766182\tvalid_1's average_precision: 0.470731\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.514333\tvalid_1's average_precision: 0.444406\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.781803\tvalid_1's average_precision: 0.47182\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.639261\tvalid_1's average_precision: 0.503656\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.553623\tvalid_1's average_precision: 0.468226\n",
      "Avg PR-AUC: 0.4718 | Avg Accuracy: 0.4638\n",
      "\n",
      "Trial 229/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.739052\tvalid_1's average_precision: 0.443107\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.62448\tvalid_1's average_precision: 0.44098\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.786323\tvalid_1's average_precision: 0.4777\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.656957\tvalid_1's average_precision: 0.428129\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.817239\tvalid_1's average_precision: 0.469747\n",
      "Avg PR-AUC: 0.4519 | Avg Accuracy: 0.6213\n",
      "\n",
      "Trial 230/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.669974\tvalid_1's average_precision: 0.454931\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.612825\tvalid_1's average_precision: 0.411025\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.658024\tvalid_1's average_precision: 0.469977\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.57436\tvalid_1's average_precision: 0.451575\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.497452\tvalid_1's average_precision: 0.462903\n",
      "Avg PR-AUC: 0.4501 | Avg Accuracy: 0.6107\n",
      "\n",
      "Trial 231/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.605996\tvalid_1's average_precision: 0.46324\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.470711\tvalid_1's average_precision: 0.449538\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.570289\tvalid_1's average_precision: 0.476934\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.564206\tvalid_1's average_precision: 0.507027\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.535081\tvalid_1's average_precision: 0.480423\n",
      "Avg PR-AUC: 0.4754 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 232/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's average_precision: 0.570701\tvalid_1's average_precision: 0.437556\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's average_precision: 0.560589\tvalid_1's average_precision: 0.424538\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's average_precision: 0.557493\tvalid_1's average_precision: 0.449642\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.468599\tvalid_1's average_precision: 0.453769\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.492029\tvalid_1's average_precision: 0.46522\n",
      "Avg PR-AUC: 0.4461 | Avg Accuracy: 0.5029\n",
      "\n",
      "Trial 233/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.766703\tvalid_1's average_precision: 0.444342\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.412915\tvalid_1's average_precision: 0.424957\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.713693\tvalid_1's average_precision: 0.465365\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.623575\tvalid_1's average_precision: 0.449144\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.594342\tvalid_1's average_precision: 0.487013\n",
      "Avg PR-AUC: 0.4542 | Avg Accuracy: 0.4604\n",
      "\n",
      "Trial 234/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.559038\tvalid_1's average_precision: 0.446824\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.447993\tvalid_1's average_precision: 0.42593\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.538346\tvalid_1's average_precision: 0.440663\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.541368\tvalid_1's average_precision: 0.494079\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.509291\tvalid_1's average_precision: 0.472258\n",
      "Avg PR-AUC: 0.4560 | Avg Accuracy: 0.6148\n",
      "\n",
      "Trial 235/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.641312\tvalid_1's average_precision: 0.461948\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.617348\tvalid_1's average_precision: 0.418931\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.623551\tvalid_1's average_precision: 0.471858\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.539387\tvalid_1's average_precision: 0.515009\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.630141\tvalid_1's average_precision: 0.47801\n",
      "Avg PR-AUC: 0.4692 | Avg Accuracy: 0.4184\n",
      "\n",
      "Trial 236/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.654746\tvalid_1's average_precision: 0.466555\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.472616\tvalid_1's average_precision: 0.439044\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.612751\tvalid_1's average_precision: 0.454065\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.55857\tvalid_1's average_precision: 0.476069\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.569424\tvalid_1's average_precision: 0.474013\n",
      "Avg PR-AUC: 0.4619 | Avg Accuracy: 0.6201\n",
      "\n",
      "Trial 237/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.630188\tvalid_1's average_precision: 0.464323\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.454348\tvalid_1's average_precision: 0.426644\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.593509\tvalid_1's average_precision: 0.437855\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.565802\tvalid_1's average_precision: 0.454836\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.577163\tvalid_1's average_precision: 0.477425\n",
      "Avg PR-AUC: 0.4522 | Avg Accuracy: 0.4201\n",
      "\n",
      "Trial 238/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.634715\tvalid_1's average_precision: 0.463009\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.61635\tvalid_1's average_precision: 0.424996\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.617515\tvalid_1's average_precision: 0.464706\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.54154\tvalid_1's average_precision: 0.482242\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.537894\tvalid_1's average_precision: 0.476877\n",
      "Avg PR-AUC: 0.4624 | Avg Accuracy: 0.3980\n",
      "\n",
      "Trial 239/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.593625\tvalid_1's average_precision: 0.464236\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.397308\tvalid_1's average_precision: 0.429604\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.527764\tvalid_1's average_precision: 0.449746\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.517289\tvalid_1's average_precision: 0.49306\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.517113\tvalid_1's average_precision: 0.486163\n",
      "Avg PR-AUC: 0.4646 | Avg Accuracy: 0.5276\n",
      "\n",
      "Trial 240/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's average_precision: 0.643096\tvalid_1's average_precision: 0.448584\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.568696\tvalid_1's average_precision: 0.407872\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.551284\tvalid_1's average_precision: 0.447\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.56535\tvalid_1's average_precision: 0.460064\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.495486\tvalid_1's average_precision: 0.463806\n",
      "Avg PR-AUC: 0.4455 | Avg Accuracy: 0.6149\n",
      "\n",
      "Trial 241/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.729185\tvalid_1's average_precision: 0.450236\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.688762\tvalid_1's average_precision: 0.435147\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.736808\tvalid_1's average_precision: 0.466645\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.559007\tvalid_1's average_precision: 0.471908\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.577594\tvalid_1's average_precision: 0.471727\n",
      "Avg PR-AUC: 0.4591 | Avg Accuracy: 0.4099\n",
      "\n",
      "Trial 242/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.679503\tvalid_1's average_precision: 0.464754\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.646128\tvalid_1's average_precision: 0.430818\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.65274\tvalid_1's average_precision: 0.46886\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.567312\tvalid_1's average_precision: 0.436974\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.562554\tvalid_1's average_precision: 0.484652\n",
      "Avg PR-AUC: 0.4572 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 243/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's average_precision: 0.719945\tvalid_1's average_precision: 0.459911\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.524044\tvalid_1's average_precision: 0.412596\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's average_precision: 0.671268\tvalid_1's average_precision: 0.477476\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.539651\tvalid_1's average_precision: 0.413881\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.544731\tvalid_1's average_precision: 0.45762\n",
      "Avg PR-AUC: 0.4443 | Avg Accuracy: 0.5533\n",
      "\n",
      "Trial 244/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.542145\tvalid_1's average_precision: 0.44453\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.410105\tvalid_1's average_precision: 0.431227\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.536342\tvalid_1's average_precision: 0.448161\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.511592\tvalid_1's average_precision: 0.49647\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.514371\tvalid_1's average_precision: 0.494357\n",
      "Avg PR-AUC: 0.4629 | Avg Accuracy: 0.5239\n",
      "\n",
      "Trial 245/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.759489\tvalid_1's average_precision: 0.47428\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.484353\tvalid_1's average_precision: 0.440685\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.737344\tvalid_1's average_precision: 0.452527\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.644158\tvalid_1's average_precision: 0.478329\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's average_precision: 0.810059\tvalid_1's average_precision: 0.461609\n",
      "Avg PR-AUC: 0.4615 | Avg Accuracy: 0.4447\n",
      "\n",
      "Trial 246/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.686511\tvalid_1's average_precision: 0.456176\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.50452\tvalid_1's average_precision: 0.437679\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.62318\tvalid_1's average_precision: 0.47363\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.604275\tvalid_1's average_precision: 0.492084\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.621924\tvalid_1's average_precision: 0.472313\n",
      "Avg PR-AUC: 0.4664 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 247/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.744371\tvalid_1's average_precision: 0.45696\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.417899\tvalid_1's average_precision: 0.41982\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.704225\tvalid_1's average_precision: 0.459323\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.67704\tvalid_1's average_precision: 0.480405\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.584615\tvalid_1's average_precision: 0.464625\n",
      "Avg PR-AUC: 0.4562 | Avg Accuracy: 0.4655\n",
      "\n",
      "Trial 248/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.711908\tvalid_1's average_precision: 0.442982\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.651414\tvalid_1's average_precision: 0.410428\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.683397\tvalid_1's average_precision: 0.464667\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.522957\tvalid_1's average_precision: 0.429648\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.598684\tvalid_1's average_precision: 0.464423\n",
      "Avg PR-AUC: 0.4424 | Avg Accuracy: 0.6108\n",
      "\n",
      "Trial 249/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's average_precision: 0.619958\tvalid_1's average_precision: 0.450095\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.487273\tvalid_1's average_precision: 0.423504\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's average_precision: 0.674759\tvalid_1's average_precision: 0.475889\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.570479\tvalid_1's average_precision: 0.511391\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.53076\tvalid_1's average_precision: 0.46189\n",
      "Avg PR-AUC: 0.4646 | Avg Accuracy: 0.4522\n",
      "\n",
      "Trial 250/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.667962\tvalid_1's average_precision: 0.466513\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.603692\tvalid_1's average_precision: 0.429891\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's average_precision: 0.705841\tvalid_1's average_precision: 0.460125\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.509524\tvalid_1's average_precision: 0.471973\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.543219\tvalid_1's average_precision: 0.473524\n",
      "Avg PR-AUC: 0.4604 | Avg Accuracy: 0.4165\n",
      "\n",
      "Trial 251/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000676 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.512558\tvalid_1's average_precision: 0.430903\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.505597\tvalid_1's average_precision: 0.412198\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's average_precision: 0.535706\tvalid_1's average_precision: 0.440931\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's average_precision: 0.540243\tvalid_1's average_precision: 0.535903\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's average_precision: 0.513134\tvalid_1's average_precision: 0.480275\n",
      "Avg PR-AUC: 0.4600 | Avg Accuracy: 0.4270\n",
      "\n",
      "Trial 252/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.737815\tvalid_1's average_precision: 0.463679\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.491032\tvalid_1's average_precision: 0.437559\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.703322\tvalid_1's average_precision: 0.458267\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.618059\tvalid_1's average_precision: 0.497287\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.571515\tvalid_1's average_precision: 0.485981\n",
      "Avg PR-AUC: 0.4686 | Avg Accuracy: 0.4521\n",
      "\n",
      "Trial 253/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.653329\tvalid_1's average_precision: 0.476403\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.439931\tvalid_1's average_precision: 0.423635\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.523972\tvalid_1's average_precision: 0.444533\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.514245\tvalid_1's average_precision: 0.495565\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.480143\tvalid_1's average_precision: 0.47802\n",
      "Avg PR-AUC: 0.4636 | Avg Accuracy: 0.4384\n",
      "\n",
      "Trial 254/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.630505\tvalid_1's average_precision: 0.461024\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.450914\tvalid_1's average_precision: 0.429674\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's average_precision: 0.682182\tvalid_1's average_precision: 0.458535\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.561844\tvalid_1's average_precision: 0.474934\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.518852\tvalid_1's average_precision: 0.482129\n",
      "Avg PR-AUC: 0.4613 | Avg Accuracy: 0.5002\n",
      "\n",
      "Trial 255/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.797215\tvalid_1's average_precision: 0.458468\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.442799\tvalid_1's average_precision: 0.433678\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.729991\tvalid_1's average_precision: 0.444655\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.528368\tvalid_1's average_precision: 0.445651\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.670109\tvalid_1's average_precision: 0.474515\n",
      "Avg PR-AUC: 0.4514 | Avg Accuracy: 0.6165\n",
      "\n",
      "Trial 256/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.668529\tvalid_1's average_precision: 0.47582\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.456621\tvalid_1's average_precision: 0.43189\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.593215\tvalid_1's average_precision: 0.457548\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.532399\tvalid_1's average_precision: 0.473501\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.487888\tvalid_1's average_precision: 0.482753\n",
      "Avg PR-AUC: 0.4643 | Avg Accuracy: 0.4679\n",
      "\n",
      "Trial 257/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.768294\tvalid_1's average_precision: 0.463552\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.643781\tvalid_1's average_precision: 0.436225\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.762325\tvalid_1's average_precision: 0.466031\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.635972\tvalid_1's average_precision: 0.447561\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.552671\tvalid_1's average_precision: 0.472602\n",
      "Avg PR-AUC: 0.4572 | Avg Accuracy: 0.5266\n",
      "\n",
      "Trial 258/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.657973\tvalid_1's average_precision: 0.454138\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.41119\tvalid_1's average_precision: 0.430355\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.587806\tvalid_1's average_precision: 0.454878\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.614297\tvalid_1's average_precision: 0.468386\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.568457\tvalid_1's average_precision: 0.46767\n",
      "Avg PR-AUC: 0.4551 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 259/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.570592\tvalid_1's average_precision: 0.450181\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.449004\tvalid_1's average_precision: 0.423321\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.60902\tvalid_1's average_precision: 0.449152\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.551862\tvalid_1's average_precision: 0.495099\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.523796\tvalid_1's average_precision: 0.477457\n",
      "Avg PR-AUC: 0.4590 | Avg Accuracy: 0.4812\n",
      "\n",
      "Trial 260/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.687851\tvalid_1's average_precision: 0.450243\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.530145\tvalid_1's average_precision: 0.439431\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.702283\tvalid_1's average_precision: 0.463315\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.49998\tvalid_1's average_precision: 0.462198\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.690694\tvalid_1's average_precision: 0.479482\n",
      "Avg PR-AUC: 0.4589 | Avg Accuracy: 0.6217\n",
      "\n",
      "Trial 261/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.663074\tvalid_1's average_precision: 0.460582\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.511118\tvalid_1's average_precision: 0.432591\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.622888\tvalid_1's average_precision: 0.467824\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.615871\tvalid_1's average_precision: 0.472534\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.560989\tvalid_1's average_precision: 0.484468\n",
      "Avg PR-AUC: 0.4636 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 262/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.624231\tvalid_1's average_precision: 0.463915\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.480377\tvalid_1's average_precision: 0.42353\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.592063\tvalid_1's average_precision: 0.464647\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.570684\tvalid_1's average_precision: 0.486667\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.548569\tvalid_1's average_precision: 0.484092\n",
      "Avg PR-AUC: 0.4646 | Avg Accuracy: 0.6196\n",
      "\n",
      "Trial 263/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.600614\tvalid_1's average_precision: 0.461534\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.422288\tvalid_1's average_precision: 0.428754\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.663277\tvalid_1's average_precision: 0.470216\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.46563\tvalid_1's average_precision: 0.457283\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.551947\tvalid_1's average_precision: 0.483809\n",
      "Avg PR-AUC: 0.4603 | Avg Accuracy: 0.6192\n",
      "\n",
      "Trial 264/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.685049\tvalid_1's average_precision: 0.457152\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.517026\tvalid_1's average_precision: 0.428949\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.617471\tvalid_1's average_precision: 0.457906\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.611028\tvalid_1's average_precision: 0.483204\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.550258\tvalid_1's average_precision: 0.479396\n",
      "Avg PR-AUC: 0.4613 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 265/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.633177\tvalid_1's average_precision: 0.461761\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.578652\tvalid_1's average_precision: 0.417853\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.598194\tvalid_1's average_precision: 0.459842\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.561977\tvalid_1's average_precision: 0.466421\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.497093\tvalid_1's average_precision: 0.472851\n",
      "Avg PR-AUC: 0.4557 | Avg Accuracy: 0.4190\n",
      "\n",
      "Trial 266/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.813178\tvalid_1's average_precision: 0.454838\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.534458\tvalid_1's average_precision: 0.435369\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.736631\tvalid_1's average_precision: 0.4354\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.505279\tvalid_1's average_precision: 0.448976\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.619229\tvalid_1's average_precision: 0.485572\n",
      "Avg PR-AUC: 0.4520 | Avg Accuracy: 0.6148\n",
      "\n",
      "Trial 267/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's average_precision: 0.623318\tvalid_1's average_precision: 0.456326\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.556377\tvalid_1's average_precision: 0.425339\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's average_precision: 0.595028\tvalid_1's average_precision: 0.451445\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.525778\tvalid_1's average_precision: 0.501508\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.506784\tvalid_1's average_precision: 0.469464\n",
      "Avg PR-AUC: 0.4608 | Avg Accuracy: 0.3949\n",
      "\n",
      "Trial 268/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.636254\tvalid_1's average_precision: 0.466534\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.578726\tvalid_1's average_precision: 0.423858\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.589907\tvalid_1's average_precision: 0.455107\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.539129\tvalid_1's average_precision: 0.517475\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.476103\tvalid_1's average_precision: 0.471073\n",
      "Avg PR-AUC: 0.4668 | Avg Accuracy: 0.4026\n",
      "\n",
      "Trial 269/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.585146\tvalid_1's average_precision: 0.432875\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.444438\tvalid_1's average_precision: 0.42709\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.580851\tvalid_1's average_precision: 0.453909\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.571525\tvalid_1's average_precision: 0.479137\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.535796\tvalid_1's average_precision: 0.488745\n",
      "Avg PR-AUC: 0.4564 | Avg Accuracy: 0.5419\n",
      "\n",
      "Trial 270/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.665355\tvalid_1's average_precision: 0.463431\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.564818\tvalid_1's average_precision: 0.448949\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.681373\tvalid_1's average_precision: 0.453344\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.567968\tvalid_1's average_precision: 0.47846\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.559353\tvalid_1's average_precision: 0.484383\n",
      "Avg PR-AUC: 0.4657 | Avg Accuracy: 0.4220\n",
      "\n",
      "Trial 271/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.533622\tvalid_1's average_precision: 0.436763\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.444973\tvalid_1's average_precision: 0.423042\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.534973\tvalid_1's average_precision: 0.45221\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.542758\tvalid_1's average_precision: 0.508468\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.498544\tvalid_1's average_precision: 0.486471\n",
      "Avg PR-AUC: 0.4614 | Avg Accuracy: 0.5745\n",
      "\n",
      "Trial 272/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.661834\tvalid_1's average_precision: 0.459664\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.471919\tvalid_1's average_precision: 0.429382\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.590478\tvalid_1's average_precision: 0.457163\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.619261\tvalid_1's average_precision: 0.472776\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.609521\tvalid_1's average_precision: 0.458234\n",
      "Avg PR-AUC: 0.4554 | Avg Accuracy: 0.4175\n",
      "\n",
      "Trial 273/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.747167\tvalid_1's average_precision: 0.466117\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.574463\tvalid_1's average_precision: 0.41232\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's average_precision: 0.785411\tvalid_1's average_precision: 0.486853\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.530008\tvalid_1's average_precision: 0.418079\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.726919\tvalid_1's average_precision: 0.449437\n",
      "Avg PR-AUC: 0.4466 | Avg Accuracy: 0.5110\n",
      "\n",
      "Trial 274/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's average_precision: 0.672474\tvalid_1's average_precision: 0.461554\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.609669\tvalid_1's average_precision: 0.422392\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.603628\tvalid_1's average_precision: 0.460226\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.567198\tvalid_1's average_precision: 0.510194\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.527194\tvalid_1's average_precision: 0.476811\n",
      "Avg PR-AUC: 0.4662 | Avg Accuracy: 0.4136\n",
      "\n",
      "Trial 275/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.606357\tvalid_1's average_precision: 0.455534\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.4047\tvalid_1's average_precision: 0.430577\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.553842\tvalid_1's average_precision: 0.462412\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.577031\tvalid_1's average_precision: 0.484893\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.545469\tvalid_1's average_precision: 0.472711\n",
      "Avg PR-AUC: 0.4612 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 276/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.684818\tvalid_1's average_precision: 0.473267\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.483695\tvalid_1's average_precision: 0.445091\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.661216\tvalid_1's average_precision: 0.470912\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.597599\tvalid_1's average_precision: 0.462552\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.562627\tvalid_1's average_precision: 0.467181\n",
      "Avg PR-AUC: 0.4638 | Avg Accuracy: 0.6209\n",
      "\n",
      "Trial 277/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.591547\tvalid_1's average_precision: 0.46052\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.447261\tvalid_1's average_precision: 0.436584\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.537138\tvalid_1's average_precision: 0.454207\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.543415\tvalid_1's average_precision: 0.492072\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.519487\tvalid_1's average_precision: 0.477426\n",
      "Avg PR-AUC: 0.4642 | Avg Accuracy: 0.5154\n",
      "\n",
      "Trial 278/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.604523\tvalid_1's average_precision: 0.453541\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's average_precision: 0.691195\tvalid_1's average_precision: 0.416009\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.590834\tvalid_1's average_precision: 0.479983\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.484907\tvalid_1's average_precision: 0.444272\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's average_precision: 0.659637\tvalid_1's average_precision: 0.469523\n",
      "Avg PR-AUC: 0.4527 | Avg Accuracy: 0.6120\n",
      "\n",
      "Trial 279/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.611861\tvalid_1's average_precision: 0.464791\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.437817\tvalid_1's average_precision: 0.422044\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.522514\tvalid_1's average_precision: 0.441633\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.564425\tvalid_1's average_precision: 0.483753\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.483547\tvalid_1's average_precision: 0.483588\n",
      "Avg PR-AUC: 0.4592 | Avg Accuracy: 0.4725\n",
      "\n",
      "Trial 280/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.616206\tvalid_1's average_precision: 0.468653\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.436352\tvalid_1's average_precision: 0.427947\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.550325\tvalid_1's average_precision: 0.451637\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.572306\tvalid_1's average_precision: 0.477489\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.550707\tvalid_1's average_precision: 0.480975\n",
      "Avg PR-AUC: 0.4613 | Avg Accuracy: 0.6156\n",
      "\n",
      "Trial 281/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.665975\tvalid_1's average_precision: 0.445733\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.798882\tvalid_1's average_precision: 0.421212\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.708956\tvalid_1's average_precision: 0.475567\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.596015\tvalid_1's average_precision: 0.436722\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.740083\tvalid_1's average_precision: 0.46172\n",
      "Avg PR-AUC: 0.4482 | Avg Accuracy: 0.6119\n",
      "\n",
      "Trial 282/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.582495\tvalid_1's average_precision: 0.446319\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.541931\tvalid_1's average_precision: 0.441684\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.571623\tvalid_1's average_precision: 0.449987\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.581652\tvalid_1's average_precision: 0.47777\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.55591\tvalid_1's average_precision: 0.45418\n",
      "Avg PR-AUC: 0.4540 | Avg Accuracy: 0.5834\n",
      "\n",
      "Trial 283/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.677086\tvalid_1's average_precision: 0.46809\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.407898\tvalid_1's average_precision: 0.431474\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.555114\tvalid_1's average_precision: 0.44925\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.589512\tvalid_1's average_precision: 0.477173\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.569326\tvalid_1's average_precision: 0.470826\n",
      "Avg PR-AUC: 0.4594 | Avg Accuracy: 0.4934\n",
      "\n",
      "Trial 284/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.645826\tvalid_1's average_precision: 0.450018\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.4728\tvalid_1's average_precision: 0.43808\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.581815\tvalid_1's average_precision: 0.4671\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.560276\tvalid_1's average_precision: 0.467394\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.589229\tvalid_1's average_precision: 0.476729\n",
      "Avg PR-AUC: 0.4599 | Avg Accuracy: 0.6166\n",
      "\n",
      "Trial 285/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.628927\tvalid_1's average_precision: 0.471339\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.402461\tvalid_1's average_precision: 0.431215\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.539301\tvalid_1's average_precision: 0.443406\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.544208\tvalid_1's average_precision: 0.503418\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.540318\tvalid_1's average_precision: 0.482711\n",
      "Avg PR-AUC: 0.4664 | Avg Accuracy: 0.4295\n",
      "\n",
      "Trial 286/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's average_precision: 0.849896\tvalid_1's average_precision: 0.468116\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.404666\tvalid_1's average_precision: 0.430582\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.607758\tvalid_1's average_precision: 0.445983\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.609248\tvalid_1's average_precision: 0.468633\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.553339\tvalid_1's average_precision: 0.480384\n",
      "Avg PR-AUC: 0.4587 | Avg Accuracy: 0.4443\n",
      "\n",
      "Trial 287/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.692104\tvalid_1's average_precision: 0.43229\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.625866\tvalid_1's average_precision: 0.439922\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.709835\tvalid_1's average_precision: 0.461901\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.626564\tvalid_1's average_precision: 0.45621\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.68322\tvalid_1's average_precision: 0.470506\n",
      "Avg PR-AUC: 0.4522 | Avg Accuracy: 0.6140\n",
      "\n",
      "Trial 288/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.682843\tvalid_1's average_precision: 0.47629\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.532625\tvalid_1's average_precision: 0.435079\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.626706\tvalid_1's average_precision: 0.454506\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.552859\tvalid_1's average_precision: 0.462048\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's average_precision: 0.71394\tvalid_1's average_precision: 0.487122\n",
      "Avg PR-AUC: 0.4630 | Avg Accuracy: 0.6199\n",
      "\n",
      "Trial 289/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.515312\tvalid_1's average_precision: 0.439674\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.432058\tvalid_1's average_precision: 0.4235\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's average_precision: 0.531815\tvalid_1's average_precision: 0.444173\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.497693\tvalid_1's average_precision: 0.498255\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.478017\tvalid_1's average_precision: 0.472234\n",
      "Avg PR-AUC: 0.4556 | Avg Accuracy: 0.5683\n",
      "\n",
      "Trial 290/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.625294\tvalid_1's average_precision: 0.452942\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.628173\tvalid_1's average_precision: 0.420338\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.644436\tvalid_1's average_precision: 0.450127\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.537961\tvalid_1's average_precision: 0.476313\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.52604\tvalid_1's average_precision: 0.472193\n",
      "Avg PR-AUC: 0.4544 | Avg Accuracy: 0.4128\n",
      "\n",
      "Trial 291/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.467302\tvalid_1's average_precision: 0.435921\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.496304\tvalid_1's average_precision: 0.420798\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.518772\tvalid_1's average_precision: 0.439283\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.473561\tvalid_1's average_precision: 0.48859\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.511443\tvalid_1's average_precision: 0.478286\n",
      "Avg PR-AUC: 0.4526 | Avg Accuracy: 0.5943\n",
      "\n",
      "Trial 292/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.743678\tvalid_1's average_precision: 0.457958\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.592849\tvalid_1's average_precision: 0.437964\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.775698\tvalid_1's average_precision: 0.493115\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.584111\tvalid_1's average_precision: 0.433266\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.557472\tvalid_1's average_precision: 0.460372\n",
      "Avg PR-AUC: 0.4565 | Avg Accuracy: 0.5498\n",
      "\n",
      "Trial 293/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.637082\tvalid_1's average_precision: 0.447399\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.707158\tvalid_1's average_precision: 0.429707\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's average_precision: 0.753987\tvalid_1's average_precision: 0.475421\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.530358\tvalid_1's average_precision: 0.473262\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.597903\tvalid_1's average_precision: 0.45524\n",
      "Avg PR-AUC: 0.4562 | Avg Accuracy: 0.6054\n",
      "\n",
      "Trial 294/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.587382\tvalid_1's average_precision: 0.445422\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.424598\tvalid_1's average_precision: 0.431498\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.545764\tvalid_1's average_precision: 0.458368\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.566264\tvalid_1's average_precision: 0.497331\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.541576\tvalid_1's average_precision: 0.481274\n",
      "Avg PR-AUC: 0.4628 | Avg Accuracy: 0.6146\n",
      "\n",
      "Trial 295/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.717668\tvalid_1's average_precision: 0.450312\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.770675\tvalid_1's average_precision: 0.424058\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.651367\tvalid_1's average_precision: 0.476207\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.589482\tvalid_1's average_precision: 0.444619\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.645965\tvalid_1's average_precision: 0.45646\n",
      "Avg PR-AUC: 0.4503 | Avg Accuracy: 0.6056\n",
      "\n",
      "Trial 296/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.783666\tvalid_1's average_precision: 0.461523\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.495659\tvalid_1's average_precision: 0.442544\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.709748\tvalid_1's average_precision: 0.464379\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.619562\tvalid_1's average_precision: 0.490678\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.572517\tvalid_1's average_precision: 0.486394\n",
      "Avg PR-AUC: 0.4691 | Avg Accuracy: 0.4543\n",
      "\n",
      "Trial 297/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.733904\tvalid_1's average_precision: 0.460248\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.619777\tvalid_1's average_precision: 0.422196\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.733562\tvalid_1's average_precision: 0.498412\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.607989\tvalid_1's average_precision: 0.476727\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.499069\tvalid_1's average_precision: 0.456688\n",
      "Avg PR-AUC: 0.4629 | Avg Accuracy: 0.4781\n",
      "\n",
      "Trial 298/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.598133\tvalid_1's average_precision: 0.454685\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.571048\tvalid_1's average_precision: 0.422254\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.600975\tvalid_1's average_precision: 0.466055\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.549682\tvalid_1's average_precision: 0.533377\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.553074\tvalid_1's average_precision: 0.479025\n",
      "Avg PR-AUC: 0.4711 | Avg Accuracy: 0.4140\n",
      "\n",
      "Trial 299/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.602487\tvalid_1's average_precision: 0.448067\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.579105\tvalid_1's average_precision: 0.41926\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's average_precision: 0.603717\tvalid_1's average_precision: 0.472529\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.557672\tvalid_1's average_precision: 0.516613\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.511817\tvalid_1's average_precision: 0.476311\n",
      "Avg PR-AUC: 0.4666 | Avg Accuracy: 0.4368\n",
      "\n",
      "Trial 300/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 16653, number of negative: 29669\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 46322, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359505 -> initscore=-0.577512\n",
      "[LightGBM] [Info] Start training from score -0.577512\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.677457\tvalid_1's average_precision: 0.448722\n",
      "[LightGBM] [Info] Number of positive: 19786, number of negative: 35255\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 55041, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.359477 -> initscore=-0.577633\n",
      "[LightGBM] [Info] Start training from score -0.577633\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.568513\tvalid_1's average_precision: 0.41052\n",
      "[LightGBM] [Info] Number of positive: 23595, number of negative: 40509\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 64104, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368074 -> initscore=-0.540489\n",
      "[LightGBM] [Info] Start training from score -0.540489\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.659045\tvalid_1's average_precision: 0.469678\n",
      "[LightGBM] [Info] Number of positive: 26949, number of negative: 46144\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 73093, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368695 -> initscore=-0.537821\n",
      "[LightGBM] [Info] Start training from score -0.537821\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.630551\tvalid_1's average_precision: 0.4224\n",
      "[LightGBM] [Info] Number of positive: 30408, number of negative: 51902\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 82310, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369433 -> initscore=-0.534652\n",
      "[LightGBM] [Info] Start training from score -0.534652\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.597189\tvalid_1's average_precision: 0.434769\n",
      "Avg PR-AUC: 0.4372 | Avg Accuracy: 0.6188\n",
      "[LightGBM] [Info] Number of positive: 33961, number of negative: 57368\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1497\n",
      "[LightGBM] [Info] Number of data points in the train set: 91329, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.371853 -> initscore=-0.524274\n",
      "[LightGBM] [Info] Start training from score -0.524274\n",
      "\n",
      "Best Config: PR-AUC: 0.4761 | Accuracy: 0.4164 | params_config {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0, 'objective': 'binary', 'metric': 'average_precision', 'boosting_type': 'gbdt', 'seed': 42} \n"
     ]
    }
   ],
   "source": [
    "# Train LightGBM with walk-forward CV\n",
    "results_df, best_config, best_model, best_oof_preds = random_search_lightgbm(final_df,\n",
    "                                                                            final_df.drop(columns=[\"strat_return\"]).columns,\n",
    "                                                                            categorical_features = categ_feats,\n",
    "                                                                            target='strat_return',\n",
    "                                                                            n_splits=5,\n",
    "                                                                            n_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83bee30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printed in train is the: Mean of fold scores = average of each foldâ€™s PR-AUC (each fold weighted equally, regardless of size).\n",
    "\n",
    "# now is the: Global PR-AUC = one curve computed from all OOF predictions at once (folds weighted by number of samples).\n",
    "\n",
    "plot_pr_curve_from_oof(best_oof_preds, final_df['strat_return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "630e4a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "def plot_shap_summary(best_model, X):\n",
    "    # Get SHAP values (pred_contrib=True gives SHAP + bias term as last column)\n",
    "    shap_values = best_model.predict(X, pred_contrib=True)\n",
    "    \n",
    "    # Remove bias term (last column)\n",
    "    shap_values = shap_values[:, :-1]\n",
    "    \n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Mean absolute SHAP value per feature\n",
    "    shap_importance = np.mean(np.abs(shap_values), axis=0)\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"mean_abs_shap\": shap_importance\n",
    "    }).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "    # Plot bar chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(importance_df[\"feature\"], importance_df[\"mean_abs_shap\"], color=\"skyblue\")\n",
    "    plt.xlabel(\"Mean |Abs SHAP value|\")\n",
    "    plt.title(\"SHAP Feature Importance (LightGBM)\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "shap_df = plot_shap_summary(best_model, final_df.drop(columns=\"strat_return\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887400c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bb8c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding or target encoding for categorical features (strategy, regime) \n",
    "# depending on your model or Embeddings (for deep learning).\n",
    "\n",
    "\n",
    "# Scale numeric features if needed (standard scaler or robust scaler). only for non-trees\n",
    "\n",
    "# Experiment with adding more features like volume weighted average price (VWAP), ATR, or more complex technical indicators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
