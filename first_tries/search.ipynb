{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c23ed25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ta\n",
    "\n",
    "# to run async code in jupyter notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "API_KEY = None\n",
    "SECRET_KEY = None\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if API_KEY is None:\n",
    "    API_KEY = os.environ.get('ALP_API_KEY')\n",
    "\n",
    "if SECRET_KEY is None:\n",
    "    SECRET_KEY = os.environ.get('ALP_SEC_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "acf5588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit\n",
    "from alpaca.data.historical.corporate_actions import CorporateActionsClient\n",
    "from alpaca.data.historical.stock import StockHistoricalDataClient\n",
    "from alpaca.trading.stream import TradingStream\n",
    "from alpaca.data.live.stock import StockDataStream\n",
    "\n",
    "from alpaca.data.requests import (\n",
    "    CorporateActionsRequest,\n",
    "    StockBarsRequest,\n",
    "    StockQuotesRequest,\n",
    "    StockTradesRequest,\n",
    ")\n",
    "\n",
    "from alpaca.data.enums import Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b31eef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regime_tickers import custom_vol_subset, custom_exp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08241fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_historical_data_client = StockHistoricalDataClient(API_KEY, SECRET_KEY)\n",
    "\n",
    "# alpaca has no older data than 2016-01-04 for this symbol set\n",
    "earliest_date = datetime(2016, 1, 4, tzinfo=ZoneInfo('America/New_York'))\n",
    "# earliest_timestamps_by_symbol = df_adj.reset_index().groupby('symbol')['timestamp'].min()\n",
    "\n",
    "req = StockBarsRequest(\n",
    "    symbol_or_symbols = list(set(custom_vol_subset + custom_exp_subset + ['SPY'])),  # add SPY for market reference\n",
    "    timeframe=TimeFrame(amount = 1, unit = TimeFrameUnit.Day), \n",
    "    start = earliest_date,                    \n",
    "    limit = None,    \n",
    "    adjustment=Adjustment('all') # adjust for splits and dividends                                           \n",
    ")\n",
    "df_adj = stock_historical_data_client.get_stock_bars(req).df.reset_index().set_index('timestamp')\n",
    "df_adj = df_adj.sort_values(by=['symbol', 'timestamp']) # Ensure sorted for correct rolling calcs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90cdb3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total NANs: 0\n",
      "             symbol\n",
      "open         BND       0\n",
      "             CPER      0\n",
      "             GLD       0\n",
      "             HYG       0\n",
      "             IWM       0\n",
      "             SCHP      0\n",
      "             SPY       0\n",
      "             VIXY      0\n",
      "             XLI       0\n",
      "high         BND       0\n",
      "             CPER      0\n",
      "             GLD       0\n",
      "             HYG       0\n",
      "             IWM       0\n",
      "             SCHP      0\n",
      "             SPY       0\n",
      "             VIXY      0\n",
      "             XLI       0\n",
      "low          BND       0\n",
      "             CPER      0\n",
      "             GLD       0\n",
      "             HYG       0\n",
      "             IWM       0\n",
      "             SCHP      0\n",
      "             SPY       0\n",
      "             VIXY      0\n",
      "             XLI       0\n",
      "close        BND       0\n",
      "             CPER      0\n",
      "             GLD       0\n",
      "             HYG       0\n",
      "             IWM       0\n",
      "             SCHP      0\n",
      "             SPY       0\n",
      "             VIXY      0\n",
      "             XLI       0\n",
      "volume       BND       0\n",
      "             CPER      0\n",
      "             GLD       0\n",
      "             HYG       0\n",
      "             IWM       0\n",
      "             SCHP      0\n",
      "             SPY       0\n",
      "             VIXY      0\n",
      "             XLI       0\n",
      "trade_count  BND       0\n",
      "             CPER      0\n",
      "             GLD       0\n",
      "             HYG       0\n",
      "             IWM       0\n",
      "             SCHP      0\n",
      "             SPY       0\n",
      "             VIXY      0\n",
      "             XLI       0\n",
      "vwap         BND       0\n",
      "             CPER      0\n",
      "             GLD       0\n",
      "             HYG       0\n",
      "             IWM       0\n",
      "             SCHP      0\n",
      "             SPY       0\n",
      "             VIXY      0\n",
      "             XLI       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "print(\"Total NANs:\", df_adj.pivot(columns=\"symbol\").isna().sum().sum())\n",
    "print(df_adj.pivot(columns=\"symbol\").isna().sum())\n",
    "\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28de4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## windows = [5, 20, 60]\n",
    "windows = [20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8281e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Log Returns\n",
    "df_adj['log_returns'] = df_adj.groupby('symbol')['close'].transform(lambda x: np.log(x / x.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b952b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_window = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1aabaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling Standard Deviation (Volatility). For further computations, later we will use z-scores of these values only\n",
    "for w in windows:\n",
    "    df_adj[f'rolling_std_20'] = df_adj.groupby('symbol')['log_returns'].transform(\n",
    "        lambda x: x.rolling(window=w, min_periods=w).std()\n",
    "    )\n",
    "\n",
    "    df_adj[f'z_rolling_std_20'] = df_adj.groupby('symbol')[f'rolling_std_20'].transform(\n",
    "        lambda x: (x - x.rolling(z_window).mean()) / x.rolling(z_window).std()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4295d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range Ratio (High - Low) / Close, per asset\n",
    "df_adj['range_ratio'] = (df_adj['high'] - df_adj['low']) / df_adj['close']\n",
    "# Adding smoothing (e.g., rolling average of 5 days)\n",
    "df_adj['range_ratio_smooth'] = df_adj.groupby('symbol')['range_ratio'].transform(lambda x: x.rolling(5).mean())\n",
    "# Standardizing with Z-scores for regime shift detection\n",
    "df_adj['z_range_ratio_smooth'] = df_adj.groupby('symbol')['range_ratio_smooth'].transform(lambda x: (x - x.rolling(z_window).mean()) / x.rolling(z_window).std())\n",
    "\n",
    "df_adj.drop(columns=['range_ratio', 'range_ratio_smooth'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a8dea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility Shock Count\n",
    "# The number of days in a recent lookback window where daily returns exceeded 2 standard deviations, either up or down.\n",
    "# It captures the frequency of abnormal moves â€” a key indicator for risk, panic clusters, or momentum bursts.\n",
    "\n",
    "# 1. Calculate return z-scores per symbol\n",
    "df_adj['z_log_returns'] = df_adj.groupby('symbol')['log_returns'].transform(\n",
    "    lambda x: (x - x.rolling(60).mean()) / x.rolling(60).std()\n",
    ")\n",
    "\n",
    "# 2. Count shocks in rolling window (e.g., abs(z) > 2 over last 20 days)\n",
    "df_adj['vol_shock_count_20'] = df_adj.groupby('symbol')['z_log_returns'].transform(\n",
    "    lambda x: x.rolling(20).apply(lambda r: (abs(r) > 2).sum(), raw=True)\n",
    ")\n",
    "\n",
    "df_adj.drop(columns=['log_returns'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e70601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = df_adj.sort_values(by=['symbol', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc8ec58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_adj.pivot(columns=\"symbol\")\n",
    "# Flatten columns ('close', 'QQQ') -> 'close_QQQ'\n",
    "df_pivot.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in df_pivot.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c9dac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility Cross-Asset Dispersion lets you measure how much the volatility levels themselves are diverging across assets. It's like saying: are\n",
    "#  all sectors jittery together or are some calm while others are chaotic? Great for reading the marketâ€™s internal stress or divergence.\n",
    "\n",
    "# Step 1: Filter only the 'rolling_std_20' columns\n",
    "rolling_std_cols = [col for col in df_pivot.columns if col.startswith('rolling_std_20_')]\n",
    "\n",
    "# Step 2: Compute cross-sectional std (dispersion) across symbols for each timestamp\n",
    "vol_dispersion = df_pivot[rolling_std_cols].std(axis=1)\n",
    "\n",
    "# Step 3: Add back into df_pivot as a new column\n",
    "df_pivot['volatility_dispersion'] = vol_dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dad288fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realized Vol / Implied Vol compares actual historical price movement (realized vol) with what the market expects (implied vol). \n",
    "# A ratio >1 means realized volatility has exceeded market expectations â€” a sign of surprise, dislocation, or a catch-up in pricing. \n",
    "# A ratio <1 suggests implied vol is elevated â€” often in times of uncertainty or hedging demand.\n",
    "\n",
    "# Z-realized vs Implied Volatility Ratios\n",
    "\n",
    "# Reference realized vol\n",
    "realized = df_pivot['rolling_std_20_IWM']\n",
    "\n",
    "# Loop over each implied asset and compute z-scored realized/implied ratios\n",
    "implied = df_pivot['rolling_std_20_VIXY']\n",
    "ratio = realized / implied\n",
    "z_col = f'z_realized_implied_vixy'\n",
    "\n",
    "df_pivot[z_col] = (ratio - ratio.rolling(z_window).mean()) / ratio.rolling(z_window).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4f293fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility Spread = VIXY implied vol proxy â€“ realized vol of SPY/IWM\n",
    "# Z-score Level\tWhat It Means\n",
    "# > +2\tImplied vol (VIXY) is much higher than realized vol â†’ Fear spike\n",
    "# < -2\tRealized vol is unusually high vs whatâ€™s priced in â†’ Complacency mispricing?\n",
    "# Around 0\tImplied and realized vol are in sync â†’ Stable regime\n",
    "\n",
    "# Step 1: Compute average realized vol of SPY and IWM\n",
    "realized_avg = df_pivot[['rolling_std_20_SPY', 'rolling_std_20_IWM']].mean(axis=1)\n",
    "\n",
    "# Step 2â€“4: Loop over implied assets to compute z-scored spread and clean up\n",
    "spread = df_pivot['rolling_std_20_VIXY'] - realized_avg\n",
    "z_col = f'z_vol_spread_vixy'\n",
    "\n",
    "df_pivot[z_col] = (spread - spread.rolling(z_window).mean()) / spread.rolling(z_window).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "620f6a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility Skew = Difference in realized vol between two symbols\n",
    "# IWM vs SPY â€” Small Caps vs Broad Market - GLD vs SPY â€” Gold vs Broad Market\n",
    "# Define the assets to compare against SPY\n",
    "skew_assets = ['IWM', 'GLD']\n",
    "\n",
    "# Loop to compute z-scored volatility skew vs SPY\n",
    "for ticker in skew_assets:\n",
    "    spread = df_pivot[f'rolling_std_20_{ticker}'] - df_pivot['rolling_std_20_SPY']\n",
    "    z_col = f'z_vol_skew_{ticker.lower()}'\n",
    "    \n",
    "    df_pivot[z_col] = (spread - spread.rolling(z_window).mean()) / spread.rolling(z_window).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab370d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify relevant columns (z-scored rolling std)\n",
    "z_vol_cols = [col for col in df_pivot.columns if col.startswith('z_rolling_std_20_')]\n",
    "\n",
    "# Step 2: Compute rolling correlation matrix and extract average pairwise correlation\n",
    "def compute_volatility_correlation_regime(df, columns, window=20):\n",
    "    avg_corr = []\n",
    "\n",
    "    for i in range(window, len(df)):\n",
    "        window_df = df.iloc[i - window:i][columns]\n",
    "        corr_matrix = window_df.corr()\n",
    "\n",
    "        # Extract upper triangle without diagonal\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        mean_corr = upper_triangle.stack().mean()\n",
    "        avg_corr.append(mean_corr)\n",
    "\n",
    "    # Align with original index\n",
    "    avg_corr_series = pd.Series(avg_corr, index=df.index[window:])\n",
    "    return avg_corr_series\n",
    "\n",
    "# Step 3: Run the function\n",
    "correlation_regime_vol = compute_volatility_correlation_regime(df_pivot, z_vol_cols, window=20)\n",
    "\n",
    "# Step 4: Add to df_pivot (optional)\n",
    "df_pivot.loc[correlation_regime_vol.index, 'correlation_regime_vol'] = correlation_regime_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9a6334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion vs. Contraction\n",
    "# Advance-Decline Ratio (ADR)\n",
    "\n",
    "# Step 1: Identify close columns\n",
    "close_cols = [col for col in df_pivot.columns if col.startswith('close_')]\n",
    "\n",
    "# Step 2: Calculate previous close using shift\n",
    "prev_close = df_pivot[close_cols].shift(1)\n",
    "\n",
    "# Step 3: Calculate change\n",
    "change = df_pivot[close_cols] - prev_close\n",
    "\n",
    "# Step 4: Classify movement\n",
    "advance = (change > 0).astype(int)\n",
    "decline = (change < 0).astype(int)\n",
    "\n",
    "# Step 5: Count advances and declines per timestamp\n",
    "advancing_count = advance.sum(axis=1)\n",
    "declining_count = decline.sum(axis=1)\n",
    "\n",
    "# Step 6: Calculate ADR  manual encoding to avoid division by zero\n",
    "\n",
    "adr_series = pd.Series(index=df_pivot.index, dtype=float)\n",
    "\n",
    "for i in df_pivot.index:\n",
    "    adv = advancing_count[i]\n",
    "    dec = declining_count[i]\n",
    "    \n",
    "    if adv == 0 and dec == 0: # avoifd division by zero\n",
    "        adr_series[i] = 1.0  # neutral market\n",
    "    elif dec == 0:\n",
    "        adr_series[i] = len(set(custom_vol_subset + custom_exp_subset))  # strong bullish signal\n",
    "    else:\n",
    "        adr_series[i] = adv / dec\n",
    "\n",
    "# analyzing trends, a rolling average helps\n",
    "adr_smoothed = pd.Series(adr_series).rolling(window=5).mean()\n",
    "\n",
    "# Step 7: Add ADR to df_pivot\n",
    "df_pivot['ADR_smooth'] = adr_smoothed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8a02197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion vs. Contraction\n",
    "# Zweig Breadth Thrust (ZBT) is a classic and powerful breadth thrust indicator used to identify the start of strong bullish moves\n",
    "\n",
    "# Step 1: Use previously computed advance matrix\n",
    "# (from your ADR calculation)\n",
    "# advance = (change > 0).astype(int)\n",
    "\n",
    "# Step 2: Compute percentage of advancing stocks per timestamp\n",
    "advancing_percent = advance.sum(axis=1) / advance.shape[1]\n",
    "\n",
    "# Step 3: Compute 10-day moving average of advancing percent, ema more smooth than sma\n",
    "zbt_series = advancing_percent.ewm(span=10, adjust=False).mean()\n",
    "df_pivot['zbt'] = zbt_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b60b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion vs. Contraction\n",
    "# % tickers Above MA50/MA200 Market-wide participation\n",
    "# Step 1: Identify close columns\n",
    "close_cols = [col for col in df_pivot.columns if col.startswith('close_')]\n",
    "\n",
    "# Step 2: Compute MA50 and MA200 for each symbol\n",
    "ma50 = df_pivot[close_cols].rolling(window=50, min_periods=1).mean()\n",
    "ma200 = df_pivot[close_cols].rolling(window=200, min_periods=1).mean()\n",
    "\n",
    "# Step 3: Compare close to MA50 and MA200\n",
    "above_ma50 = (df_pivot[close_cols] > ma50).astype(int)\n",
    "above_ma200 = (df_pivot[close_cols] > ma200).astype(int)\n",
    "\n",
    "# Step 4: Compute % of stocks above each MA\n",
    "pct_above_ma50 = above_ma50.sum(axis=1) / len(close_cols) * 100\n",
    "pct_above_ma200 = above_ma200.sum(axis=1) / len(close_cols) * 100\n",
    "\n",
    "# Step 5: Add to df_pivot\n",
    "df_pivot['Pct_Above_MA50'] = pct_above_ma50\n",
    "df_pivot['Pct_Above_MA200'] = pct_above_ma200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e56a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion vs. Contraction\n",
    "# Number of stocks making a new 20-day high, Number of stocks making a new 20-day low, New Highs vs. New Lows Ratio\n",
    "# Step 1: Identify close columns\n",
    "close_cols = [col for col in df_pivot.columns if col.startswith('close_')]\n",
    "\n",
    "# Step 2: Compute rolling 20-day high and low\n",
    "rolling_high = df_pivot[close_cols].rolling(window=20, min_periods=1).max()\n",
    "rolling_low = df_pivot[close_cols].rolling(window=20, min_periods=1).min()\n",
    "\n",
    "# Step 3: Identify new highs and new lows\n",
    "new_highs = (df_pivot[close_cols] >= rolling_high).astype(int)\n",
    "new_lows = (df_pivot[close_cols] <= rolling_low).astype(int)\n",
    "\n",
    "# Step 4: Count per timestamp\n",
    "nh_count = new_highs.sum(axis=1)\n",
    "nl_count = new_lows.sum(axis=1)\n",
    "\n",
    "# Step 5: Compute NH/NL Ratio with manual encoding to avoid division by zero\n",
    "nh_nl_ratio = pd.Series(index=df_pivot.index, dtype=float)\n",
    "\n",
    "for i in df_pivot.index:\n",
    "    nh = nh_count[i]\n",
    "    nl = nl_count[i]\n",
    "    \n",
    "    if nl == 0 and nh == 0: # avoifd division by zero\n",
    "        nh_nl_ratio[i] = 1.0  # flat market\n",
    "    elif nl == 0: # if there are no new lows, we have a strong bullish signal, avoid division by zero\n",
    "        nh_nl_ratio[i] = len(set(custom_vol_subset + custom_exp_subset))  # strong bullish signal\n",
    "    else:\n",
    "        nh_nl_ratio[i] = nh / nl # normal ratio\n",
    "\n",
    "\n",
    "nh_nl_ratio_smoothed = pd.Series(nh_nl_ratio).rolling(window=5).mean()\n",
    "\n",
    "# Step 6: Add to df_pivot\n",
    "df_pivot['NH_NL_Ratio_smooth'] = nh_nl_ratio_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7d617457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expansion vs. Contraction\n",
    "# Volume Surge feature, which compares total volume at each timestamp to its rolling average\n",
    "# Step 1: Identify volume columns\n",
    "volume_cols = [col for col in df_pivot.columns if col.startswith('volume_')]\n",
    "\n",
    "# Step 2: Compute total volume per timestamp\n",
    "total_volume = df_pivot[volume_cols].sum(axis=1)\n",
    "\n",
    "# Step 3: Compute rolling average volume (e.g., 20-day)\n",
    "rolling_avg_volume = total_volume.rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "# Step 4: Compute volume surge ratio\n",
    "volume_surge_ratio = total_volume / rolling_avg_volume\n",
    "\n",
    "# Step 5: Manual encoding to avoid NaN or inf\n",
    "volume_surge = pd.Series(index=df_pivot.index, dtype=float)\n",
    "\n",
    "for i in df_pivot.index:\n",
    "    tv = total_volume[i]\n",
    "    rv = rolling_avg_volume[i]\n",
    "    \n",
    "    if rv == 0:\n",
    "        volume_surge[i] = 1.0  # neutral if no prior volume\n",
    "    else:\n",
    "        volume_surge[i] = tv / rv\n",
    "\n",
    "df_pivot['volum_surge'] = volume_surge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb14503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'SPY' columns to avoid redundancy, they where just used for comparison\n",
    "df_pivot.drop(columns=[col for col in df_pivot.columns if 'SPY' in col], inplace=True)\n",
    "\n",
    "# Drop 'rolling_std_20' columns to avoid redundancy, they where just used for comparison, we keep z-scores only\n",
    "# Drop columns that start with 'rolling_std_20'\n",
    "df_pivot.drop(columns=[col for col in df_pivot.columns if col.startswith(\"rolling_std_20\")], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7053b660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# after 2*max(windows) +z_window +1 days, not nans\n",
    "df_pivot_clean = df_pivot[max(windows)+z_window+1:]\n",
    "\n",
    "print(df_pivot_clean.isna().sum().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe74e99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stationary = df_pivot_clean.drop(\n",
    "    columns=[col for col in df_pivot_clean.columns if any(x in col for x in [\"vwap\", \"low\", \"high\", \"close\", \"open\", \"volume\",\n",
    "                                                                              \"trade_count\", \"z_log_returns\", \"z_range_ratio_smooth\", \"z_rolling_std\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bd5766bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vol_shock_count_20_BND', 'vol_shock_count_20_CPER',\n",
       "       'vol_shock_count_20_GLD', 'vol_shock_count_20_HYG',\n",
       "       'vol_shock_count_20_IWM', 'vol_shock_count_20_SCHP',\n",
       "       'vol_shock_count_20_VIXY', 'vol_shock_count_20_XLI',\n",
       "       'volatility_dispersion', 'z_realized_implied_vixy', 'z_vol_spread_vixy',\n",
       "       'z_vol_skew_iwm', 'z_vol_skew_gld', 'correlation_regime_vol',\n",
       "       'ADR_smooth', 'zbt', 'Pct_Above_MA50', 'Pct_Above_MA200',\n",
       "       'NH_NL_Ratio_smooth', 'volum_surge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stationary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b0906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Quantile (uniform) | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Power (Yeo-Johnson) | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MinMax | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Robust | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: MaxAbs | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=3, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=5, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=8, n_neig=30, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=8, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=8, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=8, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=15, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=15, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=15, min_d=0.2, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=30, min_d=0.01, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=30, min_d=0.1, metric=euclidean\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=correlation\n",
      "\n",
      "ðŸ” Scaler: Standard | UMAP: n_comp=10, n_neig=30, min_d=0.2, metric=euclidean\n"
     ]
    }
   ],
   "source": [
    "import umap\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import (\n",
    "    QuantileTransformer, PowerTransformer, MinMaxScaler,\n",
    "    RobustScaler, MaxAbsScaler, StandardScaler\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import itertools\n",
    "\n",
    "\n",
    "# Define scalers\n",
    "scalers = {\n",
    "    \"Quantile (uniform)\": QuantileTransformer(output_distribution='uniform', random_state=0),\n",
    "    \"Power (Yeo-Johnson)\": PowerTransformer(method='yeo-johnson'),\n",
    "    \"MinMax\": MinMaxScaler(),\n",
    "    \"Robust\": RobustScaler(),\n",
    "    \"MaxAbs\": MaxAbsScaler(),\n",
    "    \"Standard\": StandardScaler(),\n",
    "}\n",
    "\n",
    "# Define parameter grids\n",
    "N_COMP = [3, 5, 8, 10]\n",
    "N_NEIG = [8, 15, 30]\n",
    "MIN_D = [0.01, 0.1, 0.2]\n",
    "METRIC = [\"correlation\", \"euclidean\"]\n",
    "\n",
    "# Store all results\n",
    "all_results = []\n",
    "\n",
    "# Range of K values to test\n",
    "k_range = range(2, 8)\n",
    "\n",
    "# Loop over scalers\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    scaled = scaler.fit_transform(df_stationary)\n",
    "\n",
    "    # Loop over all UMAP parameter combinations\n",
    "    for n_comp, n_neig, min_d, metric in itertools.product(N_COMP, N_NEIG, MIN_D, METRIC):\n",
    "        print(f\"\\nðŸ” Scaler: {scaler_name} | UMAP: n_comp={n_comp}, n_neig={n_neig}, min_d={min_d}, metric={metric}\")\n",
    "\n",
    "        # Apply UMAP\n",
    "        X_umap = umap.UMAP(\n",
    "            n_neighbors=n_neig,\n",
    "            min_dist=min_d,\n",
    "            n_components=n_comp,\n",
    "            metric=metric\n",
    "        ).fit_transform(scaled)\n",
    "\n",
    "        # Loop over cluster counts\n",
    "        for k in k_range:\n",
    "            # GMM\n",
    "            gmm = GaussianMixture(n_components=k, random_state=0)\n",
    "            gmm_labels = gmm.fit_predict(X_umap)\n",
    "\n",
    "            all_results.append({\n",
    "                \"scaler\": scaler_name,\n",
    "                \"method\": \"GMM\",\n",
    "                \"k\": k,\n",
    "                \"n_components\": n_comp,\n",
    "                \"n_neighbors\": n_neig,\n",
    "                \"min_dist\": min_d,\n",
    "                \"metric\": metric,\n",
    "                \"bic\": gmm.bic(X_umap),\n",
    "                \"aic\": gmm.aic(X_umap),\n",
    "                \"silhouette\": silhouette_score(X_umap, gmm_labels),\n",
    "                \"calinski_harabasz\": calinski_harabasz_score(X_umap, gmm_labels),\n",
    "                \"davies_bouldin\": davies_bouldin_score(X_umap, gmm_labels)\n",
    "            })\n",
    "\n",
    "            # KMeans\n",
    "            kmeans = KMeans(n_clusters=k, random_state=0, n_init='auto')\n",
    "            kmeans_labels = kmeans.fit_predict(X_umap)\n",
    "\n",
    "            all_results.append({\n",
    "                \"scaler\": scaler_name,\n",
    "                \"method\": \"KMeans\",\n",
    "                \"k\": k,\n",
    "                \"n_components\": n_comp,\n",
    "                \"n_neighbors\": n_neig,\n",
    "                \"min_dist\": min_d,\n",
    "                \"metric\": metric,\n",
    "                \"bic\": None,\n",
    "                \"aic\": None,\n",
    "                \"silhouette\": silhouette_score(X_umap, kmeans_labels),\n",
    "                \"calinski_harabasz\": calinski_harabasz_score(X_umap, kmeans_labels),\n",
    "                \"davies_bouldin\": davies_bouldin_score(X_umap, kmeans_labels)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "05706bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_results)\n",
    "results_df.to_csv(\"clustering_experiment_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
