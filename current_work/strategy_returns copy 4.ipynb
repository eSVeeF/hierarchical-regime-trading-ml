{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe8ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get current working directory (where notebook is running)\n",
    "current_dir = os.getcwd()\n",
    "# Go up one level, then into utils\n",
    "utils_path = os.path.abspath(os.path.join(current_dir, '..', 'utils'))\n",
    "# Add to sys.path\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "from trend_regime_utils import load_trend_data, process_trend_data, create_advanced_feat, mayority_vote_cluster_smooth\n",
    "from bull_trend_regime_utils import load_bull_trend_data, create_advanced_bull_feat, merge_clean_final_clusters\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import joblib\n",
    "\n",
    "# For API Keys\n",
    "from dotenv import load_dotenv\n",
    "# Alpaca API keys\n",
    "API_KEY = None\n",
    "SECRET_KEY = None\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if API_KEY is None:\n",
    "    API_KEY = os.environ.get('ALP_API_KEY')\n",
    "\n",
    "if SECRET_KEY is None:\n",
    "    SECRET_KEY = os.environ.get('ALP_SEC_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6032b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n"
     ]
    }
   ],
   "source": [
    "EARLIEST_DATE = datetime(2016, 1, 16, tzinfo=ZoneInfo('America/New_York'))\n",
    "LAST_DATE = datetime(2025, 7, 20, tzinfo=ZoneInfo('America/New_York'))\n",
    "\n",
    "df_trend_raw = load_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE)\n",
    "\n",
    "df_trend_processed = process_trend_data(df_trend_raw)\n",
    "\n",
    "df_trend_feat = create_advanced_feat(df_trend_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7a72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the project root (one level up from current working directory)\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, 'models')\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "## If want to predict\n",
    "# Load models\n",
    "scaler = joblib.load(os.path.join(MODEL_DIR, \"trend_scaler.pkl\"))\n",
    "umap_model = joblib.load(os.path.join(MODEL_DIR, \"trend_umap_model.pkl\"))\n",
    "gmm_model = joblib.load(os.path.join(MODEL_DIR, \"trend_gmm_model.pkl\"))\n",
    "\n",
    "# scale data\n",
    "trend_scaled = scaler.transform(df_trend_feat)\n",
    "\n",
    "# Apply UMAP transformation\n",
    "trend_umap = umap_model.transform(trend_scaled)\n",
    "\n",
    "# Predict clusters\n",
    "trend_gmm_labels = gmm_model.predict(trend_umap)\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# print(silhouette_score(trend_umap, trend_gmm_labels))\n",
    "\n",
    "df_with_clusters = pd.DataFrame(trend_gmm_labels, columns=[\"cluster\"], index=df_trend_feat.index)\n",
    "\n",
    "df_cluster_smooth = mayority_vote_cluster_smooth(df_with_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5115ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bull_raw = load_bull_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE)\n",
    "\n",
    "bull_features_df = create_advanced_bull_feat(df_bull_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52d6abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only bull days \n",
    "bull_days = df_cluster_smooth[df_cluster_smooth==1]\n",
    "\n",
    "# Keep only rows in bull_features_df where the index exists in bull_days\n",
    "only_bull_features_df = bull_features_df[bull_features_df.index.isin(bull_days.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e874c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\Documents\\TFG\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## If want to predict\n",
    "# Load models\n",
    "bull_scaler = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_scaler.pkl\"))\n",
    "bull_umap_model = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_umap_model.pkl\"))\n",
    "spectral_model = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_spectral_model.pkl\"))\n",
    "\n",
    "# scale data\n",
    "bull_trend_scaled = bull_scaler.transform(only_bull_features_df)\n",
    "\n",
    "# Apply UMAP transformation\n",
    "bull_trend_umap = bull_umap_model.transform(bull_trend_scaled)\n",
    "\n",
    "# Predict clusters, SpectralClustering doesnâ€™t have a .predict() method for unseen data.\n",
    "# Every time you call fit_predict(), it re-computes clusters from scratch, so for new data, you need to re-run it on all data (old + new)\n",
    "bull_trend_spectral_labels = spectral_model.fit_predict(bull_trend_umap)\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# print(silhouette_score(bull_trend_umap, bull_trend_spectral_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11edb463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_cluster\n",
       "1                0.251719\n",
       "0                0.240257\n",
       "2                0.187987\n",
       "3                0.175608\n",
       "4                0.144429\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute final clusters\n",
    "df_final_clusters = merge_clean_final_clusters(bull_trend_spectral_labels, only_bull_features_df, df_with_clusters)\n",
    "\n",
    "df_final_clusters.value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37298a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAs:  0\n"
     ]
    }
   ],
   "source": [
    "tickers_to_trade = [\n",
    "    \"SPY\",  # S&P 500 ETF\n",
    "    \"EFA\",  # MSCI EAFE (Developed Markets ex-US) ETF\n",
    "    \"EEM\",  # MSCI Emerging Markets ETF\n",
    "    \"TLT\",  # 20+ Year Treasury Bond ETF\n",
    "    \"GLD\",  # Gold ETF\n",
    "    \"USO\",  # Crude Oil ETF\n",
    "    \"QQQ\",  # Nasdaq 100 ETF\n",
    "    \"IWM\"   # Russell 2000 ETF\n",
    "]\n",
    "\n",
    "df_trade_raw = load_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE, all_tickers=tickers_to_trade)\n",
    "\n",
    "print(\"NAs: \", df_trade_raw.pivot(columns=\"symbol\").isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc6785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sma_crossover(df, short_window, long_window, signal_name):\n",
    "    \"\"\"Buy when short SMA crosses above long SMA, sell when crosses below.\"\"\"\n",
    "    \"\"\"Trend-following / Momentum\"\"\"\n",
    "    df = df.copy()\n",
    "    df['SMA_short'] = df['close'].rolling(short_window).mean()\n",
    "    df['SMA_long'] = df['close'].rolling(long_window).mean()\n",
    "    df[signal_name] = np.where(df['SMA_short'] > df['SMA_long'], 1, -1)\n",
    "    return df.drop(columns=['SMA_short', 'SMA_long'])\n",
    "\n",
    "def add_rsi(df, period, signal_name):\n",
    "    \"\"\"Buy when RSI < 30 (oversold), sell when RSI > 70 (overbought).\"\"\"\n",
    "    \"\"\"Mean reversion\"\"\"\n",
    "    df = df.copy()\n",
    "    delta = df['close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    df['RSI'] = rsi\n",
    "    df[signal_name] = np.where(df['RSI'] < 30, 1, np.where(df['RSI'] > 70, -1, 0)) # 65 35 for large periods maybe\n",
    "    return df.drop(columns=['RSI'])\n",
    "\n",
    "\n",
    "def add_bollinger_bands(df, window, num_std, signal_name):\n",
    "    \"\"\"Buy when price closes below lower band, sell when above upper band.\"\"\"\n",
    "    \"\"\"Volatility breakout & Reversion\"\"\"\n",
    "    df = df.copy()\n",
    "    sma = df['close'].rolling(window).mean()\n",
    "    rolling_std = df['close'].rolling(window).std()\n",
    "    upper_band = sma + num_std * rolling_std\n",
    "    lower_band = sma - num_std * rolling_std\n",
    "    df[signal_name] = np.where(df['close'] < lower_band, 1, np.where(df['close'] > upper_band, -1, 0))\n",
    "    return df\n",
    "\n",
    "# ---- Apply all strategies ----\n",
    "def add_all_strategies(df):\n",
    "    df = add_sma_crossover(df, short_window=5, long_window=10, signal_name=\"S1_1_signal\")\n",
    "    df = add_sma_crossover(df, short_window=10, long_window=20, signal_name=\"S1_2_signal\")\n",
    "    df = add_sma_crossover(df, short_window=14, long_window=28, signal_name=\"S1_3_signal\")\n",
    "    df = add_rsi(df, period=7, signal_name=\"S2_1_signal\")\n",
    "    df = add_rsi(df, period=14, signal_name=\"S2_2_signal\")\n",
    "    df = add_rsi(df, period=21, signal_name=\"S2_3_signal\")\n",
    "    df = add_bollinger_bands(df, window=10, num_std=1, signal_name=\"S3_1_signal\")\n",
    "    df = add_bollinger_bands(df, window=20, num_std=1, signal_name=\"S3_2_signal\")\n",
    "    df = add_bollinger_bands(df, window=40, num_std=1.5, signal_name=\"S3_3_signal\")\n",
    "    return df\n",
    "\n",
    "df_strats = add_all_strategies(df_trade_raw)\n",
    "\n",
    "# How This Works\n",
    "# Signals are numeric:\n",
    "# 1 = long bias,\n",
    "# -1 = short bias,\n",
    "# 0 = neutral (for RSI & Bollinger).\n",
    "\n",
    "# No lookahead bias in signal generation: All rolling and EMA operations use only past data.\n",
    "\n",
    "# Drop helper columns so only S1_signal to S6_signal remain, ready for ML feature building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eae2c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_signal_distribution(df, signal_cols, symbol_col='symbol'):\n",
    "    \"\"\"\n",
    "    Plots barplots showing distribution of signal values (1, 0, -1)\n",
    "    per ticker and per strategy in a 3x2 subplot layout.\n",
    "    \"\"\"\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(18, 10))\n",
    "    axes = axes.flatten()  # Flatten to easily iterate\n",
    "    \n",
    "    for i, strat in enumerate(signal_cols):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Count frequency of each signal per ticker\n",
    "        counts = (\n",
    "            df.groupby(symbol_col)[strat]\n",
    "            .value_counts()\n",
    "            .unstack(fill_value=0)\n",
    "            .reset_index()\n",
    "            .melt(id_vars=symbol_col, var_name='Signal', value_name='Count')\n",
    "        )\n",
    "        \n",
    "        # Plot on the corresponding subplot\n",
    "        sns.barplot(data=counts, x=symbol_col, y='Count', hue='Signal', palette='coolwarm', ax=ax)\n",
    "        \n",
    "        ax.set_title(f\"Signal Distribution for {strat}\", fontsize=12)\n",
    "        ax.set_xlabel(\"Ticker\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.legend(title=\"Signal\")\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Hide any unused subplots if signal_cols < 6\n",
    "    for j in range(len(signal_cols), 12):\n",
    "        fig.delaxes(axes[j])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "strategies = [\"S1_1_signal\", \"S1_2_signal\", \"S1_3_signal\", \"S2_1_signal\", \"S2_2_signal\", \"S2_3_signal\", \"S3_1_signal\", \"S3_2_signal\", \"S3_3_signal\"]\n",
    "\n",
    "plot_signal_distribution(df_strats, strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1df45b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 5\n",
    "\n",
    "def compute_forward_returns(df, horizon=HORIZON):\n",
    "    \"\"\"\n",
    "    For each symbol and timestamp, compute forward return over `horizon` days.\n",
    "    Forward return = (close at t+horizon / close at t) - 1\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['forward_return'] = df.groupby('symbol')['close'].shift(-horizon) / df['close'] - 1\n",
    "    return df\n",
    "\n",
    "def generate_strategy_returns(df, horizon=HORIZON):\n",
    "    \"\"\"\n",
    "    For each strategy S1..S6, compute forward return assuming you go LONG when signal=1,\n",
    "    SHORT when signal=-1, and 0 when neutral (signal=0).\n",
    "    \n",
    "    The strat_return per row per strategy is:\n",
    "      forward_return * signal at current time\n",
    "    \n",
    "    Returns a DataFrame in long format:\n",
    "      ['symbol', 'timestamp', 'strategy', 'signal', 'forward_return', 'strat_return']\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = compute_forward_returns(df, horizon=horizon)\n",
    "    \n",
    "    strategy_cols = [\"S1_1_signal\", \"S1_2_signal\", \"S1_3_signal\", \"S2_1_signal\", \"S2_2_signal\", \"S2_3_signal\", \"S3_1_signal\", \"S3_2_signal\", \"S3_3_signal\"]\n",
    "    records = []\n",
    "    \n",
    "    for strat in strategy_cols:\n",
    "        temp = df[['symbol', 'close', strat, 'forward_return']].copy()\n",
    "        temp = temp.rename(columns={strat: 'signal'})\n",
    "        temp['strategy'] = strat\n",
    "        \n",
    "        # strat_return is forward return weighted by position signal\n",
    "        # Long = profit if price rises, Short = profit if price falls\n",
    "        temp['strat_return'] = temp['forward_return'] * temp['signal']\n",
    "        \n",
    "        ###### Optionally remove neutral signals to reduce noise\n",
    "        # Neutral signals are safe to exclude if you want your model to focus on\n",
    "        #  performance conditional on entering a trade. Keep them if you want \n",
    "        # the model to learn when to trade vs when not to\n",
    "        temp = temp[temp['signal'] != 0]\n",
    "        \n",
    "        records.append(temp[['symbol', 'strategy', 'signal', 'forward_return', 'strat_return']])\n",
    "    \n",
    "    df_strat_returns = pd.concat(records).reset_index()\n",
    "    return df_strat_returns.set_index('timestamp')\n",
    "\n",
    "\n",
    "df_return_strats = generate_strategy_returns(df_strats, horizon=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "611837d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "        ###### Optionally remove neutral signals to reduce noise\n",
    "        # Neutral signals are safe to exclude if you want your model to focus on\n",
    "        #  performance conditional on entering a trade. Keep them if you want \n",
    "        # the model to learn when to trade vs when not to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1790a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>strategy</th>\n",
       "      <th>signal</th>\n",
       "      <th>strat_return</th>\n",
       "      <th>prev_regime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.018525</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-15 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.013268</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-16 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.010915</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-17 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.014773</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-18 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.022238</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-13 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.047494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-16 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.071129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.109235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-18 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.105506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-20 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>S3_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.118383</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91674 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          symbol     strategy  signal  strat_return  \\\n",
       "timestamp                                                             \n",
       "2016-11-14 05:00:00+00:00    EEM  S1_1_signal      -1     -0.018525   \n",
       "2016-11-15 05:00:00+00:00    EEM  S1_1_signal      -1     -0.013268   \n",
       "2016-11-16 05:00:00+00:00    EEM  S1_1_signal      -1     -0.010915   \n",
       "2016-11-17 05:00:00+00:00    EEM  S1_1_signal      -1     -0.014773   \n",
       "2016-11-18 05:00:00+00:00    EEM  S1_1_signal      -1     -0.022238   \n",
       "...                          ...          ...     ...           ...   \n",
       "2025-06-13 04:00:00+00:00    USO  S3_3_signal      -1      0.047494   \n",
       "2025-06-16 04:00:00+00:00    USO  S3_3_signal      -1      0.071129   \n",
       "2025-06-17 04:00:00+00:00    USO  S3_3_signal      -1      0.109235   \n",
       "2025-06-18 04:00:00+00:00    USO  S3_3_signal      -1      0.105506   \n",
       "2025-06-20 04:00:00+00:00    USO  S3_3_signal      -1      0.118383   \n",
       "\n",
       "                           prev_regime  \n",
       "timestamp                               \n",
       "2016-11-14 05:00:00+00:00            3  \n",
       "2016-11-15 05:00:00+00:00            3  \n",
       "2016-11-16 05:00:00+00:00            3  \n",
       "2016-11-17 05:00:00+00:00            3  \n",
       "2016-11-18 05:00:00+00:00            3  \n",
       "...                                ...  \n",
       "2025-06-13 04:00:00+00:00            1  \n",
       "2025-06-16 04:00:00+00:00            1  \n",
       "2025-06-17 04:00:00+00:00            1  \n",
       "2025-06-18 04:00:00+00:00            1  \n",
       "2025-06-20 04:00:00+00:00            1  \n",
       "\n",
       "[91674 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shift clusters since they are computed at the end of the day, so that info is not available, drop frist day since is nan\n",
    "shifted_regimes = df_final_clusters[[\"final_cluster\"]].shift(1).dropna().astype(int)\n",
    "\n",
    "# join with clusters (first months have no cluster so have to drop them)\n",
    "df_joined = df_return_strats.join(shifted_regimes, how='inner')\n",
    "df_joined.rename(columns={\"final_cluster\": \"prev_regime\"}, inplace=True)\n",
    "\n",
    "df_joined.drop(columns=\"forward_return\", inplace=True)\n",
    "# drop last days without available returns\n",
    "df_joined.dropna(subset=['strat_return'], inplace=True)\n",
    "\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c82fcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\AppData\\Local\\Temp\\ipykernel_10892\\3722318940.py:16: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_mean_return_per_strategy(df):\n",
    "    \"\"\"\n",
    "    Plot mean strat_return grouped only by strategy.\n",
    "    \"\"\"\n",
    "    # Compute mean strat_return per strategy\n",
    "    grouped = df.groupby('strategy')['strat_return'].mean().reset_index()\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    # Create barplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(\n",
    "        data=grouped,\n",
    "        x='strategy',\n",
    "        y='strat_return',\n",
    "        palette='Set2'\n",
    "    )\n",
    "\n",
    "    plt.title('Mean Strategy Return')\n",
    "    plt.xlabel('Strategy')\n",
    "    plt.ylabel('Mean strat_return')\n",
    "\n",
    "    # Add value annotations on top of bars\n",
    "    for i, row in grouped.iterrows():\n",
    "        plt.text(i, row['strat_return'], f'{row[\"strat_return\"]:.4f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_mean_return_per_strategy(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41af956d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_mean_return_by_strategy_and_regime(df):\n",
    "    \"\"\"\n",
    "    Plot mean strat_return grouped by strategy and prev_regime.\n",
    "    \"\"\"\n",
    "    # Compute mean strat_return per strategy and regime\n",
    "    grouped = df.groupby(['strategy', 'prev_regime'])['strat_return'].mean().reset_index()\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    # Create barplot with strategy on x-axis and hue=prev_regime\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=grouped,\n",
    "        x='strategy',\n",
    "        y='strat_return',\n",
    "        hue='prev_regime',\n",
    "        palette='Set2'\n",
    "    )\n",
    "\n",
    "    plt.title('Mean Strategy Return by Regime')\n",
    "    plt.xlabel('Strategy')\n",
    "    plt.ylabel('Mean strat_return')\n",
    "    plt.legend(title='Prev Regime')\n",
    "\n",
    "    # Add value annotations on top of bars\n",
    "    for i, bar in enumerate(plt.gca().patches):\n",
    "        height = bar.get_height()\n",
    "        if height:  # Avoid annotating empty bars\n",
    "            plt.gca().text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_mean_return_by_strategy_and_regime(df_joined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee6d165a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x2000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_mean_strat_return(df):\n",
    "    \"\"\"\n",
    "    Plot mean strat_return grouped by symbol, strategy, and prev_regime.\n",
    "    \"\"\"\n",
    "    # Compute mean strat_return\n",
    "    grouped = df.groupby(['symbol', 'strategy', 'prev_regime'])['strat_return'].mean().reset_index()\n",
    "\n",
    "    # Set seaborn style\n",
    "    sns.set(style='whitegrid')\n",
    "\n",
    "    symbols = grouped['symbol'].unique()\n",
    "    n_symbols = len(symbols)\n",
    "\n",
    "    # Create subplots, one per symbol (adjust cols and rows as needed)\n",
    "    cols = 2\n",
    "    rows = (n_symbols + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(14, 5 * rows), sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, sym in enumerate(symbols):\n",
    "        ax = axes[i]\n",
    "        data = grouped[grouped['symbol'] == sym]\n",
    "\n",
    "        # Draw barplot with strategy on x-axis, hue=prev_regime\n",
    "        sns.barplot(\n",
    "            data=data,\n",
    "            x='strategy',\n",
    "            y='strat_return',\n",
    "            hue='prev_regime',\n",
    "            ax=ax,\n",
    "            palette='Set2'\n",
    "        )\n",
    "\n",
    "        ax.set_title(f'Mean Strategy Return for {sym}')\n",
    "        ax.set_xlabel('Strategy')\n",
    "        ax.set_ylabel('Mean strat_return')\n",
    "        ax.legend(title='Prev Regime')\n",
    "\n",
    "        # Add vertical delimiters between strategies\n",
    "        # Strategies are categorical on x-axis, positions 0,1,2,...,n-1\n",
    "        n_strategies = data['strategy'].nunique()\n",
    "        for pos in range(0, n_strategies - 1):\n",
    "            ax.axvline(pos + 0.5, color='gray', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Remove empty subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_mean_strat_return(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de8948df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergi\\AppData\\Local\\Temp\\ipykernel_10892\\716640814.py:58: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_features = df_trade_raw.groupby('symbol', group_keys=False).apply(add_features)\n"
     ]
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. Returns\n",
    "    # df['return_1d'] = df['close'].pct_change(1)\n",
    "    # df['return_3d'] = df['close'].pct_change(3)\n",
    "    # df['return_5d'] = df['close'].pct_change(5)\n",
    "\n",
    "    # 2. Volatility (rolling std of returns)\n",
    "    df['log_return_1d'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df['vol_5d'] = df['log_return_1d'].rolling(window=5).std()\n",
    "    df['vol_10d'] = df['log_return_1d'].rolling(window=10).std()\n",
    "    df.drop(columns=\"log_return_1d\",  inplace=True)\n",
    "\n",
    "    # 3. Momentum (price relative to N-day ago)\n",
    "    # df['mom_5d'] = df['close'] / df['close'].shift(5) - 1\n",
    "    # df['mom_10d'] = df['close'] / df['close'].shift(10) - 1\n",
    "    # df['mom_20d'] = df['close'] / df['close'].shift(20) - 1\n",
    "\n",
    "    # 4. Moving averages\n",
    "    # df['sma_5d'] = df['close'].rolling(window=5).mean()\n",
    "    # df['sma_10d'] = df['close'].rolling(window=10).mean()\n",
    "    # df['sma_20d'] = df['close'].rolling(window=20).mean()\n",
    "\n",
    "    # 5. Price relative to moving averages\n",
    "    df['price_div_sma5'] = df['close'] / df['close'].rolling(window=5).mean() - 1\n",
    "    df['price_div_sma10'] = df['close'] / df['close'].rolling(window=10).mean() - 1\n",
    "    df['price_div_sma20'] = df['close'] / df['close'].rolling(window=20).mean() - 1\n",
    "\n",
    "    # 6. Volume features\n",
    "    # df['vol_rolling_5d'] = df['volume'].rolling(window=5).mean()\n",
    "    # df['vol_rolling_10d'] = df['volume'].rolling(window=10).mean()\n",
    "    # df['vol_rolling_20d'] = df['volume'].rolling(window=20).mean()\n",
    "\n",
    "    # 7. Volatility normalized by volume (volume volatility ratio)\n",
    "    #df['vol_vol_ratio_5d'] = df['vol_5d'] / (df['vol_rolling_5d'] + 1e-9)\n",
    "\n",
    "    # 8. Price range (High-Low) relative to close\n",
    "    df['range_pct'] = (df['high'] - df['low']) / df['close']\n",
    "\n",
    "    # 9. ATR (Average True Range)\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df['atr_7'] = tr.rolling(window=7).mean()\n",
    "    df['atr_14'] = tr.rolling(window=14).mean()\n",
    "\n",
    "    # 10. Log volume change\n",
    "    #df['log_vol_change_1d'] = np.log(df['volume'] + 1) - np.log(df['volume'].shift(1) + 1)\n",
    "\n",
    "    # Drop rows with NaNs due to rolling calculations\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df.drop(columns=[\"open\", \"high\", \"low\", \"close\", \"volume\", \"trade_count\", \"vwap\"])\n",
    "\n",
    "# Example usage:\n",
    "df_features = df_trade_raw.groupby('symbol', group_keys=False).apply(add_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215a4fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>vol_5d</th>\n",
       "      <th>vol_10d</th>\n",
       "      <th>price_div_sma5</th>\n",
       "      <th>price_div_sma10</th>\n",
       "      <th>price_div_sma20</th>\n",
       "      <th>range_pct</th>\n",
       "      <th>atr_7</th>\n",
       "      <th>atr_14</th>\n",
       "      <th>strategy</th>\n",
       "      <th>signal</th>\n",
       "      <th>strat_return</th>\n",
       "      <th>prev_regime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>-0.035461</td>\n",
       "      <td>-0.048507</td>\n",
       "      <td>-0.066682</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>-0.035461</td>\n",
       "      <td>-0.048507</td>\n",
       "      <td>-0.066682</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>S1_2_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>-0.035461</td>\n",
       "      <td>-0.048507</td>\n",
       "      <td>-0.066682</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>S1_3_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>-0.035461</td>\n",
       "      <td>-0.048507</td>\n",
       "      <td>-0.066682</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>S2_2_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-14 05:00:00+00:00</th>\n",
       "      <td>EEM</td>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.019238</td>\n",
       "      <td>-0.035461</td>\n",
       "      <td>-0.048507</td>\n",
       "      <td>-0.066682</td>\n",
       "      <td>0.013538</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>S3_1_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>1.707886</td>\n",
       "      <td>2.135371</td>\n",
       "      <td>S1_1_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>1.707886</td>\n",
       "      <td>2.135371</td>\n",
       "      <td>S1_2_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>1.707886</td>\n",
       "      <td>2.135371</td>\n",
       "      <td>S1_3_signal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>1.707886</td>\n",
       "      <td>2.135371</td>\n",
       "      <td>S2_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-11 04:00:00+00:00</th>\n",
       "      <td>USO</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.016432</td>\n",
       "      <td>1.707886</td>\n",
       "      <td>2.135371</td>\n",
       "      <td>S3_1_signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91674 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          symbol    vol_5d   vol_10d  price_div_sma5  \\\n",
       "timestamp                                                              \n",
       "2016-11-14 05:00:00+00:00    EEM  0.015970  0.019238       -0.035461   \n",
       "2016-11-14 05:00:00+00:00    EEM  0.015970  0.019238       -0.035461   \n",
       "2016-11-14 05:00:00+00:00    EEM  0.015970  0.019238       -0.035461   \n",
       "2016-11-14 05:00:00+00:00    EEM  0.015970  0.019238       -0.035461   \n",
       "2016-11-14 05:00:00+00:00    EEM  0.015970  0.019238       -0.035461   \n",
       "...                          ...       ...       ...             ...   \n",
       "2025-07-11 04:00:00+00:00    USO  0.017359  0.014084        0.008876   \n",
       "2025-07-11 04:00:00+00:00    USO  0.017359  0.014084        0.008876   \n",
       "2025-07-11 04:00:00+00:00    USO  0.017359  0.014084        0.008876   \n",
       "2025-07-11 04:00:00+00:00    USO  0.017359  0.014084        0.008876   \n",
       "2025-07-11 04:00:00+00:00    USO  0.017359  0.014084        0.008876   \n",
       "\n",
       "                           price_div_sma10  price_div_sma20  range_pct  \\\n",
       "timestamp                                                                \n",
       "2016-11-14 05:00:00+00:00        -0.048507        -0.066682   0.013538   \n",
       "2016-11-14 05:00:00+00:00        -0.048507        -0.066682   0.013538   \n",
       "2016-11-14 05:00:00+00:00        -0.048507        -0.066682   0.013538   \n",
       "2016-11-14 05:00:00+00:00        -0.048507        -0.066682   0.013538   \n",
       "2016-11-14 05:00:00+00:00        -0.048507        -0.066682   0.013538   \n",
       "...                                    ...              ...        ...   \n",
       "2025-07-11 04:00:00+00:00         0.024862         0.009001   0.016432   \n",
       "2025-07-11 04:00:00+00:00         0.024862         0.009001   0.016432   \n",
       "2025-07-11 04:00:00+00:00         0.024862         0.009001   0.016432   \n",
       "2025-07-11 04:00:00+00:00         0.024862         0.009001   0.016432   \n",
       "2025-07-11 04:00:00+00:00         0.024862         0.009001   0.016432   \n",
       "\n",
       "                              atr_7    atr_14     strategy  signal  \\\n",
       "timestamp                                                            \n",
       "2016-11-14 05:00:00+00:00  0.780000  0.594286  S1_1_signal      -1   \n",
       "2016-11-14 05:00:00+00:00  0.780000  0.594286  S1_2_signal      -1   \n",
       "2016-11-14 05:00:00+00:00  0.780000  0.594286  S1_3_signal      -1   \n",
       "2016-11-14 05:00:00+00:00  0.780000  0.594286  S2_2_signal       1   \n",
       "2016-11-14 05:00:00+00:00  0.780000  0.594286  S3_1_signal       1   \n",
       "...                             ...       ...          ...     ...   \n",
       "2025-07-11 04:00:00+00:00  1.707886  2.135371  S1_1_signal       1   \n",
       "2025-07-11 04:00:00+00:00  1.707886  2.135371  S1_2_signal      -1   \n",
       "2025-07-11 04:00:00+00:00  1.707886  2.135371  S1_3_signal       1   \n",
       "2025-07-11 04:00:00+00:00  1.707886  2.135371  S2_1_signal      -1   \n",
       "2025-07-11 04:00:00+00:00  1.707886  2.135371  S3_1_signal      -1   \n",
       "\n",
       "                           strat_return  prev_regime  \n",
       "timestamp                                             \n",
       "2016-11-14 05:00:00+00:00             0            3  \n",
       "2016-11-14 05:00:00+00:00             0            3  \n",
       "2016-11-14 05:00:00+00:00             0            3  \n",
       "2016-11-14 05:00:00+00:00             1            3  \n",
       "2016-11-14 05:00:00+00:00             1            3  \n",
       "...                                 ...          ...  \n",
       "2025-07-11 04:00:00+00:00             0            1  \n",
       "2025-07-11 04:00:00+00:00             1            1  \n",
       "2025-07-11 04:00:00+00:00             0            1  \n",
       "2025-07-11 04:00:00+00:00             1            1  \n",
       "2025-07-11 04:00:00+00:00             1            1  \n",
       "\n",
       "[91674 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join with previous dataset\n",
    "# Set 'symbol' as part of the index\n",
    "# Join on both index levels (timestamp and symbol)\n",
    "final_df = df_features.set_index('symbol', append=True).join(df_joined.set_index('symbol', append=True), how='inner')\n",
    "\n",
    "# back to column\n",
    "final_df = final_df.reset_index(level='symbol')\n",
    "\n",
    "# discretize the target, 1 if returns > 0.005 (+0.5%)\n",
    "final_df[\"strat_return\"] = np.where(final_df[\"strat_return\"] > 0.01, 1, 0)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90306d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strat_return\n",
       "0    0.684251\n",
       "1    0.315749\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[\"strat_return\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3d2389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symbol', 'vol_5d', 'vol_10d', 'price_div_sma5', 'price_div_sma10',\n",
       "       'price_div_sma20', 'range_pct', 'atr_7', 'atr_14', 'strategy', 'signal',\n",
       "       'strat_return', 'prev_regime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a96bd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_splits(df, n_splits=5, min_train_size=0.5):\n",
    "    \"\"\"\n",
    "    Time-aware walk-forward splits.\n",
    "    - df: DataFrame with timestamp as index, symbol as a column.\n",
    "    - n_splits: number of folds.\n",
    "    - min_train_size: fraction of timestamps in the first training set.\n",
    "    \"\"\"\n",
    "    df_reset = df.reset_index()  # bring timestamp into a column\n",
    "    df_sorted = df_reset.sort_values('timestamp')\n",
    "    \n",
    "    timestamps = df_sorted['timestamp'].unique()\n",
    "    n_timestamps = len(timestamps)\n",
    "    \n",
    "    initial_train_end = int(n_timestamps * min_train_size)\n",
    "    step_size = (n_timestamps - initial_train_end) // n_splits\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        train_end = initial_train_end + i * step_size\n",
    "        val_end = train_end + step_size\n",
    "        \n",
    "        train_mask = df_sorted['timestamp'] <= timestamps[train_end - 1]\n",
    "        val_mask = (df_sorted['timestamp'] > timestamps[train_end - 1]) & \\\n",
    "                   (df_sorted['timestamp'] <= timestamps[min(val_end - 1, n_timestamps - 1)])\n",
    "        \n",
    "        train_idx = df_sorted[train_mask].index\n",
    "        val_idx = df_sorted[val_mask].index\n",
    "        \n",
    "        yield train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10ee017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, precision_recall_curve\n",
    "from itertools import product\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_search_lightgbm(df, features, target, categorical_features, n_splits=5, n_iter=500):\n",
    "    param_space = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15],\n",
    "        'num_leaves': [15, 31, 63],\n",
    "        'max_depth': [-1, 5, 10, 20],\n",
    "        'min_data_in_leaf': [10, 20, 50],\n",
    "        'feature_fraction': [0.6, 0.8, 1.0],\n",
    "        'bagging_fraction': [0.6, 0.8, 1.0],\n",
    "        'bagging_freq': [0, 1, 5],\n",
    "        'lambda_l1': [0.0, 0.1, 1.0],\n",
    "        'lambda_l2': [0.0, 0.1, 1.0],\n",
    "        'scale_pos_weight': [1.0, 5.0, 8.0]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*param_space.items())\n",
    "    all_combinations = [dict(zip(keys, v)) for v in product(*values)]\n",
    "    sampled_params = random.sample(all_combinations, min(n_iter, len(all_combinations)))\n",
    "\n",
    "    best_pr_auc = -np.inf\n",
    "    best_config = None\n",
    "    best_oof_preds = None\n",
    "    all_results = []\n",
    "\n",
    "    for i, params in enumerate(sampled_params):\n",
    "        print(f\"\\nTrial {i+1}/{len(sampled_params)}: {params}\")\n",
    "        params.update({\n",
    "            'objective': 'binary',\n",
    "            'metric': 'average_precision',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'seed': 42\n",
    "        })\n",
    "\n",
    "        fold_pr_aucs = []\n",
    "        fold_accs = []\n",
    "        oof_preds = np.zeros(len(df))\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(walk_forward_splits(df, n_splits=n_splits)):\n",
    "            train_data = df.iloc[train_idx]\n",
    "            val_data = df.iloc[val_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_data[features], label=train_data[target], categorical_feature=categorical_features)\n",
    "            lgb_val = lgb.Dataset(val_data[features], label=val_data[target], categorical_feature=categorical_features)\n",
    "\n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                lgb_train,\n",
    "                valid_sets=[lgb_train, lgb_val],\n",
    "                num_boost_round=500,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=25)],\n",
    "            )\n",
    "\n",
    "            preds_proba = model.predict(val_data[features])\n",
    "            preds_binary = (preds_proba > 0.5).astype(int)\n",
    "\n",
    "            oof_preds[val_idx] = preds_proba\n",
    "            pr_auc_score_val = average_precision_score(val_data[target], preds_proba)\n",
    "            acc_score = accuracy_score(val_data[target], preds_binary)\n",
    "\n",
    "            fold_pr_aucs.append(pr_auc_score_val)\n",
    "            fold_accs.append(acc_score)\n",
    "\n",
    "        avg_pr_auc = np.mean(fold_pr_aucs)\n",
    "        avg_acc = np.mean(fold_accs)\n",
    "        all_results.append({'trial': i+1, 'params': params.copy(), 'avg_pr_auc': avg_pr_auc, 'avg_acc': avg_acc})\n",
    "        print(f\"Avg PR-AUC: {avg_pr_auc:.4f} | Avg Accuracy: {avg_acc:.4f}\")\n",
    "\n",
    "        if avg_pr_auc > best_pr_auc:\n",
    "            best_pr_auc = avg_pr_auc\n",
    "            best_config = params.copy()\n",
    "            best_acc = avg_acc\n",
    "            best_oof_preds = oof_preds.copy()\n",
    "\n",
    "    # Retrain best model on full dataset\n",
    "    lgb_train_full = lgb.Dataset(df[features], label=df[target], categorical_feature=categorical_features)\n",
    "    best_model = lgb.train(\n",
    "        best_config,\n",
    "        lgb_train_full,\n",
    "        num_boost_round=500\n",
    "    )\n",
    "\n",
    "    print(f\"\\nBest Config: PR-AUC: {best_pr_auc:.4f} | Accuracy: {best_acc:.4f} | params_config {best_config} \")\n",
    "    return pd.DataFrame(all_results), best_config, best_model, best_oof_preds\n",
    "\n",
    "def plot_pr_curve_from_oof(oof_preds, y_true):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, oof_preds)\n",
    "    pr_auc = average_precision_score(y_true, oof_preds)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(recall, precision, color='blue', lw=2, label=f'PR-AUC = {pr_auc:.4f}')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Cross-Validation Precision-Recall Curve')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3592c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll count forward, resetting when the regime changes\n",
    "consecutive_days = []\n",
    "count = 0\n",
    "prev = None\n",
    "for val in final_df['prev_regime']:\n",
    "    if val == prev:\n",
    "        count += 1\n",
    "    else:\n",
    "        count = 1  # start counting again\n",
    "    consecutive_days.append(count)\n",
    "    prev = val\n",
    "\n",
    "final_df['consec_days_current_regime'] = consecutive_days\n",
    "\n",
    "# Last previous regime different from current\n",
    "last_diff_regime = []\n",
    "for i, curr_regime in enumerate(final_df['prev_regime']):\n",
    "    found = np.nan # if no prev regime\n",
    "    for j in range(i-1, -1, -1):\n",
    "        if final_df['prev_regime'].iloc[j] != curr_regime:\n",
    "            found = final_df['prev_regime'].iloc[j]\n",
    "            break\n",
    "    last_diff_regime.append(found)\n",
    "\n",
    "final_df['last_prev_regime_different'] = last_diff_regime\n",
    "\n",
    "# Days since last occurrence for each regime\n",
    "for regime_type in range(5):\n",
    "    col_name = f\"days_since_regime_{regime_type}\"\n",
    "    mask = final_df['prev_regime'] == regime_type\n",
    "    \n",
    "    last_seen_idx = None\n",
    "    days_since = []\n",
    "    \n",
    "    for i, val in enumerate(final_df['prev_regime']):\n",
    "        if val == regime_type:\n",
    "            last_seen_idx = i\n",
    "            days_since.append(0)\n",
    "        else:\n",
    "            if last_seen_idx is None:\n",
    "                days_since.append(np.nan)  # NaN for never seen\n",
    "            else:\n",
    "                days_since.append(i - last_seen_idx)\n",
    "    \n",
    "    final_df[col_name] = days_since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25a28dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.dropna(inplace=True) # drop nan rows that generated with these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d282c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ternatively, label encode if your model can handle categories natively (e.g., LightGBM, CatBoost).\n",
    "#  XGBoost can handle label-encoded categorical features, but only if you use its newer categorical feature support (introduced around v1.5+).\n",
    "# final_df['strategy'] = final_df['strategy'].astype('category')\n",
    "# final_df['regime'] = final_df['regime'].astype('category')\n",
    "\n",
    "# only for Lightgbm or catboost (maybe xgboost also)\n",
    "# Categorical columns\n",
    "categ_feats = ['symbol', 'strategy', 'prev_regime', 'last_prev_regime_different']\n",
    "\n",
    "for feat in categ_feats:\n",
    "    final_df[feat] = final_df[feat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c26f5be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['symbol', 'vol_5d', 'vol_10d', 'price_div_sma5', 'price_div_sma10',\n",
       "       'price_div_sma20', 'range_pct', 'atr_7', 'atr_14', 'strategy', 'signal',\n",
       "       'strat_return', 'prev_regime', 'consec_days_current_regime',\n",
       "       'last_prev_regime_different', 'days_since_regime_0',\n",
       "       'days_since_regime_1', 'days_since_regime_2', 'days_since_regime_3',\n",
       "       'days_since_regime_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aeb760b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 1/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.590251\tvalid_1's average_precision: 0.38295\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.548949\tvalid_1's average_precision: 0.414107\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.643467\tvalid_1's average_precision: 0.399044\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.567588\tvalid_1's average_precision: 0.356174\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.574341\tvalid_1's average_precision: 0.460364\n",
      "Avg PR-AUC: 0.4025 | Avg Accuracy: 0.6667\n",
      "\n",
      "Trial 2/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.514302\tvalid_1's average_precision: 0.376557\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.492398\tvalid_1's average_precision: 0.408692\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's average_precision: 0.628971\tvalid_1's average_precision: 0.403828\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.464639\tvalid_1's average_precision: 0.349214\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.518575\tvalid_1's average_precision: 0.45273\n",
      "Avg PR-AUC: 0.3982 | Avg Accuracy: 0.6666\n",
      "\n",
      "Trial 3/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.554239\tvalid_1's average_precision: 0.389965\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.431784\tvalid_1's average_precision: 0.414937\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.476057\tvalid_1's average_precision: 0.390283\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.454682\tvalid_1's average_precision: 0.421786\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.499216\tvalid_1's average_precision: 0.468805\n",
      "Avg PR-AUC: 0.4172 | Avg Accuracy: 0.6672\n",
      "\n",
      "Trial 4/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.537401\tvalid_1's average_precision: 0.383807\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.67886\tvalid_1's average_precision: 0.433749\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.582963\tvalid_1's average_precision: 0.395891\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.647429\tvalid_1's average_precision: 0.363187\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.536466\tvalid_1's average_precision: 0.454763\n",
      "Avg PR-AUC: 0.4063 | Avg Accuracy: 0.4565\n",
      "\n",
      "Trial 5/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.557396\tvalid_1's average_precision: 0.403575\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.593826\tvalid_1's average_precision: 0.422164\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.594264\tvalid_1's average_precision: 0.399016\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.478444\tvalid_1's average_precision: 0.409242\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.527389\tvalid_1's average_precision: 0.45348\n",
      "Avg PR-AUC: 0.4175 | Avg Accuracy: 0.3928\n",
      "\n",
      "Trial 6/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.421439\tvalid_1's average_precision: 0.380196\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.387507\tvalid_1's average_precision: 0.393585\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.415645\tvalid_1's average_precision: 0.38142\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.420638\tvalid_1's average_precision: 0.405047\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttraining's average_precision: 0.424895\tvalid_1's average_precision: 0.437562\n",
      "Avg PR-AUC: 0.3996 | Avg Accuracy: 0.5631\n",
      "\n",
      "Trial 7/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.517616\tvalid_1's average_precision: 0.407956\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.495033\tvalid_1's average_precision: 0.432478\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's average_precision: 0.632478\tvalid_1's average_precision: 0.4039\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.423212\tvalid_1's average_precision: 0.392762\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.488226\tvalid_1's average_precision: 0.459453\n",
      "Avg PR-AUC: 0.4193 | Avg Accuracy: 0.6657\n",
      "\n",
      "Trial 8/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.536606\tvalid_1's average_precision: 0.388632\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.434163\tvalid_1's average_precision: 0.414297\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's average_precision: 0.625324\tvalid_1's average_precision: 0.414269\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.536257\tvalid_1's average_precision: 0.365058\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.500811\tvalid_1's average_precision: 0.44728\n",
      "Avg PR-AUC: 0.4059 | Avg Accuracy: 0.5999\n",
      "\n",
      "Trial 9/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.600213\tvalid_1's average_precision: 0.390078\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.637585\tvalid_1's average_precision: 0.430436\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.565133\tvalid_1's average_precision: 0.410066\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004175 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.515714\tvalid_1's average_precision: 0.406813\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.544271\tvalid_1's average_precision: 0.455587\n",
      "Avg PR-AUC: 0.4186 | Avg Accuracy: 0.3753\n",
      "\n",
      "Trial 10/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.521073\tvalid_1's average_precision: 0.399006\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.3606\tvalid_1's average_precision: 0.411542\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.481182\tvalid_1's average_precision: 0.401419\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.436252\tvalid_1's average_precision: 0.416819\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.434942\tvalid_1's average_precision: 0.453733\n",
      "Avg PR-AUC: 0.4165 | Avg Accuracy: 0.4111\n",
      "\n",
      "Trial 11/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.595704\tvalid_1's average_precision: 0.393034\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.634885\tvalid_1's average_precision: 0.436893\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.631863\tvalid_1's average_precision: 0.393815\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.568621\tvalid_1's average_precision: 0.342366\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.524635\tvalid_1's average_precision: 0.463528\n",
      "Avg PR-AUC: 0.4059 | Avg Accuracy: 0.6594\n",
      "\n",
      "Trial 12/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.498098\tvalid_1's average_precision: 0.394069\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.482573\tvalid_1's average_precision: 0.418791\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.52558\tvalid_1's average_precision: 0.40111\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.502923\tvalid_1's average_precision: 0.392463\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.503195\tvalid_1's average_precision: 0.46702\n",
      "Avg PR-AUC: 0.4147 | Avg Accuracy: 0.3699\n",
      "\n",
      "Trial 13/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.642902\tvalid_1's average_precision: 0.392567\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.582741\tvalid_1's average_precision: 0.436356\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.480429\tvalid_1's average_precision: 0.396989\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.484099\tvalid_1's average_precision: 0.396187\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.4814\tvalid_1's average_precision: 0.460302\n",
      "Avg PR-AUC: 0.4165 | Avg Accuracy: 0.3781\n",
      "\n",
      "Trial 14/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.431549\tvalid_1's average_precision: 0.389469\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.438412\tvalid_1's average_precision: 0.413911\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's average_precision: 0.449986\tvalid_1's average_precision: 0.397231\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.426787\tvalid_1's average_precision: 0.426969\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.424207\tvalid_1's average_precision: 0.448949\n",
      "Avg PR-AUC: 0.4153 | Avg Accuracy: 0.5994\n",
      "\n",
      "Trial 15/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.42813\tvalid_1's average_precision: 0.386104\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's average_precision: 0.45915\tvalid_1's average_precision: 0.41725\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.42633\tvalid_1's average_precision: 0.383471\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.425685\tvalid_1's average_precision: 0.40377\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's average_precision: 0.441805\tvalid_1's average_precision: 0.4489\n",
      "Avg PR-AUC: 0.4079 | Avg Accuracy: 0.5335\n",
      "\n",
      "Trial 16/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.475264\tvalid_1's average_precision: 0.386801\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.447074\tvalid_1's average_precision: 0.413139\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's average_precision: 0.492533\tvalid_1's average_precision: 0.39689\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.451325\tvalid_1's average_precision: 0.408669\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.462645\tvalid_1's average_precision: 0.448068\n",
      "Avg PR-AUC: 0.4107 | Avg Accuracy: 0.5558\n",
      "\n",
      "Trial 17/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.650946\tvalid_1's average_precision: 0.391373\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.532259\tvalid_1's average_precision: 0.436675\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.562268\tvalid_1's average_precision: 0.413817\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.541683\tvalid_1's average_precision: 0.391345\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.508969\tvalid_1's average_precision: 0.456289\n",
      "Avg PR-AUC: 0.4179 | Avg Accuracy: 0.6661\n",
      "\n",
      "Trial 18/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.537231\tvalid_1's average_precision: 0.386702\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.600189\tvalid_1's average_precision: 0.423607\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.505686\tvalid_1's average_precision: 0.39996\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.509995\tvalid_1's average_precision: 0.417955\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.505137\tvalid_1's average_precision: 0.470403\n",
      "Avg PR-AUC: 0.4197 | Avg Accuracy: 0.3843\n",
      "\n",
      "Trial 19/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's average_precision: 0.448586\tvalid_1's average_precision: 0.39326\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's average_precision: 0.432383\tvalid_1's average_precision: 0.404752\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.421573\tvalid_1's average_precision: 0.382219\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's average_precision: 0.422728\tvalid_1's average_precision: 0.410969\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's average_precision: 0.422047\tvalid_1's average_precision: 0.437576\n",
      "Avg PR-AUC: 0.4058 | Avg Accuracy: 0.4009\n",
      "\n",
      "Trial 20/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.617825\tvalid_1's average_precision: 0.399511\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.580784\tvalid_1's average_precision: 0.437762\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003926 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.623483\tvalid_1's average_precision: 0.394396\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.450731\tvalid_1's average_precision: 0.401861\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.515949\tvalid_1's average_precision: 0.463294\n",
      "Avg PR-AUC: 0.4194 | Avg Accuracy: 0.3532\n",
      "\n",
      "Trial 21/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.617139\tvalid_1's average_precision: 0.40644\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.434978\tvalid_1's average_precision: 0.416904\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.571664\tvalid_1's average_precision: 0.386911\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.487903\tvalid_1's average_precision: 0.405738\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.516258\tvalid_1's average_precision: 0.46483\n",
      "Avg PR-AUC: 0.4162 | Avg Accuracy: 0.4184\n",
      "\n",
      "Trial 22/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.60742\tvalid_1's average_precision: 0.394551\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.436216\tvalid_1's average_precision: 0.417892\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.493443\tvalid_1's average_precision: 0.398861\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.490024\tvalid_1's average_precision: 0.404766\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.523664\tvalid_1's average_precision: 0.457271\n",
      "Avg PR-AUC: 0.4147 | Avg Accuracy: 0.3446\n",
      "\n",
      "Trial 23/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.453884\tvalid_1's average_precision: 0.381403\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.520418\tvalid_1's average_precision: 0.419388\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.514066\tvalid_1's average_precision: 0.391325\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.458148\tvalid_1's average_precision: 0.391789\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.478991\tvalid_1's average_precision: 0.452962\n",
      "Avg PR-AUC: 0.4074 | Avg Accuracy: 0.3870\n",
      "\n",
      "Trial 24/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.44437\tvalid_1's average_precision: 0.395075\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.568268\tvalid_1's average_precision: 0.432814\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.45807\tvalid_1's average_precision: 0.389705\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.436737\tvalid_1's average_precision: 0.406035\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.449586\tvalid_1's average_precision: 0.460677\n",
      "Avg PR-AUC: 0.4169 | Avg Accuracy: 0.3618\n",
      "\n",
      "Trial 25/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.650263\tvalid_1's average_precision: 0.394438\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.56162\tvalid_1's average_precision: 0.419439\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.576552\tvalid_1's average_precision: 0.401838\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.492024\tvalid_1's average_precision: 0.404187\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's average_precision: 0.595483\tvalid_1's average_precision: 0.453327\n",
      "Avg PR-AUC: 0.4146 | Avg Accuracy: 0.3949\n",
      "\n",
      "Trial 26/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.695237\tvalid_1's average_precision: 0.389577\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.454876\tvalid_1's average_precision: 0.42946\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.495634\tvalid_1's average_precision: 0.384492\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.578947\tvalid_1's average_precision: 0.379058\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.593764\tvalid_1's average_precision: 0.444962\n",
      "Avg PR-AUC: 0.4055 | Avg Accuracy: 0.4427\n",
      "\n",
      "Trial 27/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.498932\tvalid_1's average_precision: 0.383776\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.44535\tvalid_1's average_precision: 0.415681\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.483867\tvalid_1's average_precision: 0.393765\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.437156\tvalid_1's average_precision: 0.353517\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.473551\tvalid_1's average_precision: 0.456125\n",
      "Avg PR-AUC: 0.4006 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 28/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.484481\tvalid_1's average_precision: 0.397871\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.461732\tvalid_1's average_precision: 0.421477\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.45199\tvalid_1's average_precision: 0.396081\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.488676\tvalid_1's average_precision: 0.427687\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.469472\tvalid_1's average_precision: 0.45583\n",
      "Avg PR-AUC: 0.4198 | Avg Accuracy: 0.6358\n",
      "\n",
      "Trial 29/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.599959\tvalid_1's average_precision: 0.390073\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.695906\tvalid_1's average_precision: 0.418616\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.587095\tvalid_1's average_precision: 0.389293\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.51229\tvalid_1's average_precision: 0.349244\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.523901\tvalid_1's average_precision: 0.458056\n",
      "Avg PR-AUC: 0.4011 | Avg Accuracy: 0.6577\n",
      "\n",
      "Trial 30/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.528562\tvalid_1's average_precision: 0.387769\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.476311\tvalid_1's average_precision: 0.437043\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.52213\tvalid_1's average_precision: 0.406866\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.507065\tvalid_1's average_precision: 0.368355\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.472403\tvalid_1's average_precision: 0.449852\n",
      "Avg PR-AUC: 0.4100 | Avg Accuracy: 0.6668\n",
      "\n",
      "Trial 31/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.574092\tvalid_1's average_precision: 0.384776\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.496277\tvalid_1's average_precision: 0.418536\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.537453\tvalid_1's average_precision: 0.398193\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000937 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.540561\tvalid_1's average_precision: 0.427806\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's average_precision: 0.538613\tvalid_1's average_precision: 0.459157\n",
      "Avg PR-AUC: 0.4177 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 32/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.58118\tvalid_1's average_precision: 0.403589\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.444478\tvalid_1's average_precision: 0.422497\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.509982\tvalid_1's average_precision: 0.394574\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000972 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.433314\tvalid_1's average_precision: 0.411526\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.446716\tvalid_1's average_precision: 0.457668\n",
      "Avg PR-AUC: 0.4180 | Avg Accuracy: 0.3470\n",
      "\n",
      "Trial 33/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.621378\tvalid_1's average_precision: 0.388402\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.425339\tvalid_1's average_precision: 0.410103\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's average_precision: 0.684698\tvalid_1's average_precision: 0.418901\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.521543\tvalid_1's average_precision: 0.366986\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.610365\tvalid_1's average_precision: 0.453841\n",
      "Avg PR-AUC: 0.4076 | Avg Accuracy: 0.6683\n",
      "\n",
      "Trial 34/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.513078\tvalid_1's average_precision: 0.385153\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.505056\tvalid_1's average_precision: 0.426709\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.476126\tvalid_1's average_precision: 0.40588\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.465162\tvalid_1's average_precision: 0.404352\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.489787\tvalid_1's average_precision: 0.462087\n",
      "Avg PR-AUC: 0.4168 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 35/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.53249\tvalid_1's average_precision: 0.387982\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.543237\tvalid_1's average_precision: 0.425074\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.509044\tvalid_1's average_precision: 0.391533\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.428373\tvalid_1's average_precision: 0.40561\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.488966\tvalid_1's average_precision: 0.446955\n",
      "Avg PR-AUC: 0.4114 | Avg Accuracy: 0.3486\n",
      "\n",
      "Trial 36/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.633089\tvalid_1's average_precision: 0.402626\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.482411\tvalid_1's average_precision: 0.423971\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.549631\tvalid_1's average_precision: 0.399849\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.442222\tvalid_1's average_precision: 0.402161\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.453637\tvalid_1's average_precision: 0.455513\n",
      "Avg PR-AUC: 0.4168 | Avg Accuracy: 0.4334\n",
      "\n",
      "Trial 37/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.585417\tvalid_1's average_precision: 0.395746\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.569139\tvalid_1's average_precision: 0.423268\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.658342\tvalid_1's average_precision: 0.403131\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.523767\tvalid_1's average_precision: 0.401752\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.583586\tvalid_1's average_precision: 0.458264\n",
      "Avg PR-AUC: 0.4164 | Avg Accuracy: 0.3853\n",
      "\n",
      "Trial 38/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.478583\tvalid_1's average_precision: 0.391766\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.520331\tvalid_1's average_precision: 0.416706\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.510285\tvalid_1's average_precision: 0.38952\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.453389\tvalid_1's average_precision: 0.415858\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's average_precision: 0.522686\tvalid_1's average_precision: 0.460241\n",
      "Avg PR-AUC: 0.4148 | Avg Accuracy: 0.3668\n",
      "\n",
      "Trial 39/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.716402\tvalid_1's average_precision: 0.391429\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.52931\tvalid_1's average_precision: 0.418771\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.50046\tvalid_1's average_precision: 0.393876\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.546629\tvalid_1's average_precision: 0.40841\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.463993\tvalid_1's average_precision: 0.45216\n",
      "Avg PR-AUC: 0.4129 | Avg Accuracy: 0.4458\n",
      "\n",
      "Trial 40/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.729199\tvalid_1's average_precision: 0.405047\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.541284\tvalid_1's average_precision: 0.435247\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.546556\tvalid_1's average_precision: 0.390306\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.541124\tvalid_1's average_precision: 0.4157\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.472787\tvalid_1's average_precision: 0.44881\n",
      "Avg PR-AUC: 0.4190 | Avg Accuracy: 0.3589\n",
      "\n",
      "Trial 41/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.636602\tvalid_1's average_precision: 0.393733\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.554378\tvalid_1's average_precision: 0.428354\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.477478\tvalid_1's average_precision: 0.405501\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.487139\tvalid_1's average_precision: 0.411575\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.500852\tvalid_1's average_precision: 0.460461\n",
      "Avg PR-AUC: 0.4199 | Avg Accuracy: 0.3554\n",
      "\n",
      "Trial 42/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.689402\tvalid_1's average_precision: 0.388406\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.548479\tvalid_1's average_precision: 0.416345\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.65634\tvalid_1's average_precision: 0.396523\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.599746\tvalid_1's average_precision: 0.3418\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.573835\tvalid_1's average_precision: 0.46031\n",
      "Avg PR-AUC: 0.4007 | Avg Accuracy: 0.6625\n",
      "\n",
      "Trial 43/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.832284\tvalid_1's average_precision: 0.377181\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.583287\tvalid_1's average_precision: 0.417283\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.685187\tvalid_1's average_precision: 0.396142\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.640894\tvalid_1's average_precision: 0.397309\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.595324\tvalid_1's average_precision: 0.437214\n",
      "Avg PR-AUC: 0.4050 | Avg Accuracy: 0.6649\n",
      "\n",
      "Trial 44/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.658135\tvalid_1's average_precision: 0.376516\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.56538\tvalid_1's average_precision: 0.420798\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's average_precision: 0.719262\tvalid_1's average_precision: 0.400559\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.541865\tvalid_1's average_precision: 0.346375\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001828 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.572793\tvalid_1's average_precision: 0.446596\n",
      "Avg PR-AUC: 0.3982 | Avg Accuracy: 0.6670\n",
      "\n",
      "Trial 45/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's average_precision: 0.534716\tvalid_1's average_precision: 0.390199\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.42154\tvalid_1's average_precision: 0.400551\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.482931\tvalid_1's average_precision: 0.392398\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's average_precision: 0.537518\tvalid_1's average_precision: 0.397073\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's average_precision: 0.501311\tvalid_1's average_precision: 0.459069\n",
      "Avg PR-AUC: 0.4079 | Avg Accuracy: 0.5117\n",
      "\n",
      "Trial 46/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.588915\tvalid_1's average_precision: 0.392764\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.556958\tvalid_1's average_precision: 0.426233\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.532355\tvalid_1's average_precision: 0.397838\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.49864\tvalid_1's average_precision: 0.431829\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.539259\tvalid_1's average_precision: 0.463379\n",
      "Avg PR-AUC: 0.4224 | Avg Accuracy: 0.3498\n",
      "\n",
      "Trial 47/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's average_precision: 0.89041\tvalid_1's average_precision: 0.390184\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.766839\tvalid_1's average_precision: 0.44208\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.656497\tvalid_1's average_precision: 0.399072\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.497489\tvalid_1's average_precision: 0.39111\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.517243\tvalid_1's average_precision: 0.436711\n",
      "Avg PR-AUC: 0.4118 | Avg Accuracy: 0.4487\n",
      "\n",
      "Trial 48/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's average_precision: 0.556579\tvalid_1's average_precision: 0.384593\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.559834\tvalid_1's average_precision: 0.421883\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's average_precision: 0.576624\tvalid_1's average_precision: 0.410503\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's average_precision: 0.571192\tvalid_1's average_precision: 0.349846\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's average_precision: 0.54277\tvalid_1's average_precision: 0.45251\n",
      "Avg PR-AUC: 0.4039 | Avg Accuracy: 0.4892\n",
      "\n",
      "Trial 49/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.528562\tvalid_1's average_precision: 0.387769\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.476311\tvalid_1's average_precision: 0.437043\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.52213\tvalid_1's average_precision: 0.406866\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.507065\tvalid_1's average_precision: 0.368355\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.472403\tvalid_1's average_precision: 0.449852\n",
      "Avg PR-AUC: 0.4100 | Avg Accuracy: 0.6668\n",
      "\n",
      "Trial 50/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.639553\tvalid_1's average_precision: 0.387946\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.733979\tvalid_1's average_precision: 0.45532\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.533919\tvalid_1's average_precision: 0.392864\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.496873\tvalid_1's average_precision: 0.404614\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.541911\tvalid_1's average_precision: 0.440022\n",
      "Avg PR-AUC: 0.4162 | Avg Accuracy: 0.3881\n",
      "\n",
      "Trial 51/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.520311\tvalid_1's average_precision: 0.389795\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.544785\tvalid_1's average_precision: 0.423296\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.492104\tvalid_1's average_precision: 0.383445\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.521132\tvalid_1's average_precision: 0.418731\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's average_precision: 0.543091\tvalid_1's average_precision: 0.465558\n",
      "Avg PR-AUC: 0.4162 | Avg Accuracy: 0.6188\n",
      "\n",
      "Trial 52/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.680336\tvalid_1's average_precision: 0.406982\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's average_precision: 0.773039\tvalid_1's average_precision: 0.432766\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.622125\tvalid_1's average_precision: 0.390866\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.59725\tvalid_1's average_precision: 0.41503\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.548565\tvalid_1's average_precision: 0.447193\n",
      "Avg PR-AUC: 0.4186 | Avg Accuracy: 0.4181\n",
      "\n",
      "Trial 53/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.4459\tvalid_1's average_precision: 0.381108\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.402532\tvalid_1's average_precision: 0.398555\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.439305\tvalid_1's average_precision: 0.383012\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.432145\tvalid_1's average_precision: 0.39738\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's average_precision: 0.462171\tvalid_1's average_precision: 0.438329\n",
      "Avg PR-AUC: 0.3997 | Avg Accuracy: 0.5498\n",
      "\n",
      "Trial 54/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.637874\tvalid_1's average_precision: 0.390662\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.440609\tvalid_1's average_precision: 0.418917\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.604967\tvalid_1's average_precision: 0.388768\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.519242\tvalid_1's average_precision: 0.346257\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.569584\tvalid_1's average_precision: 0.449124\n",
      "Avg PR-AUC: 0.3987 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 55/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.772664\tvalid_1's average_precision: 0.369681\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.675648\tvalid_1's average_precision: 0.423434\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.628246\tvalid_1's average_precision: 0.385301\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.569904\tvalid_1's average_precision: 0.403591\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.652841\tvalid_1's average_precision: 0.44903\n",
      "Avg PR-AUC: 0.4062 | Avg Accuracy: 0.6667\n",
      "\n",
      "Trial 56/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.476756\tvalid_1's average_precision: 0.388025\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.447875\tvalid_1's average_precision: 0.413779\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.474816\tvalid_1's average_precision: 0.393719\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's average_precision: 0.487804\tvalid_1's average_precision: 0.409278\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's average_precision: 0.468899\tvalid_1's average_precision: 0.446991\n",
      "Avg PR-AUC: 0.4104 | Avg Accuracy: 0.5261\n",
      "\n",
      "Trial 57/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.437461\tvalid_1's average_precision: 0.390009\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.470437\tvalid_1's average_precision: 0.414163\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.444252\tvalid_1's average_precision: 0.393577\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.430802\tvalid_1's average_precision: 0.411329\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.479817\tvalid_1's average_precision: 0.464863\n",
      "Avg PR-AUC: 0.4148 | Avg Accuracy: 0.3551\n",
      "\n",
      "Trial 58/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.556599\tvalid_1's average_precision: 0.394464\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.525151\tvalid_1's average_precision: 0.413666\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.500712\tvalid_1's average_precision: 0.392128\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.427345\tvalid_1's average_precision: 0.403248\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.513692\tvalid_1's average_precision: 0.441784\n",
      "Avg PR-AUC: 0.4091 | Avg Accuracy: 0.3804\n",
      "\n",
      "Trial 59/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.616892\tvalid_1's average_precision: 0.399522\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.653046\tvalid_1's average_precision: 0.437703\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.590125\tvalid_1's average_precision: 0.401159\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.749415\tvalid_1's average_precision: 0.34897\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.543456\tvalid_1's average_precision: 0.439363\n",
      "Avg PR-AUC: 0.4053 | Avg Accuracy: 0.4277\n",
      "\n",
      "Trial 60/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.635631\tvalid_1's average_precision: 0.393483\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.570119\tvalid_1's average_precision: 0.427465\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.579111\tvalid_1's average_precision: 0.398219\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.474864\tvalid_1's average_precision: 0.388432\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's average_precision: 0.581699\tvalid_1's average_precision: 0.449982\n",
      "Avg PR-AUC: 0.4115 | Avg Accuracy: 0.3933\n",
      "\n",
      "Trial 61/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.577128\tvalid_1's average_precision: 0.390492\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.507846\tvalid_1's average_precision: 0.426258\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.56908\tvalid_1's average_precision: 0.413321\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.505736\tvalid_1's average_precision: 0.392691\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.549545\tvalid_1's average_precision: 0.457208\n",
      "Avg PR-AUC: 0.4160 | Avg Accuracy: 0.6681\n",
      "\n",
      "Trial 62/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.599454\tvalid_1's average_precision: 0.38727\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.623026\tvalid_1's average_precision: 0.429046\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.541236\tvalid_1's average_precision: 0.408101\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.483751\tvalid_1's average_precision: 0.404156\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.503225\tvalid_1's average_precision: 0.451635\n",
      "Avg PR-AUC: 0.4160 | Avg Accuracy: 0.3910\n",
      "\n",
      "Trial 63/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.560227\tvalid_1's average_precision: 0.388009\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.47991\tvalid_1's average_precision: 0.421684\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.577809\tvalid_1's average_precision: 0.408336\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.394118\tvalid_1's average_precision: 0.359227\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.530785\tvalid_1's average_precision: 0.454142\n",
      "Avg PR-AUC: 0.4063 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 64/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.573352\tvalid_1's average_precision: 0.391053\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.642718\tvalid_1's average_precision: 0.43712\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.593792\tvalid_1's average_precision: 0.393881\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.527585\tvalid_1's average_precision: 0.39128\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.556962\tvalid_1's average_precision: 0.447073\n",
      "Avg PR-AUC: 0.4121 | Avg Accuracy: 0.4805\n",
      "\n",
      "Trial 65/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.442531\tvalid_1's average_precision: 0.392948\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.436563\tvalid_1's average_precision: 0.424585\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's average_precision: 0.440666\tvalid_1's average_precision: 0.400625\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's average_precision: 0.444514\tvalid_1's average_precision: 0.422142\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's average_precision: 0.458591\tvalid_1's average_precision: 0.46427\n",
      "Avg PR-AUC: 0.4209 | Avg Accuracy: 0.5140\n",
      "\n",
      "Trial 66/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.526723\tvalid_1's average_precision: 0.384076\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.503198\tvalid_1's average_precision: 0.409409\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.494789\tvalid_1's average_precision: 0.389531\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.489377\tvalid_1's average_precision: 0.42859\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's average_precision: 0.490365\tvalid_1's average_precision: 0.464817\n",
      "Avg PR-AUC: 0.4153 | Avg Accuracy: 0.6203\n",
      "\n",
      "Trial 67/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.722855\tvalid_1's average_precision: 0.359884\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.625947\tvalid_1's average_precision: 0.421692\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.676693\tvalid_1's average_precision: 0.391858\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.712317\tvalid_1's average_precision: 0.353358\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001801 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.617005\tvalid_1's average_precision: 0.441106\n",
      "Avg PR-AUC: 0.3936 | Avg Accuracy: 0.6621\n",
      "\n",
      "Trial 68/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.530821\tvalid_1's average_precision: 0.389503\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.495162\tvalid_1's average_precision: 0.408066\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.484962\tvalid_1's average_precision: 0.369951\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.472917\tvalid_1's average_precision: 0.351422\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.516224\tvalid_1's average_precision: 0.45591\n",
      "Avg PR-AUC: 0.3950 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 69/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.428372\tvalid_1's average_precision: 0.390138\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.424306\tvalid_1's average_precision: 0.413275\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's average_precision: 0.437637\tvalid_1's average_precision: 0.391292\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's average_precision: 0.428145\tvalid_1's average_precision: 0.416571\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's average_precision: 0.435734\tvalid_1's average_precision: 0.45508\n",
      "Avg PR-AUC: 0.4133 | Avg Accuracy: 0.4771\n",
      "\n",
      "Trial 70/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.49375\tvalid_1's average_precision: 0.394501\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.481836\tvalid_1's average_precision: 0.407978\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.465899\tvalid_1's average_precision: 0.394437\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.432889\tvalid_1's average_precision: 0.408174\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.485676\tvalid_1's average_precision: 0.449482\n",
      "Avg PR-AUC: 0.4109 | Avg Accuracy: 0.3545\n",
      "\n",
      "Trial 71/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.610687\tvalid_1's average_precision: 0.394524\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's average_precision: 0.663161\tvalid_1's average_precision: 0.427132\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.491157\tvalid_1's average_precision: 0.400329\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.482167\tvalid_1's average_precision: 0.399737\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.461923\tvalid_1's average_precision: 0.448379\n",
      "Avg PR-AUC: 0.4140 | Avg Accuracy: 0.4053\n",
      "\n",
      "Trial 72/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.597563\tvalid_1's average_precision: 0.400489\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.516012\tvalid_1's average_precision: 0.421107\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.477621\tvalid_1's average_precision: 0.399495\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.52907\tvalid_1's average_precision: 0.408032\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.534568\tvalid_1's average_precision: 0.455214\n",
      "Avg PR-AUC: 0.4169 | Avg Accuracy: 0.4400\n",
      "\n",
      "Trial 73/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.456763\tvalid_1's average_precision: 0.398598\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.447875\tvalid_1's average_precision: 0.410731\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.516151\tvalid_1's average_precision: 0.386748\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.42159\tvalid_1's average_precision: 0.397474\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.480917\tvalid_1's average_precision: 0.453341\n",
      "Avg PR-AUC: 0.4094 | Avg Accuracy: 0.3500\n",
      "\n",
      "Trial 74/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.671207\tvalid_1's average_precision: 0.394817\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.584811\tvalid_1's average_precision: 0.423219\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.592066\tvalid_1's average_precision: 0.409875\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.56289\tvalid_1's average_precision: 0.354404\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.54227\tvalid_1's average_precision: 0.448884\n",
      "Avg PR-AUC: 0.4062 | Avg Accuracy: 0.4403\n",
      "\n",
      "Trial 75/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.446135\tvalid_1's average_precision: 0.394678\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.456482\tvalid_1's average_precision: 0.41854\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.458003\tvalid_1's average_precision: 0.388656\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.458506\tvalid_1's average_precision: 0.420336\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.461568\tvalid_1's average_precision: 0.458055\n",
      "Avg PR-AUC: 0.4161 | Avg Accuracy: 0.3666\n",
      "\n",
      "Trial 76/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.539013\tvalid_1's average_precision: 0.385638\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.565236\tvalid_1's average_precision: 0.420694\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.595668\tvalid_1's average_precision: 0.397204\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.594175\tvalid_1's average_precision: 0.35629\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.50814\tvalid_1's average_precision: 0.450187\n",
      "Avg PR-AUC: 0.4020 | Avg Accuracy: 0.4538\n",
      "\n",
      "Trial 77/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.44529\tvalid_1's average_precision: 0.389121\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.43126\tvalid_1's average_precision: 0.419196\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's average_precision: 0.502598\tvalid_1's average_precision: 0.395857\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.475146\tvalid_1's average_precision: 0.421673\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.440773\tvalid_1's average_precision: 0.459851\n",
      "Avg PR-AUC: 0.4171 | Avg Accuracy: 0.4048\n",
      "\n",
      "Trial 78/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.495427\tvalid_1's average_precision: 0.384041\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.483266\tvalid_1's average_precision: 0.420503\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.55977\tvalid_1's average_precision: 0.401894\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.518076\tvalid_1's average_precision: 0.383703\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's average_precision: 0.57426\tvalid_1's average_precision: 0.460914\n",
      "Avg PR-AUC: 0.4102 | Avg Accuracy: 0.6690\n",
      "\n",
      "Trial 79/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.712553\tvalid_1's average_precision: 0.374332\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.696078\tvalid_1's average_precision: 0.427304\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.625155\tvalid_1's average_precision: 0.374253\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.610517\tvalid_1's average_precision: 0.41257\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.635486\tvalid_1's average_precision: 0.440394\n",
      "Avg PR-AUC: 0.4058 | Avg Accuracy: 0.6660\n",
      "\n",
      "Trial 80/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.535925\tvalid_1's average_precision: 0.393691\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.552676\tvalid_1's average_precision: 0.43\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.532473\tvalid_1's average_precision: 0.407314\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.475352\tvalid_1's average_precision: 0.406914\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.467804\tvalid_1's average_precision: 0.450284\n",
      "Avg PR-AUC: 0.4176 | Avg Accuracy: 0.4101\n",
      "\n",
      "Trial 81/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's average_precision: 0.605541\tvalid_1's average_precision: 0.394929\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.507994\tvalid_1's average_precision: 0.4239\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's average_precision: 0.600761\tvalid_1's average_precision: 0.409034\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.519907\tvalid_1's average_precision: 0.394463\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.524173\tvalid_1's average_precision: 0.454109\n",
      "Avg PR-AUC: 0.4153 | Avg Accuracy: 0.5784\n",
      "\n",
      "Trial 82/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.516425\tvalid_1's average_precision: 0.38318\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.581651\tvalid_1's average_precision: 0.43778\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.532685\tvalid_1's average_precision: 0.410703\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.517936\tvalid_1's average_precision: 0.424096\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001837 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.501863\tvalid_1's average_precision: 0.463901\n",
      "Avg PR-AUC: 0.4239 | Avg Accuracy: 0.4180\n",
      "\n",
      "Trial 83/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.573418\tvalid_1's average_precision: 0.390949\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.623198\tvalid_1's average_precision: 0.428269\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.521662\tvalid_1's average_precision: 0.400394\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.493924\tvalid_1's average_precision: 0.419076\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.504549\tvalid_1's average_precision: 0.461057\n",
      "Avg PR-AUC: 0.4199 | Avg Accuracy: 0.3851\n",
      "\n",
      "Trial 84/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.412535\tvalid_1's average_precision: 0.382262\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's average_precision: 0.453172\tvalid_1's average_precision: 0.417857\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's average_precision: 0.439165\tvalid_1's average_precision: 0.386846\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.420441\tvalid_1's average_precision: 0.405609\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's average_precision: 0.423755\tvalid_1's average_precision: 0.439276\n",
      "Avg PR-AUC: 0.4064 | Avg Accuracy: 0.4413\n",
      "\n",
      "Trial 85/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.51545\tvalid_1's average_precision: 0.403266\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.578278\tvalid_1's average_precision: 0.427147\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.600982\tvalid_1's average_precision: 0.394664\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.45435\tvalid_1's average_precision: 0.40738\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.482241\tvalid_1's average_precision: 0.463909\n",
      "Avg PR-AUC: 0.4193 | Avg Accuracy: 0.4441\n",
      "\n",
      "Trial 86/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.464088\tvalid_1's average_precision: 0.387378\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001366 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's average_precision: 0.525656\tvalid_1's average_precision: 0.434613\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's average_precision: 0.484714\tvalid_1's average_precision: 0.386591\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's average_precision: 0.482929\tvalid_1's average_precision: 0.410906\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.458339\tvalid_1's average_precision: 0.456052\n",
      "Avg PR-AUC: 0.4151 | Avg Accuracy: 0.4301\n",
      "\n",
      "Trial 87/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.623276\tvalid_1's average_precision: 0.393526\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.539593\tvalid_1's average_precision: 0.426785\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.505787\tvalid_1's average_precision: 0.394136\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.48528\tvalid_1's average_precision: 0.413194\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.514628\tvalid_1's average_precision: 0.464151\n",
      "Avg PR-AUC: 0.4184 | Avg Accuracy: 0.3807\n",
      "\n",
      "Trial 88/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.578245\tvalid_1's average_precision: 0.389526\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.697436\tvalid_1's average_precision: 0.423496\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.54536\tvalid_1's average_precision: 0.39423\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.430421\tvalid_1's average_precision: 0.380253\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.481476\tvalid_1's average_precision: 0.450017\n",
      "Avg PR-AUC: 0.4075 | Avg Accuracy: 0.3743\n",
      "\n",
      "Trial 89/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.486743\tvalid_1's average_precision: 0.390881\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.494561\tvalid_1's average_precision: 0.412825\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.500712\tvalid_1's average_precision: 0.392128\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.427345\tvalid_1's average_precision: 0.403248\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.521952\tvalid_1's average_precision: 0.446805\n",
      "Avg PR-AUC: 0.4092 | Avg Accuracy: 0.3793\n",
      "\n",
      "Trial 90/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.498223\tvalid_1's average_precision: 0.388366\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's average_precision: 0.829567\tvalid_1's average_precision: 0.440868\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.49334\tvalid_1's average_precision: 0.400954\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.504217\tvalid_1's average_precision: 0.417645\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.474893\tvalid_1's average_precision: 0.449687\n",
      "Avg PR-AUC: 0.4195 | Avg Accuracy: 0.4142\n",
      "\n",
      "Trial 91/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.595293\tvalid_1's average_precision: 0.387448\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.529706\tvalid_1's average_precision: 0.410261\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.535524\tvalid_1's average_precision: 0.402461\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.544543\tvalid_1's average_precision: 0.400686\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.53749\tvalid_1's average_precision: 0.459936\n",
      "Avg PR-AUC: 0.4122 | Avg Accuracy: 0.6681\n",
      "\n",
      "Trial 92/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.609236\tvalid_1's average_precision: 0.383546\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's average_precision: 0.859621\tvalid_1's average_precision: 0.434231\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.727447\tvalid_1's average_precision: 0.406243\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.583243\tvalid_1's average_precision: 0.394239\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.618106\tvalid_1's average_precision: 0.445078\n",
      "Avg PR-AUC: 0.4127 | Avg Accuracy: 0.4066\n",
      "\n",
      "Trial 93/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.628617\tvalid_1's average_precision: 0.392933\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.587446\tvalid_1's average_precision: 0.41808\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.616601\tvalid_1's average_precision: 0.413789\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.520693\tvalid_1's average_precision: 0.366982\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.518648\tvalid_1's average_precision: 0.445914\n",
      "Avg PR-AUC: 0.4075 | Avg Accuracy: 0.4786\n",
      "\n",
      "Trial 94/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.520539\tvalid_1's average_precision: 0.3963\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.520166\tvalid_1's average_precision: 0.425746\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.503214\tvalid_1's average_precision: 0.401445\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.463612\tvalid_1's average_precision: 0.407845\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.496646\tvalid_1's average_precision: 0.46297\n",
      "Avg PR-AUC: 0.4189 | Avg Accuracy: 0.3967\n",
      "\n",
      "Trial 95/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.526713\tvalid_1's average_precision: 0.3904\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.509093\tvalid_1's average_precision: 0.431205\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.555262\tvalid_1's average_precision: 0.410433\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.491632\tvalid_1's average_precision: 0.426416\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.47814\tvalid_1's average_precision: 0.456967\n",
      "Avg PR-AUC: 0.4231 | Avg Accuracy: 0.5565\n",
      "\n",
      "Trial 96/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.494124\tvalid_1's average_precision: 0.387614\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.496639\tvalid_1's average_precision: 0.424846\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's average_precision: 0.550636\tvalid_1's average_precision: 0.398073\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.482732\tvalid_1's average_precision: 0.416917\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.490927\tvalid_1's average_precision: 0.463027\n",
      "Avg PR-AUC: 0.4181 | Avg Accuracy: 0.5650\n",
      "\n",
      "Trial 97/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.59326\tvalid_1's average_precision: 0.384785\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.49442\tvalid_1's average_precision: 0.404634\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's average_precision: 0.626901\tvalid_1's average_precision: 0.402464\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.478868\tvalid_1's average_precision: 0.356159\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.488577\tvalid_1's average_precision: 0.459432\n",
      "Avg PR-AUC: 0.4015 | Avg Accuracy: 0.6661\n",
      "\n",
      "Trial 98/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.580842\tvalid_1's average_precision: 0.377135\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.503667\tvalid_1's average_precision: 0.422901\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.628063\tvalid_1's average_precision: 0.422302\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.464193\tvalid_1's average_precision: 0.372897\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.573099\tvalid_1's average_precision: 0.456368\n",
      "Avg PR-AUC: 0.4103 | Avg Accuracy: 0.6684\n",
      "\n",
      "Trial 99/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.460549\tvalid_1's average_precision: 0.380019\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.455365\tvalid_1's average_precision: 0.400273\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's average_precision: 0.459269\tvalid_1's average_precision: 0.385704\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.446266\tvalid_1's average_precision: 0.403517\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's average_precision: 0.441035\tvalid_1's average_precision: 0.438614\n",
      "Avg PR-AUC: 0.4016 | Avg Accuracy: 0.5030\n",
      "\n",
      "Trial 100/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.561228\tvalid_1's average_precision: 0.389579\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.425339\tvalid_1's average_precision: 0.410103\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.509229\tvalid_1's average_precision: 0.40934\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.508331\tvalid_1's average_precision: 0.35679\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.491004\tvalid_1's average_precision: 0.451314\n",
      "Avg PR-AUC: 0.4034 | Avg Accuracy: 0.6657\n",
      "\n",
      "Trial 101/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.607384\tvalid_1's average_precision: 0.395735\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.908504\tvalid_1's average_precision: 0.445689\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.507407\tvalid_1's average_precision: 0.386462\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.50462\tvalid_1's average_precision: 0.367444\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.470036\tvalid_1's average_precision: 0.433912\n",
      "Avg PR-AUC: 0.4058 | Avg Accuracy: 0.4004\n",
      "\n",
      "Trial 102/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.58444\tvalid_1's average_precision: 0.400176\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.593154\tvalid_1's average_precision: 0.422756\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.523761\tvalid_1's average_precision: 0.39847\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.500729\tvalid_1's average_precision: 0.407922\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.50905\tvalid_1's average_precision: 0.464611\n",
      "Avg PR-AUC: 0.4188 | Avg Accuracy: 0.3835\n",
      "\n",
      "Trial 103/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.56657\tvalid_1's average_precision: 0.375055\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.399792\tvalid_1's average_precision: 0.412339\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.549893\tvalid_1's average_precision: 0.406607\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.483169\tvalid_1's average_precision: 0.423517\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.540614\tvalid_1's average_precision: 0.460144\n",
      "Avg PR-AUC: 0.4155 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 104/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.566875\tvalid_1's average_precision: 0.388933\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.564328\tvalid_1's average_precision: 0.421399\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.511056\tvalid_1's average_precision: 0.412151\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.539988\tvalid_1's average_precision: 0.419183\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.511418\tvalid_1's average_precision: 0.459767\n",
      "Avg PR-AUC: 0.4203 | Avg Accuracy: 0.3750\n",
      "\n",
      "Trial 105/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.509665\tvalid_1's average_precision: 0.381621\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.446735\tvalid_1's average_precision: 0.425252\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.482041\tvalid_1's average_precision: 0.39936\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.422952\tvalid_1's average_precision: 0.392\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's average_precision: 0.472669\tvalid_1's average_precision: 0.462671\n",
      "Avg PR-AUC: 0.4122 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 106/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.600994\tvalid_1's average_precision: 0.394119\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.558892\tvalid_1's average_precision: 0.428019\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's average_precision: 0.572744\tvalid_1's average_precision: 0.407667\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.508254\tvalid_1's average_precision: 0.408198\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.504577\tvalid_1's average_precision: 0.446505\n",
      "Avg PR-AUC: 0.4169 | Avg Accuracy: 0.5894\n",
      "\n",
      "Trial 107/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000665 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.569363\tvalid_1's average_precision: 0.390682\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.545541\tvalid_1's average_precision: 0.421887\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's average_precision: 0.624163\tvalid_1's average_precision: 0.397312\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.52135\tvalid_1's average_precision: 0.420979\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's average_precision: 0.548907\tvalid_1's average_precision: 0.466176\n",
      "Avg PR-AUC: 0.4194 | Avg Accuracy: 0.5516\n",
      "\n",
      "Trial 108/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.639153\tvalid_1's average_precision: 0.370819\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.436627\tvalid_1's average_precision: 0.412863\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.646973\tvalid_1's average_precision: 0.398844\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.587933\tvalid_1's average_precision: 0.417261\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.591411\tvalid_1's average_precision: 0.459483\n",
      "Avg PR-AUC: 0.4119 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 109/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.645554\tvalid_1's average_precision: 0.398531\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.579103\tvalid_1's average_precision: 0.432312\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.542176\tvalid_1's average_precision: 0.402919\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.609738\tvalid_1's average_precision: 0.39678\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.489616\tvalid_1's average_precision: 0.444386\n",
      "Avg PR-AUC: 0.4150 | Avg Accuracy: 0.3813\n",
      "\n",
      "Trial 110/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.662465\tvalid_1's average_precision: 0.393345\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.619667\tvalid_1's average_precision: 0.431847\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.548542\tvalid_1's average_precision: 0.41156\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.508455\tvalid_1's average_precision: 0.371615\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.508493\tvalid_1's average_precision: 0.454308\n",
      "Avg PR-AUC: 0.4125 | Avg Accuracy: 0.5691\n",
      "\n",
      "Trial 111/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.430819\tvalid_1's average_precision: 0.388113\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.429082\tvalid_1's average_precision: 0.412124\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.434314\tvalid_1's average_precision: 0.387534\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.426744\tvalid_1's average_precision: 0.42339\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.426187\tvalid_1's average_precision: 0.451272\n",
      "Avg PR-AUC: 0.4125 | Avg Accuracy: 0.6270\n",
      "\n",
      "Trial 112/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.630115\tvalid_1's average_precision: 0.405537\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.612499\tvalid_1's average_precision: 0.426317\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.581128\tvalid_1's average_precision: 0.392352\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.552896\tvalid_1's average_precision: 0.401437\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.474317\tvalid_1's average_precision: 0.453835\n",
      "Avg PR-AUC: 0.4159 | Avg Accuracy: 0.4665\n",
      "\n",
      "Trial 113/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.542528\tvalid_1's average_precision: 0.395705\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.505755\tvalid_1's average_precision: 0.426237\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.461584\tvalid_1's average_precision: 0.385393\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.492637\tvalid_1's average_precision: 0.414397\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.463186\tvalid_1's average_precision: 0.449444\n",
      "Avg PR-AUC: 0.4142 | Avg Accuracy: 0.4355\n",
      "\n",
      "Trial 114/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.592949\tvalid_1's average_precision: 0.389096\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.433533\tvalid_1's average_precision: 0.414588\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.481479\tvalid_1's average_precision: 0.404521\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.463848\tvalid_1's average_precision: 0.410116\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.527775\tvalid_1's average_precision: 0.452293\n",
      "Avg PR-AUC: 0.4141 | Avg Accuracy: 0.4318\n",
      "\n",
      "Trial 115/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.50727\tvalid_1's average_precision: 0.387916\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.436262\tvalid_1's average_precision: 0.419487\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.514677\tvalid_1's average_precision: 0.398237\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.535001\tvalid_1's average_precision: 0.407123\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.538659\tvalid_1's average_precision: 0.447071\n",
      "Avg PR-AUC: 0.4120 | Avg Accuracy: 0.4908\n",
      "\n",
      "Trial 116/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.484764\tvalid_1's average_precision: 0.386788\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.598259\tvalid_1's average_precision: 0.417475\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.540521\tvalid_1's average_precision: 0.41237\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.533581\tvalid_1's average_precision: 0.397912\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.508691\tvalid_1's average_precision: 0.450269\n",
      "Avg PR-AUC: 0.4130 | Avg Accuracy: 0.6643\n",
      "\n",
      "Trial 117/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.484421\tvalid_1's average_precision: 0.383438\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.527229\tvalid_1's average_precision: 0.423866\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.52874\tvalid_1's average_precision: 0.405091\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.449271\tvalid_1's average_precision: 0.346673\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's average_precision: 0.614166\tvalid_1's average_precision: 0.461242\n",
      "Avg PR-AUC: 0.4041 | Avg Accuracy: 0.6705\n",
      "\n",
      "Trial 118/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.521676\tvalid_1's average_precision: 0.405579\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.495796\tvalid_1's average_precision: 0.420469\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.504819\tvalid_1's average_precision: 0.395651\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.465714\tvalid_1's average_precision: 0.41615\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.51434\tvalid_1's average_precision: 0.467367\n",
      "Avg PR-AUC: 0.4210 | Avg Accuracy: 0.3632\n",
      "\n",
      "Trial 119/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.810627\tvalid_1's average_precision: 0.378913\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.845494\tvalid_1's average_precision: 0.436741\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.609679\tvalid_1's average_precision: 0.40191\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.594527\tvalid_1's average_precision: 0.403731\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.499624\tvalid_1's average_precision: 0.440032\n",
      "Avg PR-AUC: 0.4123 | Avg Accuracy: 0.4220\n",
      "\n",
      "Trial 120/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.723729\tvalid_1's average_precision: 0.376506\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.434334\tvalid_1's average_precision: 0.412259\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.644967\tvalid_1's average_precision: 0.403219\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.597075\tvalid_1's average_precision: 0.426063\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.688537\tvalid_1's average_precision: 0.450849\n",
      "Avg PR-AUC: 0.4138 | Avg Accuracy: 0.6680\n",
      "\n",
      "Trial 121/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.721964\tvalid_1's average_precision: 0.384723\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.558469\tvalid_1's average_precision: 0.430109\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.51286\tvalid_1's average_precision: 0.383247\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.461858\tvalid_1's average_precision: 0.397249\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.483986\tvalid_1's average_precision: 0.451653\n",
      "Avg PR-AUC: 0.4094 | Avg Accuracy: 0.3805\n",
      "\n",
      "Trial 122/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.458286\tvalid_1's average_precision: 0.400127\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.456011\tvalid_1's average_precision: 0.415743\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.495358\tvalid_1's average_precision: 0.39858\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's average_precision: 0.493992\tvalid_1's average_precision: 0.409899\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.459634\tvalid_1's average_precision: 0.446274\n",
      "Avg PR-AUC: 0.4141 | Avg Accuracy: 0.3434\n",
      "\n",
      "Trial 123/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.583697\tvalid_1's average_precision: 0.378501\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.503707\tvalid_1's average_precision: 0.422988\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.640829\tvalid_1's average_precision: 0.423523\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.543594\tvalid_1's average_precision: 0.366574\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.568976\tvalid_1's average_precision: 0.457398\n",
      "Avg PR-AUC: 0.4098 | Avg Accuracy: 0.6679\n",
      "\n",
      "Trial 124/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.435164\tvalid_1's average_precision: 0.391552\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.501877\tvalid_1's average_precision: 0.426155\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.496948\tvalid_1's average_precision: 0.397452\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.446001\tvalid_1's average_precision: 0.425233\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.46821\tvalid_1's average_precision: 0.459607\n",
      "Avg PR-AUC: 0.4200 | Avg Accuracy: 0.4350\n",
      "\n",
      "Trial 125/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.607765\tvalid_1's average_precision: 0.389583\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.635648\tvalid_1's average_precision: 0.413361\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.6406\tvalid_1's average_precision: 0.405448\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.481256\tvalid_1's average_precision: 0.334672\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.521316\tvalid_1's average_precision: 0.458563\n",
      "Avg PR-AUC: 0.4003 | Avg Accuracy: 0.6658\n",
      "\n",
      "Trial 126/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.623706\tvalid_1's average_precision: 0.388327\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.599394\tvalid_1's average_precision: 0.42493\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.662727\tvalid_1's average_precision: 0.400485\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.475024\tvalid_1's average_precision: 0.40157\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.509572\tvalid_1's average_precision: 0.451622\n",
      "Avg PR-AUC: 0.4134 | Avg Accuracy: 0.4016\n",
      "\n",
      "Trial 127/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000987 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.560006\tvalid_1's average_precision: 0.391514\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.515555\tvalid_1's average_precision: 0.424122\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.508032\tvalid_1's average_precision: 0.400088\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.48598\tvalid_1's average_precision: 0.426839\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.514177\tvalid_1's average_precision: 0.459156\n",
      "Avg PR-AUC: 0.4203 | Avg Accuracy: 0.4156\n",
      "\n",
      "Trial 128/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.568152\tvalid_1's average_precision: 0.389638\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.805818\tvalid_1's average_precision: 0.44057\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.589607\tvalid_1's average_precision: 0.404878\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.550033\tvalid_1's average_precision: 0.410034\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.495014\tvalid_1's average_precision: 0.444525\n",
      "Avg PR-AUC: 0.4179 | Avg Accuracy: 0.4076\n",
      "\n",
      "Trial 129/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.638784\tvalid_1's average_precision: 0.389873\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.422064\tvalid_1's average_precision: 0.418929\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.580217\tvalid_1's average_precision: 0.402385\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.487223\tvalid_1's average_precision: 0.411096\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.498664\tvalid_1's average_precision: 0.464598\n",
      "Avg PR-AUC: 0.4174 | Avg Accuracy: 0.6646\n",
      "\n",
      "Trial 130/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.477239\tvalid_1's average_precision: 0.384324\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.536386\tvalid_1's average_precision: 0.421933\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.491238\tvalid_1's average_precision: 0.399129\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.497349\tvalid_1's average_precision: 0.416296\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.532129\tvalid_1's average_precision: 0.459536\n",
      "Avg PR-AUC: 0.4162 | Avg Accuracy: 0.4223\n",
      "\n",
      "Trial 131/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.714169\tvalid_1's average_precision: 0.392905\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's average_precision: 0.752681\tvalid_1's average_precision: 0.435914\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000998 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.65104\tvalid_1's average_precision: 0.412805\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.494847\tvalid_1's average_precision: 0.408307\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.480108\tvalid_1's average_precision: 0.445547\n",
      "Avg PR-AUC: 0.4191 | Avg Accuracy: 0.6602\n",
      "\n",
      "Trial 132/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.703502\tvalid_1's average_precision: 0.385337\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.658306\tvalid_1's average_precision: 0.4116\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.628027\tvalid_1's average_precision: 0.401361\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.463293\tvalid_1's average_precision: 0.379284\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.527278\tvalid_1's average_precision: 0.433123\n",
      "Avg PR-AUC: 0.4021 | Avg Accuracy: 0.6617\n",
      "\n",
      "Trial 133/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.438595\tvalid_1's average_precision: 0.386115\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.461468\tvalid_1's average_precision: 0.413713\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's average_precision: 0.465907\tvalid_1's average_precision: 0.39124\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.439278\tvalid_1's average_precision: 0.424474\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.451405\tvalid_1's average_precision: 0.463102\n",
      "Avg PR-AUC: 0.4157 | Avg Accuracy: 0.5460\n",
      "\n",
      "Trial 134/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.665337\tvalid_1's average_precision: 0.386658\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.425339\tvalid_1's average_precision: 0.410103\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.539509\tvalid_1's average_precision: 0.403229\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.522374\tvalid_1's average_precision: 0.369579\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.504694\tvalid_1's average_precision: 0.451297\n",
      "Avg PR-AUC: 0.4042 | Avg Accuracy: 0.6627\n",
      "\n",
      "Trial 135/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.607807\tvalid_1's average_precision: 0.399596\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.572037\tvalid_1's average_precision: 0.440589\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.520887\tvalid_1's average_precision: 0.399293\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.460374\tvalid_1's average_precision: 0.385446\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.580727\tvalid_1's average_precision: 0.456182\n",
      "Avg PR-AUC: 0.4162 | Avg Accuracy: 0.3935\n",
      "\n",
      "Trial 136/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.620587\tvalid_1's average_precision: 0.40665\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.488966\tvalid_1's average_precision: 0.419226\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.480674\tvalid_1's average_precision: 0.383931\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.495675\tvalid_1's average_precision: 0.402616\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.485834\tvalid_1's average_precision: 0.460576\n",
      "Avg PR-AUC: 0.4146 | Avg Accuracy: 0.3893\n",
      "\n",
      "Trial 137/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's average_precision: 0.599936\tvalid_1's average_precision: 0.393624\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.399055\tvalid_1's average_precision: 0.419713\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.567951\tvalid_1's average_precision: 0.406347\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.515559\tvalid_1's average_precision: 0.374846\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.499771\tvalid_1's average_precision: 0.460758\n",
      "Avg PR-AUC: 0.4111 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 138/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.645581\tvalid_1's average_precision: 0.387404\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.522788\tvalid_1's average_precision: 0.433494\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.629638\tvalid_1's average_precision: 0.398842\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.494565\tvalid_1's average_precision: 0.398246\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.49166\tvalid_1's average_precision: 0.443054\n",
      "Avg PR-AUC: 0.4122 | Avg Accuracy: 0.4607\n",
      "\n",
      "Trial 139/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.721041\tvalid_1's average_precision: 0.401969\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's average_precision: 0.848636\tvalid_1's average_precision: 0.444607\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.675381\tvalid_1's average_precision: 0.395144\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.509413\tvalid_1's average_precision: 0.401188\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.529512\tvalid_1's average_precision: 0.440596\n",
      "Avg PR-AUC: 0.4167 | Avg Accuracy: 0.3930\n",
      "\n",
      "Trial 140/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's average_precision: 0.443538\tvalid_1's average_precision: 0.392451\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.44295\tvalid_1's average_precision: 0.418313\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's average_precision: 0.450886\tvalid_1's average_precision: 0.399174\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.43016\tvalid_1's average_precision: 0.417418\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's average_precision: 0.461546\tvalid_1's average_precision: 0.462908\n",
      "Avg PR-AUC: 0.4181 | Avg Accuracy: 0.5098\n",
      "\n",
      "Trial 141/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.549064\tvalid_1's average_precision: 0.396749\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.541911\tvalid_1's average_precision: 0.425346\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.544534\tvalid_1's average_precision: 0.39267\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.467535\tvalid_1's average_precision: 0.404645\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.608886\tvalid_1's average_precision: 0.44762\n",
      "Avg PR-AUC: 0.4134 | Avg Accuracy: 0.3612\n",
      "\n",
      "Trial 142/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.493279\tvalid_1's average_precision: 0.396097\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.485203\tvalid_1's average_precision: 0.41093\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.477407\tvalid_1's average_precision: 0.402892\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.429148\tvalid_1's average_precision: 0.406092\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.517812\tvalid_1's average_precision: 0.458198\n",
      "Avg PR-AUC: 0.4148 | Avg Accuracy: 0.3431\n",
      "\n",
      "Trial 143/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.412353\tvalid_1's average_precision: 0.383909\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's average_precision: 0.452133\tvalid_1's average_precision: 0.417612\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's average_precision: 0.437726\tvalid_1's average_precision: 0.381487\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's average_precision: 0.418293\tvalid_1's average_precision: 0.403704\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's average_precision: 0.423638\tvalid_1's average_precision: 0.437518\n",
      "Avg PR-AUC: 0.4048 | Avg Accuracy: 0.4682\n",
      "\n",
      "Trial 144/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.483937\tvalid_1's average_precision: 0.394048\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.685602\tvalid_1's average_precision: 0.429198\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.555553\tvalid_1's average_precision: 0.4073\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.455318\tvalid_1's average_precision: 0.380064\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.505954\tvalid_1's average_precision: 0.456819\n",
      "Avg PR-AUC: 0.4135 | Avg Accuracy: 0.4248\n",
      "\n",
      "Trial 145/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.479788\tvalid_1's average_precision: 0.393745\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.466835\tvalid_1's average_precision: 0.413809\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.526554\tvalid_1's average_precision: 0.400719\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.454952\tvalid_1's average_precision: 0.414939\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.508644\tvalid_1's average_precision: 0.463364\n",
      "Avg PR-AUC: 0.4173 | Avg Accuracy: 0.3417\n",
      "\n",
      "Trial 146/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.516403\tvalid_1's average_precision: 0.398331\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.458888\tvalid_1's average_precision: 0.422824\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.510728\tvalid_1's average_precision: 0.400896\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.451663\tvalid_1's average_precision: 0.424585\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.477578\tvalid_1's average_precision: 0.45525\n",
      "Avg PR-AUC: 0.4204 | Avg Accuracy: 0.3678\n",
      "\n",
      "Trial 147/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's average_precision: 0.522128\tvalid_1's average_precision: 0.388854\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.425339\tvalid_1's average_precision: 0.410103\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.479786\tvalid_1's average_precision: 0.394241\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.438191\tvalid_1's average_precision: 0.357103\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.472159\tvalid_1's average_precision: 0.458215\n",
      "Avg PR-AUC: 0.4017 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 148/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.505884\tvalid_1's average_precision: 0.387266\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.488501\tvalid_1's average_precision: 0.413652\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.487667\tvalid_1's average_precision: 0.403715\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.510778\tvalid_1's average_precision: 0.381371\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.456932\tvalid_1's average_precision: 0.45153\n",
      "Avg PR-AUC: 0.4075 | Avg Accuracy: 0.6664\n",
      "\n",
      "Trial 149/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.615251\tvalid_1's average_precision: 0.370988\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.559222\tvalid_1's average_precision: 0.431208\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001592 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's average_precision: 0.693888\tvalid_1's average_precision: 0.406594\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's average_precision: 0.671656\tvalid_1's average_precision: 0.340904\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.58964\tvalid_1's average_precision: 0.441175\n",
      "Avg PR-AUC: 0.3982 | Avg Accuracy: 0.6659\n",
      "\n",
      "Trial 150/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.539089\tvalid_1's average_precision: 0.416663\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.508499\tvalid_1's average_precision: 0.414006\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.524372\tvalid_1's average_precision: 0.390554\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.444159\tvalid_1's average_precision: 0.40054\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.528318\tvalid_1's average_precision: 0.458204\n",
      "Avg PR-AUC: 0.4160 | Avg Accuracy: 0.3635\n",
      "\n",
      "Trial 151/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.472443\tvalid_1's average_precision: 0.387714\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.448293\tvalid_1's average_precision: 0.413719\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's average_precision: 0.483242\tvalid_1's average_precision: 0.397449\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.448135\tvalid_1's average_precision: 0.40416\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.463512\tvalid_1's average_precision: 0.447889\n",
      "Avg PR-AUC: 0.4102 | Avg Accuracy: 0.5689\n",
      "\n",
      "Trial 152/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's average_precision: 0.5074\tvalid_1's average_precision: 0.379817\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.47454\tvalid_1's average_precision: 0.407557\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.46667\tvalid_1's average_precision: 0.398878\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's average_precision: 0.48559\tvalid_1's average_precision: 0.402116\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's average_precision: 0.478264\tvalid_1's average_precision: 0.460472\n",
      "Avg PR-AUC: 0.4098 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 153/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.429663\tvalid_1's average_precision: 0.394962\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.435097\tvalid_1's average_precision: 0.411918\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's average_precision: 0.44835\tvalid_1's average_precision: 0.392416\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.430748\tvalid_1's average_precision: 0.42505\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.418154\tvalid_1's average_precision: 0.457469\n",
      "Avg PR-AUC: 0.4164 | Avg Accuracy: 0.6098\n",
      "\n",
      "Trial 154/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.434516\tvalid_1's average_precision: 0.388279\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.429605\tvalid_1's average_precision: 0.417681\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.432715\tvalid_1's average_precision: 0.386338\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.425405\tvalid_1's average_precision: 0.427688\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.429141\tvalid_1's average_precision: 0.453357\n",
      "Avg PR-AUC: 0.4147 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 155/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.45287\tvalid_1's average_precision: 0.390696\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.444879\tvalid_1's average_precision: 0.415639\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's average_precision: 0.509086\tvalid_1's average_precision: 0.400403\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.470897\tvalid_1's average_precision: 0.425002\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's average_precision: 0.467944\tvalid_1's average_precision: 0.458618\n",
      "Avg PR-AUC: 0.4181 | Avg Accuracy: 0.5559\n",
      "\n",
      "Trial 156/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.483967\tvalid_1's average_precision: 0.38806\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.576022\tvalid_1's average_precision: 0.420939\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.488779\tvalid_1's average_precision: 0.399469\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.4967\tvalid_1's average_precision: 0.419619\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.51265\tvalid_1's average_precision: 0.45833\n",
      "Avg PR-AUC: 0.4173 | Avg Accuracy: 0.4332\n",
      "\n",
      "Trial 157/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.521581\tvalid_1's average_precision: 0.372961\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.425339\tvalid_1's average_precision: 0.410103\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.529935\tvalid_1's average_precision: 0.399563\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.53916\tvalid_1's average_precision: 0.363291\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.534459\tvalid_1's average_precision: 0.447923\n",
      "Avg PR-AUC: 0.3988 | Avg Accuracy: 0.6682\n",
      "\n",
      "Trial 158/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.425867\tvalid_1's average_precision: 0.392281\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's average_precision: 0.441712\tvalid_1's average_precision: 0.410511\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.435053\tvalid_1's average_precision: 0.391225\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.425606\tvalid_1's average_precision: 0.422213\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.424166\tvalid_1's average_precision: 0.452877\n",
      "Avg PR-AUC: 0.4138 | Avg Accuracy: 0.5563\n",
      "\n",
      "Trial 159/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.595717\tvalid_1's average_precision: 0.398509\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's average_precision: 0.741762\tvalid_1's average_precision: 0.441463\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.515481\tvalid_1's average_precision: 0.401736\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001810 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.526118\tvalid_1's average_precision: 0.367216\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.50004\tvalid_1's average_precision: 0.45244\n",
      "Avg PR-AUC: 0.4123 | Avg Accuracy: 0.3884\n",
      "\n",
      "Trial 160/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.630496\tvalid_1's average_precision: 0.391702\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's average_precision: 0.743575\tvalid_1's average_precision: 0.431822\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.554119\tvalid_1's average_precision: 0.401373\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.492118\tvalid_1's average_precision: 0.405077\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.518503\tvalid_1's average_precision: 0.446643\n",
      "Avg PR-AUC: 0.4153 | Avg Accuracy: 0.3951\n",
      "\n",
      "Trial 161/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.478203\tvalid_1's average_precision: 0.386714\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.427701\tvalid_1's average_precision: 0.419443\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.480072\tvalid_1's average_precision: 0.395882\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.448657\tvalid_1's average_precision: 0.422215\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.455105\tvalid_1's average_precision: 0.460194\n",
      "Avg PR-AUC: 0.4169 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 162/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.452133\tvalid_1's average_precision: 0.396181\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.472348\tvalid_1's average_precision: 0.42114\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.450287\tvalid_1's average_precision: 0.39413\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.422712\tvalid_1's average_precision: 0.407012\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.479858\tvalid_1's average_precision: 0.463662\n",
      "Avg PR-AUC: 0.4164 | Avg Accuracy: 0.4187\n",
      "\n",
      "Trial 163/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.527552\tvalid_1's average_precision: 0.393012\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.519587\tvalid_1's average_precision: 0.416398\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.467628\tvalid_1's average_precision: 0.380233\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.417168\tvalid_1's average_precision: 0.403432\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.475985\tvalid_1's average_precision: 0.451038\n",
      "Avg PR-AUC: 0.4088 | Avg Accuracy: 0.3570\n",
      "\n",
      "Trial 164/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.592196\tvalid_1's average_precision: 0.386613\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.568192\tvalid_1's average_precision: 0.418354\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.686718\tvalid_1's average_precision: 0.401124\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.508392\tvalid_1's average_precision: 0.328137\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.584114\tvalid_1's average_precision: 0.431799\n",
      "Avg PR-AUC: 0.3932 | Avg Accuracy: 0.6654\n",
      "\n",
      "Trial 165/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.596759\tvalid_1's average_precision: 0.404551\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.68184\tvalid_1's average_precision: 0.427254\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.446703\tvalid_1's average_precision: 0.384116\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.44323\tvalid_1's average_precision: 0.387462\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.530041\tvalid_1's average_precision: 0.43776\n",
      "Avg PR-AUC: 0.4082 | Avg Accuracy: 0.3778\n",
      "\n",
      "Trial 166/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.491016\tvalid_1's average_precision: 0.389268\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.481719\tvalid_1's average_precision: 0.416942\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.48506\tvalid_1's average_precision: 0.397604\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.458543\tvalid_1's average_precision: 0.373398\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's average_precision: 0.477374\tvalid_1's average_precision: 0.462866\n",
      "Avg PR-AUC: 0.4080 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 167/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.734843\tvalid_1's average_precision: 0.394463\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.605333\tvalid_1's average_precision: 0.428094\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.672086\tvalid_1's average_precision: 0.393782\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.506204\tvalid_1's average_precision: 0.411356\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.540265\tvalid_1's average_precision: 0.460753\n",
      "Avg PR-AUC: 0.4177 | Avg Accuracy: 0.4229\n",
      "\n",
      "Trial 168/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.61488\tvalid_1's average_precision: 0.380572\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.607236\tvalid_1's average_precision: 0.41881\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.628544\tvalid_1's average_precision: 0.409805\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.477777\tvalid_1's average_precision: 0.344102\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.542004\tvalid_1's average_precision: 0.460786\n",
      "Avg PR-AUC: 0.4028 | Avg Accuracy: 0.6652\n",
      "\n",
      "Trial 169/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.428206\tvalid_1's average_precision: 0.391081\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.398649\tvalid_1's average_precision: 0.412484\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.424879\tvalid_1's average_precision: 0.381944\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's average_precision: 0.428003\tvalid_1's average_precision: 0.418774\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.424345\tvalid_1's average_precision: 0.441205\n",
      "Avg PR-AUC: 0.4091 | Avg Accuracy: 0.5618\n",
      "\n",
      "Trial 170/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.454584\tvalid_1's average_precision: 0.389802\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.491209\tvalid_1's average_precision: 0.409319\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.52754\tvalid_1's average_precision: 0.40869\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.432735\tvalid_1's average_precision: 0.400409\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.513011\tvalid_1's average_precision: 0.466029\n",
      "Avg PR-AUC: 0.4148 | Avg Accuracy: 0.3871\n",
      "\n",
      "Trial 171/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.507639\tvalid_1's average_precision: 0.376533\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.492398\tvalid_1's average_precision: 0.408692\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's average_precision: 0.586581\tvalid_1's average_precision: 0.396664\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.470702\tvalid_1's average_precision: 0.345261\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.509449\tvalid_1's average_precision: 0.456406\n",
      "Avg PR-AUC: 0.3967 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 172/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.447235\tvalid_1's average_precision: 0.395347\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.447217\tvalid_1's average_precision: 0.422452\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.478384\tvalid_1's average_precision: 0.385295\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.434456\tvalid_1's average_precision: 0.414659\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.448374\tvalid_1's average_precision: 0.453135\n",
      "Avg PR-AUC: 0.4142 | Avg Accuracy: 0.3441\n",
      "\n",
      "Trial 173/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.569389\tvalid_1's average_precision: 0.386477\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.481771\tvalid_1's average_precision: 0.425329\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.587503\tvalid_1's average_precision: 0.406954\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.506001\tvalid_1's average_precision: 0.386556\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.536258\tvalid_1's average_precision: 0.458176\n",
      "Avg PR-AUC: 0.4127 | Avg Accuracy: 0.6670\n",
      "\n",
      "Trial 174/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.52883\tvalid_1's average_precision: 0.403085\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.49797\tvalid_1's average_precision: 0.401467\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.556597\tvalid_1's average_precision: 0.397023\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.477461\tvalid_1's average_precision: 0.381704\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.550441\tvalid_1's average_precision: 0.456315\n",
      "Avg PR-AUC: 0.4079 | Avg Accuracy: 0.4069\n",
      "\n",
      "Trial 175/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.536556\tvalid_1's average_precision: 0.38334\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.469326\tvalid_1's average_precision: 0.415592\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.537069\tvalid_1's average_precision: 0.401689\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.484576\tvalid_1's average_precision: 0.411071\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.475329\tvalid_1's average_precision: 0.460605\n",
      "Avg PR-AUC: 0.4145 | Avg Accuracy: 0.6665\n",
      "\n",
      "Trial 176/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.428105\tvalid_1's average_precision: 0.38614\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's average_precision: 0.437337\tvalid_1's average_precision: 0.403391\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.421554\tvalid_1's average_precision: 0.382911\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.426287\tvalid_1's average_precision: 0.406093\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's average_precision: 0.429393\tvalid_1's average_precision: 0.439033\n",
      "Avg PR-AUC: 0.4035 | Avg Accuracy: 0.6022\n",
      "\n",
      "Trial 177/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.530807\tvalid_1's average_precision: 0.396785\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.514701\tvalid_1's average_precision: 0.429151\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.513115\tvalid_1's average_precision: 0.394855\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.523592\tvalid_1's average_precision: 0.407616\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.487458\tvalid_1's average_precision: 0.458415\n",
      "Avg PR-AUC: 0.4174 | Avg Accuracy: 0.3601\n",
      "\n",
      "Trial 178/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's average_precision: 0.726705\tvalid_1's average_precision: 0.403637\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.532282\tvalid_1's average_precision: 0.435162\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.565043\tvalid_1's average_precision: 0.393084\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.442522\tvalid_1's average_precision: 0.404102\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.582024\tvalid_1's average_precision: 0.452004\n",
      "Avg PR-AUC: 0.4176 | Avg Accuracy: 0.3642\n",
      "\n",
      "Trial 179/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's average_precision: 0.539967\tvalid_1's average_precision: 0.391502\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.42133\tvalid_1's average_precision: 0.400553\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's average_precision: 0.560258\tvalid_1's average_precision: 0.406274\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's average_precision: 0.523621\tvalid_1's average_precision: 0.405441\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's average_precision: 0.503193\tvalid_1's average_precision: 0.452628\n",
      "Avg PR-AUC: 0.4113 | Avg Accuracy: 0.4448\n",
      "\n",
      "Trial 180/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.481822\tvalid_1's average_precision: 0.386986\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.465078\tvalid_1's average_precision: 0.424001\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.45756\tvalid_1's average_precision: 0.397708\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.471795\tvalid_1's average_precision: 0.424068\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.452927\tvalid_1's average_precision: 0.458362\n",
      "Avg PR-AUC: 0.4182 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 181/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.560964\tvalid_1's average_precision: 0.39321\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.693341\tvalid_1's average_precision: 0.431972\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.586397\tvalid_1's average_precision: 0.410206\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.565137\tvalid_1's average_precision: 0.359597\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.53815\tvalid_1's average_precision: 0.453989\n",
      "Avg PR-AUC: 0.4098 | Avg Accuracy: 0.4699\n",
      "\n",
      "Trial 182/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.554263\tvalid_1's average_precision: 0.40243\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.502359\tvalid_1's average_precision: 0.413759\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.506419\tvalid_1's average_precision: 0.412152\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.450159\tvalid_1's average_precision: 0.398401\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.533034\tvalid_1's average_precision: 0.440852\n",
      "Avg PR-AUC: 0.4135 | Avg Accuracy: 0.4466\n",
      "\n",
      "Trial 183/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.48459\tvalid_1's average_precision: 0.395286\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.449072\tvalid_1's average_precision: 0.414778\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.497643\tvalid_1's average_precision: 0.396016\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.427559\tvalid_1's average_precision: 0.40321\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.503047\tvalid_1's average_precision: 0.457854\n",
      "Avg PR-AUC: 0.4134 | Avg Accuracy: 0.3796\n",
      "\n",
      "Trial 184/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.449766\tvalid_1's average_precision: 0.392838\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.430061\tvalid_1's average_precision: 0.42296\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.491557\tvalid_1's average_precision: 0.392697\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.453301\tvalid_1's average_precision: 0.413385\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.487586\tvalid_1's average_precision: 0.459601\n",
      "Avg PR-AUC: 0.4163 | Avg Accuracy: 0.3468\n",
      "\n",
      "Trial 185/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's average_precision: 0.493602\tvalid_1's average_precision: 0.395277\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.402529\tvalid_1's average_precision: 0.400624\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.424687\tvalid_1's average_precision: 0.383695\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's average_precision: 0.4623\tvalid_1's average_precision: 0.418947\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's average_precision: 0.441916\tvalid_1's average_precision: 0.451575\n",
      "Avg PR-AUC: 0.4100 | Avg Accuracy: 0.4986\n",
      "\n",
      "Trial 186/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.600602\tvalid_1's average_precision: 0.392489\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.573463\tvalid_1's average_precision: 0.440164\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.549968\tvalid_1's average_precision: 0.395415\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.481004\tvalid_1's average_precision: 0.403206\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.468076\tvalid_1's average_precision: 0.448047\n",
      "Avg PR-AUC: 0.4159 | Avg Accuracy: 0.3553\n",
      "\n",
      "Trial 187/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.524321\tvalid_1's average_precision: 0.394739\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.429847\tvalid_1's average_precision: 0.406868\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.568276\tvalid_1's average_precision: 0.41284\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.427288\tvalid_1's average_precision: 0.415788\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.479154\tvalid_1's average_precision: 0.461519\n",
      "Avg PR-AUC: 0.4184 | Avg Accuracy: 0.6676\n",
      "\n",
      "Trial 188/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.563411\tvalid_1's average_precision: 0.390794\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.560082\tvalid_1's average_precision: 0.432905\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's average_precision: 0.589128\tvalid_1's average_precision: 0.411744\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.527703\tvalid_1's average_precision: 0.415878\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's average_precision: 0.558548\tvalid_1's average_precision: 0.454783\n",
      "Avg PR-AUC: 0.4212 | Avg Accuracy: 0.5701\n",
      "\n",
      "Trial 189/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.565803\tvalid_1's average_precision: 0.384408\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.500127\tvalid_1's average_precision: 0.416931\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.658478\tvalid_1's average_precision: 0.411786\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.469316\tvalid_1's average_precision: 0.368069\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.558421\tvalid_1's average_precision: 0.458454\n",
      "Avg PR-AUC: 0.4079 | Avg Accuracy: 0.6667\n",
      "\n",
      "Trial 190/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.635631\tvalid_1's average_precision: 0.393483\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.570119\tvalid_1's average_precision: 0.427465\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.579111\tvalid_1's average_precision: 0.398219\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.474864\tvalid_1's average_precision: 0.388432\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's average_precision: 0.581699\tvalid_1's average_precision: 0.449982\n",
      "Avg PR-AUC: 0.4115 | Avg Accuracy: 0.3933\n",
      "\n",
      "Trial 191/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.41994\tvalid_1's average_precision: 0.379712\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's average_precision: 0.43157\tvalid_1's average_precision: 0.404561\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.422768\tvalid_1's average_precision: 0.381814\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's average_precision: 0.421837\tvalid_1's average_precision: 0.405947\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's average_precision: 0.426499\tvalid_1's average_precision: 0.439149\n",
      "Avg PR-AUC: 0.4022 | Avg Accuracy: 0.4483\n",
      "\n",
      "Trial 192/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.6255\tvalid_1's average_precision: 0.403414\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.479903\tvalid_1's average_precision: 0.425569\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.561754\tvalid_1's average_precision: 0.408416\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.536599\tvalid_1's average_precision: 0.398451\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.544999\tvalid_1's average_precision: 0.458579\n",
      "Avg PR-AUC: 0.4189 | Avg Accuracy: 0.6687\n",
      "\n",
      "Trial 193/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.462572\tvalid_1's average_precision: 0.404898\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.411083\tvalid_1's average_precision: 0.417261\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's average_precision: 0.526153\tvalid_1's average_precision: 0.401876\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.427759\tvalid_1's average_precision: 0.413227\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.510095\tvalid_1's average_precision: 0.455313\n",
      "Avg PR-AUC: 0.4185 | Avg Accuracy: 0.4285\n",
      "\n",
      "Trial 194/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.776022\tvalid_1's average_precision: 0.407098\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.620112\tvalid_1's average_precision: 0.425896\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.584274\tvalid_1's average_precision: 0.396434\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.468712\tvalid_1's average_precision: 0.386487\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.522839\tvalid_1's average_precision: 0.464466\n",
      "Avg PR-AUC: 0.4161 | Avg Accuracy: 0.4104\n",
      "\n",
      "Trial 195/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.533824\tvalid_1's average_precision: 0.401256\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.439947\tvalid_1's average_precision: 0.418918\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's average_precision: 0.592643\tvalid_1's average_precision: 0.395894\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.459068\tvalid_1's average_precision: 0.419816\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.457071\tvalid_1's average_precision: 0.463526\n",
      "Avg PR-AUC: 0.4199 | Avg Accuracy: 0.3499\n",
      "\n",
      "Trial 196/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.49861\tvalid_1's average_precision: 0.390856\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.560818\tvalid_1's average_precision: 0.43191\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.567932\tvalid_1's average_precision: 0.394685\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.428779\tvalid_1's average_precision: 0.395399\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.566102\tvalid_1's average_precision: 0.462056\n",
      "Avg PR-AUC: 0.4150 | Avg Accuracy: 0.4027\n",
      "\n",
      "Trial 197/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.538618\tvalid_1's average_precision: 0.391558\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.556033\tvalid_1's average_precision: 0.430605\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.527342\tvalid_1's average_precision: 0.397738\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.498461\tvalid_1's average_precision: 0.391563\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.451333\tvalid_1's average_precision: 0.451139\n",
      "Avg PR-AUC: 0.4125 | Avg Accuracy: 0.4114\n",
      "\n",
      "Trial 198/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.511485\tvalid_1's average_precision: 0.382478\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.374839\tvalid_1's average_precision: 0.41589\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.495758\tvalid_1's average_precision: 0.400975\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.423168\tvalid_1's average_precision: 0.392703\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.452929\tvalid_1's average_precision: 0.454849\n",
      "Avg PR-AUC: 0.4094 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 199/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.65475\tvalid_1's average_precision: 0.384655\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.520069\tvalid_1's average_precision: 0.42676\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.547229\tvalid_1's average_precision: 0.390109\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.646981\tvalid_1's average_precision: 0.338808\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.643691\tvalid_1's average_precision: 0.434748\n",
      "Avg PR-AUC: 0.3950 | Avg Accuracy: 0.6623\n",
      "\n",
      "Trial 200/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.545378\tvalid_1's average_precision: 0.386359\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.447401\tvalid_1's average_precision: 0.425395\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.487347\tvalid_1's average_precision: 0.410837\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.486005\tvalid_1's average_precision: 0.397848\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.50767\tvalid_1's average_precision: 0.456424\n",
      "Avg PR-AUC: 0.4154 | Avg Accuracy: 0.6684\n",
      "\n",
      "Trial 201/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's average_precision: 0.5174\tvalid_1's average_precision: 0.388029\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.477192\tvalid_1's average_precision: 0.406233\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.491618\tvalid_1's average_precision: 0.397704\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.419803\tvalid_1's average_precision: 0.341542\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.471751\tvalid_1's average_precision: 0.457901\n",
      "Avg PR-AUC: 0.3983 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 202/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.585872\tvalid_1's average_precision: 0.393848\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.574954\tvalid_1's average_precision: 0.429616\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.512221\tvalid_1's average_precision: 0.40152\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.490475\tvalid_1's average_precision: 0.415593\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.528425\tvalid_1's average_precision: 0.460026\n",
      "Avg PR-AUC: 0.4201 | Avg Accuracy: 0.3969\n",
      "\n",
      "Trial 203/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.690085\tvalid_1's average_precision: 0.366151\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.70543\tvalid_1's average_precision: 0.424426\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.739221\tvalid_1's average_precision: 0.381756\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.579309\tvalid_1's average_precision: 0.406791\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.671848\tvalid_1's average_precision: 0.433633\n",
      "Avg PR-AUC: 0.4026 | Avg Accuracy: 0.6659\n",
      "\n",
      "Trial 204/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.522723\tvalid_1's average_precision: 0.391217\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.538025\tvalid_1's average_precision: 0.42071\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.482075\tvalid_1's average_precision: 0.396693\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.465464\tvalid_1's average_precision: 0.417486\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.442894\tvalid_1's average_precision: 0.448559\n",
      "Avg PR-AUC: 0.4149 | Avg Accuracy: 0.3665\n",
      "\n",
      "Trial 205/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.620519\tvalid_1's average_precision: 0.374798\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.561538\tvalid_1's average_precision: 0.432772\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.606873\tvalid_1's average_precision: 0.387752\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.596114\tvalid_1's average_precision: 0.341501\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.630036\tvalid_1's average_precision: 0.446285\n",
      "Avg PR-AUC: 0.3966 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 206/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.606592\tvalid_1's average_precision: 0.382355\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.691866\tvalid_1's average_precision: 0.427436\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.601867\tvalid_1's average_precision: 0.408081\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.510677\tvalid_1's average_precision: 0.347873\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.543286\tvalid_1's average_precision: 0.453796\n",
      "Avg PR-AUC: 0.4039 | Avg Accuracy: 0.6614\n",
      "\n",
      "Trial 207/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.422523\tvalid_1's average_precision: 0.38969\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.416823\tvalid_1's average_precision: 0.412819\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.467265\tvalid_1's average_precision: 0.399106\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.428841\tvalid_1's average_precision: 0.412237\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.474452\tvalid_1's average_precision: 0.455026\n",
      "Avg PR-AUC: 0.4138 | Avg Accuracy: 0.4289\n",
      "\n",
      "Trial 208/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.713717\tvalid_1's average_precision: 0.39414\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.592097\tvalid_1's average_precision: 0.418313\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.629166\tvalid_1's average_precision: 0.387916\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.576615\tvalid_1's average_precision: 0.388992\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.525798\tvalid_1's average_precision: 0.452618\n",
      "Avg PR-AUC: 0.4084 | Avg Accuracy: 0.6636\n",
      "\n",
      "Trial 209/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.538382\tvalid_1's average_precision: 0.391427\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.480897\tvalid_1's average_precision: 0.42586\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.467527\tvalid_1's average_precision: 0.395501\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.456065\tvalid_1's average_precision: 0.409986\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.473181\tvalid_1's average_precision: 0.461825\n",
      "Avg PR-AUC: 0.4169 | Avg Accuracy: 0.3451\n",
      "\n",
      "Trial 210/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.678206\tvalid_1's average_precision: 0.393843\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.55222\tvalid_1's average_precision: 0.430154\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.569352\tvalid_1's average_precision: 0.400106\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.449136\tvalid_1's average_precision: 0.390156\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.595422\tvalid_1's average_precision: 0.454597\n",
      "Avg PR-AUC: 0.4138 | Avg Accuracy: 0.4180\n",
      "\n",
      "Trial 211/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.726831\tvalid_1's average_precision: 0.412521\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.697252\tvalid_1's average_precision: 0.418566\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.564383\tvalid_1's average_precision: 0.399995\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.596575\tvalid_1's average_precision: 0.357151\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.555459\tvalid_1's average_precision: 0.447878\n",
      "Avg PR-AUC: 0.4072 | Avg Accuracy: 0.3818\n",
      "\n",
      "Trial 212/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.563333\tvalid_1's average_precision: 0.395765\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.566398\tvalid_1's average_precision: 0.424909\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.551211\tvalid_1's average_precision: 0.398315\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.552684\tvalid_1's average_precision: 0.389631\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.494296\tvalid_1's average_precision: 0.440195\n",
      "Avg PR-AUC: 0.4098 | Avg Accuracy: 0.4165\n",
      "\n",
      "Trial 213/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.421576\tvalid_1's average_precision: 0.392291\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.419068\tvalid_1's average_precision: 0.405485\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.417128\tvalid_1's average_precision: 0.374816\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.424688\tvalid_1's average_precision: 0.413659\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's average_precision: 0.42761\tvalid_1's average_precision: 0.447799\n",
      "Avg PR-AUC: 0.4068 | Avg Accuracy: 0.5825\n",
      "\n",
      "Trial 214/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.615187\tvalid_1's average_precision: 0.412639\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.753757\tvalid_1's average_precision: 0.430325\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.647165\tvalid_1's average_precision: 0.398\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.6534\tvalid_1's average_precision: 0.363493\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.5514\tvalid_1's average_precision: 0.451476\n",
      "Avg PR-AUC: 0.4112 | Avg Accuracy: 0.3762\n",
      "\n",
      "Trial 215/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.527116\tvalid_1's average_precision: 0.384263\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.462384\tvalid_1's average_precision: 0.418305\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.539176\tvalid_1's average_precision: 0.396512\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.508882\tvalid_1's average_precision: 0.418336\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.510138\tvalid_1's average_precision: 0.460275\n",
      "Avg PR-AUC: 0.4155 | Avg Accuracy: 0.3881\n",
      "\n",
      "Trial 216/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.633395\tvalid_1's average_precision: 0.391198\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.620401\tvalid_1's average_precision: 0.417217\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.633905\tvalid_1's average_precision: 0.395547\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001587 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.710389\tvalid_1's average_precision: 0.344369\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.52158\tvalid_1's average_precision: 0.453801\n",
      "Avg PR-AUC: 0.4004 | Avg Accuracy: 0.6588\n",
      "\n",
      "Trial 217/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.830804\tvalid_1's average_precision: 0.406143\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.737975\tvalid_1's average_precision: 0.427235\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.564376\tvalid_1's average_precision: 0.396574\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.601423\tvalid_1's average_precision: 0.395347\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.637514\tvalid_1's average_precision: 0.443128\n",
      "Avg PR-AUC: 0.4137 | Avg Accuracy: 0.4201\n",
      "\n",
      "Trial 218/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.589201\tvalid_1's average_precision: 0.3881\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.520913\tvalid_1's average_precision: 0.412713\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.705587\tvalid_1's average_precision: 0.390439\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.544153\tvalid_1's average_precision: 0.386874\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.558918\tvalid_1's average_precision: 0.451952\n",
      "Avg PR-AUC: 0.4060 | Avg Accuracy: 0.4097\n",
      "\n",
      "Trial 219/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.463175\tvalid_1's average_precision: 0.38706\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's average_precision: 0.484332\tvalid_1's average_precision: 0.417668\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's average_precision: 0.463935\tvalid_1's average_precision: 0.399821\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.442435\tvalid_1's average_precision: 0.413694\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's average_precision: 0.450014\tvalid_1's average_precision: 0.455529\n",
      "Avg PR-AUC: 0.4148 | Avg Accuracy: 0.4996\n",
      "\n",
      "Trial 220/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.597378\tvalid_1's average_precision: 0.382643\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.782009\tvalid_1's average_precision: 0.434176\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.557699\tvalid_1's average_precision: 0.386723\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.657338\tvalid_1's average_precision: 0.342839\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.674462\tvalid_1's average_precision: 0.445403\n",
      "Avg PR-AUC: 0.3984 | Avg Accuracy: 0.6614\n",
      "\n",
      "Trial 221/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.434662\tvalid_1's average_precision: 0.39807\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.477908\tvalid_1's average_precision: 0.420791\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.434219\tvalid_1's average_precision: 0.389298\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.450813\tvalid_1's average_precision: 0.424402\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.471089\tvalid_1's average_precision: 0.461113\n",
      "Avg PR-AUC: 0.4187 | Avg Accuracy: 0.4747\n",
      "\n",
      "Trial 222/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's average_precision: 0.474275\tvalid_1's average_precision: 0.397287\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.436056\tvalid_1's average_precision: 0.42539\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.430106\tvalid_1's average_precision: 0.392253\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.427031\tvalid_1's average_precision: 0.417832\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's average_precision: 0.439654\tvalid_1's average_precision: 0.455532\n",
      "Avg PR-AUC: 0.4177 | Avg Accuracy: 0.5505\n",
      "\n",
      "Trial 223/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.667662\tvalid_1's average_precision: 0.388707\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.596531\tvalid_1's average_precision: 0.423694\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.538678\tvalid_1's average_precision: 0.397832\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.588473\tvalid_1's average_precision: 0.345301\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.568054\tvalid_1's average_precision: 0.458387\n",
      "Avg PR-AUC: 0.4028 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 224/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.682541\tvalid_1's average_precision: 0.375127\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.478269\tvalid_1's average_precision: 0.410873\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.67055\tvalid_1's average_precision: 0.408968\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.540966\tvalid_1's average_precision: 0.414658\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.574998\tvalid_1's average_precision: 0.463455\n",
      "Avg PR-AUC: 0.4146 | Avg Accuracy: 0.6664\n",
      "\n",
      "Trial 225/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's average_precision: 0.522128\tvalid_1's average_precision: 0.388854\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.425339\tvalid_1's average_precision: 0.410103\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.479786\tvalid_1's average_precision: 0.394241\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.438191\tvalid_1's average_precision: 0.357103\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's average_precision: 0.472159\tvalid_1's average_precision: 0.458215\n",
      "Avg PR-AUC: 0.4017 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 226/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.433299\tvalid_1's average_precision: 0.388865\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.429556\tvalid_1's average_precision: 0.418243\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's average_precision: 0.449084\tvalid_1's average_precision: 0.393509\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.425942\tvalid_1's average_precision: 0.429484\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.430884\tvalid_1's average_precision: 0.452926\n",
      "Avg PR-AUC: 0.4166 | Avg Accuracy: 0.6026\n",
      "\n",
      "Trial 227/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.489337\tvalid_1's average_precision: 0.391066\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.477758\tvalid_1's average_precision: 0.413848\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's average_precision: 0.561325\tvalid_1's average_precision: 0.402596\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.513979\tvalid_1's average_precision: 0.405684\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.483435\tvalid_1's average_precision: 0.451671\n",
      "Avg PR-AUC: 0.4130 | Avg Accuracy: 0.5781\n",
      "\n",
      "Trial 228/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.514487\tvalid_1's average_precision: 0.378926\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.562468\tvalid_1's average_precision: 0.444445\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.560289\tvalid_1's average_precision: 0.408973\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.527335\tvalid_1's average_precision: 0.40218\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's average_precision: 0.596605\tvalid_1's average_precision: 0.452413\n",
      "Avg PR-AUC: 0.4174 | Avg Accuracy: 0.6704\n",
      "\n",
      "Trial 229/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.442833\tvalid_1's average_precision: 0.391132\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's average_precision: 0.471949\tvalid_1's average_precision: 0.427061\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's average_precision: 0.493357\tvalid_1's average_precision: 0.395955\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.443329\tvalid_1's average_precision: 0.424676\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.445161\tvalid_1's average_precision: 0.457404\n",
      "Avg PR-AUC: 0.4192 | Avg Accuracy: 0.4439\n",
      "\n",
      "Trial 230/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.484649\tvalid_1's average_precision: 0.390927\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.438827\tvalid_1's average_precision: 0.420177\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.491198\tvalid_1's average_precision: 0.380325\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.459951\tvalid_1's average_precision: 0.419831\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.448011\tvalid_1's average_precision: 0.455559\n",
      "Avg PR-AUC: 0.4134 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 231/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.582288\tvalid_1's average_precision: 0.386679\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.494717\tvalid_1's average_precision: 0.43026\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.456497\tvalid_1's average_precision: 0.393535\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.507498\tvalid_1's average_precision: 0.410981\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.48479\tvalid_1's average_precision: 0.455463\n",
      "Avg PR-AUC: 0.4154 | Avg Accuracy: 0.4546\n",
      "\n",
      "Trial 232/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002919 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.498071\tvalid_1's average_precision: 0.39681\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.436753\tvalid_1's average_precision: 0.419514\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.450377\tvalid_1's average_precision: 0.389136\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.434033\tvalid_1's average_precision: 0.407482\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.493703\tvalid_1's average_precision: 0.46729\n",
      "Avg PR-AUC: 0.4160 | Avg Accuracy: 0.3484\n",
      "\n",
      "Trial 233/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.817142\tvalid_1's average_precision: 0.370153\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.65454\tvalid_1's average_precision: 0.427268\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.689391\tvalid_1's average_precision: 0.406278\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.676721\tvalid_1's average_precision: 0.357919\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.562373\tvalid_1's average_precision: 0.439316\n",
      "Avg PR-AUC: 0.4002 | Avg Accuracy: 0.6629\n",
      "\n",
      "Trial 234/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.6451\tvalid_1's average_precision: 0.401959\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.67909\tvalid_1's average_precision: 0.438028\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.6936\tvalid_1's average_precision: 0.397419\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.465492\tvalid_1's average_precision: 0.405434\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.484779\tvalid_1's average_precision: 0.454746\n",
      "Avg PR-AUC: 0.4195 | Avg Accuracy: 0.5113\n",
      "\n",
      "Trial 235/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.525727\tvalid_1's average_precision: 0.388173\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[193]\ttraining's average_precision: 0.651664\tvalid_1's average_precision: 0.437655\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's average_precision: 0.592515\tvalid_1's average_precision: 0.402073\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.504199\tvalid_1's average_precision: 0.389497\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's average_precision: 0.494518\tvalid_1's average_precision: 0.446891\n",
      "Avg PR-AUC: 0.4129 | Avg Accuracy: 0.4625\n",
      "\n",
      "Trial 236/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.44225\tvalid_1's average_precision: 0.389628\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.437585\tvalid_1's average_precision: 0.423649\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.479615\tvalid_1's average_precision: 0.397196\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.448831\tvalid_1's average_precision: 0.416989\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's average_precision: 0.522167\tvalid_1's average_precision: 0.461852\n",
      "Avg PR-AUC: 0.4179 | Avg Accuracy: 0.3501\n",
      "\n",
      "Trial 237/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.484088\tvalid_1's average_precision: 0.392396\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.500672\tvalid_1's average_precision: 0.437026\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.494591\tvalid_1's average_precision: 0.401995\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.461434\tvalid_1's average_precision: 0.422504\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.551343\tvalid_1's average_precision: 0.460308\n",
      "Avg PR-AUC: 0.4228 | Avg Accuracy: 0.3936\n",
      "\n",
      "Trial 238/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.874344\tvalid_1's average_precision: 0.403352\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003764 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.727989\tvalid_1's average_precision: 0.42519\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.754978\tvalid_1's average_precision: 0.404265\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.844961\tvalid_1's average_precision: 0.334345\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.809696\tvalid_1's average_precision: 0.424215\n",
      "Avg PR-AUC: 0.3983 | Avg Accuracy: 0.6505\n",
      "\n",
      "Trial 239/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.534681\tvalid_1's average_precision: 0.391967\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.523179\tvalid_1's average_precision: 0.427908\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's average_precision: 0.569559\tvalid_1's average_precision: 0.397371\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.467982\tvalid_1's average_precision: 0.410958\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.455156\tvalid_1's average_precision: 0.452146\n",
      "Avg PR-AUC: 0.4161 | Avg Accuracy: 0.4185\n",
      "\n",
      "Trial 240/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.597972\tvalid_1's average_precision: 0.38537\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.649002\tvalid_1's average_precision: 0.425977\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.545328\tvalid_1's average_precision: 0.398756\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.556673\tvalid_1's average_precision: 0.405048\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.541484\tvalid_1's average_precision: 0.449558\n",
      "Avg PR-AUC: 0.4129 | Avg Accuracy: 0.6633\n",
      "\n",
      "Trial 241/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.593944\tvalid_1's average_precision: 0.411786\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.556527\tvalid_1's average_precision: 0.429693\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.497594\tvalid_1's average_precision: 0.387186\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.49885\tvalid_1's average_precision: 0.398513\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.575414\tvalid_1's average_precision: 0.461489\n",
      "Avg PR-AUC: 0.4177 | Avg Accuracy: 0.3692\n",
      "\n",
      "Trial 242/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.565748\tvalid_1's average_precision: 0.402011\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.580892\tvalid_1's average_precision: 0.447193\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's average_precision: 0.556658\tvalid_1's average_precision: 0.393456\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.445129\tvalid_1's average_precision: 0.404757\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001127 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.465304\tvalid_1's average_precision: 0.457946\n",
      "Avg PR-AUC: 0.4211 | Avg Accuracy: 0.3558\n",
      "\n",
      "Trial 243/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.701436\tvalid_1's average_precision: 0.398297\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.484\tvalid_1's average_precision: 0.435607\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.52302\tvalid_1's average_precision: 0.409333\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.508736\tvalid_1's average_precision: 0.36829\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.593124\tvalid_1's average_precision: 0.451667\n",
      "Avg PR-AUC: 0.4126 | Avg Accuracy: 0.6685\n",
      "\n",
      "Trial 244/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.475679\tvalid_1's average_precision: 0.400848\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.472706\tvalid_1's average_precision: 0.418745\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.428592\tvalid_1's average_precision: 0.383244\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.423266\tvalid_1's average_precision: 0.405739\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.494574\tvalid_1's average_precision: 0.453062\n",
      "Avg PR-AUC: 0.4123 | Avg Accuracy: 0.4845\n",
      "\n",
      "Trial 245/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.55341\tvalid_1's average_precision: 0.389553\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.589474\tvalid_1's average_precision: 0.430374\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.531632\tvalid_1's average_precision: 0.400406\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.485226\tvalid_1's average_precision: 0.410978\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.48168\tvalid_1's average_precision: 0.453437\n",
      "Avg PR-AUC: 0.4169 | Avg Accuracy: 0.3942\n",
      "\n",
      "Trial 246/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.727469\tvalid_1's average_precision: 0.370361\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.773399\tvalid_1's average_precision: 0.449328\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.704905\tvalid_1's average_precision: 0.378271\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.564503\tvalid_1's average_precision: 0.340465\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.677226\tvalid_1's average_precision: 0.424622\n",
      "Avg PR-AUC: 0.3926 | Avg Accuracy: 0.6599\n",
      "\n",
      "Trial 247/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's average_precision: 0.477399\tvalid_1's average_precision: 0.396869\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttraining's average_precision: 0.483148\tvalid_1's average_precision: 0.422368\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.42465\tvalid_1's average_precision: 0.384698\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's average_precision: 0.43568\tvalid_1's average_precision: 0.404293\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[223]\ttraining's average_precision: 0.478651\tvalid_1's average_precision: 0.461015\n",
      "Avg PR-AUC: 0.4138 | Avg Accuracy: 0.4765\n",
      "\n",
      "Trial 248/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.508524\tvalid_1's average_precision: 0.404776\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.590784\tvalid_1's average_precision: 0.433643\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.5947\tvalid_1's average_precision: 0.396863\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.444765\tvalid_1's average_precision: 0.402176\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.466261\tvalid_1's average_precision: 0.456176\n",
      "Avg PR-AUC: 0.4187 | Avg Accuracy: 0.3534\n",
      "\n",
      "Trial 249/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.661118\tvalid_1's average_precision: 0.393399\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.609736\tvalid_1's average_precision: 0.439156\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.638941\tvalid_1's average_precision: 0.405401\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.581205\tvalid_1's average_precision: 0.379687\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.606063\tvalid_1's average_precision: 0.454964\n",
      "Avg PR-AUC: 0.4145 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 250/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.566489\tvalid_1's average_precision: 0.370994\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.568968\tvalid_1's average_precision: 0.415836\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.602005\tvalid_1's average_precision: 0.392344\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.521172\tvalid_1's average_precision: 0.408453\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.530032\tvalid_1's average_precision: 0.457751\n",
      "Avg PR-AUC: 0.4091 | Avg Accuracy: 0.6661\n",
      "\n",
      "Trial 251/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's average_precision: 0.515534\tvalid_1's average_precision: 0.386513\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.446733\tvalid_1's average_precision: 0.425252\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.481569\tvalid_1's average_precision: 0.400003\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.42265\tvalid_1's average_precision: 0.392\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's average_precision: 0.475399\tvalid_1's average_precision: 0.463666\n",
      "Avg PR-AUC: 0.4135 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 252/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.673429\tvalid_1's average_precision: 0.390815\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.687991\tvalid_1's average_precision: 0.440385\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.738535\tvalid_1's average_precision: 0.409798\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.622693\tvalid_1's average_precision: 0.354545\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.649569\tvalid_1's average_precision: 0.452058\n",
      "Avg PR-AUC: 0.4095 | Avg Accuracy: 0.6681\n",
      "\n",
      "Trial 253/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.556981\tvalid_1's average_precision: 0.396704\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.561417\tvalid_1's average_precision: 0.420657\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.506473\tvalid_1's average_precision: 0.399208\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.424147\tvalid_1's average_precision: 0.411212\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.479701\tvalid_1's average_precision: 0.464887\n",
      "Avg PR-AUC: 0.4185 | Avg Accuracy: 0.6661\n",
      "\n",
      "Trial 254/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.498126\tvalid_1's average_precision: 0.394729\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.477775\tvalid_1's average_precision: 0.423405\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.47914\tvalid_1's average_precision: 0.397155\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.555501\tvalid_1's average_precision: 0.415231\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.471361\tvalid_1's average_precision: 0.462848\n",
      "Avg PR-AUC: 0.4187 | Avg Accuracy: 0.4035\n",
      "\n",
      "Trial 255/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.667569\tvalid_1's average_precision: 0.390112\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.549297\tvalid_1's average_precision: 0.414918\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.602264\tvalid_1's average_precision: 0.418463\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.612706\tvalid_1's average_precision: 0.348864\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's average_precision: 0.690189\tvalid_1's average_precision: 0.45083\n",
      "Avg PR-AUC: 0.4046 | Avg Accuracy: 0.6652\n",
      "\n",
      "Trial 256/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.503407\tvalid_1's average_precision: 0.384784\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.441083\tvalid_1's average_precision: 0.415009\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.520428\tvalid_1's average_precision: 0.398797\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.47928\tvalid_1's average_precision: 0.392745\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.468319\tvalid_1's average_precision: 0.455146\n",
      "Avg PR-AUC: 0.4093 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 257/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.554481\tvalid_1's average_precision: 0.398001\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's average_precision: 0.437303\tvalid_1's average_precision: 0.411\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.529953\tvalid_1's average_precision: 0.391685\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.479886\tvalid_1's average_precision: 0.414572\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.496291\tvalid_1's average_precision: 0.45858\n",
      "Avg PR-AUC: 0.4148 | Avg Accuracy: 0.4785\n",
      "\n",
      "Trial 258/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.56127\tvalid_1's average_precision: 0.39378\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.516888\tvalid_1's average_precision: 0.426866\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's average_precision: 0.527657\tvalid_1's average_precision: 0.404526\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.439657\tvalid_1's average_precision: 0.348379\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.476025\tvalid_1's average_precision: 0.455668\n",
      "Avg PR-AUC: 0.4058 | Avg Accuracy: 0.6665\n",
      "\n",
      "Trial 259/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.462928\tvalid_1's average_precision: 0.389905\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.440924\tvalid_1's average_precision: 0.416061\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\ttraining's average_precision: 0.544363\tvalid_1's average_precision: 0.404763\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.441184\tvalid_1's average_precision: 0.428247\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's average_precision: 0.468401\tvalid_1's average_precision: 0.460577\n",
      "Avg PR-AUC: 0.4199 | Avg Accuracy: 0.5347\n",
      "\n",
      "Trial 260/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.472584\tvalid_1's average_precision: 0.392118\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.497783\tvalid_1's average_precision: 0.427735\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.467786\tvalid_1's average_precision: 0.398126\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.458329\tvalid_1's average_precision: 0.412102\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's average_precision: 0.503782\tvalid_1's average_precision: 0.462375\n",
      "Avg PR-AUC: 0.4185 | Avg Accuracy: 0.6100\n",
      "\n",
      "Trial 261/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.60774\tvalid_1's average_precision: 0.404666\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.51775\tvalid_1's average_precision: 0.433888\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.468773\tvalid_1's average_precision: 0.384863\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.448877\tvalid_1's average_precision: 0.406665\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.491229\tvalid_1's average_precision: 0.458273\n",
      "Avg PR-AUC: 0.4177 | Avg Accuracy: 0.3689\n",
      "\n",
      "Trial 262/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.522218\tvalid_1's average_precision: 0.382323\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.810514\tvalid_1's average_precision: 0.442483\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.62434\tvalid_1's average_precision: 0.403444\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.604727\tvalid_1's average_precision: 0.417178\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.558683\tvalid_1's average_precision: 0.450486\n",
      "Avg PR-AUC: 0.4192 | Avg Accuracy: 0.3841\n",
      "\n",
      "Trial 263/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's average_precision: 0.657727\tvalid_1's average_precision: 0.402937\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.553636\tvalid_1's average_precision: 0.437625\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.493054\tvalid_1's average_precision: 0.398034\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.441379\tvalid_1's average_precision: 0.396541\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's average_precision: 0.590483\tvalid_1's average_precision: 0.447205\n",
      "Avg PR-AUC: 0.4165 | Avg Accuracy: 0.3802\n",
      "\n",
      "Trial 264/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.647828\tvalid_1's average_precision: 0.385998\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.64156\tvalid_1's average_precision: 0.419387\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.703803\tvalid_1's average_precision: 0.400179\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.613712\tvalid_1's average_precision: 0.356361\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.566999\tvalid_1's average_precision: 0.443427\n",
      "Avg PR-AUC: 0.4011 | Avg Accuracy: 0.6665\n",
      "\n",
      "Trial 265/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.505485\tvalid_1's average_precision: 0.388257\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.46902\tvalid_1's average_precision: 0.410203\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.473429\tvalid_1's average_precision: 0.387065\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.49008\tvalid_1's average_precision: 0.4154\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's average_precision: 0.484807\tvalid_1's average_precision: 0.458144\n",
      "Avg PR-AUC: 0.4118 | Avg Accuracy: 0.6043\n",
      "\n",
      "Trial 266/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.447026\tvalid_1's average_precision: 0.391072\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.439965\tvalid_1's average_precision: 0.414239\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's average_precision: 0.468903\tvalid_1's average_precision: 0.395157\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's average_precision: 0.447408\tvalid_1's average_precision: 0.420647\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.441779\tvalid_1's average_precision: 0.45228\n",
      "Avg PR-AUC: 0.4147 | Avg Accuracy: 0.5500\n",
      "\n",
      "Trial 267/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's average_precision: 0.547122\tvalid_1's average_precision: 0.388457\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.518614\tvalid_1's average_precision: 0.426429\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.468689\tvalid_1's average_precision: 0.397831\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.445746\tvalid_1's average_precision: 0.430523\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.477843\tvalid_1's average_precision: 0.468396\n",
      "Avg PR-AUC: 0.4223 | Avg Accuracy: 0.6669\n",
      "\n",
      "Trial 268/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.561269\tvalid_1's average_precision: 0.389145\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.707756\tvalid_1's average_precision: 0.429472\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.640188\tvalid_1's average_precision: 0.391715\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.543729\tvalid_1's average_precision: 0.417187\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's average_precision: 0.578921\tvalid_1's average_precision: 0.455457\n",
      "Avg PR-AUC: 0.4166 | Avg Accuracy: 0.3781\n",
      "\n",
      "Trial 269/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.606648\tvalid_1's average_precision: 0.397768\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.55561\tvalid_1's average_precision: 0.422836\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.519205\tvalid_1's average_precision: 0.405576\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.558937\tvalid_1's average_precision: 0.419425\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.519857\tvalid_1's average_precision: 0.455579\n",
      "Avg PR-AUC: 0.4202 | Avg Accuracy: 0.3677\n",
      "\n",
      "Trial 270/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.484327\tvalid_1's average_precision: 0.393282\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.441337\tvalid_1's average_precision: 0.413334\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.481948\tvalid_1's average_precision: 0.397444\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.423128\tvalid_1's average_precision: 0.37356\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.479735\tvalid_1's average_precision: 0.462202\n",
      "Avg PR-AUC: 0.4080 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 271/300: {'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.494193\tvalid_1's average_precision: 0.3838\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.46685\tvalid_1's average_precision: 0.416839\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.465289\tvalid_1's average_precision: 0.38829\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.482443\tvalid_1's average_precision: 0.410374\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's average_precision: 0.475771\tvalid_1's average_precision: 0.458722\n",
      "Avg PR-AUC: 0.4116 | Avg Accuracy: 0.6440\n",
      "\n",
      "Trial 272/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.665809\tvalid_1's average_precision: 0.40729\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.721904\tvalid_1's average_precision: 0.439457\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.559813\tvalid_1's average_precision: 0.393641\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.448452\tvalid_1's average_precision: 0.39907\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.564224\tvalid_1's average_precision: 0.450661\n",
      "Avg PR-AUC: 0.4180 | Avg Accuracy: 0.3993\n",
      "\n",
      "Trial 273/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.530154\tvalid_1's average_precision: 0.388649\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.495239\tvalid_1's average_precision: 0.408066\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's average_precision: 0.588329\tvalid_1's average_precision: 0.39748\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's average_precision: 0.47217\tvalid_1's average_precision: 0.349779\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.48808\tvalid_1's average_precision: 0.454418\n",
      "Avg PR-AUC: 0.3997 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 274/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.460533\tvalid_1's average_precision: 0.39205\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.430065\tvalid_1's average_precision: 0.422962\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.486883\tvalid_1's average_precision: 0.398139\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.458202\tvalid_1's average_precision: 0.408328\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's average_precision: 0.475876\tvalid_1's average_precision: 0.454309\n",
      "Avg PR-AUC: 0.4152 | Avg Accuracy: 0.3473\n",
      "\n",
      "Trial 275/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's average_precision: 0.548889\tvalid_1's average_precision: 0.393523\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's average_precision: 0.544028\tvalid_1's average_precision: 0.431477\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.482377\tvalid_1's average_precision: 0.402402\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.441509\tvalid_1's average_precision: 0.408096\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's average_precision: 0.509444\tvalid_1's average_precision: 0.453826\n",
      "Avg PR-AUC: 0.4179 | Avg Accuracy: 0.3771\n",
      "\n",
      "Trial 276/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.580261\tvalid_1's average_precision: 0.411749\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.508751\tvalid_1's average_precision: 0.425837\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.516008\tvalid_1's average_precision: 0.400319\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.424391\tvalid_1's average_precision: 0.384228\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.554965\tvalid_1's average_precision: 0.457365\n",
      "Avg PR-AUC: 0.4159 | Avg Accuracy: 0.6694\n",
      "\n",
      "Trial 277/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.580616\tvalid_1's average_precision: 0.385888\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.659855\tvalid_1's average_precision: 0.452042\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.708761\tvalid_1's average_precision: 0.382346\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.51753\tvalid_1's average_precision: 0.356896\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.605144\tvalid_1's average_precision: 0.441595\n",
      "Avg PR-AUC: 0.4038 | Avg Accuracy: 0.6677\n",
      "\n",
      "Trial 278/300: {'learning_rate': 0.1, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.684764\tvalid_1's average_precision: 0.375665\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.436278\tvalid_1's average_precision: 0.411566\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.706108\tvalid_1's average_precision: 0.375538\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.560971\tvalid_1's average_precision: 0.404271\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's average_precision: 0.666062\tvalid_1's average_precision: 0.440099\n",
      "Avg PR-AUC: 0.4014 | Avg Accuracy: 0.6656\n",
      "\n",
      "Trial 279/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.610711\tvalid_1's average_precision: 0.383282\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.727699\tvalid_1's average_precision: 0.418388\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.563255\tvalid_1's average_precision: 0.39018\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.553467\tvalid_1's average_precision: 0.387253\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.517\tvalid_1's average_precision: 0.448013\n",
      "Avg PR-AUC: 0.4054 | Avg Accuracy: 0.4062\n",
      "\n",
      "Trial 280/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's average_precision: 0.527931\tvalid_1's average_precision: 0.384381\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.44674\tvalid_1's average_precision: 0.425252\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's average_precision: 0.481419\tvalid_1's average_precision: 0.3985\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's average_precision: 0.42285\tvalid_1's average_precision: 0.39271\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\ttraining's average_precision: 0.495747\tvalid_1's average_precision: 0.466118\n",
      "Avg PR-AUC: 0.4134 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 281/300: {'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.421111\tvalid_1's average_precision: 0.386612\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.412383\tvalid_1's average_precision: 0.411384\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttraining's average_precision: 0.44815\tvalid_1's average_precision: 0.392297\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.422037\tvalid_1's average_precision: 0.422166\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.418134\tvalid_1's average_precision: 0.449748\n",
      "Avg PR-AUC: 0.4124 | Avg Accuracy: 0.5622\n",
      "\n",
      "Trial 282/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.443185\tvalid_1's average_precision: 0.390208\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.432984\tvalid_1's average_precision: 0.404396\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.461711\tvalid_1's average_precision: 0.39063\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.444078\tvalid_1's average_precision: 0.406602\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.46996\tvalid_1's average_precision: 0.460184\n",
      "Avg PR-AUC: 0.4104 | Avg Accuracy: 0.3488\n",
      "\n",
      "Trial 283/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's average_precision: 0.611779\tvalid_1's average_precision: 0.375912\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.513834\tvalid_1's average_precision: 0.417081\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.522298\tvalid_1's average_precision: 0.391879\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's average_precision: 0.59062\tvalid_1's average_precision: 0.375239\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.514845\tvalid_1's average_precision: 0.453794\n",
      "Avg PR-AUC: 0.4028 | Avg Accuracy: 0.6652\n",
      "\n",
      "Trial 284/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': -1, 'min_data_in_leaf': 20, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.598192\tvalid_1's average_precision: 0.392367\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's average_precision: 0.744213\tvalid_1's average_precision: 0.428332\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.562054\tvalid_1's average_precision: 0.403032\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.479638\tvalid_1's average_precision: 0.40572\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.516293\tvalid_1's average_precision: 0.455851\n",
      "Avg PR-AUC: 0.4171 | Avg Accuracy: 0.3979\n",
      "\n",
      "Trial 285/300: {'learning_rate': 0.15, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.588205\tvalid_1's average_precision: 0.388124\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.399376\tvalid_1's average_precision: 0.412345\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's average_precision: 0.577277\tvalid_1's average_precision: 0.406418\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.503647\tvalid_1's average_precision: 0.399782\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's average_precision: 0.587622\tvalid_1's average_precision: 0.454738\n",
      "Avg PR-AUC: 0.4123 | Avg Accuracy: 0.6675\n",
      "\n",
      "Trial 286/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 0, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.813749\tvalid_1's average_precision: 0.367226\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.43377\tvalid_1's average_precision: 0.412247\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.677243\tvalid_1's average_precision: 0.388679\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.582987\tvalid_1's average_precision: 0.38686\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001095 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's average_precision: 0.56631\tvalid_1's average_precision: 0.454081\n",
      "Avg PR-AUC: 0.4018 | Avg Accuracy: 0.6638\n",
      "\n",
      "Trial 287/300: {'learning_rate': 0.1, 'num_leaves': 15, 'max_depth': 10, 'min_data_in_leaf': 20, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.558534\tvalid_1's average_precision: 0.407361\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000749 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.489643\tvalid_1's average_precision: 0.422913\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.445747\tvalid_1's average_precision: 0.392949\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.462077\tvalid_1's average_precision: 0.407814\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.502132\tvalid_1's average_precision: 0.458838\n",
      "Avg PR-AUC: 0.4180 | Avg Accuracy: 0.3484\n",
      "\n",
      "Trial 288/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.8, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.463776\tvalid_1's average_precision: 0.393335\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.462714\tvalid_1's average_precision: 0.414995\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's average_precision: 0.493579\tvalid_1's average_precision: 0.397839\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's average_precision: 0.457533\tvalid_1's average_precision: 0.42623\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's average_precision: 0.471229\tvalid_1's average_precision: 0.46219\n",
      "Avg PR-AUC: 0.4189 | Avg Accuracy: 0.5536\n",
      "\n",
      "Trial 289/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\ttraining's average_precision: 0.571904\tvalid_1's average_precision: 0.394314\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's average_precision: 0.536251\tvalid_1's average_precision: 0.443634\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's average_precision: 0.568917\tvalid_1's average_precision: 0.405833\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's average_precision: 0.521971\tvalid_1's average_precision: 0.4062\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034885 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[68]\ttraining's average_precision: 0.477193\tvalid_1's average_precision: 0.459476\n",
      "Avg PR-AUC: 0.4219 | Avg Accuracy: 0.4392\n",
      "\n",
      "Trial 290/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': -1, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's average_precision: 0.508006\tvalid_1's average_precision: 0.393622\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.482029\tvalid_1's average_precision: 0.409249\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's average_precision: 0.491512\tvalid_1's average_precision: 0.40714\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's average_precision: 0.422029\tvalid_1's average_precision: 0.404532\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's average_precision: 0.524673\tvalid_1's average_precision: 0.465118\n",
      "Avg PR-AUC: 0.4159 | Avg Accuracy: 0.3637\n",
      "\n",
      "Trial 291/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 50, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's average_precision: 0.452846\tvalid_1's average_precision: 0.393719\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.484885\tvalid_1's average_precision: 0.426415\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's average_precision: 0.501831\tvalid_1's average_precision: 0.396749\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.464599\tvalid_1's average_precision: 0.41191\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.517558\tvalid_1's average_precision: 0.461376\n",
      "Avg PR-AUC: 0.4180 | Avg Accuracy: 0.4265\n",
      "\n",
      "Trial 292/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's average_precision: 0.807701\tvalid_1's average_precision: 0.394125\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.534248\tvalid_1's average_precision: 0.420389\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.579743\tvalid_1's average_precision: 0.402105\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.582335\tvalid_1's average_precision: 0.358405\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's average_precision: 0.508667\tvalid_1's average_precision: 0.4533\n",
      "Avg PR-AUC: 0.4057 | Avg Accuracy: 0.6630\n",
      "\n",
      "Trial 293/300: {'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's average_precision: 0.432884\tvalid_1's average_precision: 0.382301\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000793 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's average_precision: 0.430803\tvalid_1's average_precision: 0.409469\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's average_precision: 0.491564\tvalid_1's average_precision: 0.402263\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's average_precision: 0.47822\tvalid_1's average_precision: 0.422618\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's average_precision: 0.47074\tvalid_1's average_precision: 0.457622\n",
      "Avg PR-AUC: 0.4149 | Avg Accuracy: 0.3813\n",
      "\n",
      "Trial 294/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 1.0, 'lambda_l2': 0.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's average_precision: 0.514242\tvalid_1's average_precision: 0.393593\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.485461\tvalid_1's average_precision: 0.423125\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's average_precision: 0.495272\tvalid_1's average_precision: 0.409011\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's average_precision: 0.462605\tvalid_1's average_precision: 0.412955\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's average_precision: 0.476812\tvalid_1's average_precision: 0.457186\n",
      "Avg PR-AUC: 0.4192 | Avg Accuracy: 0.5239\n",
      "\n",
      "Trial 295/300: {'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 20, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.486256\tvalid_1's average_precision: 0.386835\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's average_precision: 0.507746\tvalid_1's average_precision: 0.407645\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.459129\tvalid_1's average_precision: 0.385644\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's average_precision: 0.535763\tvalid_1's average_precision: 0.340725\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's average_precision: 0.543143\tvalid_1's average_precision: 0.458379\n",
      "Avg PR-AUC: 0.3958 | Avg Accuracy: 0.6663\n",
      "\n",
      "Trial 296/300: {'learning_rate': 0.05, 'num_leaves': 63, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.6, 'bagging_fraction': 1.0, 'bagging_freq': 0, 'lambda_l1': 0.1, 'lambda_l2': 1.0, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's average_precision: 0.705868\tvalid_1's average_precision: 0.371019\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's average_precision: 0.437327\tvalid_1's average_precision: 0.411556\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.673244\tvalid_1's average_precision: 0.41033\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.605459\tvalid_1's average_precision: 0.424698\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.635263\tvalid_1's average_precision: 0.448089\n",
      "Avg PR-AUC: 0.4131 | Avg Accuracy: 0.6665\n",
      "\n",
      "Trial 297/300: {'learning_rate': 0.15, 'num_leaves': 15, 'max_depth': 5, 'min_data_in_leaf': 10, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's average_precision: 0.534321\tvalid_1's average_precision: 0.399853\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's average_precision: 0.576977\tvalid_1's average_precision: 0.428242\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's average_precision: 0.49968\tvalid_1's average_precision: 0.397764\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's average_precision: 0.458859\tvalid_1's average_precision: 0.423737\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's average_precision: 0.536374\tvalid_1's average_precision: 0.447073\n",
      "Avg PR-AUC: 0.4193 | Avg Accuracy: 0.3505\n",
      "\n",
      "Trial 298/300: {'learning_rate': 0.15, 'num_leaves': 63, 'max_depth': 5, 'min_data_in_leaf': 20, 'feature_fraction': 1.0, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 1.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's average_precision: 0.584078\tvalid_1's average_precision: 0.386386\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's average_precision: 0.549677\tvalid_1's average_precision: 0.401726\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.548685\tvalid_1's average_precision: 0.406922\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.573286\tvalid_1's average_precision: 0.369449\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's average_precision: 0.561955\tvalid_1's average_precision: 0.448011\n",
      "Avg PR-AUC: 0.4025 | Avg Accuracy: 0.6664\n",
      "\n",
      "Trial 299/300: {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'lambda_l1': 1.0, 'lambda_l2': 1.0, 'scale_pos_weight': 5.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007272 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's average_precision: 0.61126\tvalid_1's average_precision: 0.39327\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.583224\tvalid_1's average_precision: 0.436361\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's average_precision: 0.616492\tvalid_1's average_precision: 0.396747\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's average_precision: 0.483751\tvalid_1's average_precision: 0.392758\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's average_precision: 0.493538\tvalid_1's average_precision: 0.462541\n",
      "Avg PR-AUC: 0.4163 | Avg Accuracy: 0.3873\n",
      "\n",
      "Trial 300/300: {'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': 10, 'min_data_in_leaf': 10, 'feature_fraction': 0.8, 'bagging_fraction': 0.6, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.0, 'scale_pos_weight': 8.0}\n",
      "[LightGBM] [Info] Number of positive: 13832, number of negative: 32558\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 46390, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298168 -> initscore=-0.856038\n",
      "[LightGBM] [Info] Start training from score -0.856038\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's average_precision: 0.501869\tvalid_1's average_precision: 0.396669\n",
      "[LightGBM] [Info] Number of positive: 16472, number of negative: 38674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 55146, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298698 -> initscore=-0.853506\n",
      "[LightGBM] [Info] Start training from score -0.853506\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's average_precision: 0.507717\tvalid_1's average_precision: 0.42276\n",
      "[LightGBM] [Info] Number of positive: 20036, number of negative: 44138\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 64174, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.312214 -> initscore=-0.789790\n",
      "[LightGBM] [Info] Start training from score -0.789790\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's average_precision: 0.545501\tvalid_1's average_precision: 0.398501\n",
      "[LightGBM] [Info] Number of positive: 22923, number of negative: 50239\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 73162, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313318 -> initscore=-0.784651\n",
      "[LightGBM] [Info] Start training from score -0.784651\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's average_precision: 0.474164\tvalid_1's average_precision: 0.420227\n",
      "[LightGBM] [Info] Number of positive: 25790, number of negative: 56602\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 82392, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313016 -> initscore=-0.786058\n",
      "[LightGBM] [Info] Start training from score -0.786058\n",
      "Training until validation scores don't improve for 25 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's average_precision: 0.457712\tvalid_1's average_precision: 0.449687\n",
      "Avg PR-AUC: 0.4176 | Avg Accuracy: 0.3610\n",
      "[LightGBM] [Info] Number of positive: 28895, number of negative: 62641\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3537\n",
      "[LightGBM] [Info] Number of data points in the train set: 91536, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.315668 -> initscore=-0.773751\n",
      "[LightGBM] [Info] Start training from score -0.773751\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Best Config: PR-AUC: 0.4239 | Accuracy: 0.4180 | params_config {'learning_rate': 0.1, 'num_leaves': 31, 'max_depth': 5, 'min_data_in_leaf': 50, 'feature_fraction': 1.0, 'bagging_fraction': 1.0, 'bagging_freq': 5, 'lambda_l1': 0.0, 'lambda_l2': 0.1, 'scale_pos_weight': 5.0, 'objective': 'binary', 'metric': 'average_precision', 'boosting_type': 'gbdt', 'seed': 42} \n"
     ]
    }
   ],
   "source": [
    "# Train LightGBM with walk-forward CV\n",
    "results_df, best_config, best_model, best_oof_preds = random_search_lightgbm(final_df,\n",
    "                                                                            final_df.drop(columns=[\"strat_return\"]).columns,\n",
    "                                                                            categorical_features = categ_feats,\n",
    "                                                                            target='strat_return',\n",
    "                                                                            n_splits=5,\n",
    "                                                                            n_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83bee30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAImCAYAAABJp6KRAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXh5JREFUeJzt3QeYU1X+xvEfvRdRmhRRUJoiIEUUFFCxrpX1L4qKSrEiIlgRCxYEFEVFQcGO2AVddLGwq6srgrqWpSgKClIFBIGhzcz/ec/snclkZiCTyeTm3vl+nidMkrlJTnIy5M3vnntOqczMzEwDAAAAQqC03w0AAAAAEoVwCwAAgNAg3AIAACA0CLcAAAAIDcItAAAAQoNwCwAAgNAg3AIAACA0CLcAAAAIDcItAPwPa9oAQPARboEU9d1339nw4cOte/fu1qZNGzv++OPttttus+XLl1sqO/HEE+3UU08t8Pc7d+60zp072w033BDT/TVv3tweeeQRd37u3Lnusn7GeptYffjhh3bjjTdmX471sRLBe6zIU4sWLax9+/Z23nnn2UcffWTJsGLFCvfYb7zxRrFsXxyvk06HHnqoHXPMMe49tW7dOvNDz5497aabbir0eyeof+dAKivrdwMA5PXiiy/avffe60Lg9ddfb3Xq1LFffvnFpkyZYrNnz7Znn33WhZ9UdPbZZ9uDDz5oCxcutJYtW+b5/T/+8Q/7448/7K9//Wuh77t169b28ssvW7NmzSzRnnnmmaQ9VkFGjhzpHterIm/atMmmTp1qV155pU2aNMmOPfbYYn18vc/0nBs3blws2xfH6yRbt261L7/80iZPnmxLly61V1991YIgyH/nQCoj3AIpRh/S99xzj11wwQV26623Zl+vD0BVdc4880y75ZZbklYtKyy17+GHH7aZM2fmG27ffPNNa9KkiXXs2LHQ9121alVr27ZtglqaOo/lUZCOfswOHTq4qt5zzz1X7OG2fPnyhXrOhd2+OF+no48+2u0VePLJJ23JkiVJ/VJSEv/OgVTGsAQgxahqU61aNRs6dGie39WqVcvt+jzuuONs27Zt2btDVf25+OKL3W5N74Ny7dq1dvPNN7tApOt79+7tdr1H+vTTT+3cc8+1du3aubB5xRVX2E8//ZT9+19//dUuv/xy94F7+OGH2//93//ZP//5zz22v27dutatWzf729/+ZhkZGbl+t2HDBvvkk0/snHPOyd6trV3JXbt2dZW4Ll26uMsbN27M977z2937xRdfuHapfRoS8dlnn+W53d4e58ILL3T3o5N3//k9lnYhX3bZZe710JABvTY//vhjnvb9+9//tksvvdS1SaFr7Nixlp6ebvGG7AMPPNBWrlyZ6zGmT59uPXr0cO1QP8r8+fOtb9++7nE7derkhlnoNY/0888/29VXX+1+rz4fNGhQdp9HDzNQ/40fP969x7TrXz8feOAB27VrV77by7Jly2zw4MHueSuA6rVVkIvsC93m3Xffddvpvae2jBgxIvs9Ha/q1au7n6VKlcq+7ocffnDPUa+TTldddVWeXf76W9FrpfeF2qPX8Ouvv87+vV7DO++8073eeh3UXt2Pnkuy/s7zG2qjy7reo9vo/4Hbb7/dPddTTjnFLrnkErc3JZr2Bpx++unZl2N57wBBQbgFUoh2Rf/rX/9yH7KVKlXKdxt9YOmDtXLlyrl2bx522GE2ceJEF2J///1391MfWNddd537EGzQoIG7nSqqog94fcDpw/rxxx93VSTt0h04cKALNTopFKSlpdmYMWPcfdesWdMFYO063ROF1zVr1riwGOmdd95xz/Gss85y93vRRRe5YKUPY33Y67JCsQJVLP773/+6EKmQMGHCBHf76LAQy+Po+latWrmTdrNH7vL2fP7559anTx93Xl8m7r77blu1apUbExv5hUCGDRtmRxxxhD3xxBN22mmn2VNPPRX3rnJVIxWionf9P/rooy6AaBe9Atm8efOsX79+VrFiRXvooYdc1U+vv57r9u3b3W3UJ/oioAB6xx13uNCt94oCkYaKRFMV9KWXXnLvGw2P0PPX66f3S35UMVWQUnsVVseNG+eCpu4/+r2g11zvSb2v9IXhtddeK/B+o+m9uXv37uyT2q7d+Gqbvsjpy4Do/az+Wb9+vd1///3uPa73vZ6HrvOGNOiyvjRo7Kte1woVKrj3lV4nvV/1d6AvEOpXPYa+HOgLjJ5DMv/OY6G/eb0vH3vsMTfU4YwzznB/J5F/s5s3b7aPP/7Y/U5iee8AQcKwBCCFqJK4Y8cOa9iwYaFut//++7sPXo9Ci6ouf//7312AEFVw9QGmoKrA9e2337oPLn1wq9oq9erVc9VdVYsUClXlUwD2docrOOjDX4FrT1ThUvXp7bfftiOPPDL7+rfeessd+FO7dm03JlePp9DRqFEj93tt+8033+QJQgXRONR9993XhaJy5cq56/bZZx8X6D0KKHt7HO3CVoVUCtrNrorlAQcc4MZ1lilTxl2nSvAJJ5zggrWGYng0nljBRBRgPvjgAzfWWEErltAm+vnbb7+58Ke+1O7rSOeff76ddNJJudqnUKfXxGufqnA6uO/11193t9e4YvXd008/7fpANKZT4U6vR9OmTXM9hl4fffnxKu2q6CmM6ctEfvTe0FAFDaHwXk8NqdD7Te87BViP3lPeAXx6jRQe9RopkO2N3sfRatSo4SqdCqilS5fObo/aq+fttUePpd3++sKhx9cwGb3O+ukNo1HVU8MCFPp0e520rYaIiCr32quhL0LJ/DuPhd43d911l3vPi/6WVXXWF0vvPakvAtqToH6J9b0DBAnhFkgh3gdLYXdhR49tVShRNc8Lth7thtRQBYVWfXipQqUKr0KSQqc+tBVgpUqVKi706chtVZkU5LSNbu/xglhk+1WpU9BUVUgfjKpuKfBo970qSN4HrNo8bdo0F+gUQFVZUuVPbYu+34Jod7eCtBdspVevXtmvY6IeRwFBQxJUsYu8b+0G1+NHD9XQax9JQSOWXe75hTaFd1VB9doX1Of6IqJwqgqoqoLe81KYV2BVcFRA0eul8O4FW69tc+bMceejd7Pr/aDgoyCtIQkKqtp1XRC97/R6eEFSypYt60KSKomqknqiv0SoHQqZ4u05iKT78SisqbqubfRlTEFVwx+uueaaPNV2BXJVJL3XRG1TSPWGr+g1UciMfD0VZvXF0KOwrtdVr4/eP3rvfPXVV3v9kpfov/NYaO+KF2xFlV+F+VmzZmX/7WmvhUK+vtTG+t4BgoRwC6QQVZ8UKr3xlflRSNKYR23rid51qaPsvSplpP322y97t6SC6wsvvOAqkaqo6QNcYU1BZsiQIS6kale0qqLvv/++q7oqROqDUuHizz//dJWySPfdd1/2+D5V+1QhVDVOgVOVMYUqBSSPfq9d99qtrLapSqhgofuOhZ6nKrXRISj6uqI+jrbTB7/3+kW/ptH3ozAVSZXEWObQ9UKbF4DUx6rKR44hza/P1Z8KehpGoFM0fYkRPf/CVAv79+/v3o/6kqIhBtojcPDBB7uwHVmRj+yPgl4jPf8tW7ZkXxe9Oz7yNVIQVtU10uLFi7PPq8qoYTiiL2l6X3rDCTSsxqPnq1CnUzTtWfC20ReIPdFQHs0Aot39Co8KwtF9nIy/81jofqPpi6aew6JFi1xfaAiGhtYU5r0DBAnhFkgxqpDqw0e7LfP7YHnllVfcLnYF0vzGhoo+EPOb79O7zgt/kcMMVMHSblaFQO2qPvnkk11lR2MzVX3VB+N7773nPgB1e1VwI3czS2RwUghS8NDuUAViDVHQWFuvaqXLo0ePdruRFYi9sHHttde6KmksFDQ0ZjSSN4WWJxGPo93wCpjRj+W9pmpHIkSGtsIGGrVPld/85hj2gqSeR34HCWn8qPouOkQrcKpqp5PGqKpCrfeHKqTeQWzR77uCXiPR+0YHb+2NDnKM/BK0NxoHrqEfGh6i2x1yyCHZz/eoo45yB1VF8yrB2ia/A8NUmdXz0RACDUlQZVjVTW8Ij4ZZRB4ol4y/8+hKb6wH4KlKqy+WOohPP/V4+sJZmPcOECQcUAakGB3IomqSDuzILySomqqqa0HBVnQUvI729nbzelS90Yebxo5qHKJ2ISvYatiAPgBHjRrltlNFSbdXMNDYXH34qVqlsawKDvq9bqMgFnmKrpiqeqsDVzSsQaHGG7spCgaqFKs66AVOb77S6F3SBVGbdf/aterRbAze0fyFeRxvnGZ+VCVVtVfhIDJgqGKryrQOHvOTdrXrYDjtLo/sD33B0MGE3owP2h2vXdCRAVehVa9NfrNgaIywDpwTVTf15UBBV9W+yCps5PtOQxwif6fXS7vB1R69Z2KhABn93toTBVV9CdMuda+9oiEJGoKi9653P+pHvfe1N8J7TXSQWeSsFwqcCvAKlvo70PtEl71gq+fkDWuI9b1a1L9z9bEOCIwO4LHQF8q//OUvrm/0BVVfNr3Kf6zvHSBICLdAitFYRFUV9eGmXazaparKmoYNaHysPnjz+0CMpEqVqomqxsyYMcMFFwVTjUHUTwU57VbWh6jG4en3CqCqxiqAKPTqA0+7XjVllsKJPuQ0u4AOBNOUW7HwKkE6Sl1BQ/PbelQ1VkhSVVX3rQqrgpMqf5FhdU/UdlWvVFHTKl4KIzrSO3IMbqyPowCso+v1WkdWfj060MmbTULjPBUSNAuAvhx4Yxn9pFki1Idqp/pTr4dCq56PF5D0flD/6nqNKdU2ms5MYzQVfvILq5otQdVavXb6cqQhHupL74tCJI1J1vtTR9nr9dHrpMdSeMxvyqtE0jhnjSlXO/UlRHQwpA780kGTquzqi49Cqt7P3uIICuwawqPqr56fttHz0BckDdHxxqDrIC39/eh109+X9mRIvNOXFfbvXBVptVtTwGk77YnY26wl0UMTNLRDX+q8WRIK894BgoRwC6QgfdBqLKxobJw+/DQ+Vh9wGvsafVR7NFVnFUr0waRKlj5ENV5QR9571VN9uCu0qMqmDzd9oKuSpA/bgw46yO261HlVcBROFSAVVvQhn9+8mflRVUhBWAdyRVZtRUMUFAoVRAYMGOB2KauKpvtXO6Kn18qPwrJeF1WmFNr1/LQLOXKcYqyPo8CrUKxtVA3Or0qsYKcZJvR66UA7VfK0+9jbDe4n7ebWNFWrV69288fqS4leF7XZO3irfv367uA6rYSlOVH1ZUbXaSWs/MZ26n2j8Ksxtwo7+oKgx9FrmB+9V3T/qvLqvhXANExEgU17AYqbZgzRbnYNGdAXF73HNU2e9jzo9dDroi90GtPr7ZbXe1TvIQ2h0Z4LjTdXNVZtVujVQXWabk0VXL039BpoHLQ3JrgoQxMK83eu11NfOjVUQc9DlddYZpbw6LXQ+1R9o/dyYd87QJCUyozlKAcAAAAgAKjcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAiNEr/8ruYu1GxokZO+AwAAIHVoYRXNWa0FW/amxFduFWyTOdWvHksrGjG9cHDRh8FHHwYb/Rd89GHwZSa5DwuT10p85dar2O5t7fJE0VKNWr5Ua4Z7a3sjWOjD4KMPg43+Cz76MPi2JbkPv/vuu5i3LfGVWwAAAIQH4RYAAAChQbgFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAChQbgFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAChQbgFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAChkVLhdtKkSXbhhRfucZuNGzfa9ddfbx07drROnTrZnXfeaWlpaUlrIwAAAFJXWb8b4HnxxRftoYcesg4dOuxxu8GDB7sw+8wzz9jmzZvt1ltvtW3bttn999+ftLYCAAAgNfkebtesWWO33367zZ0715o0abLHbb/++mv74osvbNasWda0aVN33V133WX9+/e3oUOHWt26dZPUagAAAKQi34cl/Pe//7Vy5crZzJkz7fDDD9/jtvPnz7fatWtnB1vR0IRSpUrZl19+aUGQmWn2xx9l/G4GAABAKPleue3Zs6c7xVrlrV+/fq7rypcvbzVr1rRVq1bF3YbMzEw3tCEZzjqrrL3/flsbOnSbjRqVnMdEYnljvBnrHVz0YbDRf8FHHwZfWpL7UFlNxcxAhNvC0AuoMButQoUKtmPHjrjvd9euXbZw4UIrbrt3m73//hHu/LRpZez8878v9sdE8Vm2bJnfTUAR0YfBRv8FH30YfMuS2If5ZcDAh9uKFSvazp0781yvYFu5cuW471fDIpo1a2bJVKpUWWvZsmVSHxOJ+5KlP2aNEa9UqZLfzUEc6MNgo/+Cjz4MvrQk9+GSJUti3jZQ4bZevXr2wQcf5LpOYfePP/6wOnXqxH2/KnMXJRwXRoMGGfbbb6WT+pgoHvpjpg+DjT4MNvov+OjD4KuUpD6MdUhCShxQVhia23b16tX2yy+/ZF+n2RPkiCOydvcDAACg5ErpcJuenm7r1q2z7du3u8uaTaF9+/Z23XXX2bfffmuff/65jRw50s4880ymAQMAAEBqh1vNgNC1a1c3r61Xkn700UetYcOGdvHFF9uQIUPsmGOOsTvuuMPvpgIAACAFpNSY29GjR+e6rBC7ePHiXNftu+++NmHChCS3DAAAAEGQ0pVbAAAAoDAItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQIt0n2229ZL/nKlbz0AAAAiUbC8tHq1X63AAAAIFwItz5ascLvFgAAAIQL4dZHpXn1AQAAEsr3eJWRkWETJkywbt26Wdu2bW3AgAG2fPnyArdftmyZDRw40Dp06GDHHHOMu+3u3bstiAi3AAAAieV7vJo4caJNmzbNRo0aZdOnT3dht3///rZz5848227atMkuuOACS0tLs2effdYefPBBe/fdd23kyJEWRKVK+d0CAACAcPE13CrATp061QYPHmzdu3e3Fi1a2Pjx42316tU2e/bsPNu/+eabtm3bNnv44YetdevWrnp799132+uvv24rAjiAlcotAABAYvkarxYtWmRbt261Ll26ZF9XvXp1a9Wqlc2bNy/P9r/88osddNBBVqtWrezrtK3Mnz/fgoZwCwAAkFi+xitVaKV+/fq5rq9Tp07276KvX7t2raWnp2df99tvv7mf69evt6Ah3AIAACRWWfORxs5K+fLlc11foUIFN7422sknn+zG6N533302dOhQN0RBwxLKli1ru3btirsdmZmZ7r6So3L2ue3b02zbtswkPS4S/b71fiJ46MNgo/+Cjz4MvrQk96GyWqkYD1byNdxWrFgxe+ytd1527NhhlSpVyrN9kyZN3HhbHUD24osvWuXKle2aa66xJUuWWLVq1eJuh4LxwoULLTmOyD63dOlPlpGxI0mPi0TTzB0INvow2Oi/4KMPg29ZEvswuhiakuHWG46goQaNGzfOvl6Xmzdvnu9tevbs6U7apmbNmm4asNGjR1ujRo3ibke5cuWsWbNmlmwHH9zUmjalchs0+paqP2Z92crvSxhSH30YbPRf8NGHwZeW5D5UITNWvoZbzY5QtWpVmzt3bna43bx5sy1YsMD69u2bZ3sdNKbK7dNPP+3G38qsWbPci9q+ffu426Eyt6rAyVa5ciXz4WGRIHrf+fG+QeLQh8FG/wUffRh8lZLUh7EOSfA93Kq8rBA7btw4NwNCgwYNbOzYsVavXj3r1auXO3Bsw4YNbsiBhi1opoTFixfb/fffbxdddJE7rzG3gwYNciE5aDigDAAAILF8DbeiOW41tGDEiBG2fft269ixo02ZMsUNFdDctccdd5w7gOzss892AfiJJ55wwxBOO+00q127tl199dXWr18/CyIWcQAAAAhZuC1TpowNHz7cnaI1bNjQVWcjafjBK6+8ksQWAgAAICjYMe4jKrcAAACJRbj1EeEWAAAgsQi3PiLcAgAAJBbh1keEWwAAgMQi3PqIcAsAAJBYhFsAAACEBuEWAAAAoUG4BQAAQGgQbgEAABAahFsAAACEBuHWR5mZfrcAAAAgXAi3AAAACA3CLQAAAEKDcAsAAIDQINwCAAAgNAi3AAAACA3CLQAAAEKDcAsAAIDQINwCAAAgNAi3Pvr1V79bAAAAEC6EWx8dfbRZerrfrQAAAAgPwq3PfvzR7xYAAACEB+HWZ+XK+d0CAACA8CDc+qxsWb9bAAAAEB6EW58RbgEAABKHcOszwi0AAEDiEG59VpoeAAAASBiiFQAAAEKDcOuznTv9bgEAAEB4EG59NmaM3y0AAAAID8KtzyZM8LsFAAAA4UG4BQAAQGgQbgEAABAahFsAAACEBuHWZ2XK+N0CAACA8CDc+oxFHAAAABKHaJVkp566O9dlKrcAAACJQ7hNsvT0UrkuE24BAAASh3CbZLtzF24JtwAAAAlEuE2y9PTclwm3AAAAiUO49TncckAZAABA4hCtkiwjI/dlKrcAAACJQ7j1ecxtnz5+tQQAACB8CLc+D0uoV8+vlgAAAIQP4dbncJuZ6VdLAAAAwodw6/M8twAAAEgcwq3PY24BAACQOIRbn2dLeP55v1oCAAAQPoRbn8fcLlzoV0sAAADCh3Drc7gFAABAiMJtRkaGTZgwwbp162Zt27a1AQMG2PLlywvcfv369Xb99dfbkUceaZ07d7brrrvO1qxZY0HBmFsAAIAQh9uJEyfatGnTbNSoUTZ9+nQXdvv37287d+7Md/shQ4bYypUr7emnn3Ynnb/qqqssKKjcAgAAhDTcKsBOnTrVBg8ebN27d7cWLVrY+PHjbfXq1TZ79uw822/evNm++OILV91t2bKltWrVygYOHGjfffed/fHHHxYEhFsAAICQhttFixbZ1q1brUuXLtnXVa9e3YXWefPm5dm+YsWKVqVKFXvrrbdsy5Yt7jRjxgw78MAD3e2CgHluAQAAik9Z85EqtFK/fv1c19epUyf7d5HKly9vo0ePtpEjR1qHDh2sVKlSbtsXXnjBSpeOP6dnZmbatm3bLBl2765oZrkDbrIeG4mRlpaW6yeChz4MNvov+OjD4EtLch8qqyn3pXy49V4QhdZIFSpUsE2bNuX7xBYuXGjt2rVz43LT09PdMIYrr7zSXnrpJatatWpc7di1a5e732TYtevwPAXzZD02EmvZsmV+NwFFRB8GG/0XfPRh8C1LYh9G58WUDLcaZuCNvfXOy44dO6xSpUp5tn/33XddlXbOnDnZQfaJJ56wHj162GuvvWb9+vWLqx3lypWzZs2aWTJkZuatMGv8MIJDX8r0x9ykSZN836dIffRhsNF/wUcfBl9akvtwyZIlMW/ra7j1hiOsXbvWGjdunH29Ljdv3jzP9vPnz3fjayMrtDVq1HDX/fLLL3G3Q2XuypUrWzKkp2fmuS5Zj43E0h8zfRds9GGw0X/BRx8GX6Uk9WGsQxJ8P6BMsyMoqM6dOzfXjAgLFiywjh075tm+Xr16LsSqshs5XnXFihXum0MQMFsCAABA8fE13GrsRN++fW3cuHH24YcfutkTtCiDQmyvXr3cmNp169bZ9u3b3fZnnnlm9ly32lanoUOHujG6Z599tgUB4RYAACDEizhojtvevXvbiBEjrE+fPlamTBmbMmWKGwe7atUq69q1q82aNcttq5kRtOCDDiy7+OKL7ZJLLnHb6bpq1apZEKcCO+4435oCAAAQOr6OuRWF2eHDh7tTtIYNG9rixYtzXde0aVN3EFlYRBxHBwAAgKBXbgEAAIBEIdwCAAAgNAi3AAAACA3Crc/+9je/WwAAABAehFsAAACEBuEWAAAAoUG4BQAAQGgQbgEAABAahFsAAACEBuEWAAAAoUG4TQG//eZ3CwAAAMKBcJsCli3zuwUAAADhQLhNAWXL+t0CAACAcCDcpgDCLQAAQGIQblNAqVJ+twAAACAcCLcpIDPT7xYAAACEA+EWAAAAoUG4TQFUbgEAABKDcAsAAIDQINymACq3AAAAiUG4BQAAQGgQblMAlVsAAIDEINwCAAAgNAi3AAAACA3CbQpgWAIAAEBiEG4BAAAQGoTbFEDlFgAAIDEItwAAAAgNwm0KoHILAACQGIRbAAAAhAbhNgXs3u13CwAAAMKBcJsCnn7a7xYAAACEA+E2Bfz0k98tAAAACAfCbQo45RS/WwAAABAOhNsUULas3y0AAAAIB8JtChg2zO8WAAAAhAPhFgAAAKFBuAUAAEBoEG4BAAAQGoTbFNC1q98tAAAACAfCbQro2dPvFgAAAIQD4RYAAAChQbgFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAChQbgFAABAaBBuAQAAEBqE2yQ78MAMv5sAAAAQWr6H24yMDJswYYJ169bN2rZtawMGDLDly5fnu+0jjzxizZs3z/d08803WxC88cYO69btD+vVKz37usxMX5sEAAAQGmXjveGff/5pn3/+uW3bts0y80lnZ555Zkz3M3HiRJs2bZqNHj3a6tWrZ2PHjrX+/fvb22+/beXLl8+17aWXXmrnnXderuuefvppe+mll6xfv34WBIcckmnjx/9kq1a1ttmzy7jrMijmAgAA+BduP/nkExs8eLBt374932BbqlSpmMLtzp07berUqTZs2DDr3r27u278+PGuijt79mw77bTTcm1fpUoVd/IsWLDAnnvuORs1apSr3gZJ6Yia+X33md19t5+tAQAAKMHh9oEHHrCDDjrIDQWoW7eulY5MaoWwaNEi27p1q3Xp0iX7uurVq1urVq1s3rx5ecJttLvuuss6dOhgZ511lgVNqVI556ncAgAA+Bhuf/rpJzecQMGyKFavXu1+1q9fP9f1derUyf5dQebMmWNff/21vfXWW1ZUqj5reEUypKWluZ8//rg71/XJenwkrg+9nwge+jDY6L/gow+DLy3JfaisppEBxRZu999/f9uyZYsVlfeCRI+trVChgm3atGmPt9VY2x49eljLli2L3I5du3bZwoULLZk2blxnZlWzLyf78VF0y5Yt87sJKCL6MNjov+CjD4NvWRL7MDovJjTcDho0yB577DE77LDDrGHDhhavihUrZo+99c7Ljh07rFKlSgXebuXKlTZ37lybPHmyJUK5cuWsWbNmlgwK9Hoj1KxZO9f1iQjpsKT2YZMmTfb4PkXqog+Djf4LPvow+NKS3IdLliyJedu4wq1mMlizZo2dcMIJVqtWrVzBVFQ2/uCDD/Z6P95whLVr11rjxo2zr9flPR0gpvvW4x599NGWCGpv5cqVLZlKl8797SPZj4+i0x8z/RZs9GGw0X/BRx8GX6Uk9WGsQxLiDreaskunomrRooVVrVrVVWG9cLt582Y3C0Lfvn0LvN38+fOtU6dOVrZs3DOZ+W537iG3AAAASIC40uF9mrsqQWMnFGLHjRvnKrENGjRw89wqOPfq1cvS09Ntw4YNVq1atVzVYYXfc845x4LssMOYIgEAACDRilT6/Pjjj+2LL75w1dZ99tnHzZ6gOWoLQ/Pl7t6920aMGOHmze3YsaNNmTLFjYNdsWKFHXfccS5Mn3322dm3WbdundWsWdOC7KijCLcAAAApEW51ANiVV15p//rXv6xMmTIu2G7cuNEd4HXkkUfapEmTYj6iTbcfPny4O0XTwWqLFy/Oc/0333wTT7MBAAAQcnGtvvDII4/Yl19+aWPGjLFvv/3WhVwFTlVY//Of/9jjjz+e+JYCAAAAxRFu33nnHbv66qvt9NNPd5VX0cFdWnJX12s2BQAAACAQ4VYHeWmJ3Pzoek0TBgAAAAQi3GraLg1LyM+8efPyLKcLAAAApOwBZeedd56NHj3aTc916qmn2n777We///67G67w5JNPuqEJAAAAQCDCbZ8+fdxcs5qf9oEHHsi+PjMz08466ywbOHBgItsYWu3bm331lZb/9bslAAAAJTjcli5d2u655x675JJLsue5rVGjhls1rGnTpolvZchlZvrdAgAAgHAo0iIOzZo1cyfEpxDLJAMAACCR4VYrhT322GPWokUL69mzp5XaQzLT7z744INY7xoAAABIbrjVkIMqVapkn99TuAUAAABSOtxq9TGPZkoAAAAAQjPmdsuWLbZ161arW7eu7dq1y55//nlbuXKlnXjiidaxY8fEtjLkOKAMAADAx0UcvvnmG+vRo4e98MIL7vLdd99tY8aMsZkzZ9rFF19sH374YYKaF26M7AAAAEiBcPvQQw+5Kb/OPfdcS0tLsxkzZtj555/vpgXr3bu3PfHEEwluJgAAAFCMldsrrrjCGjVqZJ9++qnt2LHDzjjjDPe7U045xX788cd47hYAAABIfrjVIg4VKlRw5z/55BOrXr26tWnTJnssrpblRewYcwsAAODjAWWHHnqovfrqqy7Evvfee9a9e3c3Ndj69evtySefdL/H3jHmFgAAIAUqt8OHD7fPPvvMzjvvPCtTpowboiCnnXaaLVu2zIYMGZLgZobTvHlZPzMy/G4JAABACa7ctm7d2t5//3376aef7OCDD7bKlSu76++44w5r37691a5dO9HtDL0//zSrVs3vVgAAAJTQeW6rVq1qhx9+eK7rNMct4rNtG+EWAAAgaeH2uOOOs8cee8xatGhhPXv23OPyu/rdBx98UOTGlSRl4/6aAQAAAE/MkapTp05WpUqV7PN7CreIzZFHmn3+edZ5xt0CAAAkMdzed9992edHjx6d5/e7d++2spQfC6Vu3Zzz6el+tgQAAKAEz5YgkydPtoEDB2Zf/vLLL61r167ZS/Ji7zZvzjmfluZnSwAAAEpwuJ06dapbgrdJkybZ1zVu3NhOOukkV9XVHLjYuzlzcs6PH+9nSwAAAEpwuJ0+fbqby/aWW27Jvq5+/fo2YsQIu/rqq+2ZZ55JZBtLhEce8bsFAAAAJTTcrlmzxg477LB8f6fpwVasWFHUdgEAAADJCbcNGjSwf//73/n+bt68eVavXr147hYAAAAokrimNzj33HNt7NixtmvXLjv++ONt3333tQ0bNticOXPs6aeftuuvv75orQIAAACSFW779evnhiY8//zzucbXlilTxi6++GK75JJLEtnG0OrRI/dBZQAAACiauCemvfHGG+3KK6+0//znP/bHH39Y9erVrU2bNrbPPvsUsUklx0knEW4BAAASqUirLmjFstq1a1tmZqa1b9/eLeSA2O3Y4XcLAAAAwiXucDtjxgx74IEHbN26dW4pXs1t+8gjj1i5cuXc9eXLl09sS0No+3a/WwAAABAucc2WMGvWLDcs4cgjj7QHH3zQMjIy3PUnnHCC/fOf/7SJEycmup2hROUWAAAgBSq3TzzxhJ133nl2xx13WHp6evb155xzjps14ZVXXnGLPGDPCLcAAAApULldunSpq9IWtIiDZlLA3jEsAQAAIAXCrea1/emnn/L9na7X77F3VG4BAABSINyecsopNmHCBHvvvfds586d7jodVPb999+78bYnaY4r7BXhFgAAIAXG3Go87Q8//OB+li6dlY8vvPBC27Ztm3Xo0MGuvfbaBDcznBiWAAAAkALhVtN8PfXUU/bpp5/a559/7hZxqFatmnXq1MmOPfZYV8XF3lG5BQAASIFwe9lll1n//v3t6KOPdifEp1kzs7//3e9WAAAAlPAxt1999RXV2QS46y6/WwAAABAucYXbbt262cyZM23Xrl2Jb1EJUquWWYsWWeerV/e7NQAAACV0WEKFChVcuH333XetadOmVrly5Vy/V1X32WefTVQbQ80rgGdm+t0SAACAEhpuV69ebe3atcu+nBmVzKIvo2CEWwAAAB/D7bfffmvnn3++NW7c2Fq3bp3AppRMhFsAAAAfwu3mzZtt0KBB9p///Cf7OlVvH3jgAatfv34Cm1SyEG4BAAB8OKDsoYcesgULFtg111xjkyZNshtvvNF+/vlnGzlyZAKbU/JkZGT93LbN75YAAACUoMrtnDlzbOjQoXbxxRe7y8ccc4zVrVvXhg0b5lYmiz6oDLFZsCDnvKq3zLAGAACQhMrtunXr8oyx7dy5s6Wnp9uqVavibkBGRoZNmDDBTS/Wtm1bGzBggC1fvrzA7TX9mIZCeNv37dvXFi5caGGwcaPfLQAAACgh4Xb37t1u2d1INWrUcD93FGEd2YkTJ9q0adNs1KhRNn36dBd2tfrZzp07893+jjvusDfeeMPuvfdee/31161WrVouEP/5558WdGXjmrsCAAAARVrEIVq8U38pwE6dOtUGDx5s3bt3txYtWtj48ePdVGOzZ8/Os70qugq099xzj6vcao7du+++24Xu77//3oLus8/8bgEAAECwJSTcxrsU76JFi2zr1q3WpUuX7OuqV69urVq1snnz5uXZ/tNPP7Vq1aq58b6R23/00Ue57iOoFi3yuwUAAADBVqgd4RoSULVq1TwV29tuu82qVKlS6BXKVKGV6KnE6tSpk/27SEuXLrVGjRq5qu7kyZNtzZo1LgjfdNNNroobdOXK+d0CAACAEhJuO3bsmO8QhPyuj3WYQlpamvsZPZZXy/tu2rQpz/ZbtmyxX375xY3TveGGG1zV9vHHH3eLSsyaNcv23Xdfi4faqxkfksF7zt5Ps5xZJqZNS7dLLol//DLMpz5E0NCHwUb/BR99GHxpSe5DZbVYRwrEHG6ff/55S7SKFStmj731znsHqFWqVCnP9mXLlnUBV+NyvUqtzh977LH25ptvugPR4qEZGJI948KyZcv+d+6I7Os++6xMaGZ+KAly+hBBRR8GG/0XfPRh8C1LYh9GF0ML4uvx+d5whLVr17rlfD263Lx58zzb16tXzwXcyCEICsUaqrBixYq421GuXDlr1qyZJYO+4eiN0KRJExfgjz463T79tEz271u2bJmUdiBxfYjgoQ+Djf4LPvow+NKS3IdLliyJeVtfw61mR9AY3rlz52aHWy3zq5XQNH9tNA2B0JRk3333nR122GHuuu3bt7tZFE499dS426Eyd7IXodAbQY958ME6UC7nehbDCA6vDxFc9GGw0X/BRx8GX6Uk9WFhJi/wNdyqvKwQO27cODdfbYMGDWzs2LGuQturVy+3QMSGDRvcDAmq0Hbo0MGOOuoot/TvXXfdZTVr1nQLQJQpU8bOOOMMCyKGGwEAAKTYVGBFoTlue/fubSNGjLA+ffq4oDplyhQ3VEArn3Xt2tUdLOZ55JFHrFOnTnb11Ve722kM7nPPPefCcRBt35778i+/+NUSAACA4PN9TSyF2eHDh7tTtIYNG9rixYtzXadhDJqSTKcwiK7caq7bAw7wqzUAAADB5nvltqSLDrcR0wUDAACgkAi3KTYsgXALAAAQP8JtilVuK1TwqyUAAADBR7j1GbMlAAAAJA7hNsWGJcS4cjEAAADyQbj12Smn+N0CAACA8CDc+uy++3JfpnILAAAQP8Ktz/bd16x/f79bAQAAEA6E2xRD5RYAACB+hNsUUKqU3y0AAAAIB8JtiqFyCwAAED/CbQqgcgsAAJAYhNsUQ+UWAAAgfoTbFEDlFgAAIDEItymGyi0AAED8CLcp5tZb/W4BAABAcBFuU8CkSTnnZ83ysyUAAADBRrgFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAChQbhNAeef73cLAAAAwoFwmwIaNfK7BQAAAOFAuE0BW7b43QIAAIBwINymgJNP9rsFAAAA4UC4TQGnnJJzvkwZP1sCAAAQbITbFFCqVM759HSzjAw/WwMAABBchNsUtHix3y0AAAAIJsJtCqpUye8WAAAABBPhNgWVK+d3CwAAAIKJcJuCMjP9bgEAAEAwEW5TEOEWAAAgPoTbFNG+fc55wi0AAEB8CLcpolmznPOEWwAAgPgQblNwrlvCLQAAQHwItyli48ac84RbAACA+BBuU8Ts2fmfBwAAQOwItyno8sv9bgEAAEAwEW4BAAAQGoTbFFSaXgEAAIgLMSpFDBuWc/7MM/1sCQAAQHARblPE77/nnH/jDT9bAgAAEFyE2xTxzDN+twAAACD4CLcp4oIL/G4BAABA8BFuU8RDD/ndAgAAgOAj3KaIqlX9bgEAAEDwEW5TRLlyuS9nZPjVEgAAgOAi3KaIMmVyX961y6+WAAAABBfhNoX06JFzfudOP1sCAAAQTITbFFKpUs75HTv8bAkAAEAw+R5uMzIybMKECdatWzdr27atDRgwwJYvX17g9jNnzrTmzZvnOa1YscKCrmLFnPOEWwAAgMIraz6bOHGiTZs2zUaPHm316tWzsWPHWv/+/e3tt9+28uXL59l+8eLF1qlTJ3vwwQdzXV+rVi0LOsItAABAgCu3O3futKlTp9rgwYOte/fu1qJFCxs/frytXr3aZs+ene9tfvjhB1eprV27dq5TmegjsgJo9eqc89u3+9kSAACAYPI13C5atMi2bt1qXbp0yb6uevXq1qpVK5s3b16+t1HltmnTphZGH32Uc751az9bAgAAEEy+DktQhVbq16+f6/o6depk/y7Spk2bbM2aNTZ//nw3lGHjxo3Wpk0bGz58uB144IFxtyMzM9O2bdtmyZCWlpbrZ26Vc11KVpuQyD5EENCHwUb/BR99GHxpSe5DZbVSpUqlfrj1XpDosbUVKlRwQTbajz/+mP0E77vvPtu+fbs9/vjjdv7557sxuvvtt19c7di1a5ctXLjQkmnZsmX5XHtErkvJbhMS0YcIEvow2Oi/4KMPg29ZEvswv2OxUi7cVvzfEVQae+udlx07dlilyHmx/qdDhw7273//2/bZZ5/s9P7oo4+68bpvvPGGDRw4MK52lCtXzpo1a2bJCvR6IzRp0iTPc7znnp126605HdeyZcuktAmJ60MEA30YbPRf8NGHwZeW5D5csmRJzNv6Gm694Qhr1661xo0bZ1+vyzpoLD/RsyLoBW3YsKEbrhAvBeXKlXMPCShuanf0Yx5/vNmtt2ad79/fkt4mFL0PESz0YbDRf8FHHwZfpST1YaxDEnw/oEyzI1StWtXmzp2bfd3mzZttwYIF1rFjxzzbv/zyy9a5c+dcY1G3bNnivjkkq/JanEpH9EaFCn62BAAAIJh8DbcaO9G3b18bN26cffjhh272hOuuu87Nd9urVy9LT0+3devWubG1cswxx7hFH2644QY3/va7776za665xlVzzz77bAu6yC8lGRl+tgQAACCYfF+hTHPc9u7d20aMGGF9+vRx89VOmTLFjYNdtWqVde3a1WbNmpU9jOGZZ55xlVtt269fP6tWrZo999xz7iC0MFVuMzP9bAkAAEAw+b5CmcKspvLSKZrG0mpe20itW7d2Cz+EUWS4pXILAAAQwMot8h+WQOUWAACg8Ai3KYTKLQAAQNEQblMIY24BAACKhnCbQpgtAQAAoGgItylaud2508+WAAAABBPhNoVEDkWYNs3PlgAAAAQT4TaF/PST3y0AAAAINsJtCunQwe8WAAAABBvhNoXUqOF3CwAAAIKNcJtCypTJfZnpwAAAAAqHcJtCyvq+GDIAAECwEW5TdJ5bAAAAFB7hNoWtX+93CwAAAIKFcJvCfv7Z7xYAAAAEC+E2hVWt6ncLAAAAgoVwm2Lq1Mk5zxhcAACAwiHcppjTT885n57uZ0sAAACCh3CbwnPd7t7tZ0sAAACCh3CbYjIycs4TbgEAAAqHcJtinnwy5/wbb/jZEgAAgOAh3KawN9/0uwUAAADBQrhNYYsWxXe7tDSzRo3Mmjc3W7Ik0a0CAABIXYTbFDNkSO7Lu3YV7vbbtplVrmy2YoXZDz+YjRqV0OYBAACkNMJtilm8OPflr78u3O2rVMl9+bnnit4mAACAoCDcpphPPtnz5T1ZuTLhzQEAAAgUwm2K2bIl9+UaNfJus2NHzvn167PG2Mrxxxdz4wAAAFJcWb8bgNyqVzfbvDnncoMGuX9fqZLZ9u15b7dhg9nChfnfp1Y6i1wcAgAAIKyo3KaYBQtyX54xI+f800/nH2zlsMMKvs/Ig8oUgkuVyjoddVRRWwsAAJBaCLcpRpXaTp1yLms6L8+llxZ8u99+K/h3d96Zc37ffXPO//vfZtOnx91UAACAlEO4TUEXX5xzXuNpMzPN/vWv2G//4INml12Wc7lLF7N587KqtdH69Ml7naYfU/D1xvLmZ9Mms2efNfvll9jbBQAAUNwItykoctndBx4w697drFu32G9/3XVmRx+dc1lBNbIavDfly2cNWdB8ucOGmf35Z9a4Xc/u3WY1a5r162fWpInZK6/Eft8AAADFiXCbgiJXFdMY2Y8/Lvx9HHpo7NtqxgXPTz/l/p3CtQ5yK1s2Z6xuuXK5t/m//zM75hizH380e/11s1WrcirACsYAAADJQrhNQffeG9t2++2X9zrNpiDt2sX+eLqfwYOzzjdrZnHRfLyHHGLWu7fZ/vtnhWBVgBWMdV7h96STzHbujO/+AQAAYkG4TUENG+7597NmmW3darZ2bd7fvftu1k9VWvPTqFHWGN5ojzxi1qOHFRuF37//3axCBbPJk4vvcQAAQMlGuE1BGiO7J6qAajysKqKR03xpqd1jj825/McfeW+7aFHB9/uPf8R/4FthDBoU3+0AAAD2hnCbgjS7wZ5EznowYkRWJVanCy/Mu7rZU0/lXK5TJysUx0IHsSk4a/xvdEjWTAx6vGeeyRpTW7euFdqeQjYAAEC8CLcp6Igj4pvPNj8Kol9/bfb552Zr1uRcf/vte77dnDlZwblp06yQ7A130NjcyMBctarZDz/kXD7ggJyw/dFHBd9/y5aFex4AAACxYPndFFSlSsFzy+oArcJq2zbvdXfcYXbqqWYbN5q1apU1FteT38FoGgqR31hdUZuWLcsa1nDBBTnXawxv5G1OP93s7bdzLqsirCnFvBkb1BYd0KZV2CpWLPzzBAAAoHIbIPEE2z3p2NGsV6+sA9heey3ruiOPzFrwobBUsdUY3IIOZJNXX819eZ99cqYX04wNBx+cdV4zPuinlhuOnF8XAABgbwi3KSpy7lkvCBanc87JqrLqYLYyZYrnMTRTQmFoueHLL886n5Fhds89ZhddZLZtW7E0DwAAhADhNkXVqpX7climz4oO7Xuj8b2q4ipwawzw889nDdvo2XPPywMDAICSiXCbwsaMyTmvxRHCEtpVhS0qHfCmmR80fy4AAICHcJvChg/PmXkgTFSJ9Z6XTt98kzULhHd5x47Y70srn0VOjQYAAEo2wi1816ZN1pK9Hi3bG61cObNJkwq+D+/ANO+k6c8AAEDJQ7hFSlIFVwtEbN6cdX7nTrOBA812745tZbT27bNC7k8/JaO1AAAgVRBukbK0QES1armv04FlWhlNgfeDD/Z+H5o3FwAAlBws4oDAOu643AtBFEQVXK2wtnp11rLCmkrskEP2PCcvAAAIJj7eEWhaGlhVXK1qpp9a6EJDF6KdfHLe67Ra2mmnJaWZAAAgSRiWgFDQcr1a2WzXrqypxj79dO+3+ctfsqq6991n9s47yWglAAAIfbjNyMiwCRMmWLdu3axt27Y2YMAAW758eUy3nTlzpjVv3txWrFhR7O1EcCiwHnWU2YIFsW1/yy05QVfhGAAABJfv4XbixIk2bdo0GzVqlE2fPt2F3f79+9tOHR6/B7/99pvdddddSWsngqdly6yhCh99ZPbyy2ZLl5o98MCebxM5DdnatbmnF+M7FAAAqc/XcKsAO3XqVBs8eLB1797dWrRoYePHj7fVq1fb7NmzC7ydAvDw4cOtdevWSW0vgqlHD7NzzzVr0sRs6NCswLuHt1d2mK1bN/f1jRqZLVxY7M0FAABBDbeLFi2yrVu3WpcuXbKvq169urVq1crmzZtX4O2eeOIJ27Vrlw0aNChJLUXYnHBCVshNT8+aQzdWrVqZff99qewlhBOxlDAAAAjJbAmq0Er9+vVzXV+nTp3s30X79ttvXbX3tddeszVr1iSkHZmZmbZN80MlQVpaWq6fSA09elSwOXPKxLRt586VzOyIXNc1bpxhPXtm2GOPxZ6Ut27NOgiutO+Dg0oe/g6Djf4LPvow+NKS3IfKaqW0WzXVw633gpSPWm+1QoUKtmnTpjzbK4AOGzbMnZo0aZKwcKsq8MIk729etmxZUh8PezZmjNn8+dVs2LCmtnVrTsj97LOvrHz5TOvQIXeYjfbrr6XtmWd0yv9P6q9/XWvr1pWzf/xjn3x//8QTi61Dhy1FfBYoLP4Og43+Cz76MPiWJbEPo/NiSobbipq/6X9jb73zsmPHDqukklaUu+++2w488EA777zzEtqOcuXKWbMkLWWlQK83gsJ5fs8R/tGQg4su2hF1bQv376ZN26xGjcpx3/err9bZ4+8vv7x59vnbbttpN9202w2beP/90nbUURlutTYkDn+HwUb/BR99GHxpSe7DJUuWxLytr+HWG46wdu1aa9y4cfb1uqwpvqK9/vrrLrW3a9fOXU7XgEnTRPyn2eWXX+5O8VCZu3Ll+INLPPRGSPZjomgUNvW39corO23SpAx74IFS9te/Vkj444waVd6dInXokHVgnA6Iq1cv4Q9ZYvF3GGz0X/DRh8FXKUl9GOuQBN/DrWZHqFq1qs2dOzc73G7evNkWLFhgffv2zbN99AwK33zzjZs1YfLkyXaI1lMFipkK/EOG7LYTT1xoLVu2dIF3/XpV/80aNDDbUoiRBTqQTW/7AoaX5zJ/ftZp7Nisy3pcAACQYuFWVViF2HHjxlmtWrWsQYMGNnbsWKtXr5716tXLVWY3bNhg1apVc8MWDjjggFy39w4623///a1mzZo+PQuUdPvum/Xzzz8Lf9tVq7IWmyjsrHbvvpv/ksIAAJR0vh+nrTlue/fubSNGjLA+ffpYmTJlbMqUKW4c7KpVq6xr1642a9Ysv5sJFOtYX1VivSpw5FCEU0/N/zannGJ2xhlJayIAAIHha+VWFGY1tECnaA0bNrTFixcXeNvOnTvv8fdA0NSqVfCQAy0R/M47OZdnzsxabGLKFB0IZ1bW979mAAD853vlFkBs3n47a5W1aJddljXmV0H3wQf9aBkAAKmDcAsEyNKlWUMSCnL99Vkhl3nRAQAlFeEWCJi//c1sD6tTO5qVRSG3ShWzlSs1R7TZNddovt5ktRIAAH8QboEA0sFm3kFo48cXvJ1WldYUZbfdZvboo2aaVEShV6f/+z+zjIysmRc2bsx72w0bsn6nbQAACArCLRBwQ4ZkhdzCHlv5yis6oDNrmIMOZLvgArMZM8wGDDDr3TtrijP9Tttw3CYAICg4vhoICa1jopD73XdmTz5p9sgjhbv9tGlZp/y0yFqF2LQ44FdfFb2tAAAUFyq3QMgcdpjZhAlZQffLL7PCqM5rsYg77zQbMyb++/7666whDYsWJbLFAAAkDuEWCLH27bOqrdKypdnIkWaaUlphV2Np09PN7r8/7+1efnnPK67pvrTNmjUsBQwASC2EW6CEUgW2dGmzG27IOTjNO517rlnVqjmXn3027+3PO8+sXr2s+1BoBgAgFRBuAeyVVkDb06wJo0aZjR6ddV5Tjy1cmLSmAQCQC+EWQMyVXlVxtVBEfm6+OWsbTT3WqlXOlGPRJ/3+xRfNunfPuqyq765due+LoQ4AgHgRbgEUyrhxWeFT43U1XVhhqbLbt6/ZP/+ZU/UtXz53ANZQB+/8oEFZc/kefXTW5fvuy3p8BWJv2IR444h3707s8wUABAvhFkBcFEB//93ssceK93EmTzYbOtTss8+yLt9yS9ZjKxDrpxeEFbQ1J2+5cjnBWNs0apR1XgtZeAfRAQDCi3ALoEiuvNJs1aqs82PHZlVOVUX9+GOzZcuSN/42v1XWVN1dsSLrvJYgVvgtW1bLEle2Dh2OcD9VSQYAhAeLOAAoMs2aED1Otlu3wo2hVUV17dqsMHrEEWb9+pk9/7wVO40Blh9/NKtbNysQ79xp9uuvZsuXm/XqZVatWvG3AwCQGIRbAClBVdX69bNO8txzWaeCqEKsKuy775odcEDWKmoaopCWZjZ1qtn775vVrp217VNP7f3xDz5479ssWWLWtGmszwgA4AeGJQAIJAVbOfnkrNkZFGylUiWzq64ye+utrGWIdYqcw1fjbj//PC2ux2zWLGv87oMPmm3enMAnAwBIGMItgBJF4fSwwzJt/vwvbcuWbW6xisLSdGg1amTd19KlxdFKAEC8CLcASiyFUy0zHL1Cm3fautVszJg938dBB+XMzqBp0qLn7AUAJBfhFgAKULmy2fDhWUF3xw6ziRP3vL229ebsnTGDxSgAwA+EWwCIgULrFVfkVHW1mMSenHlm7sUoPvooWS0FgJKNcAsAcbjpppyg++qre9/+uONyVly75pqc+XcBAIlFuAWAIurdO2cmBs35u7cV1x59NGflNJ20+IXm1QUAFB3hFgASREFVq7VFHpQ2fvzeb3fDDVlz9e6zj9mkSWbTp5t9+63Z+vXJaDUAhAuLOABAMRoyJOuk+Xa1AtuddxY8o8Iff5hdfnn+v9OqaeXKFWtTASAUqNwCQBIMGGB2661ZIdUbwqDhCLHyZmHQ6fDDzd58szhbCwDBRbgFAB8opA4bljN8oV+/rOtioSELZ59tVqeO2VdfFXdLASBYCLcAkAKefjqrmhu9kMS77xZ8m3XrzI44Iqeiq9Pu3clsNQCkHsItAKSwk07KCrnbtpn9619mDz5oNnRowdtrXG5k2J05M+u2AFBScEAZAARApUpmRx+ddZK6dc1uvHHvtzvjjNyXVR2OdfgDAAQRlVsACCBNH+YNXdi4MfbbeaumMc0YgLCiclsI6enptqugOXxitEML1P/vZ2l9yiBwgtSHZcuWtTJlylgpSnWhVrNmVsj1bNlidu21ZlOnFnyb/fYz+/57s9atk9JEAEgawm0MMjMzbfXq1faHJqEsooyMDBc4Vq5cmfLBCOHoQ4XbOnXqWI0aNQi5JUTVqmZTpmSdZPNmsxo18m536KFZ27RpY1alilnlyjk/NQyCtwuAICLcxsALtgoIlStXLlJAUPVXFb8KFSq40IHgCUof6kvZ7t27bfPmzbZq1SpLS0uz+vXr+90s+KB69ZzK7tVXmz32WM7vLrus4NtFht3on3v6Xaw/y/IJBKAY8F9LDEHGC7b77rtvQu5PKlasmNLBCOHpw2rVqrkg/vvvv7v3cRDajOLz6KO5w+2eaJaF4pxpQTM7xBOMtedk48Za9sMPZdySxQVtW7Ei1WegJCLc7oU3xlYVWyCoqlSpYuvWrXPvZ8ItNGNCixZmP/xg1qmTWceOZlu3ZgXZvf3UbRNF/71qtFfhR3yVN7MD97qVgm1xV5/5cwJSD+E2RoxVRJDx/kUkvR0WLy787TS0QcdTRobdWAJxQT/zu+5/x2smhNqr+9WpuGhZ5HiDcSzbVKhA9RkoLMItACAmClna1a9TrVrF8xhaYS0tbc/BeOPGHbZ06RqrVq2e7d5dvtChOnJmiaLauTPrVJjp2ApDx6wWV/XZO1F9RtgQbgEAKUMHmVWrlnUqyLZt6bZw4Tpr2XI/q1xZQxQKX32Ot9ocS8VaYTdRNAxEU7vpVFxUHS7O6rOq21SfkUyE2xKkZ8+e9ttvv+XaVa2xxK1atbJrr73WOmrgnZnddNNN9uabb+a6rQ7g2GeffaxLly528803W60YyzbXX3+9vfPOO/bYY4/Z8ccfn+t3c+fOtYsuusg+/PBDa9iwYa7frVixwo477jh77rnnrHPnztnXL1q0yKZMmeJuqwP9dPT/SSedZAMGDLCqmv8owVN+Pfroo/bqq6/an3/+6V6fkSNH2v7771/gbf773//amDFj7Ntvv3UHcfXq1cuGDx/uDury6Lpffvkl1+3OOussGz16tDu/fv16u/fee+3TTz91Mx4cddRRrk/qakmq/x3QptdTfaRtmzVrZoMHD7bu3bsn9PkDYa8+J+AY4QKrz/EG41hCdaKrzwr7Om3YYMVCleHo0FuxYgXLzDzYateu4L7IFLX6HIBZGZFEhNsS5tJLL3UnUXBSQHzwwQetf//+9u6772YHt3bt2tkjjzySfbvt27fb119/bXfddZe7zZNPPrnXx1Ig/OCDD+zAAw+06dOn5wm3hTV79mwXlk877TSbMGGCm71i8eLFLkz+61//ckFYB04lysSJE23atGkudNarV8/Gjh3rXqe33nor3+01G8Ell1zinucdd9xhGzdutNtuu80FU4VR2bZtmy1fvtwmTZpkrSNmz9fMC54hQ4a4Kbyefvpp10d33nmnXXXVVfbaa6+53z/88MMucN93333WtGlT9+XhyiuvtFdeecUO1cSlAHyvPmv6NZ2Kg4Lt9u2JrTZH/yziekW5aIKZP//MOuXQWIjEvUD6L7S4q88IDsJtCaNKbe3atbMva2oohadjjjnG3n//fbv44ovd9eXKlcu1nTRq1Mh+/fVXF3oVXCOrkflR6NKR+QpeN954o6vGRldoY6Uj/RUS+/TpY7fcckuuNh1yyCF28skn2wsvvGCDBg2yRNi5c6dNnTrVhg0bll0RHT9+vHXr1s29TqoqR1NVvGvXru4LgCrdCvXnnnuuu51nyZIlriKsLw9aVCGa5qT94osv7PHHH7eWLVu66wYOHOheQ32pqFmzppvx4NZbb81u1xVXXOHa+vnnnxNugRJSfdYiGzoVF4Xb4qg6R55PJIV9nYprWWl9YSmuGTe8RVOoPicO4RYuiEn5GL6aale7hjPEMp3UG2+8YZ06dXJBUGFZlcWhQ4fG1ca3337bVY8V5KI1btzYnn32WRcmC2qHhlLkp0GDBvbRRx/luV7DH7Zu3eqGYXiqV6/uhnDMnz8/33B7+OGHuyq456effrIZM2bY0UcfnX2dKs377bdfvsHWq+Cq+qzqsF470X3ouenxRV8UPHpNVMXVAg2RwzcAoKhzEOu/qQL+qyqyLVu22TffLLKGDVuo7JLQqrM3Q8b/piRP2FATrfSnU3FRwC3O6nO5clZiEG7j9OqrZiNHRu9miUVpy8ysVKSpmVQwHTXKrHdvK7I1a9a48Z2q6B577LEFbqfd4xqWoBCpMaN7m/f3xx9/dONO77//fhfWVGV8/fXX7ZprrnFBt7C+//57F/A07jc/HTp0KPC2p5xyiqu45qegkK5V6SR6RS9Vur3f7cmJJ55oy5Ytc+FZ43Yjw61eO42R/eqrr9zzOeecc9zYYy3lqy8YGgahsb16Tnqf6DFVlY5e6nfmzJl2ww03uL7R63rYYYfttV0AkAr031nFipmmHYTFNY28DuwrarV5T+Fas3okku4v0fcZSR+9iaw+6/Np167UPFKQcBunsWNV3YvnlnojlErI48cTbjXWU7uwReM6tftd4zYfeuihXAdKqTqpXeceLTerg8gUFDUmdG9ULVWV1xtne+qpp9rf//53NwZXQwgKa9OmTdmVy8JSNTRyTGssVAnNr5qt56ThAXszbtw4dx8ap6vgquqrQr5Cv4YeKPxqHO2XX37pttHz00F9CqoLFy50r73G9+rgMQ1r0LCEl156KddBczrATRVeHXimirH65/zzzy/U8wSAsNJ/3zrVrFk896+ZLPY2bV1RwrVOiV40ZdOmrFNiVLK6dQ+1L7/cXWxfUOJFuI3TDTeY3XZbPJXbTBdgsiq3peKu3A4fHtdN7bzzzrMLL7zQnVclUGM48xs7q7GbCmje7vVRo0ZZixYtXADzqrYKwJqlwKNw/Le//c2FZlUVVQn2wpgqtwp3OrDMC7fecAi9HtG867xtVOFcuXJlXM9Zbbn99tvz/Z3X5mheGFb4jwzGCvmVYhjo5lVRVbXV66BxumeeeaY7EE/34b3mzZs3ty1btrgxtqq+vvfee65KO2fOnOzX7oknnrAePXq4A8r69euX/RiqKuukftHsC5pFgnALAMmrPquCmcDjmHPRx6ACaXFMV7f1fz81Trko1qwpb0uXZliDBpZSCLdxUtU0nsppenqGGyepwOTHMqga63nAAQfsdTu1z9tOPzWu9a9//asbM6uwpXCuABw5c4AXRP/xj3+4mQMU6DRG1aMqpKbwWrp0qRti4I07VSUzmlcdVfgWVTIVQjds2JDvNGSaOUBhUAExvynQNB42P16bo3nDEdauXeueu0eXdQBbfn7++Wd3wF3klFyavkvPQcM/vEpwdDVY96dZFFS91RcGvTaRFVq9TrpOAVZfHPT66nWNrLQrJKtaDgAIB9XAvOpzASPyiiw9Pf/qcyzBePPm3dao0W/Wrl3ug89TAeEWMdFcqpo5QDMBqPqqWQsiA3Akja1VpfWZZ57JNU5UU2B5U1bpoKgmTZq4aq4CXeS0WKLd9Qp42kZU7dXueQXryNkSvMqydtnnd7CZ6H4KOweuqqG6jcK4F24VwhcsWFBgdfSzzz7LnpbMG0KhsKspwTT0Q9XoE044wVVwr7766uzbfffdd25mCr1mmnJMIV7VXQ2BEAVfzTRx+umnuy9Eml6sd+/eblo0zzfffOP6CACAWKnGpo/HeKaJ37Ztpy1c+LuVKpV64ZaJJxAzhTod5KThCl4lMpoqth9//LGbAksBUVVJ76QZBjQDgCqM2t2vqqnm3NW8rQrMCoIak/riiy+66cYuv/zy7Oq2qrUaWqBd9gq3OlhN22ss62WXXeamzYrcZV9Uqq727dvXPVctMqHZE6677joXPhVQvUq0pihTJV40/66qtFq0Qc9DoV0HjrVp08YNK1C1W7fV8IFZs2a59r/88sv21FNPue1EwVc0rlmPqZOq5Qq6Z599trsPvWaa01czSOigtcmTJ7tp1/KrWgMAUNL4XrktaBUozV8a7wpQKB4KVnfffbedccYZbpECjRPNb3yrKpSq7OZHixyowqoFI3Q/qmBqMQZVczWzgmgXvAKsZhGI9Je//MWFS4VDVYBVSdVsBNpO9xvLWNjCUODUMIARI0a4AKv3ph5bsz0o2GrWBIVVDYlQ8FSw1WwSmu1Az1/BXIFe8/N6IV3VVlWEdQCYbq95fzVnrb4MiGZG0MIROshMcw6r8q0vFLrOe48rzKsN+gKwatUqO+igg9yiFvlNTwYAQElTKjO/o3mSSMFW1bjIVaC0C1ZVqeixiaoK6mh9HYGvA5m8FaC069pbAaqwtEtYCppGSaHGGyNa2CPu86NQ5OeYW1iJ7MNEv4+DTkM9NCuFKv57m9YOqYf+Cz76MPi2JbkP95bXUmZYgrcKlCpkOghHu7E1rlIVLS21uqcVoPQh3b59e1fx0lRIAAAAgK/hdk+rQM2bN6/AFaC8I9zzWwEKAAAAJZevY26LsgpUQStAAQAAoOTyNdzuaRUozfkZzwpQ8dCwY40dyY+mZNJBbxpnqVNReUOc9TMR94fkC2Ifqp16H+tvRj9LOu//Hu8ngoX+Cz76MPjSktyHOQtgpXi4LcoqUAWtABWPXbt2uUHRBdEwCLUpkRJ9f0i+IPWh2qqZH7TQBHJo7w+Ci/4LPvow+JYlsQ+ji6EpGW73tAqUVlyKZwWoeGhapYImwFco0LKvekETcZS5vnl4E/TH+g0EqSWIfag260ua/s68xSFKMlUa9B+yZlpJ9BRyKH70X/DRh8GXluQ+XLJkSczb+hpu97QKlCbQL+wKUPFSQCloGgsFAY3/VZgp7CpX+fF2Y+sxgzKNFILfh5oKTG3V301Q2pwM+g+ZaYiCi/4LPvow+ColqQ8LU0zyNdxGrgKlFah0cJjG0Gq+Wy3OoBCxYcMGN3m9qqZaAUqrMWnRBi0Fq3G5WlTAWwGqOCgIqDKsarKoA4tSrdNz8nZnEzKCKSh9qGqthiLoC6NOeh+ncnsBAAjFCmV7WgVKizlo1aXCrABVHBS2xQu4RaGDefR8tYtYq08heILWh/rb0BCgGjVq+N0UAADCH271watKrE7RtDTp4sWLc12nxRsmTZqUxBZmlcIVDjRFmQ4+K+oYFY0d1jAMxhkFU5D6UAFcf2NBGRsMAEDgw22QKCQUtULsTcOksbwsgxpM9CEAAKkr9fepAgAAADEi3AIAACA0CLcAAAAIjVKZ3lqiJdRXX33lpkyKddWLotJj6aA0zQbBQT7BRB8GH30YbPRf8NGHwZeZ5D7UarZ6nPbt2+912xJ/QFmy/6j0eMkK0ige9GHw0YfBRv8FH30YfKWS3Id6vFgzW4mv3AIAACA8GHMLAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3CbYBkZGTZhwgTr1q2btW3b1gYMGGDLly8vcPuNGzfa9ddfbx07drROnTrZnXfeaWlpaUltM4rWhz/++KMNHDjQOnfubF26dLHBgwfbypUrk9pmFK0PI82cOdOaN29uK1asKPZ2IjH9t2vXLnvggQeyt+/bt68tXLgwqW1G0fpw/fr17rPwyCOPdP+XXnfddbZmzZqkthkFmzRpkl144YV72CK18gzhNsEmTpxo06ZNs1GjRtn06dPdH3j//v1t586d+W6vIPTLL7/YM888Yw8//LD985//tDvuuCPp7UZ8fag/5ksuucQqVqxozz//vD355JO2YcMGt/2OHTt8aT8K/3fo+e233+yuu+5KWjuRmP7T/5lvvPGG3Xvvvfb6669brVq1XJj6888/k952xNeHQ4YMcUWBp59+2p10/qqrrkp6u5HXiy++aA899JDtTUrlmUwkzI4dOzLbtWuX+eKLL2Zft2nTpsw2bdpkvv3223m2/+qrrzIPOeSQzCVLlmRf98knn2Q2b948c/Xq1UlrN+Lvw1deecVtn5aWln3dypUrXb9+9tlnSWs34u9DT3p6emafPn0yL7roItd/y5cvT1KLUZT++/XXX93/mXPmzMm1fY8ePfgbDEgf6nf6m/vwww+zr/vggw/cdRs3bkxau5GbcsigQYMy27Ztm3nSSSdl9u3bN7MgqZZnqNwm0KJFi2zr1q1u17SnevXq1qpVK5s3b16e7efPn2+1a9e2pk2bZl+nUn6pUqXsyy+/TFq7EX8fajtVKFS59ZQunfVntXnz5iS1GkXpQ88TTzzhdm8PGjQoSS1FIvrv008/tWrVqtkxxxyTa/uPPvoo130gdftQ/39WqVLF3nrrLduyZYs7zZgxww488EB3O/jjv//9r5UrV84N1Tr88MP3uG2q5ZmySX/EEFu9erX7Wb9+/VzX16lTJ/t3kTSeKHrb8uXLW82aNW3VqlXF3Fokog8bNmzoTpEmT57s/rPWuCOkfh/Kt99+a1OnTrXXXnuNcX4B67+lS5dao0aNbPbs2e5vT/2nEHXTTTfl+qBF6vahPvdGjx5tI0eOtA4dOrhApG1feOGF7GIBkq9nz57uFItUyzO8axLIGzitDo1UoUKFfMdfavvobfe0PVKvD6Np3K3+Qx42bJgb94fU78Nt27a5/tKpSZMmSWsnEtN/qvJpnJ/2oAwdOtQef/xxK1u2rJ1//vnuICWkfh9mZma6AwDbtWvnxnc+++yztv/++9uVV17p+hepLy3F8gzhNoG8XdPRA+bVsZUqVcp3+/wG12v7ypUrF2NLkag+jPzPWQPu7777brviiiv2elQpUqcP1Wfa/XneeeclrY1IXP8pyCoAjR8/3rp27Wpt2rRx5+XNN99MUqtRlD589913XVFg7NixdsQRR7jd2RompAM8tTcFqa9iiuUZwm0CeSX5tWvX5rpel+vWrZtn+3r16uXZVm+OP/74w+2SQer3oWic5vDhw91/xjfffLM76hfB6UMdXf/ZZ5+5qpFOOspeTjvtNNenSP3/RxVwI4cg6INWQxWYzi0YfajxmvqCWbVq1ezratSo4a5TVR6pr16K5RnCbQK1aNHC/XHOnTs3+zodVLRgwYJ8x1/qOo0/ivzj/eKLL9xPfXtF6veh3HDDDfbee++5eTb79euXxNYiEX2osZrvvPOOO5hFJ1VyReM3qeYG4//R3bt323fffZd93fbt292cqgcccEDS2o34+1DBSJ+DkbuvNVxIX04YKhQMHVMsz3BAWQJpvIkmDx83bpwbb9mgQQO3m0V/uL169bL09HQ3B6qO7FVlQUcftm/f3k1Wrbng9MesAfVnnnlmgVVCpFYfam7NWbNmuYCrXWnr1q3Lvi9vG6R2H0YHIO+AF43508EQSO3+0wFIRx11lN14441ujmL1mRYPKFOmjJ1xxhl+P50SqbB9qM+8KVOmuL1e1157rbsPDfPSeM2zzz7b76eDfKR8nkn65GMht3v37swxY8ZkHnnkkW5uuAEDBmTPl6mfmgfu9ddfz97+999/z7zmmmvctp07d868/fbbM7dv3+7jM0Bh+vCSSy5xl/M7RfYzUvvvMNLnn3/OPLcB678///zT/d+p/0MPP/xw93f5448/+vgMUNg+1PyomlO1U6dO7jZXX301f4Mp5MYbb8w1z22q55lS+if5kRoAAABIPMbcAgAAIDQItwAAAAgNwi0AAABCg3ALAACA0CDcAgAAIDQItwAAAAgNwi0AAABCg3ALAD668MILrXnz5rlOWr5Uq/1odaYZM2YkvU1aeU/t0PKnXht1AoAgYPldAPBZq1at7Pbbb8+1tKWWAX7mmWfc0s5aUvbYY4/1tY0AEBSEWwDwWdWqVa1t27Z5rj/mmGOsS5curpJKuAWA2DAsAQBSVIUKFax8+fJWqlQpdzkjI8MmT55sJ5xwgh166KF24okn2vPPP5/ndm+99ZadddZZdvjhh1v37t3tgQcesJ07d2b//oMPPrDzzz/f2rVr5+7npJNOshdffDGpzw0AiguVWwDwWWZmpu3evTvXsITffvvNHnvsMdu6daudccYZ7vo77rjDVXEHDRrkgum8efPs3nvvtc2bN9tVV13ltlFIveuuu+yvf/2rDR061JYvX25jxoyxTZs2uev/8Y9/uG0vuugiu+aaa2z79u02bdo09zsFXQViAAgywi0A+EwhtXXr1rmuU7X2kEMOsYcffth69OhhS5cutVdeecUF1oEDB7ptunbt6rabNGmSq8TWqFHDBeLjjz/e7r777uz7SktLs7/97W+2a9cuW7Jkiavq3nrrrdm/V1Du3LmzzZ07l3ALIPAItwDgMwXbO++8051fu3atPfTQQy6I6udBBx3krv/8889dhbdnz565qry6/Pjjj9uXX35pBx54oK1fv94NW4h02WWXuZP079/f/VRFWIH5119/te+++85dFzl0AQCCinALAD6rUqWKHXbYYdmXVT09/fTT7dJLL3XDEGrVqmV//PGH+92pp56a732sWbPG9tlnH3d+3333LfCxNmzY4GZm0LhbVX0POOAA69Chg/udwjMABB3hFgBSzH777WcjR460a6+91u655x53QFj16tXd75599lkXhqPtv//+LriK99OzceNGW7BggRt+MGzYMPv555/dNGO6rAPWNGxBQx4AIAyYLQEAUpBmMOjWrZu988479sUXX2RXVxVUVeX1TgqyGperyq6GMKh6O2fOnFz3pYUgNE5XQx00fKFXr15ujK2CrXz88cfZszEAQNBRuQWAFHXLLbe44Qk6OOzNN99052+77TY3k4JmNtCY2fHjx1vDhg2tSZMmVqZMGTcDgmY+0NAEjcfVNhMmTLALLrjAHXDWpk0be/vtt90433r16tlXX33lphfTEAVVcAEg6Ai3AJCiVInVsrdTp061l156ye677z43M8L06dPdCmYKsKeccooNGTLEBVtRiK1cubJNmTLFXn75ZRdgBwwY4E4yevRoGzVqlDuJQrEOZps5c6bNnz/f1+cLAIlQKpMjCAAAABASjLkFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAChQbgFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAChQbgFAABAaBBuAQAAEBqEWwAAAIQG4RYAAAAWFv8PECYsLhYvYVsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printed in train is the: Mean of fold scores = average of each foldâ€™s PR-AUC (each fold weighted equally, regardless of size).\n",
    "\n",
    "# now is the: Global PR-AUC = one curve computed from all OOF predictions at once (folds weighted by number of samples).\n",
    "\n",
    "plot_pr_curve_from_oof(best_oof_preds, final_df['strat_return'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "630e4a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "def plot_shap_summary(best_model, X):\n",
    "    # Get SHAP values (pred_contrib=True gives SHAP + bias term as last column)\n",
    "    shap_values = best_model.predict(X, pred_contrib=True)\n",
    "    \n",
    "    # Remove bias term (last column)\n",
    "    shap_values = shap_values[:, :-1]\n",
    "    \n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Mean absolute SHAP value per feature\n",
    "    shap_importance = np.mean(np.abs(shap_values), axis=0)\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": feature_names,\n",
    "        \"mean_abs_shap\": shap_importance\n",
    "    }).sort_values(by=\"mean_abs_shap\", ascending=False)\n",
    "\n",
    "    # Plot bar chart\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(importance_df[\"feature\"], importance_df[\"mean_abs_shap\"], color=\"skyblue\")\n",
    "    plt.xlabel(\"Mean |Abs SHAP value|\")\n",
    "    plt.title(\"SHAP Feature Importance (LightGBM)\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.show()\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "shap_df = plot_shap_summary(best_model, final_df.drop(columns=\"strat_return\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887400c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bb8c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding or target encoding for categorical features (strategy, regime) \n",
    "# depending on your model or Embeddings (for deep learning).\n",
    "\n",
    "\n",
    "# Scale numeric features if needed (standard scaler or robust scaler). only for non-trees\n",
    "\n",
    "# Experiment with adding more features like volume weighted average price (VWAP), ATR, or more complex technical indicators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
