{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe8ab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get current working directory (where notebook is running)\n",
    "current_dir = os.getcwd()\n",
    "# Go up one level, then into utils\n",
    "utils_path = os.path.abspath(os.path.join(current_dir, '..', 'utils'))\n",
    "# Add to sys.path\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "from trend_regime_utils import load_trend_data, process_trend_data, create_advanced_feat, mayority_vote_cluster_smooth\n",
    "from bull_trend_regime_utils import load_bull_trend_data, create_advanced_bull_feat, merge_clean_final_clusters\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "import joblib\n",
    "\n",
    "# For API Keys\n",
    "from dotenv import load_dotenv\n",
    "# Alpaca API keys\n",
    "API_KEY = None\n",
    "SECRET_KEY = None\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if API_KEY is None:\n",
    "    API_KEY = os.environ.get('ALP_API_KEY')\n",
    "\n",
    "if SECRET_KEY is None:\n",
    "    SECRET_KEY = os.environ.get('ALP_SEC_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6032b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n",
      "c:\\Users\\sergi\\Documents\\TFG\\utils\\trend_regime_utils.py:96: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_feat = df_subset.groupby('symbol').apply(compute_trend_features)\n"
     ]
    }
   ],
   "source": [
    "EARLIEST_DATE = datetime(2016, 1, 16, tzinfo=ZoneInfo('America/New_York'))\n",
    "LAST_DATE = datetime(2025, 7, 20, tzinfo=ZoneInfo('America/New_York'))\n",
    "\n",
    "df_trend_raw = load_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE)\n",
    "\n",
    "df_trend_processed = process_trend_data(df_trend_raw)\n",
    "\n",
    "df_trend_feat = create_advanced_feat(df_trend_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7a72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the project root (one level up from current working directory)\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "MODEL_DIR = os.path.join(PROJECT_ROOT, 'models')\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "## If want to predict\n",
    "# Load models\n",
    "scaler = joblib.load(os.path.join(MODEL_DIR, \"trend_scaler.pkl\"))\n",
    "umap_model = joblib.load(os.path.join(MODEL_DIR, \"trend_umap_model.pkl\"))\n",
    "gmm_model = joblib.load(os.path.join(MODEL_DIR, \"trend_gmm_model.pkl\"))\n",
    "\n",
    "# scale data\n",
    "trend_scaled = scaler.transform(df_trend_feat)\n",
    "\n",
    "# Apply UMAP transformation\n",
    "trend_umap = umap_model.transform(trend_scaled)\n",
    "\n",
    "# Predict clusters\n",
    "trend_gmm_labels = gmm_model.predict(trend_umap)\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# print(silhouette_score(trend_umap, trend_gmm_labels))\n",
    "\n",
    "df_with_clusters = pd.DataFrame(trend_gmm_labels, columns=[\"cluster\"], index=df_trend_feat.index)\n",
    "\n",
    "df_cluster_smooth = mayority_vote_cluster_smooth(df_with_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e5115ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bull_raw = load_bull_trend_data(API_KEY, SECRET_KEY, EARLIEST_DATE, LAST_DATE)\n",
    "\n",
    "bull_features_df = create_advanced_bull_feat(df_bull_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d6abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only bull days \n",
    "bull_days = df_cluster_smooth[df_cluster_smooth==1]\n",
    "\n",
    "# Keep only rows in bull_features_df where the index exists in bull_days\n",
    "only_bull_features_df = bull_features_df[bull_features_df.index.isin(bull_days.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e874c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sergi\\Documents\\TFG\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## If want to predict\n",
    "# Load models\n",
    "bull_scaler = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_scaler.pkl\"))\n",
    "bull_umap_model = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_umap_model.pkl\"))\n",
    "spectral_model = joblib.load(os.path.join(MODEL_DIR, \"bull_trend_spectral_model.pkl\"))\n",
    "\n",
    "# scale data\n",
    "bull_trend_scaled = bull_scaler.transform(only_bull_features_df)\n",
    "\n",
    "# Apply UMAP transformation\n",
    "bull_trend_umap = bull_umap_model.transform(bull_trend_scaled)\n",
    "\n",
    "# Predict clusters, SpectralClustering doesnâ€™t have a .predict() method for unseen data.\n",
    "# Every time you call fit_predict(), it re-computes clusters from scratch, so for new data, you need to re-run it on all data (old + new)\n",
    "bull_trend_spectral_labels = spectral_model.fit_predict(bull_trend_umap)\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# print(silhouette_score(bull_trend_umap, bull_trend_spectral_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11edb463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "final_cluster\n",
       "1                0.251719\n",
       "0                0.240257\n",
       "2                0.187987\n",
       "3                0.175608\n",
       "4                0.144429\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute final clusters\n",
    "df_final_clusters = merge_clean_final_clusters(bull_trend_spectral_labels, only_bull_features_df, df_with_clusters)\n",
    "\n",
    "df_final_clusters.value_counts(normalize=True, dropna=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
